<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bayesian statistics on Andrea Gabrio</title>
    <link>/tags/bayesian-statistics/</link>
    <description>Recent content in Bayesian statistics on Andrea Gabrio</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>`{year}`</copyright>
    <lastBuildDate>Tue, 07 Jul 2020 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="/tags/bayesian-statistics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Why be Bayesian?</title>
      <link>/post/update-july/</link>
      <pubDate>Tue, 07 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/update-july/</guid>
      <description>


&lt;p&gt;Many times I have been asked by co-workers and people around me who are a bit familiar with statistics why I choose to be Bayesian and whether I feel confident in using this approach for my data analysis rather than the most widely accepted frequentist methods, at least in my research area. Well, I am sure there are many valid arguments I could use to reply to this question but if I have to summarise my answer in two words I would say: &lt;strong&gt;why not&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;Now, a bit more into the details for those who were not extremely annoyed by my previous sentence. So, I truly believe that the Bayesian approach can be considered as a complement rather than a substitute to the frequentist paradigm. The main reason is relate to its much stronger links with probability theory compared with the classical approach in that not only are sampling distributions required for summaries of data, but also a wide range of distributions are used to represent prior opinion about proportions, event rates, and other unknown quantities. In a nutshell, the key difference between the two approaches is how they confront the concept of &lt;strong&gt;probability&lt;/strong&gt; of a certain event. In fact, although there is general consensus about the &lt;em&gt;rules&lt;/em&gt; of probability, that there is no universal &lt;em&gt;concept&lt;/em&gt; of probability, and two quite different definitions come from the frequentist and Bayesian approach:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The most widely known definition is: the proportion of times a will occur in an infinitely long series of repeated identical situations. This is known as the &lt;strong&gt;frequentist&lt;/strong&gt; perspective, as it rests on the &lt;em&gt;frequency&lt;/em&gt; with which specific events occur.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In contrast, the &lt;strong&gt;Bayesian&lt;/strong&gt; approach rests on an essentially subjective interpretation of probability, which is allowed to express generic uncertainty or &lt;em&gt;degree of belief&lt;/em&gt; about any unknown but potentially observable quantity, whether or not it is one of a number of repeatable experiments.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Rather than debating on philosophical debates about the foundations of statistics I prefer to focus on those aspects which I believe make the Bayesian approach, if not more intuitive than the frequentist counterpart, at least more attractive. Be worn I am not trying to start a war as I think both approaches could be used without the need to completely discard the other. The simple fact of being able to choose between two methods, rather than restricting themselves to a single option, seems a good enough reason for me to advocate the use of &lt;strong&gt;both&lt;/strong&gt; approaches. I terms of your own knowledge, experience and skills, You do not gain anything by saying “I will never be Bayesian” or “I will never be a frequentist”. On the contrary, by opening your mind and explore the use of one or the other method you will be able to have more options at your disposal that you can use to tackle the different problems you will face in your analyses.&lt;/p&gt;
&lt;p&gt;For the purpose of this post I just want to highlight some aspects which make the Bayesian approach particularly useful and, in some cases, even arguably preferable than the frequentist approach. Note that I am well aware there could be cases where the opposite holds and this is precisely why I believe it is important that statisticians should become familiar with both methods. By doing so they will be able to overcome the limitations/concerns associated with one method for a specific problem at hand using the instruments made available from the other method. Since I am a Bayesian, here I want to report the reasons and situations in which the Bayesian approach could provide a powerful tool.&lt;/p&gt;
&lt;p&gt;Let us start with a quick recap of the basic principle behind Bayesian methods. Bayesian statistical analysis relies on &lt;strong&gt;Bayes’s Theorem&lt;/strong&gt;, which tells us how to update prior
beliefs about parameters and hypotheses in light of data, to yield posterior beliefs. The theorem itself is utterly uncontroversial and follows directly from the conventional definition of conditional probability. If &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; is some object of interest, but subject to uncertainty, e.g. a parameter, a hypothesis, a model, a data point, then Bayes Theorem tells us how to rationally
revise prior beliefs about &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(p(\theta)\)&lt;/span&gt;, in light of the data &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, to yield posterior beliefs &lt;span class=&#34;math inline&#34;&gt;\(p(y \mid \theta)\)&lt;/span&gt;. In this way Bayes Theorem provides a solution to the general problem of &lt;em&gt;induction&lt;/em&gt;, while in the specific case of statistical inference, Bayes Theorem provides a solution to problem of &lt;em&gt;how to learn from data&lt;/em&gt;. Thus, in a general sense, Bayesian statistical analysis is remarkably simple and even elegant, relying on this same simple recipe in each and every application.&lt;/p&gt;
&lt;p&gt;As I see it, there are a few major reasons why statisticians should consider learning about the Bayesian approach to statistical inference, and in the social sciences in particular:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Bayesian inference is simple and direct&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The result of a Bayesian analysis is a posterior probability statement, ‘posterior’ in the literal sense, in that such a statement characterizes beliefs after looking at data. Examples include: the posterior probability that a regression coefficient is positive, negative or lies in a particular interval; the posterior probability that a subject belongs to a particular latent class; the posterior probabilities that a particular statistical model is true model among a
family of statistical models.&lt;/p&gt;
&lt;p&gt;Note that the posterior probability statements produced by a Bayesian analysis are probability
statements over the quantities or objects of direct substantive interest to the researcher (e.g. parameters, hypotheses, models, predictions from models). Bayesian procedures condition on the data at hand to produce posterior probability statements about parameters and hypotheses. Frequentist procedures do just the reverse: one conditions on a null hypothesis to assess the plausibility of the data one observes (and more ‘extreme’ data sets that one did not observe but we might have had we done additional sampling), with another step of reasoning required to either reject or fail to reject the null hypothesis. Thus, compared to frequentist procedures, Bayesian procedures are simple and straightforward, at least conceptually.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Hierarchical modeling&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The prior density also provides a way for model expansion when we work with data sets that pool data over multiple units and/or time periods. Data sets of this sort abound in the social sciences. Individuals live in different locations, with environmental factors that are constant for anyone within that location, but vary across locations. key question in research of this type is how the causal structure that operates at one level of analysis (e.g. individuals) varies across a ‘higher’ level of analysis (e.g. localities or time periods). The Bayesian approach to statistical inference is extremely well-suited to answering this question. Recall that in the Bayesian approach parameters are always random variables, typically (and most basically) in the sense that the researcher is unsure as to their value, but can characterize that uncertainty in the form of a prior density &lt;span class=&#34;math inline&#34;&gt;\(p(\theta)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We can replace the prior with a stochastic model formalizing the researcher’s assumptions about the way that parameters &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; might vary across groups &lt;span class=&#34;math inline&#34;&gt;\(j = 1,..., J\)&lt;/span&gt; , perhaps as a function of observable characteristics of the groups; e.g., &lt;span class=&#34;math inline&#34;&gt;\(\theta_j \sim f (z_j, \gamma )\)&lt;/span&gt;, where now &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is a set of unknown hyperparameters. That is, the model is now comprised of a nested hierarchy of stochastic relations: the data from unit &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(y_j\)&lt;/span&gt;, are modeled as a function of covariates and parameters &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; , while cross-unit heterogeneity in the &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; is modeled as function of unit-specific covariates &lt;span class=&#34;math inline&#34;&gt;\(z_j\)&lt;/span&gt; and hyperparameters &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt;. Models of this sort are known to Bayesians as &lt;em&gt;hierarchical models&lt;/em&gt;, but go by many different names in different parts of the social sciences depending on the specific form of the model and the estimation strategy being used (e.g. ‘random’ or ‘varying’ coefficients models, ‘multilevel’ or ‘mixed’ models). Compared with the frequentist counterpart, thanks to the use of &lt;em&gt;Markov chain Monte Carlo&lt;/em&gt; (MCMC) methods, Bayesian computation for these models has also become rather simple. Indeed, MCMC algorithms have proven themselves amazingly powerful and flexible, and have brought wide classes of models and data sets out of the ‘too hard’ basket. Other modelling examples include data sets with lots of missing data, or models with lots of parameters, model with latent variables, mixture
models, and flexible semi-and non-parametric models.&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Statistically significant?&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Frequentist inference asks assuming hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; is true, how often would we obtain a result at least as extreme as the result actually obtained?’, where ‘extreme’ is relative to the hypothesis being tested. If results such as the one obtained are sufficiently rare under hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; (e.g. generate a sufficiently small p value), then we conclude that &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; is incorrect, rejecting it in favor of some alternative hypothesis. Indeed, we teach our students to say that when the preceding conditions hold, we have a &lt;em&gt;statistically significant&lt;/em&gt; result. My experience is that in substituting this phrase for the much longer textbook definition, people quickly forget the frequentist underpinnings of what it is they are really asserting, and, hence seldom question whether the appeal to the long-run, repeated sampling properties of a statistical procedure is logical or realistic.&lt;/p&gt;
&lt;p&gt;In the Bayesian approach we condition on the data at hand to assess the plausibility of a hypothesis (via Bayes Rule), while the frequentist approach conditions on a hypothesis to assess the plausibility of the data (or more extreme data sets), with another step of reasoning required to either reject or fail to reject hypotheses. The frequentist p-value is the relative frequency of obtaining a result at least as extreme as the result actually obtained, assuming hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; to be true, where the sampling distribution of the result tells us how to assess relative frequencies of possible different results, under &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;. But what about cases where repeated sampling makes no sense, even as a thought experiment?&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Intervals&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Recall that in the frequentist approach, parameters are fixed characteristics of populations, so &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; either lies in the interval or it doesn’t. The correct interpretation of a frequentist confidence interval concerns the repeated sampling characteristics of a sample statistic. In the case of a &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; confidence interval, the correct frequentist interpretation is that &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; of the &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; confidence intervals one would draw in repeated samples will include &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;. Now, is the &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; confidence interval that one constructs from the data set at hand one of the lucky &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; that actually contains &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, or not? No ones knows.&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Rational subjectivity&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Finally, aside from acknowledging the subjectivity inherent to the general scientific exercise, the Bayesian approach rests on a subjective notion of probability, but demands that subjective
beliefs conform to the laws of probability. Put differently, in the Bayesian approach, the subjectivity of scientists is acknowledged, but simultaneously insists that subjectivity be
rational, in the sense that when confronted with evidence, subjective beliefs are updated rationally, in accord with the axioms of probability. Again, it is in this sense that Bayesian procedures offer a more direct path to inference; as I put it earlier, the Bayesian approach lets researchers mean what they say and say what they mean. For instance, the statement, having looked at the data, I am &lt;span class=&#34;math inline&#34;&gt;\(95\%\)&lt;/span&gt; sure that &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is included in an interval is a natural product of a Bayesian analysis, a characterization of the researcher’s beliefs about a parameter in formal, probabilistic terms, rather than a statement about the repeated sampling properties of a statistical procedure.&lt;/p&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;The mathematics and computation underlying Bayesian analysis has been dramatically simplified
via a suite of MCMC algorithms. The combination of the popularization of MCMC and vast
increases in the computing power available to social scientists means that Bayesian analysis
is now well and truly part of the mainstream of quantitative social science. Despite these important pragmatic reasons for adopting the Bayesian approach, it is important to remember that MCMC algorithms are Bayesian algorithms: they are tools that simplify the computation of posterior densities. So, before we can fully and sensibly exploit the power of MCMC algorithms, it is important that we understand the foundations of Bayesian inference.&lt;/p&gt;
&lt;p&gt;This time I went overboard with the discussion but I thought it could be interesting to clarify here the key points, in my opinion, which make the Bayesian approach not only valid and efficient, but even a powerful tool that, once grasped the underlying phylosophy, can be used to overcome the difficulties of standard methods, especially when dealing with complex analyses.&lt;/p&gt;
&lt;p&gt;So what are you waiting for? do not sit in your frequentist comfort zone but expand your statistical knowledge! Evolve!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/u1k1kpDZSw5sA/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian methods for addressing missing data in health economic evaluations</title>
      <link>/talk/albacete2019/</link>
      <pubDate>Tue, 11 Jun 2019 10:00:00 +0000</pubDate>
      
      <guid>/talk/albacete2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Bayesian Parametric Approach to Handle Missing Longitudinal Outcome Data in Trial-Based Health Economic Evaluations</title>
      <link>/publication/gabrio2019c/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/gabrio2019c/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bayesian Statistical Economic Evaluation Methods for Health Technology Assessment</title>
      <link>/publication/gabrio2019b/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/gabrio2019b/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Full Bayesian Model to Handle Structural Ones and Missingness in Economic Evaluations from Individual-Level Data</title>
      <link>/publication/gabrio2019a/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/gabrio2019a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Full Bayesian Model to Handle Structural Ones and Missingness in Health Economic Evaluations from Individual-Level Data</title>
      <link>/talk/hesymposium2018/</link>
      <pubDate>Mon, 05 Feb 2018 10:00:00 +0000</pubDate>
      
      <guid>/talk/hesymposium2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>missingHE</title>
      <link>/missinghe/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/missinghe/</guid>
      <description>&lt;p&gt;&lt;code&gt;missingHE&lt;/code&gt; is a &lt;code&gt;R&lt;/code&gt; package aimed at providing some useful tools to analysts in order to handle missing outcome data under a Full Bayesian framework in economic evaluations. The package relies on the &lt;code&gt;R&lt;/code&gt; package &lt;code&gt;R2jags&lt;/code&gt; to implement Bayesian methods via the statistical software &lt;code&gt;JAGS&lt;/code&gt;. The package allows to obtain inferences using Markov Chain Monte Carlo (MCMC) methods under a range of modelling approaches and missing data assumptions. The package also contains functions specifically defined to assess model fit and possible issues in model convergence as well as to summarise the main results from the economic analysis.&lt;/p&gt;
&lt;p&gt;Missing data are iteratively imputed using data augmentation methods according to the type of model, distribution and missingness assumptions specified by the user using different arguments in the functions of the package. The posterior distribution of the main quantities of interest (e.g. some suitable measures of costs and clinical benefits) is then summarised to assess the cost-effectiveness of a new intervention ($t=2$) against a standard intervention ($t=1$).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;missingHE&lt;/code&gt; produces plots which compares the observed and imputed values for both cost and benefit measures in each treatment intervention considered to detect possible concerns about the plausibility of the imputation methods. In addition, the output of &lt;code&gt;missingHE&lt;/code&gt; cab be analysed using different funtions in the &lt;code&gt;R&lt;/code&gt; package &lt;code&gt;BCEA&lt;/code&gt; which produces a synthesis of the decision process given the current evidence and uncertainty, as well as several indicators that can be used to perform Probabilistic Sensitivity Analysis to parameter and model uncertainty.&lt;/p&gt;



  




&lt;figure&gt;

&lt;img src=&#34;/img/imputed.jpg&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Example of a graphical output from missingHE&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;h1 id=&#34;example&#34;&gt;Example&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;library&lt;/span&gt;(missingHE)
model.sel &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;selection&lt;/span&gt;(data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MenSS, model.eff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; e &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; u.0, model.cost &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; e, model.me &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; me &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, model.mc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mc &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, 
                       type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MAR&amp;#34;&lt;/span&gt;, n.chains &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, n.iter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;, n.burnin &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, dist_e &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;norm&amp;#34;&lt;/span&gt;, dist_c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;norm&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;summary&lt;/span&gt;(model.sel)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt; Cost&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;effectiveness analysis summary 
 
 Comparator intervention&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; intervention &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; 
 Reference intervention&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; intervention &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; 
 
 Parameter estimates under MAR assumption
 
 Comparator intervention 
               mean     sd      LB      UB
mean.effects  &lt;span style=&#34;color:#ae81ff&#34;&gt;0.874&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0.017&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;0.846&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;0.901&lt;/span&gt;
mean.costs   &lt;span style=&#34;color:#ae81ff&#34;&gt;238.34&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;52.432&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;153.541&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;325.355&lt;/span&gt;

 Reference intervention 
                  mean    sd      LB      UB
mean.effects.1   &lt;span style=&#34;color:#ae81ff&#34;&gt;0.917&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.022&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;0.881&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;0.953&lt;/span&gt;
mean.costs.1   &lt;span style=&#34;color:#ae81ff&#34;&gt;186.825&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;41.26&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;119.672&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;254.125&lt;/span&gt;

 Incremental results 
                   mean     sd       LB     UB
delta.effects     &lt;span style=&#34;color:#ae81ff&#34;&gt;0.043&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0.028&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;-0.003&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;0.089&lt;/span&gt;
delta.costs     &lt;span style=&#34;color:#ae81ff&#34;&gt;-51.514&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67.025&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;-162.862&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;58.327&lt;/span&gt;
ICER          &lt;span style=&#34;color:#ae81ff&#34;&gt;-1198.431&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;news-and-updates-about-missinghe&#34;&gt;News and updates about &lt;code&gt;missingHE&lt;/code&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;From 25/09/2019, the updated version (1.2.1) of &lt;code&gt;missingHE&lt;/code&gt; has become available on &lt;a href=&#34;https://cran.r-project.org/web/packages/missingHE/&#34;&gt;CRAN&lt;/a&gt;, which allows to perform posterior predictive checks for each type of model as a further way to assess the fit of the model to the observed data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The checks can be done by first setting the optional argument &lt;code&gt;ppc = TRUE&lt;/code&gt; when fitting the model using one of the main function of the package. For example, when using &lt;code&gt;selection&lt;/code&gt; to fit selection models you would have something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;model.sel &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;selection&lt;/span&gt;(data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data, model.eff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; e &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; age, model.cost &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; age &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; e, model.me &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; me &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; age, model.mc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mc &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; age, 
dist_e &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;norm&amp;#34;&lt;/span&gt;, dist_c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;gamma&amp;#34;&lt;/span&gt;, type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MAR&amp;#34;&lt;/span&gt;, n.iter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;, ppc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TRUE&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then you can use the function &lt;code&gt;ppc&lt;/code&gt; to perform different types of posterior predictive checks that you can choose among a set of pre-specified types using the &lt;code&gt;type&lt;/code&gt; argument. For example, if we want to compare histograms of the empirical and predictive distributions of the effectiveness variable in one arm (e.g. control), then we can type&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;ppc&lt;/span&gt;(model.sel, type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;histogram&amp;#34;&lt;/span&gt;, outcome &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;effects_arm1&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and we get something like this&lt;/p&gt;



  




&lt;figure&gt;

&lt;img src=&#34;/img/plotpred.png&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Example of posterior predictive checks in missingHE&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;From 07/01/2020, the updated version (1.3.2) of &lt;code&gt;missingHE&lt;/code&gt; has become available on &lt;a href=&#34;https://cran.r-project.org/web/packages/missingHE/&#34;&gt;CRAN&lt;/a&gt;, which allows to choose among more distributions for the effectiveness measures, including continuous (Gamma, Weibull, Exponential, Logistic), discrete (Poisson, Negative Binomial) and binary (Bernoulli) health outcomes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, we can choose to specify a selection model assuming a Bernoulli distribution for the effects (if this is a binary outcome) and a LogNormak distribution for the costs&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;model.sel &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;selection&lt;/span&gt;(data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data, model.eff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; e &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; age, model.cost &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; age &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; e, model.me &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; me &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, model.mc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mc &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, 
dist_e &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bern&amp;#34;&lt;/span&gt;, dist_c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;lnorm&amp;#34;&lt;/span&gt;, type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MAR&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;From 30/04/2020, the updated version (1.4.0) of &lt;code&gt;missingHE&lt;/code&gt; has become available on &lt;a href=&#34;https://cran.r-project.org/web/packages/missingHE/&#34;&gt;CRAN&lt;/a&gt;, which allows to perform fit random effects for each type of model implemented. The random terms can be specified using the following notation&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;model.sel &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;selection&lt;/span&gt;(data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data, model.eff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; e &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; age &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (age &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; site), model.cost &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; age &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; e &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (age &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; e &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; site), 
model.me &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; me &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; age &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; site), model.mc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mc &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; age &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; age &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; site), 
dist_e &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;norm&amp;#34;&lt;/span&gt;, dist_c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;gamma&amp;#34;&lt;/span&gt;, type &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MAR&amp;#34;&lt;/span&gt;, n.iter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;, ppc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TRUE&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I borrowed this notation, alongside with a couple of internal functions, from the &lt;code&gt;lme4&lt;/code&gt; package. The terms inside the brackets on the left of the bar are the terms for which the random effects are assumed (these must also be included as fixed effects). The term on the right of the bar is the clustering variable over which the random effects are specified.&lt;/p&gt;
&lt;p&gt;For example the formula &lt;code&gt; + (age | site)&lt;/code&gt; specifies random effects for the intercept and &lt;code&gt;age&lt;/code&gt; across the values of the &lt;code&gt;site&lt;/code&gt; variable. It aslo possible to specify random slope only models (i.e. remove the random intercept) by adding the term &lt;code&gt;0 +&lt;/code&gt; inside the brackets on the left of the bar.&lt;/p&gt;
&lt;p&gt;All functions in the package have been updated to take into account the possibility that random effects are specified and to perform diagnostic and posterior predictive checks based on the random effects if these are included. In addition, a new generic function called &lt;code&gt;coef&lt;/code&gt; is now available to extract the fixed or random effect terms from the effectiveness and cost models for each type of model in &lt;code&gt;missingHE&lt;/code&gt;. For example, we can extract summary statistics for the fixed effects from the fitted selection model by using the command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;coef&lt;/span&gt;(model.sel, random &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FALSE&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;which prints something like this&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Comparator
&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Comparator&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Effects
              mean    sd  lower  &lt;span style=&#34;color:#a6e22e&#34;&gt;upper
&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;&lt;/span&gt;(Intercept)  &lt;span style=&#34;color:#ae81ff&#34;&gt;4.520&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2.128&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;1.694&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;7.584&lt;/span&gt;
age         &lt;span style=&#34;color:#ae81ff&#34;&gt;-0.059&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.011&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;-0.081&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;-0.037&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Comparator&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Costs
                mean      sd     lower    &lt;span style=&#34;color:#a6e22e&#34;&gt;upper
&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;&lt;/span&gt;(Intercept)  &lt;span style=&#34;color:#ae81ff&#34;&gt;553.614&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;576.375&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;-412.631&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2118.222&lt;/span&gt;
age           &lt;span style=&#34;color:#ae81ff&#34;&gt;-9.534&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;32.682&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;-75.701&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;50.304&lt;/span&gt;
e           &lt;span style=&#34;color:#ae81ff&#34;&gt;-934.280&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;428.726&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;-1749.524&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;-85.378&lt;/span&gt;


&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Reference
&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Reference&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Effects
              mean    sd  lower &lt;span style=&#34;color:#a6e22e&#34;&gt;upper
&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;&lt;/span&gt;(Intercept) &lt;span style=&#34;color:#ae81ff&#34;&gt;-1.294&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2.381&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;-4.411&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2.091&lt;/span&gt;
age          &lt;span style=&#34;color:#ae81ff&#34;&gt;0.032&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.100&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;-0.094&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.155&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Reference&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Costs
                mean      sd     lower    &lt;span style=&#34;color:#a6e22e&#34;&gt;upper
&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;&lt;/span&gt;(Intercept)  &lt;span style=&#34;color:#ae81ff&#34;&gt;273.504&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;387.796&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;-349.418&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1047.288&lt;/span&gt;
age           &lt;span style=&#34;color:#ae81ff&#34;&gt;-9.138&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;36.223&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;-78.510&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;56.514&lt;/span&gt;
e           &lt;span style=&#34;color:#ae81ff&#34;&gt;-264.332&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;421.044&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;-1094.129&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;571.148&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we set &lt;code&gt;random = TRUE&lt;/code&gt;, then summary statistics for the random effects terms are printed.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;From 10/06/2020 a new version (1.4.1) of &lt;code&gt;missingHE&lt;/code&gt; is available to download from my &lt;a href=&#34;https://github.com/AnGabrio/missingHE&#34;&gt;GitHub&lt;/a&gt; page, which includes three vignettes providing some tutorials on how to use the functions of the package. Each vignette is specifically designed to help different types of users:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The first vignette is named &lt;em&gt;Introduction_to_missingHE&lt;/em&gt; and is designed to provide some introductory summary about the use of the functions of the package based on the default settings, what the user needs to specify and how to interpret and extract the results. See the &lt;a href=&#34;/files/Introduction_to_missingHE.pdf&#34; target=&#34;_blank&#34;&gt; pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second vignette is named &lt;em&gt;Fitting_MNAR_models_in_missingHE&lt;/em&gt; and is deisgned to help those who would like to explore MNAR assumptions and how this can be done within each main function of the package. See the &lt;a href=&#34;/files/Fitting_MNAR_models_in_missingHE.pdf&#34; target=&#34;_blank&#34;&gt; pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The third vinette is named &lt;em&gt;Model_customisation_in_missingHE&lt;/em&gt; and is designed for those who are already familiar with the package but who would like to customise the functions in a more flexile way, for example by including random effects, using different priors or modelling assumptions. See  the &lt;a href=&#34;/files/Model_customisation_in_missingHE.pdf&#34; target=&#34;_blank&#34;&gt; pdf&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Soon, this version will also be uploaded on CRAN as well. In the meantime, the pdf files of these vignettes can be accessed from my website.&lt;/p&gt;
&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;
&lt;p&gt;There are two ways of installing &lt;code&gt;missingHE&lt;/code&gt;. A &lt;em&gt;stable&lt;/em&gt; version (currently 1.4.0) is packaged and available from &lt;a href=&#34;https://cran.r-project.org/web/packages/missingHE/&#34;&gt;CRAN&lt;/a&gt;. You can simply type on your &lt;code&gt;R&lt;/code&gt; terminal&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;install.packages&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;missingHE&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The second way involves using the &lt;em&gt;development&lt;/em&gt; version of &lt;code&gt;missingHE&lt;/code&gt;, which is available from &lt;a href=&#34;https://github.com/AnGabrio/missingHE&#34;&gt;GitHub&lt;/a&gt; - this will usually be updated more frequently and may be continuously tested. On Windows machines, you need to install a few dependencies, including Rtools first, e.g. by running&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;pkgs &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;R2jags&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ggplot2&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;gridExtra&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;BCEA&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ggmcmc&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;loo&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Rtools&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;devtools&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;utils&amp;#34;&lt;/span&gt;)
repos &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://cran.rstudio.com&amp;#34;&lt;/span&gt;) 
&lt;span style=&#34;color:#a6e22e&#34;&gt;install.packages&lt;/span&gt;(pkgs,repos&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;repos,dependencies &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Depends&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;before installing the package using &lt;code&gt;devtools&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;devtools&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;install_github&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;AnGabrio/missingHE&amp;#34;&lt;/span&gt;, build_vignettes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TRUE&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The optional argument &lt;code&gt;build_vignettes = TRUE&lt;/code&gt; allows to install the vignettes of the package locally on your computer. These consist in brief tutorials to guid the user on how to use and customise the models in missingHE using different functions of the package. Once the package is installed, they can be accessed by using the command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;browseVignettes&lt;/span&gt;(package &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;missingHE&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;All models implemented in missingHE are written in the &lt;code&gt;BUGS&lt;/code&gt; language using the software &lt;code&gt;JAGS&lt;/code&gt;, which needs to be installed from its own repository and instructions for installations under different OS can be found online. Once installed, the software is called in missingHE via the &lt;code&gt;R&lt;/code&gt; package &lt;code&gt;R2jags&lt;/code&gt;. Note that the missingHE package is currently under active development and therefore it is advisable to reinstall the package directly from &lt;a href=&#34;https://github.com/AnGabrio/missingHE&#34;&gt;GitHub&lt;/a&gt; before each use to ensure that you are using the most updated version.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
