<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Andrea Gabrio</title>
    <link>/authors/andrea-gabrio/</link>
    <description>Recent content on Andrea Gabrio</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Feb 2020 21:13:14 -0500</lastBuildDate>
    
	    <atom:link href="/authors/andrea-gabrio/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Factorial Analysis of Variance - JAGS</title>
      <link>/jags/factorial-anova-jags/factorial-anova-jags/</link>
      <pubDate>Thu, 06 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/factorial-anova-jags/factorial-anova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Factorial designs are an extension of single factor ANOVA designs in which additional factors are added such that each level of one factor is applied to all levels of the other factor(s) and these combinations are replicated. For example, we might design an experiment in which the effects of temperature (high vs low) and fertiliser (added vs not added) on the growth rate of seedlings are investigated by growing seedlings under the different temperature and fertilizer combinations. In addition to investigating the impacts of the main factors, factorial designs allow us to investigate whether the effects of one factor are consistent across levels of another factor. For example, is the effect of temperature on growth rate the same for both fertilised and unfertilized seedlings and similarly, does the impact of fertiliser treatment depend on the temperature under which the seedlings are grown?&lt;/p&gt;
&lt;p&gt;Arguably, these interactions give more sophisticated insights into the dynamics of the system we are investigating. Hence, we could add additional main effects, such as soil pH, amount of water, etc, along with all the two way (temp:fert, temp:pH, temp:water, etc), three-way (temp:fert:pH, temp:pH:water), four-way (and so on) interactions in order to explore how these various factors interact with one another to effect the response. However, the more interactions, the more complex the model becomes to specify, compute and interpret - not to mention the rate at which the number of required observations increases. Factorial designs can consist:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;entirely of crossed fixed factors (&lt;strong&gt;Model I ANOVA&lt;/strong&gt; - most common) in which conclusions are restricted to the specific combinations of levels selected for the experiment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;entirely of crossed random factors (&lt;strong&gt;Model II ANOVA&lt;/strong&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;a mixture of crossed fixed and random factors (&lt;strong&gt;Model III ANOVA&lt;/strong&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The latter are useful for investigating the generality of a main treatment effect (fixed) over broad spatial, temporal or clinical levels of organisation. That is whether the observed effects of temperature and/or fertiliser (for example) are observed across the entire genera or country.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear model&lt;/h2&gt;
&lt;p&gt;As with single factor ANOVA, the linear model could be constructed as either effects or means parameterisation, although only effects parameterisation will be considered here. The linear models for two and three factor design are&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \epsilon_{ijk},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_j + \gamma_k + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \epsilon_{ijkl},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the effect of Factor A, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of Factor B, &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the effect of Factor C and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component. Note that although the linear models for Model I, Model II and Model III designs are identical, the interpretation of terms (and thus null hypothesis) differ. Recall from the tutorial on single factor ANOVA, that categorical variables in linear models are actually re-parameterised dummy codes - and thus the &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; term above, actually represents one or more dummy codes. Thus, if we actually had two levels of Factor A (A1 and A2) and three levels of Factor B (B1, B2, B3), then the fully parameterised linear model would be:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y=\beta_{A1B1}+\beta_{A2B1−A1B1}+\beta_{A1B2−A1B1}+\beta_{A1B3−A1B1}+\beta_{A2B2−A1B2−A2B1−A1B1}+\beta_{A2B3−A1B3−A2B1−A1B1}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thus, such a model would have six parameters to estimate (in addition to the variance).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis&lt;/h2&gt;
&lt;p&gt;There are separate null hypothesis associated with each of the main effects and the interaction terms.&lt;/p&gt;
&lt;div id=&#34;model-1---fixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 1 - fixed effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Factor A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to an overall mean. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the overall mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The effect of each group equals zero. If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), the null hypothesis is rejected indicating that the treatment has been found to affect the response variable. Note, as with multiple regression models, these “effects” represent &lt;em&gt;partial effects&lt;/em&gt;. In the above, the effect of Factor A is actually the effect of Factor A at the first level of the Factor(s).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal - at the first level of Factor A. Equivalent interpretation to Factor A above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\mu_{ij}=\mu_i+\mu_j-\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. For any given combination of factor levels, the population group mean will be equal to the difference between the overall population mean and the simple additive effects of the individual factor group means. That is, the effects of the main treatment factors are purely additive and independent of one another. This is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(H_0(AB): \alpha\beta_{ij}=0\)&lt;/span&gt;, no interaction between Factor A and Factor B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-2---random-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 2 - random effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Factor A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\sigma^2_{\alpha}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of A.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\sigma^2_{\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of B.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\sigma^2_{\alpha\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is no added variance due to all possible interactions between all possible levels of A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-3---mixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 3 - mixed effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Fixed factor - e.g. A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (pooled over all levels of the random factor) is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to an overall mean pooling over all possible levels of the random factor. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the overall mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;No effect of any level of this factor pooled over all possible levels of the random factor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Random factor - e.g. B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\sigma^2_{\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of B.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The interaction of a fixed and random factor is always considered a random factor.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\sigma^2_{\alpha\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible interactions between all possible levels of A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;When fixed factorial designs are balanced, the total variance in the response variable can be sequentially partitioned into what is explained by each of the model terms (factors and their interactions) and what is left unexplained. For each of the specific null hypotheses, the overall unexplained variability is used as the denominator in F-ratio calculations, and when a null hypothesis is true, an F-ratio should follow an F distribution with an expected value less than &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;. Random factors are added to provide greater generality of conclusions. That is, to enable us to make conclusions about the effect of one factor (such as whether or not fertiliser is added) over all possible levels (not just those sampled) of a random factor (such as all possible locations, seasons, varieties, etc). In order to expand our conclusions beyond the specific levels used in the design, the hypothesis tests (and thus F-ratios) must reflect this extra generality by being more conservative.&lt;/p&gt;
&lt;p&gt;The appropriate F-ratios for fixed, random and mixed factorial designs are presented below. Generally, once the terms (factors and interactions) have been ordered into a hierarchy (single factors at the top, highest level interactions at the bottom and terms of same order given equivalent positions in the hierarchy), the denominator for any term is selected as the next appropriate random term (an interaction that includes the term to be tested) encountered lower in the hierarchy. Interaction terms that contain one or more random factors are considered themselves to be random terms, as is the overall residual term (as all observations are assumed to be random representations of the entire population(s)). Note, when designs include a mixture of fixed and random crossed effects, exact denominator degrees of freedoms for certain F-ratios are undefined and traditional approaches adopt rather inexact estimated approximate or “Quasi” F-ratios. Pooling of non-significant F-ratio denominator terms, in which lower random terms are added to the denominator (provided &lt;span class=&#34;math inline&#34;&gt;\(\alpha &amp;gt; 0.25\)&lt;/span&gt;), may also be useful. For random factors within mixed models, selecting F-ratio denominators that are appropriate for the intended hypothesis tests is a particularly complex and controversial issue. Traditionally, there are two alternative approaches and whilst the statistical resumes of each are complicated, essentially they differ in whether or not the interaction term is constrained for the test of the random factor.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;constrained or restricted method&lt;/em&gt; (&lt;strong&gt;Model I&lt;/strong&gt;), stipulates that for the calculation of a random factor F-ratio (which investigates the added variance added due to the random factor), the overall effect of the interaction is treated as zero. Consequently, the random factor is tested against the residual term. The &lt;em&gt;unconstrained or unrestrained method&lt;/em&gt; (&lt;strong&gt;Model II&lt;/strong&gt;) however, does not set the interaction effect to zero and therefore the interaction term is used as the random factor F-ratio denominator. This method assumes that the interaction terms for each level of the random factor are completely independent (correlations between the fixed factor must be consistent across all levels of the random factor). Some statisticians maintain that the independence of the interaction term is difficult to assess for clinical data and therefore, the restricted approach is more appropriate. However, others have suggested that the restricted method is only appropriate for balanced designs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quasi-f-ratios&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quasi F-ratios&lt;/h2&gt;
&lt;p&gt;An additional complication for three or more factor models that contain two or more random factors, is that there may not be a single appropriate interaction term to use as the denominator for many of the main effects F-ratios. For example, if Factors A and B are random and C is fixed, then there are two random interaction terms of equivalent level under Factor C (&lt;span class=&#34;math inline&#34;&gt;\(A^\prime \times C\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B^\prime \times C\)&lt;/span&gt;). As a result, the value of the of the &lt;em&gt;Mean Squares&lt;/em&gt; (MS) expected when the null hypothesis is true cannot be easily defined. The solutions for dealing with such situations (&lt;em&gt;quasi F-ratios&lt;/em&gt;) involve adding (and subtracting) terms together to create approximate estimates of F-ratio denominators. Alternatively, for random factors, variance components with confidence intervals can be used. These solutions are sufficiently unsatisfying as to lead many statisticians to recommend that factorial designs with two or more random factors should avoided if possible. Arguably however, linear mixed effects models offer more appropriate solutions to the above issues as they are more robust for unbalanced designs, accommodate covariates and provide a more comprehensive treatment and overview of all the underlying data structures.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; fact_anova_table
    df           MS       A,B fixed          A,B random       
A   &amp;quot;a-1&amp;quot;        &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;  &amp;quot;(MS A)/(MS AB)&amp;quot; 
B   &amp;quot;b-1&amp;quot;        &amp;quot;MS B&amp;quot;   &amp;quot;(MS B)/(MS res)&amp;quot;  &amp;quot;(MS B)/(MS AB)&amp;quot; 
AB  &amp;quot;(b-1)(a-1)&amp;quot; &amp;quot;MS AB&amp;quot;  &amp;quot;(MS AB)/(MS res)&amp;quot; &amp;quot;(MS AB)/(MS AB)&amp;quot;
Res &amp;quot;(n-1)ba&amp;quot;    &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;                 &amp;quot;&amp;quot;               
    A fixed B random (model I) A fixed B random (model II)
A   &amp;quot;(MS A)/(MS AB)&amp;quot;           &amp;quot;(MS A)/(MS AB)&amp;quot;           
B   &amp;quot;(MS B)/(MS res)&amp;quot;          &amp;quot;(MS B)/(MS AB)&amp;quot;           
AB  &amp;quot;(MS AB)/(MS res)&amp;quot;         &amp;quot;(MS AB)/(MS res)&amp;quot;         
Res &amp;quot;&amp;quot;                         &amp;quot;&amp;quot;                         &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The corresponding &lt;code&gt;R&lt;/code&gt; syntax is given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Type I SS (Balanced)
&amp;gt; anova(lm(y ~ A * B, data))
&amp;gt; 
&amp;gt; #Type II SS (Unbalanced)
&amp;gt; Anova(lm(y ~ A * B, data), type = &amp;quot;II&amp;quot;)
&amp;gt; 
&amp;gt; #Type III SS (Unbalanced)
&amp;gt; Anova(lm(y ~ A * B, data), type = &amp;quot;III&amp;quot;)
&amp;gt; 
&amp;gt; #Variance components
&amp;gt; summary(lmer(y ~ 1 + (1 | A) + (1 | B) + (1 | A:B), data))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that for fixed factor models, when null hypotheses of interactions are rejected, the null hypothesis of the individual constituent factors are unlikely to represent the true nature of the effects and thus are of little value. The nature of such interactions are further explored by fitting simpler linear models (containing at least one less factor) separately for each of the levels of the other removed factor(s). Such &lt;em&gt;Main effects&lt;/em&gt; tests are based on a subset of the data, and therefore estimates of the overall residual (unexplained) variability are unlikely to be as precise as the estimates based on the global model. Consequently, F-ratios involving &lt;code&gt;MSResid&lt;/code&gt; should use the estimate of &lt;code&gt;MSResid&lt;/code&gt; from the global model rather than that based on the smaller, theoretically less precise subset of data. For random and mixed models, since the objective is to generalise the effect of one factor over and above any interactions with other factors, the main factor effects can be interpreted even in the presence of significant interactions. Nevertheless, it should be noted that when a significant interaction is present in a mixed model, the power of the main fixed effects will be reduced (since the amount of variability explained by the interaction term will be relatively high, and this term is used as the denominator for the F-ratio calculation).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;Hypothesis tests assume that the residuals are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator (see table above) should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;independent of one another.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Planned and unplanned comparisons&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As with single factor analysis of variance, planned and unplanned multiple comparisons (such as &lt;em&gt;Tukey&lt;/em&gt;’s test) can be incorporated into or follow the linear model respectively so as to further investigate any patterns or trends within the main factors and/or the interactions. As with single factor analysis of variance, the contrasts must be defined prior to fitting the linear model, and no more than &lt;span class=&#34;math inline&#34;&gt;\(p−1\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the number of levels of the factor) contrasts can be defined for a factor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Unbalanced designs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A factorial design can be thought of as a table made up of rows (representing the levels of one factor), columns (levels of another factor), and cells (the individual combinations of the set of factors). Whilst the middle left table does not have equal sample sizes in each cell, the sample sizes are in proportion and as such, does not present the issues discussed below for unbalanced designs.&lt;/p&gt;
&lt;p&gt;In addition to impacting on normality and homogeneity of variance, unequal sample sizes in factorial designs have major implications for the partitioning of the total sums of squares into each of the model components. For balanced designs, the total sums of squares (&lt;code&gt;SSTotal&lt;/code&gt;) is equal to the additive sums of squares of each of the components (including the residual). For example, in a two factor balanced design, &lt;code&gt;SSTotal=SSA+SSB+SSAB+SSResid&lt;/code&gt;. This can be represented diagrammatically by a &lt;em&gt;Venn Diagram&lt;/em&gt; in which each of the &lt;code&gt;SS&lt;/code&gt; for the term components butt against one another and are surrounded by the &lt;code&gt;SSResid&lt;/code&gt;. However, in unbalanced designs, the sums of squares will be non-orthogonal and the sum of the individual components does not add up to the total sums of squares. Diagrammatically, the &lt;code&gt;SS&lt;/code&gt; of the terms intersect or are separated.&lt;/p&gt;
&lt;p&gt;In regular &lt;em&gt;sequential sums of squares&lt;/em&gt; (&lt;strong&gt;Type I SS&lt;/strong&gt;), the sum of the individual sums of squares must be equal to the total sums of squares, the sums of squares of the last factor to be estimated will be calculated as the difference between the total sums of squares and what has already been accounted for by other components. Consequently, the order in which factors are specified in the model (and thus estimated) will alter their sums of squares and therefore their F-ratios. To overcome this problem, traditionally there are two other alternative methods of calculating sums of squares.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Type II (hierarchical) SS&lt;/strong&gt; estimate the sums of squares of each term as the improvement it contributes upon addition of that term to a model of greater complexity and lower in the hierarchy (recall that the hierarchical structure descends from the simplest model down to the fully populated model). The SS for the interaction as well as the first factor to be estimated are the same as for Type I SS. Type II SS estimate the contribution of a factor over and above the contributions of other factors of equal or lower complexity but not above the contributions of the interaction terms or terms nested within the factor. However, these sums of squares are weighted by the sample sizes of each level and therefore are biased towards the trends produced by the groups (levels) that have higher sample sizes. As a result of the weightings, Type II SS actually test hypotheses about really quite complex combinations of factor levels. Rather than test a hypothesis that &lt;span class=&#34;math inline&#34;&gt;\(\mu_{High}=\mu_{Medium}=\mu_{Low}\)&lt;/span&gt;, Type II SS might be testing that &lt;span class=&#34;math inline&#34;&gt;\(4\times\mu_{High}=1\times\mu_{Medium}=0.25\times\mu_{Low}\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Type III (marginal or orthogonal) SS&lt;/strong&gt; estimate the sums of squares of each term as the improvement based on a comparison of models with and without the term and are unweighted by sample sizes. Type III SS essentially measure just the unique contribution of each factor over and above the contributions of the other factors and interactions. For unbalanced designs,Type III SS essentially test equivalent hypotheses to balanced Type I SS and are therefore arguably more appropriate for unbalanced factorial designs than Type II SS. Importantly, Type III SS are only interpretable if they are based on orthogonal contrasts (such as sum or helmert contrasts and not treatment contrasts).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The choice between Type II and III SS clearly depends on the nature of the question. For example, if we had measured the growth rate of seedlings subjected to two factors (temperature and fertiliser), Type II SS could address whether there was an effect of temperature across the level of fertiliser treatment, whereas Type III SS could assess whether there was an effect of temperature within each level of the fertiliser treatment.&lt;/p&gt;
&lt;p&gt;When an entire combination, or cell, is missing (perhaps due to unforeseen circumstances) it is not possible to test all the main effects and/or interactions. The bottom right table above depicts such as situation. One solution is to fit a large single factor ANOVA with as many levels as there are cells (this is known as a cell means model) and investigate various factor and interaction effects via specific contrasts (see the following tables). Difficulties in establishing appropriate error terms, makes missing cells in random and mixed factor designs substantially more complex.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Imagine we has designed an experiment in which we had measured the response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) under a combination of two different potential influences (Factor A: levels a1 and a2; and Factor B: levels b1, b2 and b3), each combination replicated &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; times (&lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; nA &amp;lt;- 2  #number of levels of A
&amp;gt; nB &amp;lt;- 3  #number of levels of B
&amp;gt; nsample &amp;lt;- 10  #number of reps in each
&amp;gt; A &amp;lt;- gl(nA, 1, nA, lab = paste(&amp;quot;a&amp;quot;, 1:nA, sep = &amp;quot;&amp;quot;))
&amp;gt; B &amp;lt;- gl(nB, 1, nB, lab = paste(&amp;quot;b&amp;quot;, 1:nB, sep = &amp;quot;&amp;quot;))
&amp;gt; data &amp;lt;- expand.grid(A = A, B = B, n = 1:nsample)
&amp;gt; X &amp;lt;- model.matrix(~A * B, data = data)
&amp;gt; eff &amp;lt;- c(40, 15, 5, 0, -15, 10)
&amp;gt; sigma &amp;lt;- 3  #residual standard deviation
&amp;gt; n &amp;lt;- nrow(data)
&amp;gt; eps &amp;lt;- rnorm(n, 0, sigma)  #residuals
&amp;gt; data$y &amp;lt;- as.numeric(X %*% eff + eps)
&amp;gt; head(data)  #print out the first six rows of the data set
   A  B n        y
1 a1 b1 1 38.31857
2 a2 b1 1 54.30947
3 a1 b2 1 49.67612
4 a2 b2 1 45.21153
5 a1 b3 1 40.38786
6 a2 b3 1 70.14519
&amp;gt; 
&amp;gt; with(data, interaction.plot(A, B, y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/generate_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ## ALTERNATIVELY, we could supply the population means and get the effect parameters from these.  To
&amp;gt; ## correspond to the model matrix, enter the population means in the order of: a1b1, a2b1, a1b1,
&amp;gt; ## a2b2,a1b3,a2b3
&amp;gt; pop.means &amp;lt;- as.matrix(c(40, 55, 45, 45, 40, 65), byrow = F)
&amp;gt; ## Generate a minimum model matrix for the effects
&amp;gt; XX &amp;lt;- model.matrix(~A * B, expand.grid(A = factor(1:2), B = factor(1:3)))
&amp;gt; ## Use the solve() function to solve what are effectively simultaneous equations
&amp;gt; (eff &amp;lt;- as.vector(solve(XX, pop.means)))
[1]  40  15   5   0 -15  10
&amp;gt; 
&amp;gt; data$y &amp;lt;- as.numeric(X %*% eff + eps)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type. Does treatment type effect the response?.&lt;/p&gt;
&lt;div id=&#34;assumptions-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;The assumptions are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All of the observations are independent - this must be addressed at the design and collection stages. Importantly, to be considered independent replicates, the replicates must be made at the same scale at which the treatment is applied. For example, if the experiment involves subjecting organisms housed in tanks to different water temperatures, then the unit of replication is the individual tanks not the individual organisms in the tanks. The individuals in a tank are strictly not independent with respect to the treatment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (and thus the residuals) should be normally distributed for each sampled populations (combination of factors). Boxplots of each treatment combination are useful for diagnosing major issues with normality.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately) for each combination of treatments. Again, boxplots are useful.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ A * B, data)
&amp;gt; 
&amp;gt; # OR via ggplot2
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = y, x = A, fill = B)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/exp1_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity&lt;/p&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X \boldsymbol \beta\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; represents the intercept associated with the first combination of groups, as well as the (effects) differences between this intercept and each other group. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X\)&lt;/span&gt; is the model matrix. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. Exploratory data analysis suggests that the intercept and effects could be drawn from similar distributions (with mean in the &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;’s and variances in the &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;’s). Whilst we might therefore be tempted to provide different priors for the intercept, compared to the effects, for a simple model such as this, it is unlikely to be necessary. However, for more complex models, where prior specification becomes more critical, separate priors would probably be necessary.&lt;/p&gt;
&lt;p&gt;We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Note the following example as group means calculated as derived posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau)
+   mean[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   #Priors
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) 
+   }
+   sigma ~ dunif(0, 100)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;fact_anovaModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X &amp;lt;- model.matrix(~A * B, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = X, n = nrow(data), ngroups = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;fact_anovaModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 60
   Unobserved stochastic nodes: 7
   Total graph size: 502

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;fact_anovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.187   0.927  38.381  39.572  40.186  40.810  42.028 1.001 15000
beta[2]   14.739   1.297  12.177  13.875  14.741  15.611  17.281 1.001 15000
beta[3]    4.997   1.301   2.439   4.127   4.996   5.850   7.555 1.001  6200
beta[4]   -0.335   1.302  -2.922  -1.201  -0.323   0.523   2.182 1.001  9300
beta[5]  -14.551   1.831 -18.188 -15.752 -14.535 -13.331 -10.976 1.001 15000
beta[6]   11.081   1.823   7.514   9.859  11.073  12.288  14.680 1.001 15000
sigma      2.909   0.286   2.410   2.707   2.886   3.092   3.525 1.001  3100
deviance 296.719   4.003 290.996 293.788 296.037 298.923 306.334 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 8.0 and DIC = 304.7
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trace plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters (such as &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;s).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3895  3746         1.040     
 beta[2]  2        3649  3746         0.974     
 beta[3]  2        3981  3746         1.060     
 beta[4]  2        3811  3746         1.020     
 beta[5]  2        3855  3746         1.030     
 beta[6]  2        3770  3746         1.010     
 deviance 2        3981  3746         1.060     
 sigma    4        5074  3746         1.350     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3729  3746         0.995     
 beta[2]  2        3853  3746         1.030     
 beta[3]  2        3649  3746         0.974     
 beta[4]  2        3770  3746         1.010     
 beta[5]  2        3853  3746         1.030     
 beta[6]  2        3770  3746         1.010     
 deviance 2        3649  3746         0.974     
 sigma    4        5366  3746         1.430     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
            beta[1]      beta[2]       beta[3]      beta[4]      beta[5]
Lag 0   1.000000000  1.000000000  1.0000000000  1.000000000  1.000000000
Lag 1  -0.002519333  0.009718890  0.0097211169  0.004831644  0.013455394
Lag 5  -0.004466196  0.013453425  0.0012166509 -0.009459535  0.010837730
Lag 10 -0.006418970 -0.004825081  0.0002148708 -0.003297864 -0.004528907
Lag 50  0.004241571  0.010613172 -0.0056258926 -0.002886136 -0.003130607
            beta[6]     deviance        sigma
Lag 0   1.000000000  1.000000000  1.000000000
Lag 1   0.004411377  0.194295905  0.335565370
Lag 5   0.004680461  0.011707557  0.003364317
Lag 10 -0.012377072  0.006873975  0.005557072
Lag 50  0.003484518 -0.008999031 -0.012155151&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.&lt;/p&gt;
&lt;p&gt;There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Standardised residuals&lt;/strong&gt;. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Studentised residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the residuals. Note that &lt;strong&gt;externally studentised residuals&lt;/strong&gt; are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pearson residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%) back thereby allowing us to train the model on &lt;span class=&#34;math inline&#34;&gt;\(75\)&lt;/span&gt;% of the data and then see how well the model can predict the withheld &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.&lt;/p&gt;
&lt;p&gt;Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within &lt;code&gt;JAGS&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; wch
[1] 1 2 3 4 5 6
&amp;gt; 
&amp;gt; head(mcmc)
      beta[1]  beta[2]  beta[3]     beta[4]   beta[5]  beta[6] deviance
[1,] 41.07993 14.73872 4.532543 -1.58279310 -14.91723 11.28780 292.8658
[2,] 40.30651 13.02455 4.475566 -0.86754574 -12.02942 13.36371 295.1239
[3,] 40.42144 14.71551 5.149725  0.09616707 -14.80497 10.82830 290.7322
[4,] 39.79269 16.35682 5.776724 -0.53251753 -17.64694 10.59484 295.1674
[5,] 39.40269 14.69470 5.237430 -0.29022676 -14.12951 12.81751 293.3136
[6,] 41.27115 12.58706 5.908648 -2.34899624 -13.31913 13.79862 302.0972
        sigma
[1,] 3.032059
[2,] 2.467221
[3,] 2.874167
[4,] 2.561227
[5,] 2.841503
[6,] 3.403891
&amp;gt; 
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; library(tidyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; print(coefs)
    beta[1]     beta[2]     beta[3]     beta[4]     beta[5]     beta[6] 
 40.1859804  14.7407405   4.9960673  -0.3233121 -14.5348136  11.0732139 
&amp;gt;  
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = B)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; #generate a model matrix
&amp;gt; Xmat = model.matrix(~A*B, data)
&amp;gt; ##get median parameter estimates
&amp;gt; coefs = mcmc[,wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,], mcmc[i, &amp;#39;sigma&amp;#39;]))
&amp;gt; newdata = data.frame(A=data$A, B=data$B, yRep) %&amp;gt;% gather(key=Sample, value=Value,-A,-B)
&amp;gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=A, fill=&amp;#39;Model&amp;#39;), alpha=0.5)+
+  geom_violin(data=data, aes(y=y,x=A,fill=&amp;#39;Obs&amp;#39;), alpha=0.5) +
+  geom_point(data=data, aes(y=y, x=A), position=position_jitter(width=0.1,height=0),
+             color=&amp;#39;black&amp;#39;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=B, fill=&amp;#39;Model&amp;#39;, group=B, color=A), alpha=0.5)+
+  geom_point(data=data, aes(y=y, x=B, group=B,color=A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;fact_anovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.187   0.927  38.381  39.572  40.186  40.810  42.028 1.001 15000
beta[2]   14.739   1.297  12.177  13.875  14.741  15.611  17.281 1.001 15000
beta[3]    4.997   1.301   2.439   4.127   4.996   5.850   7.555 1.001  6200
beta[4]   -0.335   1.302  -2.922  -1.201  -0.323   0.523   2.182 1.001  9300
beta[5]  -14.551   1.831 -18.188 -15.752 -14.535 -13.331 -10.976 1.001 15000
beta[6]   11.081   1.823   7.514   9.859  11.073  12.288  14.680 1.001 15000
sigma      2.909   0.286   2.410   2.707   2.886   3.092   3.525 1.001  3100
deviance 296.719   4.003 290.996 293.788 296.037 298.923 306.334 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 8.0 and DIC = 304.7
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 8 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    40.2       0.927    38.4      42.0 
2 beta[2]    14.7       1.30     12.2      17.3 
3 beta[3]     5.00      1.30      2.43      7.55
4 beta[4]    -0.335     1.30     -2.89      2.21
5 beta[5]   -14.6       1.83    -18.2     -11.0 
6 beta[6]    11.1       1.82      7.57     14.7 
7 deviance  297.        4.00    290.      304.  
8 sigma       2.91      0.286     2.37      3.47&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The intercept represents the mean of the first combination Aa1:Bb1 is &lt;span class=&#34;math inline&#34;&gt;\(40.2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb1 is &lt;span class=&#34;math inline&#34;&gt;\(14.7\)&lt;/span&gt; units greater than Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa1:Bb2 is &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; units greater Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa1:Bb3 is &lt;span class=&#34;math inline&#34;&gt;\(-0.335\)&lt;/span&gt; units greater Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb2 is &lt;span class=&#34;math inline&#34;&gt;\(-14.6\)&lt;/span&gt; units greater than the difference between (Aa1:Bb2 + Aa2:Bb1) and (2*Aa1:Bb1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb3 is &lt;span class=&#34;math inline&#34;&gt;\(11.1\)&lt;/span&gt; units greater than the difference between (Aa1:Bb3 + Aa2:Bb1) and (2*Aa1:Bb1)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility interval for both interactive effects (Aa2:Bb2 and Aa2:Bb3) do not contain &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, implying significant interactions between A and B. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])
[1] 0.0004666667
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[4]&amp;quot;])
[1] 0.7912667
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[5]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[6]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta[5]&amp;quot;, &amp;quot;beta[6]&amp;quot;)])
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence of an interaction between A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = expand.grid(A=levels(data$A), B=levels(data$B))
&amp;gt; Xmat = model.matrix(~A*B,newdata)
&amp;gt; coefs = mcmc[,wch]
&amp;gt; fit=coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int=TRUE, conf.method=&amp;#39;HPDinterval&amp;#39;))
&amp;gt; newdata
   A  B estimate std.error conf.low conf.high
1 a1 b1 40.18727 0.9270982 38.38136  42.02744
2 a2 b1 54.92636 0.9160115 53.12047  56.67452
3 a1 b2 45.18473 0.9196740 43.37733  46.98224
4 a2 b2 45.37262 0.9197287 43.61538  47.19883
5 a1 b3 39.85206 0.9156380 38.11053  41.70144
6 a2 b3 65.67189 0.9209489 63.84038  67.47931
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y=estimate, x=B, fill=A)) +
+  geom_blank() +
+  geom_line(aes(x=as.numeric(B), linetype=A)) +
+  geom_linerange(aes(ymin=conf.low, ymax=conf.high))+
+  geom_point(aes(shape=A), size=3)+
+  scale_y_continuous(&amp;#39;Y&amp;#39;)+
+  scale_x_discrete(&amp;#39;B&amp;#39;)+
+  scale_shape_manual(&amp;#39;A&amp;#39;,values=c(21,16))+
+  scale_fill_manual(&amp;#39;A&amp;#39;,values=c(&amp;#39;white&amp;#39;,&amp;#39;black&amp;#39;))+
+  scale_linetype_manual(&amp;#39;A&amp;#39;,values=c(&amp;#39;solid&amp;#39;,&amp;#39;dashed&amp;#39;))+
+  theme_classic() +
+  theme(legend.justification=c(0,1), legend.position=c(0.05,1),
+   axis.title.y=element_text(vjust=2, size=rel(1.25)),
+   axis.title.x=element_text(vjust=-2, size=rel(1.25)),
+   plot.margin=unit(c(0.5,0.5,2,2), &amp;#39;lines&amp;#39;),
+   legend.key.size=unit(1,&amp;#39;cm&amp;#39;)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A        10.4     0.917      8.65     12.3 
2 sd.B         3.06    0.640      1.79      4.28
3 sd.AB       10.4     0.734      9.04     11.9 
4 sd.resid     2.84    0.0836     2.72      3.00
# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A         39.1     1.95     35.2       42.8
2 sd.B         11.4     1.90      7.60      15.0
3 sd.AB        39.0     0.947    37.0       40.8
4 sd.resid     10.6     0.822     9.30      12.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/eff_pop1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(39\)&lt;/span&gt;% of the total finite population standard deviation is due to the interaction between factor A and factor B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; Xmat = model.matrix(~A * B, data)
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.913   0.00817    0.897     0.925
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ A * B, data))

Call:
lm(formula = y ~ A * B, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5694 -1.8517 -0.0589  1.7120  6.5966 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.1940     0.8980  44.760  &amp;lt; 2e-16 ***
Aa2          14.7163     1.2700  11.588 2.88e-16 ***
Bb2           4.9823     1.2700   3.923 0.000249 ***
Bb3          -0.3464     1.2700  -0.273 0.786077    
Aa2:Bb2     -14.5093     1.7960  -8.079 7.37e-11 ***
Aa2:Bb3      11.1056     1.7960   6.184 8.65e-08 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 2.84 on 54 degrees of freedom
Multiple R-squared:   0.92, Adjusted R-squared:  0.9125 
F-statistic: 124.1 on 5 and 54 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dealing-with-interactions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dealing with interactions&lt;/h1&gt;
&lt;p&gt;In the presence of interations, conclusions about the main effects are overly simplistic at best and completely inaccurate at worst. Therefore, in the presense of interactions we should attempt to tease the analysis appart a little. In the current working example, we have identified that there is a significant interaction between Factor A and Factor B. Our exploration of the regression coefficients, indicated that the pattern between b1, b2 and b3 might differ between a1 and a2. Similarly, if we consider the coefficients from the perspective of Factor A, we can see that the patterns between a1 and a2 are similar for b1 and b3, yet very different for b2.&lt;/p&gt;
&lt;p&gt;At this point, we can then split the two-factor model up into a series of single-factor models, either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;examining the effects of Factor B separately for each level of Factor A (two single-factor models) or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;examining the effects of Factor A separately for each level of Factor B (three single-factor models)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, rather than subset the data and fit isolated smaller models, it is arguably better to treat these explorations as contrasts. As such we could either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;apply specific contrasts to the already fit model&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;define the specific contrasts and use them to refit the model&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will do the former of these options since we have already fit the global model. For this demonstration, we will explore the effect of factor A at each level of factor B. I will illustrate two ways to perform these contrasts on an already fit model:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&amp;gt; Xmat = model.matrix(~A * B, data = newdata)
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; head(fit)
            1        2        3        4        5        6
[1,] 41.07993 55.81865 45.61247 45.43397 39.49714 65.52366
[2,] 40.30651 53.33106 44.78207 45.77720 39.43896 65.82722
[3,] 40.42144 55.13695 45.57116 45.48170 40.51761 66.06142
[4,] 39.79269 56.14951 45.56942 44.27930 39.26017 66.21183
[5,] 39.40269 54.09738 44.64012 45.20530 39.11246 66.62467
[6,] 41.27115 53.85821 47.17980 46.44773 38.92215 65.30783
&amp;gt; 
&amp;gt; ## we want to compare columns 2-1, 4-3 and 6-5
&amp;gt; comps = fit[, c(2, 4, 6)] - fit[, c(1, 3, 5)]
&amp;gt; tidyMCMC(comps, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 3 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2       14.7        1.30    12.2      17.3 
2 4        0.188      1.30    -2.30      2.83
3 6       25.8        1.30    23.2      28.4 &lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&amp;gt; Xmat = model.matrix(~A * B, data = newdata)
&amp;gt; contr = attr(Xmat, &amp;quot;contrasts&amp;quot;)
&amp;gt; newdata.a1 = model.frame(~A * B, expand.grid(A = levels(data$A)[1], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&amp;gt; Xmat.a1 = model.matrix(~A * B, data = newdata.a1, contrasts = contr)
&amp;gt; newdata.a2 = model.frame(~A * B, expand.grid(A = levels(data$A)[2], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&amp;gt; Xmat.a2 = model.matrix(~A * B, data = newdata.a2, contrasts = contr)
&amp;gt; Xmat = Xmat.a2 - Xmat.a1
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 3 x 4
  estimate std.error conf.low conf.high
     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1   14.7        1.30    12.2      17.3 
2    0.188      1.30    -2.30      2.83
3   25.8        1.30    23.2      28.4 &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Factorial Analysis of Variance - STAN</title>
      <link>/stan/factorial-anova-stan/factorial-anova-stan/</link>
      <pubDate>Thu, 06 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/stan/factorial-anova-stan/factorial-anova-stan/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;STAN&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman, Lee, and Guo (2015)&lt;/span&gt;) using the package &lt;code&gt;rstan&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Stan Development Team (2018)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Factorial designs are an extension of single factor ANOVA designs in which additional factors are added such that each level of one factor is applied to all levels of the other factor(s) and these combinations are replicated. For example, we might design an experiment in which the effects of temperature (high vs low) and fertiliser (added vs not added) on the growth rate of seedlings are investigated by growing seedlings under the different temperature and fertilizer combinations. In addition to investigating the impacts of the main factors, factorial designs allow us to investigate whether the effects of one factor are consistent across levels of another factor. For example, is the effect of temperature on growth rate the same for both fertilised and unfertilized seedlings and similarly, does the impact of fertiliser treatment depend on the temperature under which the seedlings are grown?&lt;/p&gt;
&lt;p&gt;Arguably, these interactions give more sophisticated insights into the dynamics of the system we are investigating. Hence, we could add additional main effects, such as soil pH, amount of water, etc, along with all the two way (temp:fert, temp:pH, temp:water, etc), three-way (temp:fert:pH, temp:pH:water), four-way (and so on) interactions in order to explore how these various factors interact with one another to effect the response. However, the more interactions, the more complex the model becomes to specify, compute and interpret - not to mention the rate at which the number of required observations increases. Factorial designs can consist:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;entirely of crossed fixed factors (&lt;strong&gt;Model I ANOVA&lt;/strong&gt; - most common) in which conclusions are restricted to the specific combinations of levels selected for the experiment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;entirely of crossed random factors (&lt;strong&gt;Model II ANOVA&lt;/strong&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;a mixture of crossed fixed and random factors (&lt;strong&gt;Model III ANOVA&lt;/strong&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The latter are useful for investigating the generality of a main treatment effect (fixed) over broad spatial, temporal or clinical levels of organisation. That is whether the observed effects of temperature and/or fertiliser (for example) are observed across the entire genera or country.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear model&lt;/h2&gt;
&lt;p&gt;As with single factor ANOVA, the linear model could be constructed as either effects or means parameterisation, although only effects parameterisation will be considered here. The linear models for two and three factor design are&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \epsilon_{ijk},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_j + \gamma_k + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \epsilon_{ijkl},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the effect of Factor A, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of Factor B, &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the effect of Factor C and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component. Note that although the linear models for Model I, Model II and Model III designs are identical, the interpretation of terms (and thus null hypothesis) differ. Recall from the tutorial on single factor ANOVA, that categorical variables in linear models are actually re-parameterised dummy codes - and thus the &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; term above, actually represents one or more dummy codes. Thus, if we actually had two levels of Factor A (A1 and A2) and three levels of Factor B (B1, B2, B3), then the fully parameterised linear model would be:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y=\beta_{A1B1}+\beta_{A2B1−A1B1}+\beta_{A1B2−A1B1}+\beta_{A1B3−A1B1}+\beta_{A2B2−A1B2−A2B1−A1B1}+\beta_{A2B3−A1B3−A2B1−A1B1}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thus, such a model would have six parameters to estimate (in addition to the variance).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis&lt;/h2&gt;
&lt;p&gt;There are separate null hypothesis associated with each of the main effects and the interaction terms.&lt;/p&gt;
&lt;div id=&#34;model-1---fixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 1 - fixed effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Factor A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to an overall mean. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the overall mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The effect of each group equals zero. If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), the null hypothesis is rejected indicating that the treatment has been found to affect the response variable. Note, as with multiple regression models, these “effects” represent &lt;em&gt;partial effects&lt;/em&gt;. In the above, the effect of Factor A is actually the effect of Factor A at the first level of the Factor(s).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal - at the first level of Factor A. Equivalent interpretation to Factor A above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\mu_{ij}=\mu_i+\mu_j-\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. For any given combination of factor levels, the population group mean will be equal to the difference between the overall population mean and the simple additive effects of the individual factor group means. That is, the effects of the main treatment factors are purely additive and independent of one another. This is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(H_0(AB): \alpha\beta_{ij}=0\)&lt;/span&gt;, no interaction between Factor A and Factor B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-2---random-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 2 - random effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Factor A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\sigma^2_{\alpha}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of A.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\sigma^2_{\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of B.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\sigma^2_{\alpha\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is no added variance due to all possible interactions between all possible levels of A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-3---mixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 3 - mixed effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Fixed factor - e.g. A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (pooled over all levels of the random factor) is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to an overall mean pooling over all possible levels of the random factor. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the overall mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;No effect of any level of this factor pooled over all possible levels of the random factor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Random factor - e.g. B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\sigma^2_{\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of B.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The interaction of a fixed and random factor is always considered a random factor.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\sigma^2_{\alpha\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible interactions between all possible levels of A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;When fixed factorial designs are balanced, the total variance in the response variable can be sequentially partitioned into what is explained by each of the model terms (factors and their interactions) and what is left unexplained. For each of the specific null hypotheses, the overall unexplained variability is used as the denominator in F-ratio calculations, and when a null hypothesis is true, an F-ratio should follow an F distribution with an expected value less than &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;. Random factors are added to provide greater generality of conclusions. That is, to enable us to make conclusions about the effect of one factor (such as whether or not fertiliser is added) over all possible levels (not just those sampled) of a random factor (such as all possible locations, seasons, varieties, etc). In order to expand our conclusions beyond the specific levels used in the design, the hypothesis tests (and thus F-ratios) must reflect this extra generality by being more conservative.&lt;/p&gt;
&lt;p&gt;The appropriate F-ratios for fixed, random and mixed factorial designs are presented below. Generally, once the terms (factors and interactions) have been ordered into a hierarchy (single factors at the top, highest level interactions at the bottom and terms of same order given equivalent positions in the hierarchy), the denominator for any term is selected as the next appropriate random term (an interaction that includes the term to be tested) encountered lower in the hierarchy. Interaction terms that contain one or more random factors are considered themselves to be random terms, as is the overall residual term (as all observations are assumed to be random representations of the entire population(s)). Note, when designs include a mixture of fixed and random crossed effects, exact denominator degrees of freedoms for certain F-ratios are undefined and traditional approaches adopt rather inexact estimated approximate or “Quasi” F-ratios. Pooling of non-significant F-ratio denominator terms, in which lower random terms are added to the denominator (provided &lt;span class=&#34;math inline&#34;&gt;\(\alpha &amp;gt; 0.25\)&lt;/span&gt;), may also be useful. For random factors within mixed models, selecting F-ratio denominators that are appropriate for the intended hypothesis tests is a particularly complex and controversial issue. Traditionally, there are two alternative approaches and whilst the statistical resumes of each are complicated, essentially they differ in whether or not the interaction term is constrained for the test of the random factor.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;constrained or restricted method&lt;/em&gt; (&lt;strong&gt;Model I&lt;/strong&gt;), stipulates that for the calculation of a random factor F-ratio (which investigates the added variance added due to the random factor), the overall effect of the interaction is treated as zero. Consequently, the random factor is tested against the residual term. The &lt;em&gt;unconstrained or unrestrained method&lt;/em&gt; (&lt;strong&gt;Model II&lt;/strong&gt;) however, does not set the interaction effect to zero and therefore the interaction term is used as the random factor F-ratio denominator. This method assumes that the interaction terms for each level of the random factor are completely independent (correlations between the fixed factor must be consistent across all levels of the random factor). Some statisticians maintain that the independence of the interaction term is difficult to assess for clinical data and therefore, the restricted approach is more appropriate. However, others have suggested that the restricted method is only appropriate for balanced designs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quasi-f-ratios&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quasi F-ratios&lt;/h2&gt;
&lt;p&gt;An additional complication for three or more factor models that contain two or more random factors, is that there may not be a single appropriate interaction term to use as the denominator for many of the main effects F-ratios. For example, if Factors A and B are random and C is fixed, then there are two random interaction terms of equivalent level under Factor C (&lt;span class=&#34;math inline&#34;&gt;\(A^\prime \times C\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B^\prime \times C\)&lt;/span&gt;). As a result, the value of the of the &lt;em&gt;Mean Squares&lt;/em&gt; (MS) expected when the null hypothesis is true cannot be easily defined. The solutions for dealing with such situations (&lt;em&gt;quasi F-ratios&lt;/em&gt;) involve adding (and subtracting) terms together to create approximate estimates of F-ratio denominators. Alternatively, for random factors, variance components with confidence intervals can be used. These solutions are sufficiently unsatisfying as to lead many statisticians to recommend that factorial designs with two or more random factors should avoided if possible. Arguably however, linear mixed effects models offer more appropriate solutions to the above issues as they are more robust for unbalanced designs, accommodate covariates and provide a more comprehensive treatment and overview of all the underlying data structures.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; fact_anova_table
    df           MS       A,B fixed          A,B random       
A   &amp;quot;a-1&amp;quot;        &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;  &amp;quot;(MS A)/(MS AB)&amp;quot; 
B   &amp;quot;b-1&amp;quot;        &amp;quot;MS B&amp;quot;   &amp;quot;(MS B)/(MS res)&amp;quot;  &amp;quot;(MS B)/(MS AB)&amp;quot; 
AB  &amp;quot;(b-1)(a-1)&amp;quot; &amp;quot;MS AB&amp;quot;  &amp;quot;(MS AB)/(MS res)&amp;quot; &amp;quot;(MS AB)/(MS AB)&amp;quot;
Res &amp;quot;(n-1)ba&amp;quot;    &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;                 &amp;quot;&amp;quot;               
    A fixed B random (model I) A fixed B random (model II)
A   &amp;quot;(MS A)/(MS AB)&amp;quot;           &amp;quot;(MS A)/(MS AB)&amp;quot;           
B   &amp;quot;(MS B)/(MS res)&amp;quot;          &amp;quot;(MS B)/(MS AB)&amp;quot;           
AB  &amp;quot;(MS AB)/(MS res)&amp;quot;         &amp;quot;(MS AB)/(MS res)&amp;quot;         
Res &amp;quot;&amp;quot;                         &amp;quot;&amp;quot;                         &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The corresponding &lt;code&gt;R&lt;/code&gt; syntax is given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Type I SS (Balanced)
&amp;gt; anova(lm(y ~ A * B, data))
&amp;gt; 
&amp;gt; #Type II SS (Unbalanced)
&amp;gt; Anova(lm(y ~ A * B, data), type = &amp;quot;II&amp;quot;)
&amp;gt; 
&amp;gt; #Type III SS (Unbalanced)
&amp;gt; Anova(lm(y ~ A * B, data), type = &amp;quot;III&amp;quot;)
&amp;gt; 
&amp;gt; #Variance components
&amp;gt; summary(lmer(y ~ 1 + (1 | A) + (1 | B) + (1 | A:B), data))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that for fixed factor models, when null hypotheses of interactions are rejected, the null hypothesis of the individual constituent factors are unlikely to represent the true nature of the effects and thus are of little value. The nature of such interactions are further explored by fitting simpler linear models (containing at least one less factor) separately for each of the levels of the other removed factor(s). Such &lt;em&gt;Main effects&lt;/em&gt; tests are based on a subset of the data, and therefore estimates of the overall residual (unexplained) variability are unlikely to be as precise as the estimates based on the global model. Consequently, F-ratios involving &lt;code&gt;MSResid&lt;/code&gt; should use the estimate of &lt;code&gt;MSResid&lt;/code&gt; from the global model rather than that based on the smaller, theoretically less precise subset of data. For random and mixed models, since the objective is to generalise the effect of one factor over and above any interactions with other factors, the main factor effects can be interpreted even in the presence of significant interactions. Nevertheless, it should be noted that when a significant interaction is present in a mixed model, the power of the main fixed effects will be reduced (since the amount of variability explained by the interaction term will be relatively high, and this term is used as the denominator for the F-ratio calculation).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;Hypothesis tests assume that the residuals are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator (see table above) should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;independent of one another.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Planned and unplanned comparisons&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As with single factor analysis of variance, planned and unplanned multiple comparisons (such as &lt;em&gt;Tukey&lt;/em&gt;’s test) can be incorporated into or follow the linear model respectively so as to further investigate any patterns or trends within the main factors and/or the interactions. As with single factor analysis of variance, the contrasts must be defined prior to fitting the linear model, and no more than &lt;span class=&#34;math inline&#34;&gt;\(p−1\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the number of levels of the factor) contrasts can be defined for a factor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Unbalanced designs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A factorial design can be thought of as a table made up of rows (representing the levels of one factor), columns (levels of another factor), and cells (the individual combinations of the set of factors). Whilst the middle left table does not have equal sample sizes in each cell, the sample sizes are in proportion and as such, does not present the issues discussed below for unbalanced designs.&lt;/p&gt;
&lt;p&gt;In addition to impacting on normality and homogeneity of variance, unequal sample sizes in factorial designs have major implications for the partitioning of the total sums of squares into each of the model components. For balanced designs, the total sums of squares (&lt;code&gt;SSTotal&lt;/code&gt;) is equal to the additive sums of squares of each of the components (including the residual). For example, in a two factor balanced design, &lt;code&gt;SSTotal=SSA+SSB+SSAB+SSResid&lt;/code&gt;. This can be represented diagrammatically by a &lt;em&gt;Venn Diagram&lt;/em&gt; in which each of the &lt;code&gt;SS&lt;/code&gt; for the term components butt against one another and are surrounded by the &lt;code&gt;SSResid&lt;/code&gt;. However, in unbalanced designs, the sums of squares will be non-orthogonal and the sum of the individual components does not add up to the total sums of squares. Diagrammatically, the &lt;code&gt;SS&lt;/code&gt; of the terms intersect or are separated.&lt;/p&gt;
&lt;p&gt;In regular &lt;em&gt;sequential sums of squares&lt;/em&gt; (&lt;strong&gt;Type I SS&lt;/strong&gt;), the sum of the individual sums of squares must be equal to the total sums of squares, the sums of squares of the last factor to be estimated will be calculated as the difference between the total sums of squares and what has already been accounted for by other components. Consequently, the order in which factors are specified in the model (and thus estimated) will alter their sums of squares and therefore their F-ratios. To overcome this problem, traditionally there are two other alternative methods of calculating sums of squares.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Type II (hierarchical) SS&lt;/strong&gt; estimate the sums of squares of each term as the improvement it contributes upon addition of that term to a model of greater complexity and lower in the hierarchy (recall that the hierarchical structure descends from the simplest model down to the fully populated model). The SS for the interaction as well as the first factor to be estimated are the same as for Type I SS. Type II SS estimate the contribution of a factor over and above the contributions of other factors of equal or lower complexity but not above the contributions of the interaction terms or terms nested within the factor. However, these sums of squares are weighted by the sample sizes of each level and therefore are biased towards the trends produced by the groups (levels) that have higher sample sizes. As a result of the weightings, Type II SS actually test hypotheses about really quite complex combinations of factor levels. Rather than test a hypothesis that &lt;span class=&#34;math inline&#34;&gt;\(\mu_{High}=\mu_{Medium}=\mu_{Low}\)&lt;/span&gt;, Type II SS might be testing that &lt;span class=&#34;math inline&#34;&gt;\(4\times\mu_{High}=1\times\mu_{Medium}=0.25\times\mu_{Low}\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Type III (marginal or orthogonal) SS&lt;/strong&gt; estimate the sums of squares of each term as the improvement based on a comparison of models with and without the term and are unweighted by sample sizes. Type III SS essentially measure just the unique contribution of each factor over and above the contributions of the other factors and interactions. For unbalanced designs,Type III SS essentially test equivalent hypotheses to balanced Type I SS and are therefore arguably more appropriate for unbalanced factorial designs than Type II SS. Importantly, Type III SS are only interpretable if they are based on orthogonal contrasts (such as sum or helmert contrasts and not treatment contrasts).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The choice between Type II and III SS clearly depends on the nature of the question. For example, if we had measured the growth rate of seedlings subjected to two factors (temperature and fertiliser), Type II SS could address whether there was an effect of temperature across the level of fertiliser treatment, whereas Type III SS could assess whether there was an effect of temperature within each level of the fertiliser treatment.&lt;/p&gt;
&lt;p&gt;When an entire combination, or cell, is missing (perhaps due to unforeseen circumstances) it is not possible to test all the main effects and/or interactions. The bottom right table above depicts such as situation. One solution is to fit a large single factor ANOVA with as many levels as there are cells (this is known as a cell means model) and investigate various factor and interaction effects via specific contrasts (see the following tables). Difficulties in establishing appropriate error terms, makes missing cells in random and mixed factor designs substantially more complex.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Imagine we has designed an experiment in which we had measured the response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) under a combination of two different potential influences (Factor A: levels a1 and a2; and Factor B: levels b1, b2 and b3), each combination replicated &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; times (&lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; nA &amp;lt;- 2  #number of levels of A
&amp;gt; nB &amp;lt;- 3  #number of levels of B
&amp;gt; nsample &amp;lt;- 10  #number of reps in each
&amp;gt; A &amp;lt;- gl(nA, 1, nA, lab = paste(&amp;quot;a&amp;quot;, 1:nA, sep = &amp;quot;&amp;quot;))
&amp;gt; B &amp;lt;- gl(nB, 1, nB, lab = paste(&amp;quot;b&amp;quot;, 1:nB, sep = &amp;quot;&amp;quot;))
&amp;gt; data &amp;lt;- expand.grid(A = A, B = B, n = 1:nsample)
&amp;gt; X &amp;lt;- model.matrix(~A * B, data = data)
&amp;gt; eff &amp;lt;- c(40, 15, 5, 0, -15, 10)
&amp;gt; sigma &amp;lt;- 3  #residual standard deviation
&amp;gt; n &amp;lt;- nrow(data)
&amp;gt; eps &amp;lt;- rnorm(n, 0, sigma)  #residuals
&amp;gt; data$y &amp;lt;- as.numeric(X %*% eff + eps)
&amp;gt; head(data)  #print out the first six rows of the data set
   A  B n        y
1 a1 b1 1 38.31857
2 a2 b1 1 54.30947
3 a1 b2 1 49.67612
4 a2 b2 1 45.21153
5 a1 b3 1 40.38786
6 a2 b3 1 70.14519
&amp;gt; 
&amp;gt; with(data, interaction.plot(A, B, y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/generate_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ## ALTERNATIVELY, we could supply the population means and get the effect parameters from these.  To
&amp;gt; ## correspond to the model matrix, enter the population means in the order of: a1b1, a2b1, a1b1,
&amp;gt; ## a2b2,a1b3,a2b3
&amp;gt; pop.means &amp;lt;- as.matrix(c(40, 55, 45, 45, 40, 65), byrow = F)
&amp;gt; ## Generate a minimum model matrix for the effects
&amp;gt; XX &amp;lt;- model.matrix(~A * B, expand.grid(A = factor(1:2), B = factor(1:3)))
&amp;gt; ## Use the solve() function to solve what are effectively simultaneous equations
&amp;gt; (eff &amp;lt;- as.vector(solve(XX, pop.means)))
[1]  40  15   5   0 -15  10
&amp;gt; 
&amp;gt; data$y &amp;lt;- as.numeric(X %*% eff + eps)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type. Does treatment type effect the response?.&lt;/p&gt;
&lt;div id=&#34;assumptions-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;The assumptions are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All of the observations are independent - this must be addressed at the design and collection stages. Importantly, to be considered independent replicates, the replicates must be made at the same scale at which the treatment is applied. For example, if the experiment involves subjecting organisms housed in tanks to different water temperatures, then the unit of replication is the individual tanks not the individual organisms in the tanks. The individuals in a tank are strictly not independent with respect to the treatment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (and thus the residuals) should be normally distributed for each sampled populations (combination of factors). Boxplots of each treatment combination are useful for diagnosing major issues with normality.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately) for each combination of treatments. Again, boxplots are useful.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ A * B, data)
&amp;gt; 
&amp;gt; # OR via ggplot2
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = y, x = A, fill = B)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/exp1_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity&lt;/p&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X \boldsymbol \beta\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; represents the intercept associated with the first combination of groups, as well as the (effects) differences between this intercept and each other group. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X\)&lt;/span&gt; is the model matrix. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. Exploratory data analysis suggests that the intercept and effects could be drawn from similar distributions (with mean in the &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;’s and variances in the &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;’s). Whilst we might therefore be tempted to provide different priors for the intercept, compared to the effects, for a simple model such as this, it is unlikely to be necessary. However, for more complex models, where prior specification becomes more critical, separate priors would probably be necessary.&lt;/p&gt;
&lt;p&gt;We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Note the following example as group means calculated as derived posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   // Likelihood
+   y~normal(mu,sigma);
+   
+   // Priors
+   beta ~ normal(0,100);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString, con = &amp;quot;fact_anovaModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~A * B, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = Xmat, nX = ncol(Xmat), n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;log_lik&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 500
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 2000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 1500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now compile and run the Stan code via the &lt;code&gt;rstan&lt;/code&gt; interface. Note that the first time &lt;code&gt;stan&lt;/code&gt; is run after the &lt;code&gt;rstan&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;During the warmup stage, the No-U-Turn sampler (NUTS) attempts to determine the optimum stepsize - the stepsize that achieves the target acceptance rate (&lt;span class=&#34;math inline&#34;&gt;\(0.8\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(80\)&lt;/span&gt;% by default) without divergence (occurs when the stepsize is too large relative to the curvature of the log posterior and results in approximations that are likely to diverge and be biased) - and without hitting the maximum treedepth (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;). At each iteration of the NUTS algorithm, the number of leapfrog steps doubles (as it increases the treedepth) and only terminates when either the NUTS criterion are satisfied or the tree depth reaches the maximum (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; by default).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rstan &amp;lt;- stan(data = data.list, file = &amp;quot;fact_anovaModel.stan&amp;quot;, chains = nChains, pars = params,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;fact_anovaModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.065 seconds (Warm-up)
Chain 1:                0.086 seconds (Sampling)
Chain 1:                0.151 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;fact_anovaModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.071 seconds (Warm-up)
Chain 2:                0.088 seconds (Sampling)
Chain 2:                0.159 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.rstan, par = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: fact_anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]  40.19    0.03 0.90  38.43  39.57  40.17  40.81  41.99   710 1.00
beta[2]  14.71    0.05 1.33  12.05  13.83  14.71  15.56  17.39   655 1.01
beta[3]   4.99    0.04 1.29   2.42   4.11   5.03   5.88   7.35   845 1.00
beta[4]  -0.35    0.04 1.29  -2.80  -1.22  -0.37   0.53   2.15   907 1.00
beta[5] -14.51    0.07 1.86 -18.22 -15.78 -14.49 -13.21 -10.84   772 1.00
beta[6]  11.12    0.07 1.85   7.41   9.93  11.15  12.42  14.68   791 1.01
sigma     2.89    0.01 0.28   2.41   2.70   2.88   3.07   3.48  1521 1.00

Samples were drawn using NUTS(diag_e) at Mon Feb 17 11:26:56 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; s = as.array(data.rstan)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, dimnames(s)$parameters)
&amp;gt; s = s[, , wch]
&amp;gt; mcmc &amp;lt;- do.call(mcmc.list, plyr:::alply(s[, , -(length(s[1, 1, ]))], 2, as.mcmc))
&amp;gt; denplot(mcmc, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(mcmc, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(mcmc)
$`1`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

$`2`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; stan_ac(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_rhat(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_ess(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag4-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Rhat and effective sample size. In this instance, most of the parameters have reasonably high effective samples and thus there is likely to be a good range of values from which to estimate paramter properties.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model. Residuals are not computed directly within &lt;code&gt;rstan&lt;/code&gt; However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; library(tidyr)
&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; print(coefs)
    beta[1]     beta[2]     beta[3]     beta[4]     beta[5]     beta[6] 
 40.1693379  14.7128347   5.0341367  -0.3693605 -14.4877785  11.1514524 
&amp;gt; 
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = B)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentized residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; #generate a model matrix
&amp;gt; Xmat = model.matrix(~A*B, data)
&amp;gt; ##get median parameter estimates
&amp;gt; coefs = mcmc[,wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,], mcmc[i, &amp;#39;sigma&amp;#39;]))
&amp;gt; newdata = data.frame(A=data$A, B=data$B, yRep) %&amp;gt;% gather(key=Sample, value=Value,-A,-B)
&amp;gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=A, fill=&amp;#39;Model&amp;#39;), alpha=0.5)+
+  geom_violin(data=data, aes(y=y,x=A,fill=&amp;#39;Obs&amp;#39;), alpha=0.5) +
+  geom_point(data=data, aes(y=y, x=A), position=position_jitter(width=0.1,height=0),
+             color=&amp;#39;black&amp;#39;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=B, fill=&amp;#39;Model&amp;#39;, group=B, color=A), alpha=0.5)+
+  geom_point(data=data, aes(y=y, x=B, group=B,color=A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(as.matrix(data.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(as.matrix(data.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.rstan, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: fact_anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]  40.19    0.03 0.90  38.43  39.57  40.17  40.81  41.99   710 1.00
beta[2]  14.71    0.05 1.33  12.05  13.83  14.71  15.56  17.39   655 1.01
beta[3]   4.99    0.04 1.29   2.42   4.11   5.03   5.88   7.35   845 1.00
beta[4]  -0.35    0.04 1.29  -2.80  -1.22  -0.37   0.53   2.15   907 1.00
beta[5] -14.51    0.07 1.86 -18.22 -15.78 -14.49 -13.21 -10.84   772 1.00
beta[6]  11.12    0.07 1.85   7.41   9.93  11.15  12.42  14.68   791 1.01
sigma     2.89    0.01 0.28   2.41   2.70   2.88   3.07   3.48  1521 1.00

Samples were drawn using NUTS(diag_e) at Mon Feb 17 11:26:56 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(data.rstan, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
# A tibble: 7 x 5
  term    estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]   40.2       0.905    38.5      42.0 
2 beta[2]   14.7       1.33     12.2      17.5 
3 beta[3]    4.99      1.29      2.35      7.29
4 beta[4]   -0.349     1.29     -2.78      2.16
5 beta[5]  -14.5       1.86    -18.4     -11.1 
6 beta[6]   11.1       1.85      7.40     14.7 
7 sigma      2.89      0.279     2.38      3.43&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The intercept represents the mean of the first combination Aa1:Bb1 is &lt;span class=&#34;math inline&#34;&gt;\(40.2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb1 is &lt;span class=&#34;math inline&#34;&gt;\(14.7\)&lt;/span&gt; units greater than Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa1:Bb2 is &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; units greater Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa1:Bb3 is &lt;span class=&#34;math inline&#34;&gt;\(-0.335\)&lt;/span&gt; units greater Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb2 is &lt;span class=&#34;math inline&#34;&gt;\(-14.6\)&lt;/span&gt; units greater than the difference between (Aa1:Bb2 + Aa2:Bb1) and (2*Aa1:Bb1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb3 is &lt;span class=&#34;math inline&#34;&gt;\(11.1\)&lt;/span&gt; units greater than the difference between (Aa1:Bb3 + Aa2:Bb1) and (2*Aa1:Bb1)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility interval for both interactive effects (Aa2:Bb2 and Aa2:Bb3) do not contain &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, implying significant interactions between A and B. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[2]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[3]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[4]&amp;quot;])
[1] 0.777
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[5]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[6]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, c(&amp;quot;beta[5]&amp;quot;, &amp;quot;beta[6]&amp;quot;)])
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence of an interaction between A and B. In a Bayesian context, we can compare models using the &lt;strong&gt;leave-one-out cross-validation&lt;/strong&gt; statistics. Leave-one-out (LOO) cross-validation explores how well a series of models can predict withheld values &lt;span class=&#34;citation&#34;&gt;Vehtari, Gelman, and Gabry (2017)&lt;/span&gt;. The LOO Information Criterion (LOOIC) is analogous to the AIC except that the LOOIC takes priors into consideration, does not assume that the posterior distribution is drawn from a multivariate normal and integrates over parameter uncertainty so as to yield a distribution of looic rather than just a point estimate. The LOOIC does however assume that all observations are equally influential (it does not matter which observations are left out). This assumption can be examined via the Pareto &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; estimate (values greater than &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt; or more conservatively &lt;span class=&#34;math inline&#34;&gt;\(0.75\)&lt;/span&gt; are considered overly influential). We can compute LOOIC if we store the loglikelihood from our &lt;code&gt;STAN&lt;/code&gt; model, which can then be extracted to compute the information criterion using the package &lt;code&gt;loo&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(loo)
&amp;gt; (full = loo(extract_log_lik(data.rstan)))

Computed from 2000 by 60 log-likelihood matrix

         Estimate   SE
elpd_loo   -151.8  5.2
p_loo         6.3  1.1
looic       303.5 10.5
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k &amp;lt; 0.5).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; # now fit a model without main factor
&amp;gt; modelString2 = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   // Likelihood
+   y~normal(mu,sigma);
+   
+   // Priors
+   beta ~ normal(0,1000);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString2, con = &amp;quot;fact_anovaModel2.stan&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~A + B, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = Xmat, n = nrow(data), nX = ncol(Xmat)))
&amp;gt; data.rstan.red &amp;lt;- stan(data = data.list, file = &amp;quot;fact_anovaModel2.stan&amp;quot;, chains = nChains,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;fact_anovaModel2&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.053 seconds (Warm-up)
Chain 1:                0.061 seconds (Sampling)
Chain 1:                0.114 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;fact_anovaModel2&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.056 seconds (Warm-up)
Chain 2:                0.055 seconds (Sampling)
Chain 2:                0.111 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; (reduced = loo(extract_log_lik(data.rstan.red)))

Computed from 2000 by 60 log-likelihood matrix

         Estimate  SE
elpd_loo   -196.6 3.9
p_loo         4.4 0.5
looic       393.2 7.7
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k &amp;lt; 0.5).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; par(mfrow = 1:2, mar = c(5, 3.8, 1, 0) + 0.1, las = 3)
&amp;gt; plot(full, label_points = TRUE)
&amp;gt; plot(reduced, label_points = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_looic-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;the expected out-of-sample predictive accuracy is substantially lower for the model that includes the interaction (full model).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = expand.grid(A=levels(data$A), B=levels(data$B))
&amp;gt; Xmat = model.matrix(~A*B,newdata)
&amp;gt; coefs = mcmc[,wch]
&amp;gt; fit=coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int=TRUE, conf.method=&amp;#39;HPDinterval&amp;#39;))
&amp;gt; newdata
   A  B estimate std.error conf.low conf.high
1 a1 b1 40.18899 0.9047706 38.49347  42.01653
2 a2 b1 54.89674 0.9051450 53.09543  56.61192
3 a1 b2 45.17758 0.9211897 43.52976  47.13596
4 a2 b2 45.37979 0.8898798 43.70321  47.20260
5 a1 b3 39.84017 0.9091679 38.15775  41.68992
6 a2 b3 65.67259 0.9105872 63.89731  67.49493
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y=estimate, x=B, fill=A)) +
+  geom_blank() +
+  geom_line(aes(x=as.numeric(B), linetype=A)) +
+  geom_linerange(aes(ymin=conf.low, ymax=conf.high))+
+  geom_point(aes(shape=A), size=3)+
+  scale_y_continuous(&amp;#39;Y&amp;#39;)+
+  scale_x_discrete(&amp;#39;B&amp;#39;)+
+  scale_shape_manual(&amp;#39;A&amp;#39;,values=c(21,16))+
+  scale_fill_manual(&amp;#39;A&amp;#39;,values=c(&amp;#39;white&amp;#39;,&amp;#39;black&amp;#39;))+
+  scale_linetype_manual(&amp;#39;A&amp;#39;,values=c(&amp;#39;solid&amp;#39;,&amp;#39;dashed&amp;#39;))+
+  theme_classic() +
+  theme(legend.justification=c(0,1), legend.position=c(0.05,1),
+   axis.title.y=element_text(vjust=2, size=rel(1.25)),
+   axis.title.x=element_text(vjust=-2, size=rel(1.25)),
+   plot.margin=unit(c(0.5,0.5,2,2), &amp;#39;lines&amp;#39;),
+   legend.key.size=unit(1,&amp;#39;cm&amp;#39;)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A        10.4     0.942      8.64     12.4 
2 sd.B         3.06    0.634      1.81      4.25
3 sd.AB       10.4     0.734      9.02     11.9 
4 sd.resid     2.84    0.0811     2.72      3.00
# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A         39.1     1.94     35.0       42.6
2 sd.B         11.5     1.90      7.70      15.1
3 sd.AB        39.0     0.946    37.2       41.0
4 sd.resid     10.6     0.862     9.37      12.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/effects_modelv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(39\)&lt;/span&gt;% of the total finite population standard deviation is due to the interaction between factor A and factor B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- as.matrix(data.rstan)
&amp;gt; Xmat = model.matrix(~A * B, data)
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.913   0.00814    0.898     0.925
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ A * B, data))

Call:
lm(formula = y ~ A * B, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5694 -1.8517 -0.0589  1.7120  6.5966 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.1940     0.8980  44.760  &amp;lt; 2e-16 ***
Aa2          14.7163     1.2700  11.588 2.88e-16 ***
Bb2           4.9823     1.2700   3.923 0.000249 ***
Bb3          -0.3464     1.2700  -0.273 0.786077    
Aa2:Bb2     -14.5093     1.7960  -8.079 7.37e-11 ***
Aa2:Bb3      11.1056     1.7960   6.184 8.65e-08 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 2.84 on 54 degrees of freedom
Multiple R-squared:   0.92, Adjusted R-squared:  0.9125 
F-statistic: 124.1 on 5 and 54 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dealing-with-interactions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dealing with interactions&lt;/h1&gt;
&lt;p&gt;In the presence of interations, conclusions about the main effects are overly simplistic at best and completely inaccurate at worst. Therefore, in the presense of interactions we should attempt to tease the analysis appart a little. In the current working example, we have identified that there is a significant interaction between Factor A and Factor B. Our exploration of the regression coefficients, indicated that the pattern between b1, b2 and b3 might differ between a1 and a2. Similarly, if we consider the coefficients from the perspective of Factor A, we can see that the patterns between a1 and a2 are similar for b1 and b3, yet very different for b2.&lt;/p&gt;
&lt;p&gt;At this point, we can then split the two-factor model up into a series of single-factor models, either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;examining the effects of Factor B separately for each level of Factor A (two single-factor models) or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;examining the effects of Factor A separately for each level of Factor B (three single-factor models)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, rather than subset the data and fit isolated smaller models, it is arguably better to treat these explorations as contrasts. As such we could either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;apply specific contrasts to the already fit model&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;define the specific contrasts and use them to refit the model&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will do the former of these options since we have already fit the global model. For this demonstration, we will explore the effect of factor A at each level of factor B. I will illustrate two ways to perform these contrasts on an already fit model:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&amp;gt; Xmat = model.matrix(~A * B, data = newdata)
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; head(fit)
          
iterations        1        2        3        4        5        6
      [1,] 39.69752 55.00221 44.75174 45.00506 40.68290 66.39012
      [2,] 38.09011 54.98489 46.07381 45.40083 40.12613 65.72993
      [3,] 38.43453 55.88735 45.44974 44.95014 39.88235 65.69477
      [4,] 40.62015 55.15234 45.25819 45.63459 39.89825 65.41017
      [5,] 41.36307 54.24942 45.07712 46.12218 39.55757 64.96870
      [6,] 41.36075 54.50463 45.34008 44.16493 38.64767 66.31968
&amp;gt; 
&amp;gt; ## we want to compare columns 2-1, 4-3 and 6-5
&amp;gt; comps = fit[, c(2, 4, 6)] - fit[, c(1, 3, 5)]
&amp;gt; tidyMCMC(comps, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 3 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2       14.7        1.33    12.2      17.5 
2 4        0.202      1.29    -2.37      2.74
3 6       25.8        1.26    23.4      28.3 &lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&amp;gt; Xmat = model.matrix(~A * B, data = newdata)
&amp;gt; contr = attr(Xmat, &amp;quot;contrasts&amp;quot;)
&amp;gt; newdata.a1 = model.frame(~A * B, expand.grid(A = levels(data$A)[1], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&amp;gt; Xmat.a1 = model.matrix(~A * B, data = newdata.a1, contrasts = contr)
&amp;gt; newdata.a2 = model.frame(~A * B, expand.grid(A = levels(data$A)[2], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&amp;gt; Xmat.a2 = model.matrix(~A * B, data = newdata.a2, contrasts = contr)
&amp;gt; Xmat = Xmat.a2 - Xmat.a1
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 3 x 4
  estimate std.error conf.low conf.high
     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1   14.7        1.33    12.2      17.5 
2    0.202      1.29    -2.37      2.74
3   25.8        1.26    23.4      28.3 &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2015stan&#34;&gt;
&lt;p&gt;Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt; 40 (5): 530–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanpackage&#34;&gt;
&lt;p&gt;Stan Development Team. 2018. “RStan: The R Interface to Stan.” &lt;a href=&#34;http://mc-stan.org/&#34;&gt;http://mc-stan.org/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vehtari2017practical&#34;&gt;
&lt;p&gt;Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and Waic.” &lt;em&gt;Statistics and Computing&lt;/em&gt; 27 (5): 1413–32.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Analysis of Covariance - JAGS</title>
      <link>/jags/ancova-jags/ancova-jags/</link>
      <pubDate>Wed, 05 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/ancova-jags/ancova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Previous tutorials have concentrated on designs for either continuous (Regression) or categorical (ANOVA) predictor variables. &lt;em&gt;Analysis of covariance&lt;/em&gt; (ANCOVA) models are essentially ANOVA models that incorporate one or more continuous and categorical variables (covariates). Although the relationship between a response variable and a covariate may itself be of substantial clinical interest, typically covariate(s) are incorporated to reduce the amount of unexplained variability in the model and thereby increase the power of any treatment effects.&lt;/p&gt;
&lt;p&gt;In ANCOVA, a reduction in unexplained variability is achieved by adjusting the response (to each treatment) according to slight differences in the covariate means as well as accounting for any underlying trends between the response and covariate(s). To do so, the extent to which the within treatment group small differences in covariate means between groups and treatment groups are essentially compared via differences in their &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercepts. The total variation is thereafter partitioned into explained (using the deviations between the overall trend and trends approximated for each of the treatment groups) and unexplained components (using the deviations between the observations and the approximated within group trends). In this way, ANCOVA can be visualized as a regular ANOVA in which the group and overall means are replaced by group and overall trendlines. Importantly, it should be apparent that ANCOVA is only appropriate when each of the within group trends have the same slope and are thus parallel to one another and the overall trend. Furthermore, ANCOVA is not appropriate when the resulting adjustments must be extrapolated from a linear relationship outside the measured range of the covariate.&lt;/p&gt;
&lt;p&gt;As an example, an experiment might be set up to investigate the energetic impacts of sexual vs parthenogenetic (egg development without fertilization) reproduction on leaf insect food consumption. To do so, researchers could measure the daily food intake of individual adult female leaf insects from female only (parthenogenetic) and mixed (sexual) populations. Unfortunately, the available individual leaf insects varied substantially in body size which was expected to increase the variability of daily food intake of treatment groups. Consequently, the researchers also measured the body mass of the individuals as a covariate, thereby providing a means by which daily food consumption could be standardized for body mass. ANCOVA attempts to reduce unexplained variability by standardising the response to the treatment by the effects of the specific covariate condition. Thus ANCOVA provides a means of exercising some statistical control over the variability when it is either not possible or not desirable to exercise experimental control (such as blocking or using otherwise homogeneous observations).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Factor A: the main treatment effect&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1(adj)=\mu_2(adj)=\ldots=\mu_i(adj)=\mu(adj)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The adjusted population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; adjusted for the covariate is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; adjusted for the covariate and so on, and thus all population means adjusted for the covariate are equal to an overall adjusted mean. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group adjusted mean and the overall adjusted mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i(adj)=\mu_i(adj)−\mu(adj)\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1(adj)=\alpha_2(adj)=\ldots=\alpha_i(adj)=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The effect of each group equals zero. If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i(adj)\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), the null hypothesis is not true, indicating that the treatment does affect the response variable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B: the covariate effect&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\beta_1(pooled)=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The pooled population slope equals zero. Note, that this null hypothesis is rarely of much interest. It is precisely because of this nuisance relationship that ANCOVA designs are applied.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models&lt;/h2&gt;
&lt;p&gt;One or more covariates can be incorporated into single factor, nested, factorial and partly nested designs in order to reduce the unexplained variation. Fundamentally, the covariate(s) are purely used to adjust the response values prior to the regular analysis. The difficulty is in determining the appropriate adjustments. Following is a list of the appropriate linear models and adjusted response calculations for a range of ANCOVA designs. Note that these linear models do not include interactions involving the covariates as these are assumed to be zero. The inclusion of these interaction terms is a useful means of testing the homogeneity of slopes assumption.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Single categorical and single covariate&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \beta(x_{ij}-\bar{x}) + \epsilon_{ij}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij(adj)}=y_{ij} - b(x_{ij} - \bar{x})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Single categorical and two covariates&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \beta_{YX}(x_{ij}-\bar{x}) + \beta_{YZ}(z_{ij}-\bar{z}) + \epsilon_{ij}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij(adj)}=y_{ij} - b_{YX}(x_{ij} - \bar{x}) - b_{YZ}(z_{ij} - \bar{z})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Factorial designs&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \gamma_j + (\alpha\gamma)_{ij}+ \beta(x_{ijk}-\bar{x}) + \epsilon_{ijk}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk(adj)}=y_{ijk} - b(x_{ijk} - \bar{x})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Nested designs&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk}=\mu + \alpha_i + \gamma_{j(i)} + \beta(x_{ijk}-\bar{x}) + \epsilon_{ijk}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk(adj)}=y_{ijk} - b(x_{ijk} - \bar{x})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Partly nested designs&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijkl}=\mu + \alpha_i + \gamma_{j(i)} + \delta_k + (\alpha\delta)_{ik} + (\gamma\delta)_{j(i)k} + \beta(x_{ijk}-\bar{x}) + \epsilon_{ijkl}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk(adj)}=y_{ijkl} - b_{between}(x_{i} - \bar{x}) - b_{within}(x_{ijk} - \bar{x}_i)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;In ANCOVA, the total variability of the response variable is sequentially partitioned into components explained by each of the model terms, starting with the covariate and is therefore equivalent to performing a regular analysis of variance on the response variables that have been adjusted for the covariate. The appropriate unexplained residuals and therefore the appropriate &lt;em&gt;F-ratios&lt;/em&gt; for each factor differ according to the different null hypotheses associated with different linear models as well as combinations of fixed and random factors in the model (see the following tables). Note that since the covariate levels measured are typically different for each group, ANCOVA designs are inherently non-orthogonal (unbalanced). Consequently, sequential (Type I sums of squares) should not be used. For very simple Ancova designs that incorporate a single categorical and single covariate, Type I sums of squares can be used provided the covariate appears in the linear model first (and thus is partitioned out last) as we are typically not interested in estimating this effect.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ancova_table
          df       MS       F-ratio (A&amp;amp;B fixed) F-ratio (B fixed) 
Factor A  &amp;quot;a-1&amp;quot;    &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot; 
Factor B  &amp;quot;1&amp;quot;      &amp;quot;MS B&amp;quot;   &amp;quot;(MS B)/(MS res)&amp;quot;   &amp;quot;(MS B)/(MS res)&amp;quot; 
Factor AB &amp;quot;a-1&amp;quot;    &amp;quot;MS AB&amp;quot;  &amp;quot;(MS AB)/(MS res)&amp;quot;  &amp;quot;(MS AB)/(MS res)&amp;quot;
Residual  &amp;quot;(n-2)a&amp;quot; &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;                  &amp;quot;&amp;quot;                &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The corresponding &lt;code&gt;R&lt;/code&gt; syntax is given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(DV ~ B * A, dataset))
&amp;gt; # OR
&amp;gt; anova(aov(DV ~ B * A, dataset))
&amp;gt; # OR (make sure not using treatment contrasts)
&amp;gt; Anova(lm(DV ~ B * A, dataset), type = &amp;quot;III&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;As ANCOVA designs are essentially regular ANOVA designs that are first adjusted (centered) for the covariate(s), ANCOVA designs inherit all of the underlying assumptions of the appropriate ANOVA design. Specifically, hypothesis tests assume that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The appropriate residuals are normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator, see the above tables) should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The appropriate residuals are equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The appropriate residuals are independent of one another.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The relationship between the response variable and the covariate should be linear. Linearity can be explored using scatterplots and residual plots should reveal no patterns.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For repeated measures and other designs in which treatment levels within blocks can not be be randomly ordered, the variance/covariance matrix is assumed to display sphericity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For designs that utilise blocking, it is assumed that there are no block by within block interactions.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Homogeneity of Slopes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In addition to the above assumptions, ANCOVA designs also assume that slopes of relationships between the response variable and the covariate(s) are the same for each treatment level (group). That is, all the trends are parallel. If the individual slopes deviate substantially from each other (and thus the overall slope), then adjustments made to each of the observations are nonsensical. This situation is analogous to an interaction between two or more factors. In ANCOVA, interactions involving the covariate suggest that the nature of the relationship between the response and the covariate differs between the levels of the categorical treatment. More importantly, they also indicate that whether or not there is an effect of the treatment depends on what range of the covariate you are focussed on. Clearly then, it is not possible to make conclusions about the main effects of treatments in the presence of such interactions. The assumption of homogeneity of slopes can be examined via interaction plots or more formally, by testing hypotheses about the interactions between categorical variables and the covariate(s). There are three broad approaches for dealing with ANCOVA designs with heterogeneous slopes and selection depends on the primary focus of the study.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;When the primary objective of the analysis is to investigate the effects of categorical treatments, it is possible to adopt an approach similar to that taken when exploring interactions in multiple regression. The effect of treatments can be examined at specific values of the covariate (such as the mean and &lt;span class=&#34;math inline&#34;&gt;\(\pm\)&lt;/span&gt; one standard deviation). This approach is really only useful at revealing broad shifts in patterns over the range of the covariate and if the selected values of the covariate do not have some inherent clinical meaning (selected arbitrarily), then the outcomes can be of only limited clinical interest.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Alternatively, the &lt;em&gt;Johnson-Neyman technique&lt;/em&gt; (or Wilxon modification thereof) procedure indicates the ranges of the covariate over which the individual regression lines of pairs of treatment groups overlap or cross. Although less powerful than the previous approach, the &lt;em&gt;Wilcox(J-N)&lt;/em&gt; procedure has the advantage of revealing the important range (ranges for which the groups are different and not different) of the covariate rather than being constrained by specific levels selected.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use contrast treatments to split up the interaction term into its constituent contrasts for each level of the treatment. Essentially this compares each of the treatment level slopes to the slope from the “control” group and is useful if the primary focus is on the relationships between the response and the covariate.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Similar covariate ranges&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Adjustments made to the response means in an attempt to statistically account for differences in the covariate involve predicting mean response values along displaced linear relationships between the overall response and covariate variables. The degree of trend displacement for any given group is essentially calculated by multiplying the overall regression slope by the degree of difference between the overall covariate mean and the mean of the covariate for that group. However, when the ranges of the covariate within each of the groups differ substantially from one another, these adjustments are effectively extrapolations and therefore of unknown reliability. If a simple ANOVA of the covariate modelled against the categorical factor indicates that the covariate means differ significantly between groups, it may be necessary to either remove extreme observations or reconsider the analysis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Robust ANCOVA&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ANCOVA based on rank transformed data can be useful for accommodating data with numerous problematic outliers. Nevertheless, problems about the difficulties of detecting interactions from rank transformed data, obviously have implications for inferential tests of homogeneity of slopes. Randomisation tests that maintain response0covariate pairs and repeatedly randomise these observations amongst the levels of the treatments can also be useful, particularly when there is doubt over the independence of observations. Both planned and unplanned comparisons follow those of other ANOVA chapters without any real additional complications. Notably, recent implementations of the &lt;em&gt;Tukey’s test&lt;/em&gt; (within &lt;code&gt;R&lt;/code&gt;) accommodate unbalanced designs and thus negate the need for some of the more complicated and specialised techniques that have been highlighted in past texts.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Consider an experimental design aimed at exploring the effects of a categorical variable with three levels (Group A, Group B and Group C) on a response. From previous studies, we know that the response is influenced by another variable (covariate). Unfortunately, it was not possible to ensure that all sampling units were the same degree of the covariate. Therefore, in an attempt to account for this anticipated extra source of variability, we measured the level of the covariate for each sampling unit. Actually, in allocating treatments to the various treatment groups, we tried to ensure a similar mean and range of the covariate within each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n &amp;lt;- 10
&amp;gt; p &amp;lt;- 3
&amp;gt; A.eff &amp;lt;- c(40, -15, -20)
&amp;gt; beta &amp;lt;- -0.45
&amp;gt; sigma &amp;lt;- 4
&amp;gt; B &amp;lt;- rnorm(n * p, 0, 15)
&amp;gt; A &amp;lt;- gl(p, n, lab = paste(&amp;quot;Group&amp;quot;, LETTERS[1:3]))
&amp;gt; mm &amp;lt;- model.matrix(~A + B)
&amp;gt; data &amp;lt;- data.frame(A = A, B = B, Y = as.numeric(c(A.eff, beta) %*% t(mm)) + rnorm(n * p, 0, 4))
&amp;gt; data$B &amp;lt;- data$B + 20
&amp;gt; head(data)
        A        B        Y
1 Group A 11.59287 45.48907
2 Group A 16.54734 40.37341
3 Group A 43.38062 33.05922
4 Group A 21.05763 43.03660
5 Group A 21.93932 42.41363
6 Group A 45.72597 31.17787&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(car)
&amp;gt; scatterplot(Y ~ B | A, data = data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; boxplot(Y ~ A, data)
&amp;gt; 
&amp;gt; # OR via ggplot
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = Y, x = B, group = A)) + geom_point() + geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data, aes(y = Y, x = A)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_data-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is no evidence of obvious non-normality. The assumption of linearity seems reasonable. The variability of the three groups seems approximately equal. The slopes (&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; vs B trends) appear broadly similar for each treatment group.&lt;/p&gt;
&lt;p&gt;We can explore inferential evidence of unequal slopes by examining estimated effects of the interaction between the categorical variable and the covariate. Note, pay no attention to the main effects - only the interaction. Even though I intend to illustrate Bayesian analyses here, for such a simple model, it is considerably simpler to use traditional OLS for testing for the presence of an interaction.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(Y ~ B * A, data = data))
Analysis of Variance Table

Response: Y
          Df  Sum Sq Mean Sq  F value    Pr(&amp;gt;F)    
B          1  989.99  989.99  92.6782 1.027e-09 ***
A          2 2320.05 1160.02 108.5956 9.423e-13 ***
B:A        2   51.36   25.68   2.4041    0.1118    
Residuals 24  256.37   10.68                       
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is very little evidence to suggest that the assumption of equal slopes will be inappropriate.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X \boldsymbol \beta\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; represents the vector of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;’s - the intercept associated with the first group, the (effects) differences between this intercept and the intercepts for each other group as well as the slope associated with the continuous covariate. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X\)&lt;/span&gt; is the model matrix. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. Note, exploratory data analysis suggests that while the intercept (intercept of Group A) and categorical predictor effects (differences between intercepts of each of the Group and Group A’s intercept) could be drawn from a similar distribution (with mean in the &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;’s and variances in the &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;’s), the slope (effect associated with Group A linear relationship) is likely to be an order of magnitude less. We might therefore be tempted to provide different priors for the intercept, categorical effects and slope effect. For a simple model such as this, it is unlikely to be necessary. However, for more complex models, where prior specification becomes more critical, separate priors would probably be necessary.&lt;/p&gt;
&lt;p&gt;We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Note the following example as group means calculated as derived posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau)
+   mean[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   #Priors
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) 
+   }
+   sigma ~ dunif(0, 100)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;ancovaModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X &amp;lt;- model.matrix(~A + B, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = Y, X = X, n = nrow(data), ngroups = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;ancovaModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 30
   Unobserved stochastic nodes: 5
   Total graph size: 224

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;ancovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   51.001   1.529  47.977  50.009  50.995  52.016  53.980 1.001 15000
beta[2]  -16.254   1.623 -19.455 -17.342 -16.259 -15.170 -13.090 1.001 10000
beta[3]  -20.656   1.667 -23.941 -21.752 -20.672 -19.566 -17.330 1.001 15000
beta[4]   -0.484   0.048  -0.577  -0.516  -0.484  -0.453  -0.389 1.001 15000
sigma      3.607   0.526   2.740   3.236   3.546   3.912   4.793 1.001  7400
deviance 160.601   3.509 155.859 158.002 159.905 162.478 169.218 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 6.2 and DIC = 166.8
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trace plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters (such as &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;s).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3689  3746         0.985     
 beta[2]  2        3938  3746         1.050     
 beta[3]  2        3853  3746         1.030     
 beta[4]  2        3811  3746         1.020     
 deviance 2        3895  3746         1.040     
 sigma    5        5552  3746         1.480     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3770  3746         1.010     
 beta[2]  2        3729  3746         0.995     
 beta[3]  2        3811  3746         1.020     
 beta[4]  2        3895  3746         1.040     
 deviance 2        3855  3746         1.030     
 sigma    4        5247  3746         1.400     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
            beta[1]      beta[2]      beta[3]       beta[4]     deviance
Lag 0   1.000000000  1.000000000  1.000000000  1.0000000000  1.000000000
Lag 1   0.017910611 -0.003186598  0.009149022  0.0039919666  0.266991768
Lag 5  -0.004399550 -0.002747041 -0.001891657 -0.0213261543  0.005499734
Lag 10 -0.001972741  0.005855050 -0.004887402  0.0186597337 -0.008683579
Lag 50 -0.002269863  0.015348324 -0.001446494 -0.0004828212 -0.010725173
              sigma
Lag 0   1.000000000
Lag 1   0.382742913
Lag 5   0.007377659
Lag 10 -0.001255836
Lag 50  0.003892668&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.&lt;/p&gt;
&lt;p&gt;There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Standardised residuals&lt;/strong&gt;. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Studentised residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the residuals. Note that &lt;strong&gt;externally studentised residuals&lt;/strong&gt; are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pearson residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%) back thereby allowing us to train the model on &lt;span class=&#34;math inline&#34;&gt;\(75\)&lt;/span&gt;% of the data and then see how well the model can predict the withheld &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.&lt;/p&gt;
&lt;p&gt;Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within &lt;code&gt;JAGS&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$Y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(tidyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$Y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = B)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$Y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~A + B, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:4]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; newdata = data.frame(A = data$A, B = data$B, yRep) %&amp;gt;% gather(key = Sample,
+     value = Value, -A, -B)
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = A, fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_violin(data = data, aes(y = Y, x = A,
+     fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) + geom_point(data = data, aes(y = Y,
+     x = A), position = position_jitter(width = 0.1, height = 0),
+     color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = B, fill = &amp;quot;Model&amp;quot;,
+     group = B, color = A), alpha = 0.5) + geom_point(data = data,
+     aes(y = Y, x = B, group = B, color = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;ancovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   51.001   1.529  47.977  50.009  50.995  52.016  53.980 1.001 15000
beta[2]  -16.254   1.623 -19.455 -17.342 -16.259 -15.170 -13.090 1.001 10000
beta[3]  -20.656   1.667 -23.941 -21.752 -20.672 -19.566 -17.330 1.001 15000
beta[4]   -0.484   0.048  -0.577  -0.516  -0.484  -0.453  -0.389 1.001 15000
sigma      3.607   0.526   2.740   3.236   3.546   3.912   4.793 1.001  7400
deviance 160.601   3.509 155.859 158.002 159.905 162.478 169.218 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 6.2 and DIC = 166.8
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 6 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    51.0      1.53     48.0      53.9  
2 beta[2]   -16.3      1.62    -19.5     -13.1  
3 beta[3]   -20.7      1.67    -23.9     -17.3  
4 beta[4]    -0.484    0.0478   -0.577    -0.389
5 deviance  161.       3.51    155.      167.   
6 sigma       3.61     0.526     2.69      4.70 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The intercept of the first group (Group A) is &lt;span class=&#34;math inline&#34;&gt;\(51\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the second group (Group B) is &lt;span class=&#34;math inline&#34;&gt;\(-16.3\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the third group (Group C) is &lt;span class=&#34;math inline&#34;&gt;\(-20.7\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A one unit increase in B in Group A is associated with a &lt;span class=&#34;math inline&#34;&gt;\(-0.484\)&lt;/span&gt; units increase in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of Group B, Group C and the partial slope associated with B do not overlapp with 0 implying a significant difference between group A and groups B, C and a significant negative relationship with B. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])  # effect of (B-A = 0)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])  # effect of (C-A = 0)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[4]&amp;quot;])  # effect of (slope = 0)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, 2:4])  # effect of (model)
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence that the reponse differs between the groups.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = expand.grid(A = levels(data$A), B = seq(min(data$B), max(data$B),
+     len = 100))
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;, &amp;quot;beta[4]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = B, fill = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~A + B, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$Y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = B, fill = A)) + geom_point(data = rdata,
+     aes(y = partial.resid, x = B, color = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posteriors&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Posteriors&lt;/h1&gt;
&lt;p&gt;In frequentist statistics, when we have more than two groups, we are typically not only interested in whether there is evidence for an overall “effect” of a factor - we are also interested in how various groups compare to one another. To explore these trends, we either compare each group to each other in a pairwise manner (controlling for family-wise Type I error rates) or we explore an independent subset of the possible comparisons. Although these alternate approaches can adequately address a specific research agenda, often they impose severe limitations and compromises on the scope and breadth of questions that can be asked of your data. The reason for these limitations is that in a frequentist framework, any single hypothesis carries with it a (nominally) &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% chance of a false rejection (since it is based on long-run frequency). Thus, performing multiple tests are likely to compound this error rate. The point is, that each comparison is compared to its own probability distribution (and each carries a &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% error rate). By contrast, in Bayesian statistics, all comparisons (contrasts) are drawn from the one (hopefully stable and convergent) posterior distribution and this posterior is invariant to the type and number of comparisons drawn. Hence, the theory clearly indicates that having generated our posterior distribution, we can then query this distribution in any way that we wish thereby allowing us to explore all of our research questions simultaneously.&lt;/p&gt;
&lt;p&gt;Bayesian “contrasts” can be performed either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;within the Bayesian sampling model or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;construct them from the returned MCMC samples (they are drawn from the posteriors)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Only the latter will be demonstrated as it provides a consistent approach across all routines. In order to allow direct comparison to the frequentist equivalents, I will explore the same set of planned and &lt;em&gt;Tukey&lt;/em&gt;’s test comparisons described here. For the “planned comparison” we defined two contrasts: 1) group B vs group C; and 2) group A vs the average of groups B and C. Of course each of these could be explored at multiple values of B, however, since we fit an additive model (which assumes that the slopes are homogeneous), the contrasts will be constant throughout the domain of B.&lt;/p&gt;
&lt;p&gt;Lets start by comparing each group to each other group in a pairwise manner. Arguably the most elegant way to do this is to generate a Tukey’s contrast matrix. This is a model matrix specific to comparing each group to each other group. Again, since the lines are parallel, it does not really matter what level of B we estimate these efffects at - so lets use the mean B.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:4]
&amp;gt; newdata &amp;lt;- data.frame(A = levels(data$A), B = mean(data$B))
&amp;gt; # A Tukeys contrast matrix
&amp;gt; library(multcomp)
&amp;gt; tuk.mat &amp;lt;- contrMat(n = table(newdata$A), type = &amp;quot;Tukey&amp;quot;)
&amp;gt; Xmat &amp;lt;- model.matrix(~A + B, data = newdata)
&amp;gt; pairwise.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; pairwise.mat
                  (Intercept) AGroup B AGroup C B
Group B - Group A           0        1        0 0
Group C - Group A           0        0        1 0
Group C - Group B           0       -1        1 0
&amp;gt; 
&amp;gt; mcmc_areas(coefs %*% t(pairwise.mat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/posterior1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; (comps = tidyMCMC(coefs %*% t(pairwise.mat), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 3 x 5
  term              estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 Group B - Group A   -16.3       1.62   -19.5     -13.1 
2 Group C - Group A   -20.7       1.67   -23.9     -17.3 
3 Group C - Group B    -4.40      1.69    -7.68     -1.04
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/posterior1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With a couple of modifications, we could also express this as percentage changes. A percentage change represents the change (difference between groups) divided by one of the groups (determined by which group you want to express the percentage change to). Hence, we generate an additional mcmc matrix that represents the cell means for the divisor group (group we want to express change relative to). Since the &lt;code&gt;tuk.mat&lt;/code&gt; defines comparisons as &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; pairs, if we simply replace all the &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, the eventual matrix multiplication will result in estimates of the divisor cell means instread of the difference. We can then divide the original mcmc matrix above with this new divisor mcmc matrix to yeild a mcmc matrix of percentage change.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # Modify the tuk.mat to replace -1 with 0.  This will allow us to get a
&amp;gt; # mcmc matrix of ..
&amp;gt; tuk.mat[tuk.mat == -1] = 0
&amp;gt; comp.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; comp.mat
                  (Intercept) AGroup B AGroup C        B
Group B - Group A           1        1        0 19.29344
Group C - Group A           1        0        1 19.29344
Group C - Group B           1        0        1 19.29344
&amp;gt; 
&amp;gt; comp.mcmc = 100 * (coefs %*% t(pairwise.mat))/coefs %*% t(comp.mat)
&amp;gt; (comps = tidyMCMC(comp.mcmc, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 3 x 5
  term              estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 Group B - Group A    -64.3      8.74    -82.4    -48.0 
2 Group C - Group A    -99.0     12.6    -124.     -74.8 
3 Group C - Group B    -21.4      9.02    -39.2     -4.13
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size (%)&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/posterior2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for the specific planned comparisons (Group B vs Group C as well as Group A vs the average of Groups B and C). This is achieved by generating our own contrast matrix (defining the contributions of each group to each contrast).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; c.mat = rbind(c(0, 1, -1), c(1/2, -1/3, -1/3))
&amp;gt; c.mat
     [,1]       [,2]       [,3]
[1,]  0.0  1.0000000 -1.0000000
[2,]  0.5 -0.3333333 -0.3333333
&amp;gt; 
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:4]
&amp;gt; newdata &amp;lt;- data.frame(A = levels(data$A), B = mean(data$B))
&amp;gt; Xmat &amp;lt;- model.matrix(~A + B, data = newdata)
&amp;gt; c.mat = c.mat %*% Xmat
&amp;gt; c.mat
     (Intercept)   AGroup B   AGroup C         B
[1,]   0.0000000  1.0000000 -1.0000000  0.000000
[2,]  -0.1666667 -0.3333333 -0.3333333 -3.215574
&amp;gt; 
&amp;gt; (comps = tidyMCMC(as.mcmc(coefs %*% t(c.mat)), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 2 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1      4.40     1.69      1.04      7.68
2 var2      5.36     0.790     3.80      6.93&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;      beta[1]   beta[2]   beta[3]    beta[4] deviance    sigma
[1,] 49.12140 -12.79223 -18.26477 -0.4972722 161.2762 3.888826
[2,] 51.03351 -16.80051 -20.03944 -0.4767683 156.2198 2.958015
[3,] 51.55756 -16.80292 -20.00531 -0.4479209 161.2724 3.984268
[4,] 50.15508 -15.15637 -21.01837 -0.4787121 158.5376 3.943798
[5,] 52.94683 -17.04043 -22.95279 -0.5209229 157.8834 3.194266
[6,] 52.16920 -17.91313 -23.53270 -0.4678091 159.4251 3.239537
# A tibble: 3 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A         3.12     1.18     0.739      5.41
2 sd.B         7.12     0.703    5.73       8.49
3 sd.resid     3.46     0.169    3.26       3.79
# A tibble: 3 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A         22.9      6.62     8.09      34.1
2 sd.B         52.3      4.54    43.1       61.2
3 sd.resid     24.9      3.22    20.8       31.9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/eff_pop1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(22.9\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat = model.matrix(~A + B, data)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$Y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.905    0.0148    0.877     0.922
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(Y ~ A + B, data))

Call:
lm(formula = Y ~ A + B, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.4381 -2.2244 -0.6829  2.1732  8.6607 

Coefficients:
             Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  51.00608    1.44814   35.22  &amp;lt; 2e-16 ***
AGroup B    -16.25472    1.54125  -10.55 6.92e-11 ***
AGroup C    -20.65596    1.57544  -13.11 5.74e-13 ***
B            -0.48399    0.04526  -10.69 5.14e-11 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 3.44 on 26 degrees of freedom
Multiple R-squared:  0.9149,    Adjusted R-squared:  0.9051 
F-statistic: 93.22 on 3 and 26 DF,  p-value: 4.901e-14&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dealing-with-heterogeneous-slopes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dealing with heterogeneous slopes&lt;/h1&gt;
&lt;p&gt;Generate the data with heterogeneous slope effects.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n &amp;lt;- 10
&amp;gt; p &amp;lt;- 3
&amp;gt; A.eff &amp;lt;- c(40, -15, -20)
&amp;gt; beta &amp;lt;- c(-0.45, -0.1, 0.5)
&amp;gt; sigma &amp;lt;- 4
&amp;gt; B &amp;lt;- rnorm(n * p, 0, 15)
&amp;gt; A &amp;lt;- gl(p, n, lab = paste(&amp;quot;Group&amp;quot;, LETTERS[1:3]))
&amp;gt; mm &amp;lt;- model.matrix(~A * B)
&amp;gt; data1 &amp;lt;- data.frame(A = A, B = B, Y = as.numeric(c(A.eff, beta) %*% t(mm)) + rnorm(n * p, 0, 4))
&amp;gt; data1$B &amp;lt;- data1$B + 20
&amp;gt; head(data1)
        A        B        Y
1 Group A 11.59287 45.48907
2 Group A 16.54734 40.37341
3 Group A 43.38062 33.05922
4 Group A 21.05763 43.03660
5 Group A 21.93932 42.41363
6 Group A 45.72597 31.17787&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; scatterplot(Y ~ B | A, data = data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; boxplot(Y ~ A, data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; # OR via ggplot
&amp;gt; ggplot(data1, aes(y = Y, x = B, group = A)) + geom_point() + geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_het-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data1, aes(y = Y, x = A)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_het-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The slopes (&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; vs B trends) do appear to differ between treatment groups - in particular, Group C seems to portray a different trend to Groups A and B.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(Y ~ B * A, data = data1))
Analysis of Variance Table

Response: Y
          Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
B          1  442.02  442.02  41.380 1.187e-06 ***
A          2 2760.60 1380.30 129.217 1.418e-13 ***
B:A        2  285.75  142.87  13.375 0.0001251 ***
Residuals 24  256.37   10.68                      
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is strong evidence to suggest that the assumption of equal slopes is violated.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fitting the model&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2 = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau)
+   mean[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   #Priors
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) 
+   }
+   sigma ~ dunif(0, 100)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;ancovaModel2.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X &amp;lt;- model.matrix(~A * B, data1)
&amp;gt; data1.list &amp;lt;- with(data1, list(y = Y, X = X, n = nrow(data1), ngroups = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data1.r2jags &amp;lt;- jags(data = data1.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;ancovaModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 30
   Unobserved stochastic nodes: 7
   Total graph size: 286

Initializing model
&amp;gt; 
&amp;gt; print(data1.r2jags)
Inference for Bugs model at &amp;quot;ancovaModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   48.194   2.035  44.200  46.864  48.200  49.531  52.217 1.001 15000
beta[2]  -10.562   2.884 -16.240 -12.453 -10.586  -8.688  -4.814 1.001  8100
beta[3]  -26.538   2.568 -31.636 -28.207 -26.525 -24.858 -21.431 1.001 15000
beta[4]   -0.351   0.082  -0.512  -0.404  -0.351  -0.297  -0.188 1.001 15000
beta[5]   -0.271   0.110  -0.491  -0.344  -0.270  -0.198  -0.055 1.001 15000
beta[6]    0.270   0.117   0.039   0.194   0.270   0.346   0.500 1.001 15000
sigma      3.454   0.535   2.601   3.074   3.396   3.757   4.689 1.002  1800
deviance 157.761   4.417 151.465 154.544 156.990 160.166 168.119 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 9.8 and DIC = 167.5
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MCMC diagnostics&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(data1.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_diag_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data1.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_diag_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trace plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters (such as &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;s).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data1.mcmc = as.mcmc(data1.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data1.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3853  3746         1.030     
 beta[2]  2        3689  3746         0.985     
 beta[3]  2        3895  3746         1.040     
 beta[4]  2        3649  3746         0.974     
 beta[5]  2        3918  3746         1.050     
 beta[6]  2        3770  3746         1.010     
 deviance 2        3938  3746         1.050     
 sigma    4        5018  3746         1.340     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3853  3746         1.030     
 beta[2]  2        3570  3746         0.953     
 beta[3]  2        3811  3746         1.020     
 beta[4]  2        3770  3746         1.010     
 beta[5]  2        3770  3746         1.010     
 beta[6]  2        3895  3746         1.040     
 deviance 2        3981  3746         1.060     
 sigma    4        5131  3746         1.370     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data1.mcmc)
            beta[1]      beta[2]     beta[3]      beta[4]       beta[5]
Lag 0   1.000000000  1.000000000 1.000000000  1.000000000  1.0000000000
Lag 1  -0.002520665 -0.007698073 0.001992162  0.000509790 -0.0005326877
Lag 5   0.001007950  0.009095032 0.001511518 -0.006890623  0.0025773251
Lag 10 -0.011280919  0.007907450 0.005969613 -0.006999313  0.0040454668
Lag 50 -0.012861369 -0.019813696 0.002604518 -0.008791380 -0.0136623372
            beta[6]     deviance        sigma
Lag 0   1.000000000  1.000000000 1.0000000000
Lag 1   0.004381248  0.332075434 0.4518687724
Lag 5  -0.001182603  0.032092130 0.0351574955
Lag 10 -0.004191097  0.003338842 0.0005457235
Lag 50  0.002636154 -0.005426687 0.0039447210&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model validation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data1.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata1 = data1
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:6], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data1$Y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data1.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata1 = newdata1
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:6], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data1$Y - fit
&amp;gt; newdata1 = newdata1 %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata1) + geom_point(aes(y = resid, x = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals2_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata1) + geom_point(aes(y = resid, x = B)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals2_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data1.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata1 = data1
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:6], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data1$Y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data1 = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals3_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data1.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~A * B, data1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:6]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data1), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; newdata1 = data.frame(A = data1$A, B = data1$B, yRep) %&amp;gt;% gather(key = Sample,
+     value = Value, -A, -B)
&amp;gt; ggplot(newdata1) + geom_violin(aes(y = Value, x = A, fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_violin(data = data1, aes(y = Y, x = A,
+     fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) + geom_point(data = data1, aes(y = Y,
+     x = A), position = position_jitter(width = 0.1, height = 0),
+     color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata1) + geom_violin(aes(y = Value, x = B, fill = &amp;quot;Model&amp;quot;,
+     group = B, color = A), alpha = 0.5) + geom_point(data = data1,
+     aes(y = Y, x = B, group = B, color = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_intervals(data1.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep2_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data1.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep2_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parameter estimates&lt;/h2&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data1.r2jags)
Inference for Bugs model at &amp;quot;ancovaModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   48.194   2.035  44.200  46.864  48.200  49.531  52.217 1.001 15000
beta[2]  -10.562   2.884 -16.240 -12.453 -10.586  -8.688  -4.814 1.001  8100
beta[3]  -26.538   2.568 -31.636 -28.207 -26.525 -24.858 -21.431 1.001 15000
beta[4]   -0.351   0.082  -0.512  -0.404  -0.351  -0.297  -0.188 1.001 15000
beta[5]   -0.271   0.110  -0.491  -0.344  -0.270  -0.198  -0.055 1.001 15000
beta[6]    0.270   0.117   0.039   0.194   0.270   0.346   0.500 1.001 15000
sigma      3.454   0.535   2.601   3.074   3.396   3.757   4.689 1.002  1800
deviance 157.761   4.417 151.465 154.544 156.990 160.166 168.119 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 9.8 and DIC = 167.5
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; tidyMCMC(as.mcmc(data1.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 8 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    48.2      2.03    44.2      52.2   
2 beta[2]   -10.6      2.88   -16.3      -4.94  
3 beta[3]   -26.5      2.57   -31.6     -21.4   
4 beta[4]    -0.351    0.0816  -0.510    -0.187 
5 beta[5]    -0.271    0.110   -0.491    -0.0541
6 beta[6]     0.270    0.117    0.0436    0.503 
7 deviance  158.       4.42   151.      167.    
8 sigma       3.45     0.535    2.51      4.50  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The intercept of the first group (Group A) is &lt;span class=&#34;math inline&#34;&gt;\(48.2\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the second group (Group B) is &lt;span class=&#34;math inline&#34;&gt;\(-10.6\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the third group (Group C) is &lt;span class=&#34;math inline&#34;&gt;\(-26.5\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A one unit increase in B in Group A is associated with a &lt;span class=&#34;math inline&#34;&gt;\(-0.351\)&lt;/span&gt; units increase in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;difference in slope between Group B and Group A &lt;span class=&#34;math inline&#34;&gt;\(-0.270\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;difference in slope between Group C and Group A &lt;span class=&#34;math inline&#34;&gt;\(0.270\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of Group B, Group C and the partial slope associated with B do not overlapp with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between group A and groups B, C (at the mean level of predictor B) and a significant negative relationship with B (for Group A). The slope associated with Group B was not found to be significantly different from that associated with Group A, however, the slope associated with Group C was found to be significantly less negative than the slope associated with Group A. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])  # effect of (B-A = 0)
[1] 0.0009333333
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])  # effect of (C-A = 0)
[1] 0
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[4]&amp;quot;])  # effect of (slope = 0)
[1] 0.0003333333
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[5]&amp;quot;])  # effect of (slopeB - slopeA = 0)
[1] 0.0152
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[6]&amp;quot;])  # effect of (slopeC - slopeA = 0)
[1] 0.0232
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, 2:6])  # effect of (model)
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence that the reponse differs between the groups.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graphical summaries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data1.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata1 = expand.grid(A = levels(data1$A), B = seq(min(data1$B), max(data1$B),
+     len = 100))
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;, &amp;quot;beta[4]&amp;quot;, &amp;quot;beta[5]&amp;quot;,
+     &amp;quot;beta[6]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata1 = newdata1 %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata1, aes(y = estimate, x = B, fill = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_post1_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata1 = rdata1 = data1
&amp;gt; fMat = rMat = model.matrix(~A * B, fdata1)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data1$Y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata1 = rdata1 %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; 
&amp;gt; ggplot(newdata1, aes(y = estimate, x = B, fill = A)) + geom_point(data = rdata1,
+     aes(y = partial.resid, x = B, color = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_post2_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Analysis of Covariance - STAN</title>
      <link>/stan/ancova-stan/ancova-stan/</link>
      <pubDate>Wed, 05 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/stan/ancova-stan/ancova-stan/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;STAN&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman, Lee, and Guo (2015)&lt;/span&gt;) using the package &lt;code&gt;rstan&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Stan Development Team (2018)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Previous tutorials have concentrated on designs for either continuous (Regression) or categorical (ANOVA) predictor variables. &lt;em&gt;Analysis of covariance&lt;/em&gt; (ANCOVA) models are essentially ANOVA models that incorporate one or more continuous and categorical variables (covariates). Although the relationship between a response variable and a covariate may itself be of substantial clinical interest, typically covariate(s) are incorporated to reduce the amount of unexplained variability in the model and thereby increase the power of any treatment effects.&lt;/p&gt;
&lt;p&gt;In ANCOVA, a reduction in unexplained variability is achieved by adjusting the response (to each treatment) according to slight differences in the covariate means as well as accounting for any underlying trends between the response and covariate(s). To do so, the extent to which the within treatment group small differences in covariate means between groups and treatment groups are essentially compared via differences in their &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercepts. The total variation is thereafter partitioned into explained (using the deviations between the overall trend and trends approximated for each of the treatment groups) and unexplained components (using the deviations between the observations and the approximated within group trends). In this way, ANCOVA can be visualized as a regular ANOVA in which the group and overall means are replaced by group and overall trendlines. Importantly, it should be apparent that ANCOVA is only appropriate when each of the within group trends have the same slope and are thus parallel to one another and the overall trend. Furthermore, ANCOVA is not appropriate when the resulting adjustments must be extrapolated from a linear relationship outside the measured range of the covariate.&lt;/p&gt;
&lt;p&gt;As an example, an experiment might be set up to investigate the energetic impacts of sexual vs parthenogenetic (egg development without fertilization) reproduction on leaf insect food consumption. To do so, researchers could measure the daily food intake of individual adult female leaf insects from female only (parthenogenetic) and mixed (sexual) populations. Unfortunately, the available individual leaf insects varied substantially in body size which was expected to increase the variability of daily food intake of treatment groups. Consequently, the researchers also measured the body mass of the individuals as a covariate, thereby providing a means by which daily food consumption could be standardized for body mass. ANCOVA attempts to reduce unexplained variability by standardising the response to the treatment by the effects of the specific covariate condition. Thus ANCOVA provides a means of exercising some statistical control over the variability when it is either not possible or not desirable to exercise experimental control (such as blocking or using otherwise homogeneous observations).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Factor A: the main treatment effect&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1(adj)=\mu_2(adj)=\ldots=\mu_i(adj)=\mu(adj)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The adjusted population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; adjusted for the covariate is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; adjusted for the covariate and so on, and thus all population means adjusted for the covariate are equal to an overall adjusted mean. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group adjusted mean and the overall adjusted mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i(adj)=\mu_i(adj)−\mu(adj)\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1(adj)=\alpha_2(adj)=\ldots=\alpha_i(adj)=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The effect of each group equals zero. If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i(adj)\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), the null hypothesis is not true, indicating that the treatment does affect the response variable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B: the covariate effect&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\beta_1(pooled)=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The pooled population slope equals zero. Note, that this null hypothesis is rarely of much interest. It is precisely because of this nuisance relationship that ANCOVA designs are applied.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models&lt;/h2&gt;
&lt;p&gt;One or more covariates can be incorporated into single factor, nested, factorial and partly nested designs in order to reduce the unexplained variation. Fundamentally, the covariate(s) are purely used to adjust the response values prior to the regular analysis. The difficulty is in determining the appropriate adjustments. Following is a list of the appropriate linear models and adjusted response calculations for a range of ANCOVA designs. Note that these linear models do not include interactions involving the covariates as these are assumed to be zero. The inclusion of these interaction terms is a useful means of testing the homogeneity of slopes assumption.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Single categorical and single covariate&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \beta(x_{ij}-\bar{x}) + \epsilon_{ij}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij(adj)}=y_{ij} - b(x_{ij} - \bar{x})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Single categorical and two covariates&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \beta_{YX}(x_{ij}-\bar{x}) + \beta_{YZ}(z_{ij}-\bar{z}) + \epsilon_{ij}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij(adj)}=y_{ij} - b_{YX}(x_{ij} - \bar{x}) - b_{YZ}(z_{ij} - \bar{z})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Factorial designs&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \gamma_j + (\alpha\gamma)_{ij}+ \beta(x_{ijk}-\bar{x}) + \epsilon_{ijk}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk(adj)}=y_{ijk} - b(x_{ijk} - \bar{x})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Nested designs&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk}=\mu + \alpha_i + \gamma_{j(i)} + \beta(x_{ijk}-\bar{x}) + \epsilon_{ijk}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk(adj)}=y_{ijk} - b(x_{ijk} - \bar{x})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Partly nested designs&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijkl}=\mu + \alpha_i + \gamma_{j(i)} + \delta_k + (\alpha\delta)_{ik} + (\gamma\delta)_{j(i)k} + \beta(x_{ijk}-\bar{x}) + \epsilon_{ijkl}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk(adj)}=y_{ijkl} - b_{between}(x_{i} - \bar{x}) - b_{within}(x_{ijk} - \bar{x}_i)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;In ANCOVA, the total variability of the response variable is sequentially partitioned into components explained by each of the model terms, starting with the covariate and is therefore equivalent to performing a regular analysis of variance on the response variables that have been adjusted for the covariate. The appropriate unexplained residuals and therefore the appropriate &lt;em&gt;F-ratios&lt;/em&gt; for each factor differ according to the different null hypotheses associated with different linear models as well as combinations of fixed and random factors in the model (see the following tables). Note that since the covariate levels measured are typically different for each group, ANCOVA designs are inherently non-orthogonal (unbalanced). Consequently, sequential (Type I sums of squares) should not be used. For very simple Ancova designs that incorporate a single categorical and single covariate, Type I sums of squares can be used provided the covariate appears in the linear model first (and thus is partitioned out last) as we are typically not interested in estimating this effect.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ancova_table
          df       MS       F-ratio (A&amp;amp;B fixed) F-ratio (B fixed) 
Factor A  &amp;quot;a-1&amp;quot;    &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot; 
Factor B  &amp;quot;1&amp;quot;      &amp;quot;MS B&amp;quot;   &amp;quot;(MS B)/(MS res)&amp;quot;   &amp;quot;(MS B)/(MS res)&amp;quot; 
Factor AB &amp;quot;a-1&amp;quot;    &amp;quot;MS AB&amp;quot;  &amp;quot;(MS AB)/(MS res)&amp;quot;  &amp;quot;(MS AB)/(MS res)&amp;quot;
Residual  &amp;quot;(n-2)a&amp;quot; &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;                  &amp;quot;&amp;quot;                &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The corresponding &lt;code&gt;R&lt;/code&gt; syntax is given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(DV ~ B * A, dataset))
&amp;gt; # OR
&amp;gt; anova(aov(DV ~ B * A, dataset))
&amp;gt; # OR (make sure not using treatment contrasts)
&amp;gt; Anova(lm(DV ~ B * A, dataset), type = &amp;quot;III&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;As ANCOVA designs are essentially regular ANOVA designs that are first adjusted (centered) for the covariate(s), ANCOVA designs inherit all of the underlying assumptions of the appropriate ANOVA design. Specifically, hypothesis tests assume that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The appropriate residuals are normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator, see the above tables) should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The appropriate residuals are equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The appropriate residuals are independent of one another.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The relationship between the response variable and the covariate should be linear. Linearity can be explored using scatterplots and residual plots should reveal no patterns.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For repeated measures and other designs in which treatment levels within blocks can not be be randomly ordered, the variance/covariance matrix is assumed to display sphericity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For designs that utilise blocking, it is assumed that there are no block by within block interactions.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Homogeneity of Slopes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In addition to the above assumptions, ANCOVA designs also assume that slopes of relationships between the response variable and the covariate(s) are the same for each treatment level (group). That is, all the trends are parallel. If the individual slopes deviate substantially from each other (and thus the overall slope), then adjustments made to each of the observations are nonsensical. This situation is analogous to an interaction between two or more factors. In ANCOVA, interactions involving the covariate suggest that the nature of the relationship between the response and the covariate differs between the levels of the categorical treatment. More importantly, they also indicate that whether or not there is an effect of the treatment depends on what range of the covariate you are focussed on. Clearly then, it is not possible to make conclusions about the main effects of treatments in the presence of such interactions. The assumption of homogeneity of slopes can be examined via interaction plots or more formally, by testing hypotheses about the interactions between categorical variables and the covariate(s). There are three broad approaches for dealing with ANCOVA designs with heterogeneous slopes and selection depends on the primary focus of the study.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;When the primary objective of the analysis is to investigate the effects of categorical treatments, it is possible to adopt an approach similar to that taken when exploring interactions in multiple regression. The effect of treatments can be examined at specific values of the covariate (such as the mean and &lt;span class=&#34;math inline&#34;&gt;\(\pm\)&lt;/span&gt; one standard deviation). This approach is really only useful at revealing broad shifts in patterns over the range of the covariate and if the selected values of the covariate do not have some inherent clinical meaning (selected arbitrarily), then the outcomes can be of only limited clinical interest.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Alternatively, the &lt;em&gt;Johnson-Neyman technique&lt;/em&gt; (or Wilxon modification thereof) procedure indicates the ranges of the covariate over which the individual regression lines of pairs of treatment groups overlap or cross. Although less powerful than the previous approach, the &lt;em&gt;Wilcox(J-N)&lt;/em&gt; procedure has the advantage of revealing the important range (ranges for which the groups are different and not different) of the covariate rather than being constrained by specific levels selected.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use contrast treatments to split up the interaction term into its constituent contrasts for each level of the treatment. Essentially this compares each of the treatment level slopes to the slope from the “control” group and is useful if the primary focus is on the relationships between the response and the covariate.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Similar covariate ranges&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Adjustments made to the response means in an attempt to statistically account for differences in the covariate involve predicting mean response values along displaced linear relationships between the overall response and covariate variables. The degree of trend displacement for any given group is essentially calculated by multiplying the overall regression slope by the degree of difference between the overall covariate mean and the mean of the covariate for that group. However, when the ranges of the covariate within each of the groups differ substantially from one another, these adjustments are effectively extrapolations and therefore of unknown reliability. If a simple ANOVA of the covariate modelled against the categorical factor indicates that the covariate means differ significantly between groups, it may be necessary to either remove extreme observations or reconsider the analysis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Robust ANCOVA&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ANCOVA based on rank transformed data can be useful for accommodating data with numerous problematic outliers. Nevertheless, problems about the difficulties of detecting interactions from rank transformed data, obviously have implications for inferential tests of homogeneity of slopes. Randomisation tests that maintain response0covariate pairs and repeatedly randomise these observations amongst the levels of the treatments can also be useful, particularly when there is doubt over the independence of observations. Both planned and unplanned comparisons follow those of other ANOVA chapters without any real additional complications. Notably, recent implementations of the &lt;em&gt;Tukey’s test&lt;/em&gt; (within &lt;code&gt;R&lt;/code&gt;) accommodate unbalanced designs and thus negate the need for some of the more complicated and specialised techniques that have been highlighted in past texts.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Consider an experimental design aimed at exploring the effects of a categorical variable with three levels (Group A, Group B and Group C) on a response. From previous studies, we know that the response is influenced by another variable (covariate). Unfortunately, it was not possible to ensure that all sampling units were the same degree of the covariate. Therefore, in an attempt to account for this anticipated extra source of variability, we measured the level of the covariate for each sampling unit. Actually, in allocating treatments to the various treatment groups, we tried to ensure a similar mean and range of the covariate within each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n &amp;lt;- 10
&amp;gt; p &amp;lt;- 3
&amp;gt; A.eff &amp;lt;- c(40, -15, -20)
&amp;gt; beta &amp;lt;- -0.45
&amp;gt; sigma &amp;lt;- 4
&amp;gt; B &amp;lt;- rnorm(n * p, 0, 15)
&amp;gt; A &amp;lt;- gl(p, n, lab = paste(&amp;quot;Group&amp;quot;, LETTERS[1:3]))
&amp;gt; mm &amp;lt;- model.matrix(~A + B)
&amp;gt; data &amp;lt;- data.frame(A = A, B = B, Y = as.numeric(c(A.eff, beta) %*% t(mm)) + rnorm(n * p, 0, 4))
&amp;gt; data$B &amp;lt;- data$B + 20
&amp;gt; head(data)
        A        B        Y
1 Group A 11.59287 45.48907
2 Group A 16.54734 40.37341
3 Group A 43.38062 33.05922
4 Group A 21.05763 43.03660
5 Group A 21.93932 42.41363
6 Group A 45.72597 31.17787&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(car)
&amp;gt; scatterplot(Y ~ B | A, data = data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/exp_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; boxplot(Y ~ A, data)
&amp;gt; 
&amp;gt; # OR via ggplot
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/exp_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = Y, x = B, group = A)) + geom_point() + geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/exp_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data, aes(y = Y, x = A)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/exp_data-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is no evidence of obvious non-normality. The assumption of linearity seems reasonable. The variability of the three groups seems approximately equal. The slopes (&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; vs B trends) appear broadly similar for each treatment group.&lt;/p&gt;
&lt;p&gt;We can explore inferential evidence of unequal slopes by examining estimated effects of the interaction between the categorical variable and the covariate. Note, pay no attention to the main effects - only the interaction. Even though I intend to illustrate Bayesian analyses here, for such a simple model, it is considerably simpler to use traditional OLS for testing for the presence of an interaction.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(Y ~ B * A, data = data))
Analysis of Variance Table

Response: Y
          Df  Sum Sq Mean Sq  F value    Pr(&amp;gt;F)    
B          1  989.99  989.99  92.6782 1.027e-09 ***
A          2 2320.05 1160.02 108.5956 9.423e-13 ***
B:A        2   51.36   25.68   2.4041    0.1118    
Residuals 24  256.37   10.68                       
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is very little evidence to suggest that the assumption of equal slopes will be inappropriate.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X \boldsymbol \beta\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; represents the vector of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;’s - the intercept associated with the first group, the (effects) differences between this intercept and the intercepts for each other group as well as the slope associated with the continuous covariate. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X\)&lt;/span&gt; is the model matrix. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. Note, exploratory data analysis suggests that while the intercept (intercept of Group A) and categorical predictor effects (differences between intercepts of each of the Group and Group A’s intercept) could be drawn from a similar distribution (with mean in the &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;’s and variances in the &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;’s), the slope (effect associated with Group A linear relationship) is likely to be an order of magnitude less. We might therefore be tempted to provide different priors for the intercept, categorical effects and slope effect. For a simple model such as this, it is unlikely to be necessary. However, for more complex models, where prior specification becomes more critical, separate priors would probably be necessary.&lt;/p&gt;
&lt;p&gt;We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Note the following example as group means calculated as derived posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   //Likelihood
+   y~normal(mu,sigma);
+   
+   //Priors
+   beta ~ normal(0,100);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString, con = &amp;quot;ancovaModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~A + B, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = Y, X = Xmat, nX = ncol(Xmat), n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;log_lik&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 500
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 2000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 1500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now compile and run the Stan code via the &lt;code&gt;rstan&lt;/code&gt; interface. Note that the first time &lt;code&gt;stan&lt;/code&gt; is run after the &lt;code&gt;rstan&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;During the warmup stage, the No-U-Turn sampler (NUTS) attempts to determine the optimum stepsize - the stepsize that achieves the target acceptance rate (&lt;span class=&#34;math inline&#34;&gt;\(0.8\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(80\)&lt;/span&gt;% by default) without divergence (occurs when the stepsize is too large relative to the curvature of the log posterior and results in approximations that are likely to diverge and be biased) - and without hitting the maximum treedepth (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;). At each iteration of the NUTS algorithm, the number of leapfrog steps doubles (as it increases the treedepth) and only terminates when either the NUTS criterion are satisfied or the tree depth reaches the maximum (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; by default).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rstan &amp;lt;- stan(data = data.list, file = &amp;quot;ancovaModel.stan&amp;quot;, chains = nChains, pars = params,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;ancovaModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.087 seconds (Warm-up)
Chain 1:                0.07 seconds (Sampling)
Chain 1:                0.157 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;ancovaModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.105 seconds (Warm-up)
Chain 2:                0.069 seconds (Sampling)
Chain 2:                0.174 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.rstan, par = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: ancovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]  50.95    0.05 1.46  48.08  50.00  50.93  51.85  53.86   949 1.01
beta[2] -16.23    0.04 1.55 -19.25 -17.24 -16.18 -15.24 -13.12  1322 1.00
beta[3] -20.60    0.04 1.52 -23.56 -21.58 -20.61 -19.61 -17.55  1430 1.00
beta[4]  -0.48    0.00 0.05  -0.57  -0.51  -0.48  -0.45  -0.40  1068 1.01
sigma     3.55    0.02 0.52   2.69   3.17   3.48   3.87   4.67  1175 1.00

Samples were drawn using NUTS(diag_e) at Mon Feb 17 11:24:26 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; s = as.array(data.rstan)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, dimnames(s)$parameters)
&amp;gt; s = s[, , wch]
&amp;gt; mcmc &amp;lt;- do.call(mcmc.list, plyr:::alply(s[, , -(length(s[1, 1, ]))], 2, as.mcmc))
&amp;gt; denplot(mcmc, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(mcmc, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(mcmc)
$`1`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

$`2`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; stan_ac(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_diag3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_rhat(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_diag4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_ess(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_diag4-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Rhat and effective sample size. In this instance, most of the parameters have reasonably high effective samples and thus there is likely to be a good range of values from which to estimate paramter properties.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model. Residuals are not computed directly within &lt;code&gt;rstan&lt;/code&gt; However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$Y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(tidyr)
&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$Y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = B)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_residuals2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$Y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentized residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~A + B, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:4]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; newdata = data.frame(A = data$A, B = data$B, yRep) %&amp;gt;% gather(key = Sample,
+     value = Value, -A, -B)
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = A, fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_violin(data = data, aes(y = Y, x = A,
+     fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) + geom_point(data = data, aes(y = Y,
+     x = A), position = position_jitter(width = 0.1, height = 0),
+     color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = B, fill = &amp;quot;Model&amp;quot;,
+     group = B, color = A), alpha = 0.5) + geom_point(data = data,
+     aes(y = Y, x = B, group = B, color = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_rep-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(as.matrix(data.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(as.matrix(data.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.rstan, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: ancovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]  50.95    0.05 1.46  48.08  50.00  50.93  51.85  53.86   949 1.01
beta[2] -16.23    0.04 1.55 -19.25 -17.24 -16.18 -15.24 -13.12  1322 1.00
beta[3] -20.60    0.04 1.52 -23.56 -21.58 -20.61 -19.61 -17.55  1430 1.00
beta[4]  -0.48    0.00 0.05  -0.57  -0.51  -0.48  -0.45  -0.40  1068 1.01
sigma     3.55    0.02 0.52   2.69   3.17   3.48   3.87   4.67  1175 1.00

Samples were drawn using NUTS(diag_e) at Mon Feb 17 11:24:26 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(data.rstan, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
# A tibble: 5 x 5
  term    estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]   51.0      1.46     48.0      53.8  
2 beta[2]  -16.2      1.55    -19.3     -13.3  
3 beta[3]  -20.6      1.52    -23.4     -17.5  
4 beta[4]   -0.483    0.0460   -0.569    -0.392
5 sigma      3.55     0.524     2.69      4.67 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The intercept of the first group (Group A) is &lt;span class=&#34;math inline&#34;&gt;\(51\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the second group (Group B) is &lt;span class=&#34;math inline&#34;&gt;\(-16.3\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the third group (Group C) is &lt;span class=&#34;math inline&#34;&gt;\(-20.7\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A one unit increase in B in Group A is associated with a &lt;span class=&#34;math inline&#34;&gt;\(-0.484\)&lt;/span&gt; units increase in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of Group B, Group C and the partial slope associated with B do not overlapp with 0 implying a significant difference between group A and groups B, C and a significant negative relationship with B. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[2]&amp;quot;])  # effect of (B-A = 0)
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[3]&amp;quot;])  # effect of (C-A = 0)
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[4]&amp;quot;])  # effect of (slope = 0)
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, 2:4])  # effect of (model)
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence that the reponse differs between the groups. There is evidence suggesting that the response of group D differs from that of group A. In a Bayesian context, we can compare models using the &lt;strong&gt;leave-one-out cross-validation&lt;/strong&gt; statistics. Leave-one-out (LOO) cross-validation explores how well a series of models can predict withheld values &lt;span class=&#34;citation&#34;&gt;Vehtari, Gelman, and Gabry (2017)&lt;/span&gt;. The LOO Information Criterion (LOOIC) is analogous to the AIC except that the LOOIC takes priors into consideration, does not assume that the posterior distribution is drawn from a multivariate normal and integrates over parameter uncertainty so as to yield a distribution of looic rather than just a point estimate. The LOOIC does however assume that all observations are equally influential (it does not matter which observations are left out). This assumption can be examined via the Pareto &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; estimate (values greater than &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt; or more conservatively &lt;span class=&#34;math inline&#34;&gt;\(0.75\)&lt;/span&gt; are considered overly influential). We can compute LOOIC if we store the loglikelihood from our &lt;code&gt;STAN&lt;/code&gt; model, which can then be extracted to compute the information criterion using the package &lt;code&gt;loo&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(loo)
&amp;gt; (full = loo(extract_log_lik(data.rstan)))

Computed from 2000 by 30 log-likelihood matrix

         Estimate  SE
elpd_loo    -83.1 4.4
p_loo         4.9 1.4
looic       166.2 8.9
------
Monte Carlo SE of elpd_loo is 0.1.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     28    93.3%   269       
 (0.5, 0.7]   (ok)        2     6.7%   371       
   (0.7, 1]   (bad)       0     0.0%   &amp;lt;NA&amp;gt;      
   (1, Inf)   (very bad)  0     0.0%   &amp;lt;NA&amp;gt;      

All Pareto k estimates are ok (k &amp;lt; 0.7).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; # now fit a model without main factor
&amp;gt; modelString2 = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   // Likelihood
+   y~normal(mu,sigma);
+   
+   // Priors
+   beta ~ normal(0,1000);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString2, con = &amp;quot;ancovaModel2.stan&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~1, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = Y, X = Xmat, n = nrow(data), nX = ncol(Xmat)))
&amp;gt; data.rstan.red &amp;lt;- stan(data = data.list, file = &amp;quot;ancovaModel2.stan&amp;quot;, chains = nChains,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;ancovaModel2&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.018 seconds (Warm-up)
Chain 1:                0.026 seconds (Sampling)
Chain 1:                0.044 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;ancovaModel2&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.019 seconds (Warm-up)
Chain 2:                0.022 seconds (Sampling)
Chain 2:                0.041 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; (reduced = loo(extract_log_lik(data.rstan.red)))

Computed from 2000 by 30 log-likelihood matrix

         Estimate  SE
elpd_loo   -116.3 3.1
p_loo         1.6 0.3
looic       232.6 6.2
------
Monte Carlo SE of elpd_loo is 0.0.

All Pareto k estimates are good (k &amp;lt; 0.5).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; par(mfrow = 1:2, mar = c(5, 3.8, 1, 0) + 0.1, las = 3)
&amp;gt; plot(full, label_points = TRUE)
&amp;gt; plot(reduced, label_points = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_looic-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The expected out-of-sample predictive accuracy is substantially lower for the model that includes &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. This might be used to suggest that the inferential evidence for a general effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = expand.grid(A = levels(data$A), B = seq(min(data$B), max(data$B),
+     len = 100))
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;, &amp;quot;beta[4]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = B, fill = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~A + B, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$Y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = B, fill = A)) + geom_point(data = rdata,
+     aes(y = partial.resid, x = B, color = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posteriors&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Posteriors&lt;/h1&gt;
&lt;p&gt;In frequentist statistics, when we have more than two groups, we are typically not only interested in whether there is evidence for an overall “effect” of a factor - we are also interested in how various groups compare to one another. To explore these trends, we either compare each group to each other in a pairwise manner (controlling for family-wise Type I error rates) or we explore an independent subset of the possible comparisons. Although these alternate approaches can adequately address a specific research agenda, often they impose severe limitations and compromises on the scope and breadth of questions that can be asked of your data. The reason for these limitations is that in a frequentist framework, any single hypothesis carries with it a (nominally) &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% chance of a false rejection (since it is based on long-run frequency). Thus, performing multiple tests are likely to compound this error rate. The point is, that each comparison is compared to its own probability distribution (and each carries a &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% error rate). By contrast, in Bayesian statistics, all comparisons (contrasts) are drawn from the one (hopefully stable and convergent) posterior distribution and this posterior is invariant to the type and number of comparisons drawn. Hence, the theory clearly indicates that having generated our posterior distribution, we can then query this distribution in any way that we wish thereby allowing us to explore all of our research questions simultaneously.&lt;/p&gt;
&lt;p&gt;Bayesian “contrasts” can be performed either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;within the Bayesian sampling model or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;construct them from the returned MCMC samples (they are drawn from the posteriors)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Only the latter will be demonstrated as it provides a consistent approach across all routines. In order to allow direct comparison to the frequentist equivalents, I will explore the same set of planned and &lt;em&gt;Tukey&lt;/em&gt;’s test comparisons described here. For the “planned comparison” we defined two contrasts: 1) group B vs group C; and 2) group A vs the average of groups B and C. Of course each of these could be explored at multiple values of B, however, since we fit an additive model (which assumes that the slopes are homogeneous), the contrasts will be constant throughout the domain of B.&lt;/p&gt;
&lt;p&gt;Lets start by comparing each group to each other group in a pairwise manner. Arguably the most elegant way to do this is to generate a Tukey’s contrast matrix. This is a model matrix specific to comparing each group to each other group. Again, since the lines are parallel, it does not really matter what level of B we estimate these efffects at - so lets use the mean B.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.rstan
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:4]
&amp;gt; newdata &amp;lt;- data.frame(A = levels(data$A), B = mean(data$B))
&amp;gt; # A Tukeys contrast matrix
&amp;gt; library(multcomp)
&amp;gt; tuk.mat &amp;lt;- contrMat(n = table(newdata$A), type = &amp;quot;Tukey&amp;quot;)
&amp;gt; Xmat &amp;lt;- model.matrix(~A + B, data = newdata)
&amp;gt; pairwise.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; pairwise.mat
                  (Intercept) AGroup B AGroup C B
Group B - Group A           0        1        0 0
Group C - Group A           0        0        1 0
Group C - Group B           0       -1        1 0
&amp;gt; 
&amp;gt; mcmc_areas(coefs %*% t(pairwise.mat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/posterior1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; (comps = tidyMCMC(coefs %*% t(pairwise.mat), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 3 x 5
  term              estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 Group B - Group A   -16.2       1.55   -19.3    -13.3  
2 Group C - Group A   -20.6       1.52   -23.4    -17.5  
3 Group C - Group B    -4.37      1.59    -7.30    -0.949
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/posterior1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With a couple of modifications, we could also express this as percentage changes. A percentage change represents the change (difference between groups) divided by one of the groups (determined by which group you want to express the percentage change to). Hence, we generate an additional mcmc matrix that represents the cell means for the divisor group (group we want to express change relative to). Since the &lt;code&gt;tuk.mat&lt;/code&gt; defines comparisons as &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; pairs, if we simply replace all the &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, the eventual matrix multiplication will result in estimates of the divisor cell means instread of the difference. We can then divide the original mcmc matrix above with this new divisor mcmc matrix to yeild a mcmc matrix of percentage change.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # Modify the tuk.mat to replace -1 with 0.  This will allow us to get a
&amp;gt; # mcmc matrix of ..
&amp;gt; tuk.mat[tuk.mat == -1] = 0
&amp;gt; comp.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; comp.mat
                  (Intercept) AGroup B AGroup C        B
Group B - Group A           1        1        0 19.29344
Group C - Group A           1        0        1 19.29344
Group C - Group B           1        0        1 19.29344
&amp;gt; 
&amp;gt; comp.mcmc = 100 * (coefs %*% t(pairwise.mat))/coefs %*% t(comp.mat)
&amp;gt; (comps = tidyMCMC(comp.mcmc, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 3 x 5
  term              estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 Group B - Group A    -64.2      8.46    -80.3    -47.3 
2 Group C - Group A    -98.5     11.7    -120.     -74.6 
3 Group C - Group B    -21.1      8.48    -36.2     -3.13
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size (%)&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/posterior2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for the specific planned comparisons (Group B vs Group C as well as Group A vs the average of Groups B and C). This is achieved by generating our own contrast matrix (defining the contributions of each group to each contrast).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; c.mat = rbind(c(0, 1, -1), c(1/2, -1/3, -1/3))
&amp;gt; c.mat
     [,1]       [,2]       [,3]
[1,]  0.0  1.0000000 -1.0000000
[2,]  0.5 -0.3333333 -0.3333333
&amp;gt; 
&amp;gt; mcmc = data.rstan
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:4]
&amp;gt; newdata &amp;lt;- data.frame(A = levels(data$A), B = mean(data$B))
&amp;gt; Xmat &amp;lt;- model.matrix(~A + B, data = newdata)
&amp;gt; c.mat = c.mat %*% Xmat
&amp;gt; c.mat
     (Intercept)   AGroup B   AGroup C         B
[1,]   0.0000000  1.0000000 -1.0000000  0.000000
[2,]  -0.1666667 -0.3333333 -0.3333333 -3.215574
&amp;gt; 
&amp;gt; (comps = tidyMCMC(as.mcmc(coefs %*% t(c.mat)), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 2 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1      4.37     1.59     0.949      7.30
2 var2      5.34     0.739    3.93       6.83&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;          parameters
iterations  beta[1]   beta[2]   beta[3]    beta[4]    sigma log_lik[1]
      [1,] 50.10205 -15.67611 -17.41476 -0.4593792 2.882566  -2.008171
      [2,] 50.53300 -15.15556 -21.29190 -0.4213328 3.333128  -2.123994
      [3,] 50.82345 -16.88383 -18.55789 -0.4953391 3.187249  -2.086291
      [4,] 51.07765 -16.56728 -18.11673 -0.4914285 3.229001  -2.091676
      [5,] 50.86176 -17.23601 -22.42360 -0.4583002 3.709629  -2.230000
      [6,] 50.54948 -17.18733 -22.94231 -0.4507465 3.679292  -2.222665
          parameters
iterations log_lik[2] log_lik[3] log_lik[4] log_lik[5] log_lik[6] log_lik[7]
      [1,]  -2.249891  -2.478578  -2.386901  -2.321355  -2.238304  -2.089910
      [2,]  -2.580156  -2.151935  -2.208046  -2.179748  -2.123208  -2.123205
      [3,]  -2.328045  -2.760643  -2.422131  -2.375369  -2.522340  -2.206070
      [4,]  -2.408442  -2.613356  -2.346400  -2.306150  -2.408162  -2.166403
      [5,]  -2.536428  -2.386884  -2.350958  -2.323661  -2.288689  -2.241980
      [6,]  -2.494402  -2.378916  -2.366281  -2.335190  -2.278379  -2.239055
          parameters
iterations log_lik[8] log_lik[9] log_lik[10] log_lik[11] log_lik[12]
      [1,]  -2.085684  -2.278190   -2.353424   -2.464663   -2.040152
      [2,]  -2.270293  -2.537363   -2.654372   -3.366142   -2.511113
      [3,]  -2.279861  -2.412778   -2.448060   -2.125289   -2.085211
      [4,]  -2.341028  -2.494345   -2.536601   -2.229693   -2.095141
      [5,]  -2.390241  -2.557991   -2.619126   -2.387999   -2.232080
      [6,]  -2.340846  -2.504261   -2.567828   -2.386463   -2.222788
          parameters
iterations log_lik[13] log_lik[14] log_lik[15] log_lik[16] log_lik[17]
      [1,]   -3.632110   -6.277306   -3.204443   -3.185018   -2.168245
      [2,]   -4.446037   -4.129568   -2.560973   -4.463466   -2.764685
      [3,]   -2.797030   -6.726618   -3.524519   -2.340742   -2.082699
      [4,]   -3.059757   -6.029865   -3.198127   -2.541258   -2.137540
      [5,]   -2.956316   -5.325142   -3.251598   -2.735297   -2.266883
      [6,]   -2.938129   -5.436729   -3.330196   -2.760533   -2.255217
          parameters
iterations log_lik[18] log_lik[19] log_lik[20] log_lik[21] log_lik[22]
      [1,]   -2.318947   -2.512054   -2.002140   -2.395950   -2.776903
      [2,]   -2.520307   -2.156718   -2.317741   -2.142335   -2.154221
      [3,]   -2.324384   -3.103347   -2.082892   -2.289348   -2.416272
      [4,]   -2.459206   -2.810777   -2.095693   -2.462432   -2.639612
      [5,]   -2.319568   -2.740113   -2.230665   -2.323836   -2.242369
      [6,]   -2.278072   -2.749544   -2.225301   -2.436018   -2.283231
          parameters
iterations log_lik[23] log_lik[24] log_lik[25] log_lik[26] log_lik[27]
      [1,]   -2.853655   -2.188530   -3.191131   -2.303986   -7.496570
      [2,]   -2.136205   -3.236045   -2.217312   -3.730505   -4.567220
      [3,]   -2.590975   -2.415939   -2.747167   -2.400663   -5.215582
      [4,]   -2.836079   -2.262250   -3.029609   -2.261575   -5.810429
      [5,]   -2.236545   -3.586947   -2.232197   -3.804767   -3.274838
      [6,]   -2.277066   -3.966924   -2.230807   -4.274277   -3.064820
          parameters
iterations log_lik[28] log_lik[29] log_lik[30]      lp__
      [1,]   -2.055777   -2.580174   -2.341634 -54.29289
      [2,]   -2.218528   -2.124156   -2.133648 -52.60671
      [3,]   -2.078444   -2.420461   -2.098403 -51.48189
      [4,]   -2.114514   -2.627423   -2.197494 -52.37989
      [5,]   -2.575753   -2.272372   -2.340851 -50.99091
      [6,]   -2.740488   -2.353656   -2.414602 -52.08341
# A tibble: 3 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A         3.10     1.12     0.681      5.16
2 sd.B         7.11     0.677    5.77       8.38
3 sd.resid     3.44     0.158    3.26       3.73
# A tibble: 3 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A         22.9      6.30     9.80      34.7
2 sd.B         52.4      4.30    44.0       61.0
3 sd.resid     24.8      3.04    20.9       31.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/effects_modelv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(22.86\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- as.matrix(data.rstan)
&amp;gt; Xmat = model.matrix(~A + B, data)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$Y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.906    0.0136    0.879     0.922
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(Y ~ A + B, data))

Call:
lm(formula = Y ~ A + B, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.4381 -2.2244 -0.6829  2.1732  8.6607 

Coefficients:
             Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  51.00608    1.44814   35.22  &amp;lt; 2e-16 ***
AGroup B    -16.25472    1.54125  -10.55 6.92e-11 ***
AGroup C    -20.65596    1.57544  -13.11 5.74e-13 ***
B            -0.48399    0.04526  -10.69 5.14e-11 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 3.44 on 26 degrees of freedom
Multiple R-squared:  0.9149,    Adjusted R-squared:  0.9051 
F-statistic: 93.22 on 3 and 26 DF,  p-value: 4.901e-14&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dealing-with-heterogeneous-slopes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dealing with heterogeneous slopes&lt;/h1&gt;
&lt;p&gt;Generate the data with heterogeneous slope effects.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n &amp;lt;- 10
&amp;gt; p &amp;lt;- 3
&amp;gt; A.eff &amp;lt;- c(40, -15, -20)
&amp;gt; beta &amp;lt;- c(-0.45, -0.1, 0.5)
&amp;gt; sigma &amp;lt;- 4
&amp;gt; B &amp;lt;- rnorm(n * p, 0, 15)
&amp;gt; A &amp;lt;- gl(p, n, lab = paste(&amp;quot;Group&amp;quot;, LETTERS[1:3]))
&amp;gt; mm &amp;lt;- model.matrix(~A * B)
&amp;gt; data1 &amp;lt;- data.frame(A = A, B = B, Y = as.numeric(c(A.eff, beta) %*% t(mm)) + rnorm(n * p, 0, 4))
&amp;gt; data1$B &amp;lt;- data1$B + 20
&amp;gt; head(data1)
        A        B        Y
1 Group A 11.59287 45.48907
2 Group A 16.54734 40.37341
3 Group A 43.38062 33.05922
4 Group A 21.05763 43.03660
5 Group A 21.93932 42.41363
6 Group A 45.72597 31.17787&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; scatterplot(Y ~ B | A, data = data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/exp_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; boxplot(Y ~ A, data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/exp_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; # OR via ggplot
&amp;gt; ggplot(data1, aes(y = Y, x = B, group = A)) + geom_point() + geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/exp_het-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data1, aes(y = Y, x = A)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/exp_het-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The slopes (&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; vs B trends) do appear to differ between treatment groups - in particular, Group C seems to portray a different trend to Groups A and B.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(Y ~ B * A, data = data1))
Analysis of Variance Table

Response: Y
          Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
B          1  442.02  442.02  41.380 1.187e-06 ***
A          2 2760.60 1380.30 129.217 1.418e-13 ***
B:A        2  285.75  142.87  13.375 0.0001251 ***
Residuals 24  256.37   10.68                      
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is strong evidence to suggest that the assumption of equal slopes is violated.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fitting the model&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2 = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   // Likelihood
+   y~normal(mu,sigma);
+   
+   // Priors
+   beta ~ normal(0,100);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;ancovaModel2.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~A * B, data1)
&amp;gt; data1.list &amp;lt;- with(data1, list(y = Y, X = Xmat, nX = ncol(Xmat), n = nrow(data1)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;log_lik&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 500
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 2000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 1500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data1.rstan &amp;lt;- stan(data = data1.list, file = &amp;quot;ancovaModel2.stan&amp;quot;, chains = nChains, pars = params,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;ancovaModel2&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.001 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 10 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.107 seconds (Warm-up)
Chain 1:                0.091 seconds (Sampling)
Chain 1:                0.198 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;ancovaModel2&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.13 seconds (Warm-up)
Chain 2:                0.102 seconds (Sampling)
Chain 2:                0.232 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data1.rstan, par = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: ancovaModel2.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]  48.14    0.09 2.00  44.21  46.88  48.13  49.45  52.06   541    1
beta[2] -10.58    0.11 2.83 -16.17 -12.34 -10.58  -8.77  -4.81   621    1
beta[3] -26.48    0.11 2.58 -31.66 -28.17 -26.48 -24.71 -21.48   551    1
beta[4]  -0.35    0.00 0.08  -0.50  -0.40  -0.35  -0.30  -0.20   555    1
beta[5]  -0.27    0.00 0.11  -0.48  -0.34  -0.27  -0.20  -0.05   597    1
beta[6]   0.27    0.00 0.12   0.04   0.20   0.27   0.35   0.50   552    1
sigma     3.39    0.02 0.50   2.57   3.02   3.33   3.67   4.50  1108    1

Samples were drawn using NUTS(diag_e) at Mon Feb 17 11:26:00 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MCMC diagnostics&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- As.mcmc.list(data1.rstan)
&amp;gt; 
&amp;gt; denplot(mcmc, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_diag_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(mcmc, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_diag_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trace plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters (such as &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;s).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(mcmc)
            beta[1]      beta[2]     beta[3]      beta[4]     beta[5]
Lag 0   1.000000000  1.000000000  1.00000000  1.000000000  1.00000000
Lag 1   0.487975871  0.425019403  0.44941737  0.460836797  0.46355010
Lag 5   0.088899283  0.062327893  0.08476067  0.087316054  0.05016421
Lag 10  0.007454517 -0.003124592 -0.00632013 -0.031363005 -0.02547379
Lag 50 -0.014702929 -0.011159634  0.01546605  0.007422907 -0.02987378
            beta[6]        sigma   log_lik[1]   log_lik[2]   log_lik[3]
Lag 0   1.000000000  1.000000000 1.0000000000  1.000000000  1.000000000
Lag 1   0.407845502  0.229381985 0.3229947423  0.148911691  0.246151735
Lag 5   0.108990741  0.013015911 0.0359928135  0.007106644 -0.041606834
Lag 10 -0.002789907 -0.006160622 0.0074013124  0.034867394  0.005265643
Lag 50  0.021062271 -0.011828026 0.0004208875 -0.010961206 -0.036358518
          log_lik[4]   log_lik[5]   log_lik[6]   log_lik[7] log_lik[8]
Lag 0   1.0000000000  1.000000000  1.000000000  1.000000000 1.00000000
Lag 1   0.0851487042  0.097545282  0.204344885  0.269672389 0.38558262
Lag 5  -0.0003507043  0.002305382 -0.049386304 -0.000960398 0.02069575
Lag 10 -0.0166774245 -0.025515245 -0.001912747 -0.016722339 0.04889381
Lag 50 -0.0162443058 -0.014714579 -0.011135106 -0.014633639 0.01680510
        log_lik[9]  log_lik[10] log_lik[11]  log_lik[12]  log_lik[13]
Lag 0  1.000000000  1.000000000  1.00000000  1.000000000  1.000000000
Lag 1  0.313784783  0.237324163  0.09482508  0.227340224 -0.047089190
Lag 5  0.056460648  0.037850329 -0.03382433  0.001289457  0.011086069
Lag 10 0.035202184  0.034879805 -0.07137294 -0.040985200 -0.021897934
Lag 50 0.008974814 -0.006569175  0.04107530  0.028135748  0.006235697
        log_lik[14]  log_lik[15] log_lik[16]  log_lik[17] log_lik[18]
Lag 0   1.000000000  1.000000000  1.00000000  1.000000000  1.00000000
Lag 1   0.066779275  0.012761718  0.05153404  0.139497451  0.06864146
Lag 5   0.021390228  0.036712340 -0.04509391 -0.007858839  0.03114302
Lag 10 -0.039601576  0.009368704 -0.06501412 -0.061861469  0.02566650
Lag 50 -0.009169908 -0.017729557  0.02175915  0.037622080 -0.04205178
       log_lik[19]  log_lik[20]  log_lik[21]  log_lik[22] log_lik[23]
Lag 0   1.00000000  1.000000000  1.000000000  1.000000000 1.000000000
Lag 1  -0.03208587  0.199707279  0.122441725  0.216102237 0.030364826
Lag 5  -0.01369268  0.017146307  0.056981177  0.031619771 0.038405137
Lag 10 -0.05184742  0.002266797 -0.002546269 -0.003615615 0.002827458
Lag 50 -0.01491998 -0.000185515  0.026181446  0.003742424 0.042867022
        log_lik[24] log_lik[25]  log_lik[26] log_lik[27] log_lik[28]
Lag 0   1.000000000 1.000000000  1.000000000  1.00000000  1.00000000
Lag 1  -0.043300952 0.008897055  0.055272052 -0.02494535 -0.03902829
Lag 5  -0.007623726 0.032328930 -0.003951948  0.04408482 -0.01410360
Lag 10  0.010511950 0.005615084 -0.005860687  0.01468160  0.01575607
Lag 50  0.051297631 0.036588261  0.018664972  0.03213627  0.04216138
       log_lik[29] log_lik[30]          lp__
Lag 0  1.000000000  1.00000000  1.0000000000
Lag 1  0.065026235 -0.01657044  0.5111573914
Lag 5  0.050138816  0.02213345  0.0005946888
Lag 10 0.002064092  0.02410877  0.0243211235
Lag 50 0.039550469  0.01788728 -0.0046540824&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_rhat(data1.rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_diag4_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_ess(data1.rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_diag4_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Rhat and effective sample size. In this instance, most of the parameters have reasonably high effective samples and thus there is likely to be a good range of values from which to estimate paramter properties.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model validation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data1.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata1 = data1
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:6], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data1$Y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_residuals_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data1.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata1 = newdata1
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:6], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data1$Y - fit
&amp;gt; newdata1 = newdata1 %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata1) + geom_point(aes(y = resid, x = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_residuals2_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata1) + geom_point(aes(y = resid, x = B)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_residuals2_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data1.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata1 = data1
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:6], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data1$Y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_residuals3_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data1.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~A * B, data1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:6]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data1), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; newdata1 = data.frame(A = data1$A, B = data1$B, yRep) %&amp;gt;% gather(key = Sample,
+     value = Value, -A, -B)
&amp;gt; ggplot(newdata1) + geom_violin(aes(y = Value, x = A, fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_violin(data = data1, aes(y = Y, x = A,
+     fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) + geom_point(data = data1, aes(y = Y,
+     x = A), position = position_jitter(width = 0.1, height = 0),
+     color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_rep_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata1) + geom_violin(aes(y = Value, x = B, fill = &amp;quot;Model&amp;quot;,
+     group = B, color = A), alpha = 0.5) + geom_point(data = data1,
+     aes(y = Y, x = B, group = B, color = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_rep_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_intervals(as.matrix(data1.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_rep2_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(as.matrix(data1.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_rep2_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parameter estimates&lt;/h2&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data1.rstan, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: ancovaModel2.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]  48.14    0.09 2.00  44.21  46.88  48.13  49.45  52.06   541    1
beta[2] -10.58    0.11 2.83 -16.17 -12.34 -10.58  -8.77  -4.81   621    1
beta[3] -26.48    0.11 2.58 -31.66 -28.17 -26.48 -24.71 -21.48   551    1
beta[4]  -0.35    0.00 0.08  -0.50  -0.40  -0.35  -0.30  -0.20   555    1
beta[5]  -0.27    0.00 0.11  -0.48  -0.34  -0.27  -0.20  -0.05   597    1
beta[6]   0.27    0.00 0.12   0.04   0.20   0.27   0.35   0.50   552    1
sigma     3.39    0.02 0.50   2.57   3.02   3.33   3.67   4.50  1108    1

Samples were drawn using NUTS(diag_e) at Mon Feb 17 11:26:00 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; # OR
&amp;gt; tidyMCMC(data1.rstan, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
# A tibble: 7 x 5
  term    estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]   48.1      2.00    43.9      51.7   
2 beta[2]  -10.6      2.83   -16.0      -4.66  
3 beta[3]  -26.5      2.58   -31.8     -21.6   
4 beta[4]   -0.350    0.0778  -0.501    -0.204 
5 beta[5]   -0.270    0.106   -0.460    -0.0436
6 beta[6]    0.269    0.115    0.0515    0.508 
7 sigma      3.39     0.502    2.49      4.33  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The intercept of the first group (Group A) is &lt;span class=&#34;math inline&#34;&gt;\(48.2\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the second group (Group B) is &lt;span class=&#34;math inline&#34;&gt;\(-10.6\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the third group (Group C) is &lt;span class=&#34;math inline&#34;&gt;\(-26.5\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A one unit increase in B in Group A is associated with a &lt;span class=&#34;math inline&#34;&gt;\(-0.351\)&lt;/span&gt; units increase in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;difference in slope between Group B and Group A &lt;span class=&#34;math inline&#34;&gt;\(-0.270\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;difference in slope between Group C and Group A &lt;span class=&#34;math inline&#34;&gt;\(0.270\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of Group B, Group C and the partial slope associated with B do not overlapp with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between group A and groups B, C (at the mean level of predictor B) and a significant negative relationship with B (for Group A). The slope associated with Group B was not found to be significantly different from that associated with Group A, however, the slope associated with Group C was found to be significantly less negative than the slope associated with Group A. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(as.matrix(data1.rstan)[, &amp;quot;beta[2]&amp;quot;])  # effect of (B-A = 0)
[1] 5e-04
&amp;gt; mcmcpvalue(as.matrix(data1.rstan)[, &amp;quot;beta[3]&amp;quot;])  # effect of (C-A = 0)
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data1.rstan)[, &amp;quot;beta[4]&amp;quot;])  # effect of (slope = 0)
[1] 0.001
&amp;gt; mcmcpvalue(as.matrix(data1.rstan)[, &amp;quot;beta[5]&amp;quot;])  # effect of (slopeB - slopeA = 0)
[1] 0.0145
&amp;gt; mcmcpvalue(as.matrix(data1.rstan)[, &amp;quot;beta[6]&amp;quot;])  # effect of (slopeC - slopeA = 0)
[1] 0.0185
&amp;gt; mcmcpvalue(as.matrix(data1.rstan)[, 2:6])  # effect of (model)
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence that the reponse differs between the groups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; (full = loo(extract_log_lik(data1.rstan)))

Computed from 2000 by 30 log-likelihood matrix

         Estimate  SE
elpd_loo    -83.6 4.8
p_loo         7.3 2.1
looic       167.1 9.5
------
Monte Carlo SE of elpd_loo is NA.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     26    86.7%   465       
 (0.5, 0.7]   (ok)        3    10.0%   233       
   (0.7, 1]   (bad)       1     3.3%   34        
   (1, Inf)   (very bad)  0     0.0%   &amp;lt;NA&amp;gt;      
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; # now fit a model without main factor
&amp;gt; modelString3 = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   // Likelihood
+   y~normal(mu,sigma);
+   
+   // Priors
+   beta ~ normal(0,1000);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString3, con = &amp;quot;ancovaModel3.stan&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~A + B, data1)
&amp;gt; data1.list &amp;lt;- with(data1, list(y = Y, X = Xmat, n = nrow(data1), nX = ncol(Xmat)))
&amp;gt; data1.rstan.red &amp;lt;- stan(data = data1.list, file = &amp;quot;ancovaModel3.stan&amp;quot;, chains = nChains,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;ancovaModel2&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.078 seconds (Warm-up)
Chain 1:                0.063 seconds (Sampling)
Chain 1:                0.141 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;ancovaModel2&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.078 seconds (Warm-up)
Chain 2:                0.06 seconds (Sampling)
Chain 2:                0.138 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; (reduced = loo(extract_log_lik(data1.rstan.red)))

Computed from 2000 by 30 log-likelihood matrix

         Estimate  SE
elpd_loo    -91.9 4.7
p_loo         5.4 1.8
looic       183.8 9.4
------
Monte Carlo SE of elpd_loo is 0.1.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     29    96.7%   379       
 (0.5, 0.7]   (ok)        1     3.3%   166       
   (0.7, 1]   (bad)       0     0.0%   &amp;lt;NA&amp;gt;      
   (1, Inf)   (very bad)  0     0.0%   &amp;lt;NA&amp;gt;      

All Pareto k estimates are ok (k &amp;lt; 0.7).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; par(mfrow = 1:2, mar = c(5, 3.8, 1, 0) + 0.1, las = 3)
&amp;gt; plot(full, label_points = TRUE)
&amp;gt; plot(reduced, label_points = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_looic_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The expected out-of-sample predictive accuracy is substantially lower for the model that includes &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. This might be used to suggest that the inferential evidence for a general effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graphical summaries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data1.rstan)
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata1 = expand.grid(A = levels(data1$A), B = seq(min(data1$B), max(data1$B),
+     len = 100))
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;, &amp;quot;beta[4]&amp;quot;, &amp;quot;beta[5]&amp;quot;,
+     &amp;quot;beta[6]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata1 = newdata1 %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata1, aes(y = estimate, x = B, fill = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_post1_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata1 = rdata1 = data1
&amp;gt; fMat = rMat = model.matrix(~A * B, fdata1)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data1$Y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata1 = rdata1 %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; 
&amp;gt; ggplot(newdata1, aes(y = estimate, x = B, fill = A)) + geom_point(data = rdata1,
+     aes(y = partial.resid, x = B, color = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/ancova-stan/2020-02-01-ancova-stan_files/figure-html/mcmc_post2_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2015stan&#34;&gt;
&lt;p&gt;Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt; 40 (5): 530–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanpackage&#34;&gt;
&lt;p&gt;Stan Development Team. 2018. “RStan: The R Interface to Stan.” &lt;a href=&#34;http://mc-stan.org/&#34;&gt;http://mc-stan.org/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vehtari2017practical&#34;&gt;
&lt;p&gt;Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and Waic.” &lt;em&gt;Statistics and Computing&lt;/em&gt; 27 (5): 1413–32.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Single Factor Anova - JAGS</title>
      <link>/jags/single-factor-anova-jags/single-factor-anova-jags/</link>
      <pubDate>Tue, 04 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/single-factor-anova-jags/single-factor-anova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Single factor Analysis of Variance&lt;/em&gt; (ANOVA), also known as single factor classification, is used to investigate the effect of a single factor comprising two or more groups (treatment levels) from a completely randomised design. Completely randomised refers to the absence of restrictions on the random allocation of experimental or sampling units to factor levels.&lt;/p&gt;
&lt;p&gt;For example, consider a situation in which three types of treatments (A, B and C) are applied to replicate sampling units across the sampling domain. Importantly, the treatments are applied at the scale of the sampling units and the treatments applied to each sampling unit do not extend to any other neighbouring sampling units. Another possible situation is where the scale of a treatment is far larger than that of a sampling unit. This design features two treatments, each replicated three times. Note that additional sampling units within each Site (the scale at which the treatment occurs) would NOT constitute additional replication. Rather, these would be sub-replicates. That is, they would be replicates of the Sites, not the treatments (since the treatments occur at the level of whole sites). In order to genuinely increase the number of replicates, it is necessary to have more Sites. The random allocation of sampling units within the sampling domain (such as population) is appropriate provided either the underlying response is reasonably homogenous throughout the domain, or else, there is a large number of sampling units. If the conditions are relatively hetrogenous, then the exact location of the sampling units is likely to be highly influential and may mask any detectable effects of treatments.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fixed-and-random-effects&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fixed and random effects&lt;/h2&gt;
&lt;p&gt;From a frequentist perspective, &lt;em&gt;fixed factors&lt;/em&gt; are factors whose levels represent the specific populations of interest. For example, a factor that comprises “high”, “medium” and “low” temperature treatments is a fixed factor - we are only interested in comparing those three populations. Conclusions about the effects of a fixed factor are restricted to the specific treatment levels investigated and for any subsequent experiments to be comparable, the same specific treatments of the factor would need to be used. By contrast, &lt;em&gt;random factors&lt;/em&gt; are factors whose levels are randomly chosen from all the possible levels of populations and are used as random representatives of the populations. For example, five random temperature treatments could be used to represent a full spectrum of temperature treatments. In this case, conclusions are extrapolated to all the possible treatment (temperature) levels and for subsequent experiments, a new random set of treatments of the factor would be selected.&lt;/p&gt;
&lt;p&gt;Other common examples of random factors include sites and subjects - factors for which we are attempting to generalise over. Furthermore, the nature of random factors means that we have no indication of how a new level of that factor (such as another subject or site) are likely to respond and thus it is not possible to predict new observations from random factors. These differences between fixed and random factors are reflected in the way their respective null hypotheses are formulated and interpreted. Whilst fixed factors contrast the effects of the different levels of the factor, random factors are modelled as the amount of additional variability they introduce. Random factors are modelled with a mean of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and their variance is estimated as the effect coefficient.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear model&lt;/h2&gt;
&lt;p&gt;The linear model for single factor classification is similar to that of multiple linear regression. The linear model can thus be represented by either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Means parameterisation&lt;/strong&gt; - in which the regression slopes represent the means of each treatment group and the intercept is removed (to prevent over-parameterisation).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \beta_1(\text{level}_1)_{ij} + \beta_2(\text{level}_2)_{ij} + \ldots + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; respectively represent the means response of treatment level &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;. This is often simplified to &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\alpha_i + \epsilon_{ij}\)&lt;/span&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Effects parameterisation&lt;/strong&gt; - the intercept represents a property such as the mean of one of the treatment groups (treatment contrasts) or the overall mean (sum contrasts), and the slope parameters represent effects (differences between each other group and the reference mean for example).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \mu + \beta_2(\text{level}_2)_{ij} + \beta_3(\text{level}_3)_{ij} + \ldots + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the mean of the first treatment group, &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_3\)&lt;/span&gt; respectively represent the effects (change from level &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;) of level &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; on the mean response. This is often simplified to: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \epsilon_{ij}\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1=0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since we are traditionally interested in investigating effects (differences) rather than treatment means, effects parameterisation is far more common (particularly when coupled with hypothesis testing). In a Bayesian framework, it does not really matter whether models are fit with means or effects parameterisation since the posterior likelihood can be querried in any way and repeatedly - thus enabling us to explore any specific effects after the model has been fit. Nevertheless, to ease comparisons with frequentist approaches, we will stick with effects paramterisation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis-fixed-factor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis: fixed factor&lt;/h2&gt;
&lt;p&gt;We can associate a null hypothesis test with each estimated parameter. For example, in a cell for each estimated mean in a means model we could test a null hypothesis that the population mean is equal to zero (e.g. &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\alpha_2=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\ldots\)&lt;/span&gt;). However, this rarely would be of much interest. By contrast, individual null hypotheses associated with each parameter of the effects model can be used to investigate the differences between each group and a reference group (for example). In addition to the individual null hypothesis tests, a single fixed factor ANOVA tests the collective &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; that there are no differences between the population group means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt; (the population group means are all equal). That is, that the mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to one another - no effect of the factor on the response. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the mean of the first group (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu_1\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0 : \alpha_2=\alpha_3=\ldots=\alpha_i=0\)&lt;/span&gt; (the effect of each group equals zero). If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), there is evidence that the null hypothesis is not true indicating that the factor does affect the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis-random-factor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis: random factor&lt;/h2&gt;
&lt;p&gt;The collective &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; for a random factor is that the variance between all possible treatment groups equals zero:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0 : \sigma^2_{\alpha}=0\)&lt;/span&gt; (added variance due to this factor equals zero).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that whilst the null hypotheses for fixed and random factors are different (fixed: population group means all equal, random: variances between populations all equal zero), the linear model fitted for fixed and random factors in single factor ANOVA models is identical. For more complex multi-factor ANOVA models however, the distinction between fixed and random factors has important consequences for building and interpreting statistical models and null hypotheses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;When the null hypothesis is true (and the populations are identical), the amount of variation among observations within groups should be similar to the amount of variation in observations between groups. However, when the null hypothesis is false (and some means are different from other means), the amount of variation among observations might be expected to be less than the amount of variation within groups. Analysis of variance, or ANOVA, partitions the total variance in the response (dependent) variable into a component of the variance that is explained by combinations of one or more categorical predictor variables (called factors) and a component of the variance that cannot be explained (residual). The variance ratio (F-ratio) from this partitioning can then be used to test the null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;) that the population group or treatment means are all equal. Ttotal variation can be decomposed into components explained by the groups (&lt;span class=&#34;math inline&#34;&gt;\(MS_{groups}\)&lt;/span&gt;) and and unexplained (&lt;span class=&#34;math inline&#34;&gt;\(MS_{residual}\)&lt;/span&gt;) by the groups. The gray arrows in b) depict the relative amounts explained by the groups. The proposed groupings generally explain why the first few points are higher on the y-axis than the last three points. The probability of collecting our sample, and thus generating the sample ratio of explained to unexplained variation (or one more extreme), when the null hypothesis is true (and population means are equal) is the area under the F-distribution beyond our sample ratio (&lt;span class=&#34;math inline&#34;&gt;\(\text{F-ratio}=\frac{MS_{groups}}{MS_{residual}}\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;When the null hypothesis is true (and the test assumptions have not been violated), the ratio (F-ratio) of explained to unexplained variance follows a theoretical probability distribution (F-distribution). When the null hypothesis is true, and there is no effect of the treatment on the response variable, the ratio of explained variability to unexplained variability is expected to be &lt;span class=&#34;math inline&#34;&gt;\(\leq 1\)&lt;/span&gt;. Since the denominator should represent the expected numerator in the absence of an effect. Importantly, the denominator in an F-ratio calculation essentially represents what we would expect the numerator to be in the absence of a treatment effect. For simple analyses, identifying what these expected values are is relatively straightforward (equivalent to the degree of within group variability). However, in more complex designs (particularly involving random factors and hierarchical treatment levels), the logical “groups” can be more difficult (and in some cases impossible) to identify. In such cases, nominating the appropriate F-ratio denominator for estimating an specific effect requires careful consideration. The following table depicts the anatomy of the single factor ANOVA table&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova_table
         df       MS       F-ratio          
Factor A &amp;quot;a-1&amp;quot;    &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;
Residual &amp;quot;(n-1)a&amp;quot; &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;               &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and corresponding &lt;code&gt;R&lt;/code&gt; syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(DV ~ A, dataset))
&amp;gt; # OR
&amp;gt; anova(aov(DV ~ A, dataset))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An F-ratio substantially greater than &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; suggests that the model relating the response variable to the categorical variable explains substantially more variability than is left unexplained. In turn, this implies that the linear model does represent the data well and that differences between observations can be explained largely by differences in treatment levels rather than purely the result of random variation. If the probability of getting the observed (sample) F-ratio or one more extreme is less than some predefined critical value (typically &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% or &lt;span class=&#34;math inline&#34;&gt;\(0.05\)&lt;/span&gt;), we conclude that it is highly unlikely that the observed samples could have been collected from populations in which the treatment has no effect and therefore we would reject the null hypothesis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;An F-ratio from real data can only reliably relate to a theoretical F-distribution when the data conform to certain assumptions. Hypothesis testing for a single factor ANOVA model assumes that the residuals (and therefore the response variable for each of the treatment levels) are all:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;normally distributed&lt;/strong&gt; - although ANOVA is robust to non-normality provided sample sizes and variances are equal. Boxplots should be used to explore normality, skewness, bimodality and outliers. In the event of homogeneity of variance issues (see below), a Q-Q normal plot can also be useful for exploring normality (as this might be the cause of non-homogeneity). Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;equally varied&lt;/strong&gt; - provided sample sizes are equal and the largest to smallest variance ratio does not exceed 3:1 (9:1 for sd), ANOVA is reasonably robust to this assumption, however, relationships between variance and mean and/or sample size are of particular concern as they elevate the Type I error rate. Boxplots and plots of means against variance should be used to explore the spread of values. Residual plots should reveal no patterns. Since unequal variances are often the result of non-normality, transformations that improve normality will also improve variance homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;independent of one another&lt;/strong&gt; - this assumption must be addressed at the design and collection stages and cannot be compensated for later (unless a model is used that specifically accounts for particular types of non-independent data, such as that introduced with hierarchical designs or autocorrelation)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Violations of these assumptions reduce the reliability of the analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Lets say we had set up a natural experiment in which we measured a response from &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; sampling units (replicates) from each of &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; treatments. Hence, we have a single categorical factor with &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; levels - we might have five different locations, or five different habitat types or substrates etc. In statistical speak, we have sampled from &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; different populations. We have then randomly selected &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; independent and random (representative) units of each population to sample. That is, we have &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; samples (replicates) of each population. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; ngroups &amp;lt;- 5  #number of populations
&amp;gt; nsample &amp;lt;- 10  #number of reps in each
&amp;gt; pop.means &amp;lt;- c(40, 45, 55, 40, 30)  #population mean length
&amp;gt; sigma &amp;lt;- 3  #residual standard deviation
&amp;gt; n &amp;lt;- ngroups * nsample  #total sample size
&amp;gt; eps &amp;lt;- rnorm(n, 0, sigma)  #residuals
&amp;gt; x &amp;lt;- gl(ngroups, nsample, n, lab = LETTERS[1:5])  #factor
&amp;gt; means &amp;lt;- rep(pop.means, rep(nsample, ngroups))
&amp;gt; X &amp;lt;- model.matrix(~x - 1)  #create a design matrix
&amp;gt; y &amp;lt;- as.numeric(X %*% pop.means + eps)
&amp;gt; data &amp;lt;- data.frame(y, x)
&amp;gt; head(data)  #print out the first six rows of the data set
         y x
1 38.31857 A
2 39.30947 A
3 44.67612 A
4 40.21153 A
5 40.38786 A
6 45.14519 A
&amp;gt; 
&amp;gt; write.csv(data, &amp;quot;simpleAnova.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type.&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Normality and Homogeneity of variance&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ x, data)
&amp;gt; 
&amp;gt; # OR via ggplot2
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/exp_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = y, x = x)) + geom_boxplot() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/exp_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity. Obvious violations could be addressed either by, for example, transforming the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0+\boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the mean of the first group and the set of &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;’s represent the differences between each other group and the first group. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Note the following example as group means calculated as derived posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau.res)
+   mean[i] &amp;lt;- alpha+beta[x[i]]
+   }
+ 
+   #Priors and derivatives
+   alpha ~ dnorm(0,1.0E-6)
+   beta[1] &amp;lt;- 0
+   for (i in 2:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) #prior
+   }
+   sigma.res ~ dunif(0, 100)
+   tau.res &amp;lt;- 1 / (sigma.res * sigma.res)
+   sigma.group &amp;lt;- sd(beta[])
+ 
+   #Group mean posteriors (derivatives)
+   for (i in 1:ngroups) {
+   Group.means[i] &amp;lt;- beta[i]+alpha
+   }
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;anovaModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.list &amp;lt;- with(data, list(y = y, x = as.numeric(x), n = nrow(data),
+     ngroups = length(levels(data$x))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma.res&amp;quot;, &amp;quot;Group.means&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;anovaModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 50
   Unobserved stochastic nodes: 6
   Total graph size: 126

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;anovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
               mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat
Group.means[1]  40.232   0.908  38.424  39.631  40.237  40.837  41.991 1.001
Group.means[2]  45.632   0.902  43.858  45.022  45.626  46.231  47.432 1.002
Group.means[3]  53.730   0.913  51.947  53.113  53.722  54.334  55.543 1.001
Group.means[4]  40.962   0.906  39.188  40.350  40.968  41.563  42.734 1.001
Group.means[5]  29.974   0.915  28.173  29.367  29.974  30.586  31.746 1.001
alpha           40.232   0.908  38.424  39.631  40.237  40.837  41.991 1.001
beta[1]          0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000
beta[2]          5.400   1.278   2.889   4.551   5.395   6.244   7.896 1.001
beta[3]         13.498   1.286  11.017  12.639  13.485  14.354  16.049 1.001
beta[4]          0.730   1.283  -1.768  -0.122   0.722   1.582   3.261 1.001
beta[5]        -10.258   1.294 -12.820 -11.110 -10.253  -9.412  -7.721 1.001
sigma.res        2.864   0.320   2.313   2.638   2.832   3.056   3.578 1.001
deviance       245.540   3.787 240.323 242.761 244.832 247.511 254.843 1.001
               n.eff
Group.means[1] 15000
Group.means[2]  2200
Group.means[3]  3800
Group.means[4] 15000
Group.means[5] 15000
alpha          15000
beta[1]            1
beta[2]         2900
beta[3]        15000
beta[4]        15000
beta[5]        15000
sigma.res      15000
deviance       15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;model-matrix-formulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model matrix formulation&lt;/h2&gt;
&lt;p&gt;For very simple models such as this example, we can write the models as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2 = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau)
+   mean[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   #Priors
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) 
+   }
+   sigma ~ dunif(0, 100)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;anovaModel2.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the data to pass to &lt;code&gt;R2jags&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X &amp;lt;- model.matrix(~x, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = X, n = nrow(data), ngroups = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;anovaModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 50
   Unobserved stochastic nodes: 6
   Total graph size: 370

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;anovaModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.226   0.901  38.475  39.624  40.222  40.824  41.999 1.001  4800
beta[2]    5.401   1.272   2.906   4.552   5.397   6.242   7.900 1.001 15000
beta[3]   13.492   1.296  10.969  12.634  13.484  14.355  16.038 1.001  5100
beta[4]    0.734   1.279  -1.793  -0.114   0.740   1.582   3.263 1.001 15000
beta[5]  -10.248   1.283 -12.785 -11.108 -10.242  -9.380  -7.731 1.001  9800
sigma      2.863   0.315   2.321   2.642   2.838   3.053   3.558 1.001  6200
deviance 245.551   3.785 240.353 242.765 244.844 247.603 254.815 1.002  1800

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3895  3746         1.040     
 beta[2]  2        3729  3746         0.995     
 beta[3]  2        3811  3746         1.020     
 beta[4]  3        4115  3746         1.100     
 beta[5]  2        3853  3746         1.030     
 deviance 2        3729  3746         0.995     
 sigma    5        5834  3746         1.560     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3853  3746         1.03      
 beta[2]  2        3918  3746         1.05      
 beta[3]  2        3811  3746         1.02      
 beta[4]  2        3853  3746         1.03      
 beta[5]  2        3853  3746         1.03      
 deviance 2        3981  3746         1.06      
 sigma    4        5306  3746         1.42      &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
             beta[1]     beta[2]       beta[3]       beta[4]      beta[5]
Lag 0   1.0000000000 1.000000000  1.0000000000  1.0000000000  1.000000000
Lag 1   0.0015561854 0.001902670 -0.0023462263  0.0063854498 -0.008928813
Lag 5  -0.0006487164 0.003556616 -0.0008267107 -0.0003892349  0.004087306
Lag 10  0.0141414517 0.012308363  0.0064688638 -0.0029210457  0.009117446
Lag 50 -0.0019115790 0.005069522  0.0072096979 -0.0030858504  0.002938152
           deviance        sigma
Lag 0   1.000000000  1.000000000
Lag 1   0.198317688  0.334172270
Lag 5  -0.001425768  0.005514213
Lag 10 -0.000422188 -0.001600486
Lag 50 -0.008805916  0.007414425&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.&lt;/p&gt;
&lt;p&gt;There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Standardised residuals&lt;/strong&gt;. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Studentised residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the residuals. Note that &lt;strong&gt;externally studentised residuals&lt;/strong&gt; are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pearson residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%) back thereby allowing us to train the model on &lt;span class=&#34;math inline&#34;&gt;\(75\)&lt;/span&gt;% of the data and then see how well the model can predict the withheld &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.&lt;/p&gt;
&lt;p&gt;Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within &lt;code&gt;JAGS&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(tidyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = x)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:5]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; newdata = data.frame(x = data$x, yRep) %&amp;gt;% gather(key = Sample,
+     value = Value, -x)
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = x, fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_violin(data = data, aes(y = y, x = x,
+     fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) + geom_point(data = data, aes(y = y,
+     x = x), position = position_jitter(width = 0.1, height = 0),
+     color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;anovaModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.226   0.901  38.475  39.624  40.222  40.824  41.999 1.001  4800
beta[2]    5.401   1.272   2.906   4.552   5.397   6.242   7.900 1.001 15000
beta[3]   13.492   1.296  10.969  12.634  13.484  14.355  16.038 1.001  5100
beta[4]    0.734   1.279  -1.793  -0.114   0.740   1.582   3.263 1.001 15000
beta[5]  -10.248   1.283 -12.785 -11.108 -10.242  -9.380  -7.731 1.001  9800
sigma      2.863   0.315   2.321   2.642   2.838   3.053   3.558 1.001  6200
deviance 245.551   3.785 240.353 242.765 244.844 247.603 254.815 1.002  1800

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 7 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    40.2       0.901    38.5      42.0 
2 beta[2]     5.40      1.27      2.90      7.89
3 beta[3]    13.5       1.30     11.0      16.1 
4 beta[4]     0.734     1.28     -1.82      3.21
5 beta[5]   -10.2       1.28    -12.7      -7.68
6 deviance  246.        3.79    240.      253.  
7 sigma       2.86      0.315     2.26      3.48&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the mean of the first group (A) is &lt;span class=&#34;math inline&#34;&gt;\(40.2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the mean of the second group (B) is &lt;span class=&#34;math inline&#34;&gt;\(5.4\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the third group (C) is &lt;span class=&#34;math inline&#34;&gt;\(13.5\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the forth group (D) is &lt;span class=&#34;math inline&#34;&gt;\(0.74\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the fifth group (E) is &lt;span class=&#34;math inline&#34;&gt;\(-10.2\)&lt;/span&gt; units greater (i.e. less) than (A)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of B, C and E do not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between group A and groups B, C and E. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])  # effect of (B-A)
[1] 6.666667e-05
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])  # effect of (C-A)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[4]&amp;quot;])  # effect of (D-A)
[1] 0.5576
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[5]&amp;quot;])  # effect of (E-A)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, 2:5])  # effect of (all groups)
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence that the reponse differs between the groups. There is evidence suggesting that the response of group D differs from that of group A.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = rbind(data.frame(x = levels(data$x)))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;, &amp;quot;beta[4]&amp;quot;, &amp;quot;beta[5]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_linerange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_point() + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = as.numeric(x) - 0.1)) + geom_blank(aes(x = x)) +
+     geom_point(data = rdata, aes(y = partial.resid, x = as.numeric(x) +
+         0.1), color = &amp;quot;gray&amp;quot;) + geom_linerange(aes(ymin = conf.low, ymax = conf.high)) +
+     geom_point() + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posteriors&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Posteriors&lt;/h1&gt;
&lt;p&gt;In frequentist statistics, when we have more than two groups, we are typically not only interested in whether there is evidence for an overall “effect” of a factor - we are also interested in how various groups compare to one another. To explore these trends, we either compare each group to each other in a pairwise manner (controlling for family-wise Type I error rates) or we explore an independent subset of the possible comparisons. Although these alternate approaches can adequately address a specific research agenda, often they impose severe limitations and compromises on the scope and breadth of questions that can be asked of your data. The reason for these limitations is that in a frequentist framework, any single hypothesis carries with it a (nominally) &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% chance of a false rejection (since it is based on long-run frequency). Thus, performing multiple tests are likely to compound this error rate. The point is, that each comparison is compared to its own probability distribution (and each carries a &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% error rate). By contrast, in Bayesian statistics, all comparisons (contrasts) are drawn from the one (hopefully stable and convergent) posterior distribution and this posterior is invariant to the type and number of comparisons drawn. Hence, the theory clearly indicates that having generated our posterior distribution, we can then query this distribution in any way that we wish thereby allowing us to explore all of our research questions simultaneously.&lt;/p&gt;
&lt;p&gt;Bayesian “contrasts” can be performed either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;within the Bayesian sampling model or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;construct them from the returned MCMC samples (they are drawn from the posteriors)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Only the latter will be demonstrated as it povides a consistent approach across all routines. In order to allow direct comparison to the frequentist equivalents, I will explore the same set of planned and &lt;em&gt;Tukey&lt;/em&gt;’s test comparisons described here. For the “planned comparison” we defined two contrasts: 1) group 3 vs group 5; and 2) the average of groups 1 and 2 vs the average of groups 3, 4 and 5.&lt;/p&gt;
&lt;p&gt;Lets start by comparing each group to each other group in a pairwise manner. Arguably the most elegant way to do this is to generate a Tukey’s contrast matrix. This is a model matrix specific to comparing each group to each other group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:5]
&amp;gt; newdata &amp;lt;- data.frame(x = levels(data$x))
&amp;gt; # A Tukeys contrast matrix
&amp;gt; library(multcomp)
&amp;gt; # table(newdata$x) - gets the number of replicates of each level
&amp;gt; tuk.mat &amp;lt;- contrMat(n = table(newdata$x), type = &amp;quot;Tukey&amp;quot;)
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data = newdata)
&amp;gt; pairwise.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; pairwise.mat
      (Intercept) xB xC xD xE
B - A           0  1  0  0  0
C - A           0  0  1  0  0
D - A           0  0  0  1  0
E - A           0  0  0  0  1
C - B           0 -1  1  0  0
D - B           0 -1  0  1  0
E - B           0 -1  0  0  1
D - C           0  0 -1  1  0
E - C           0  0 -1  0  1
E - D           0  0  0 -1  1
&amp;gt; 
&amp;gt; mcmc_areas(coefs %*% t(pairwise.mat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; (comps = tidyMCMC(coefs %*% t(pairwise.mat), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 B - A    5.40       1.27     2.90      7.89
 2 C - A   13.5        1.30    11.0      16.1 
 3 D - A    0.734      1.28    -1.82      3.21
 4 E - A  -10.2        1.28   -12.7      -7.68
 5 C - B    8.09       1.29     5.58     10.7 
 6 D - B   -4.67       1.30    -7.19     -2.02
 7 E - B  -15.6        1.28   -18.1     -13.1 
 8 D - C  -12.8        1.31   -15.3     -10.2 
 9 E - C  -23.7        1.29   -26.2     -21.2 
10 E - D  -11.0        1.29   -13.5      -8.46
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With a couple of modifications, we could also express this as percentage changes. A percentage change represents the change (difference between groups) divided by one of the groups (determined by which group you want to express the percentage change to). Hence, we generate an additional mcmc matrix that represents the cell means for the divisor group (group we want to express change relative to). Since the &lt;code&gt;tuk.mat&lt;/code&gt; defines comparisons as &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; pairs, if we simply replace all the &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, the eventual matrix multiplication will result in estimates of the divisor cell means instread of the difference. We can then divide the original mcmc matrix above with this new divisor mcmc matrix to yeild a mcmc matrix of percentage change.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # Modify the tuk.mat to replace -1 with 0.  This will allow us to get a
&amp;gt; # mcmc matrix of ..
&amp;gt; tuk.mat[tuk.mat == -1] = 0
&amp;gt; comp.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; comp.mat
      (Intercept) xB xC xD xE
B - A           1  1  0  0  0
C - A           1  0  1  0  0
D - A           1  0  0  1  0
E - A           1  0  0  0  1
C - B           1  0  1  0  0
D - B           1  0  0  1  0
E - B           1  0  0  0  1
D - C           1  0  0  1  0
E - C           1  0  0  0  1
E - D           1  0  0  0  1
&amp;gt; 
&amp;gt; comp.mcmc = 100 * (coefs %*% t(pairwise.mat))/coefs %*% t(comp.mat)
&amp;gt; (comps = tidyMCMC(comp.mcmc, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 B - A    11.8       2.63     6.52     16.8 
 2 C - A    25.1       2.13    21.0      29.4 
 3 D - A     1.74      3.10    -4.30      7.88
 4 E - A   -34.3       5.09   -44.3     -24.4 
 5 C - B    15.0       2.24    10.4      19.2 
 6 D - B   -11.5       3.38   -18.1      -4.70
 7 E - B   -52.3       5.53   -63.2     -41.6 
 8 D - C   -31.2       3.73   -38.5     -23.9 
 9 E - C   -79.4       6.26   -91.9     -67.5 
10 E - D   -36.8       5.15   -47.1     -27.0 
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size (%)&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for the specific planned comparisons (Group 3 vs Group 5 and the average of Groups 1 and 2 vs the average of Groups 3, 4 and 5). This is achieved by generating our own contrast matrix (defining the contributions of each group to each contrast).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; c.mat = rbind(c(0, 0, -1, 0, 1), c(-1/2, -1/2, 1/3, 1/3, 1/3))
&amp;gt; c.mat
     [,1] [,2]       [,3]      [,4]      [,5]
[1,]  0.0  0.0 -1.0000000 0.0000000 1.0000000
[2,] -0.5 -0.5  0.3333333 0.3333333 0.3333333
&amp;gt; 
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:5]
&amp;gt; newdata &amp;lt;- data.frame(x = levels(data$x))
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data = newdata)
&amp;gt; c.mat = c.mat %*% Xmat
&amp;gt; c.mat
       (Intercept)   xB         xC        xD        xE
[1,]  0.000000e+00  0.0 -1.0000000 0.0000000 1.0000000
[2,] -1.110223e-16 -0.5  0.3333333 0.3333333 0.3333333
&amp;gt; 
&amp;gt; (comps = tidyMCMC(as.mcmc(coefs %*% t(c.mat)), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 2 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1    -23.7      1.29    -26.2    -21.2  
2 var2     -1.37     0.836    -3.01     0.273&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;      beta[1]  beta[2]  beta[3]    beta[4]    beta[5] deviance    sigma
[1,] 41.14988 5.425974 13.10634  0.5423808 -12.004913 245.9651 2.374957
[2,] 41.77436 3.165155 12.08478 -2.5284367 -11.070257 251.2837 3.546706
[3,] 39.87873 5.074910 13.46806  0.7805140  -7.932663 245.7947 3.020465
[4,] 41.15168 3.079048 10.80976 -0.5505218 -10.396170 249.3934 2.547300
[5,] 39.93263 4.548017 13.82126  1.2192389  -9.549601 242.2442 2.449639
[6,] 40.41198 4.705732 12.87972  2.3548628  -8.868949 250.1582 2.432338
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         9.94    0.528      8.86     10.9 
2 sd.resid     2.79    0.0903     2.67      2.96
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         78.3      1.07     76.0      79.7
2 sd.resid     21.7      1.07     20.3      24.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/eff_pop1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(78.3\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.887    0.0127    0.862     0.905
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ x, data))

Call:
lm(formula = y ~ x, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5257 -1.9000 -0.2589  1.4935  6.5330 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.2239     0.8801  45.702  &amp;lt; 2e-16 ***
xB            5.4020     1.2447   4.340 7.97e-05 ***
xC           13.5024     1.2447  10.848 3.82e-14 ***
xD            0.7423     1.2447   0.596    0.554    
xE          -10.2500     1.2447  -8.235 1.57e-10 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 2.783 on 45 degrees of freedom
Multiple R-squared:  0.8957,    Adjusted R-squared:  0.8865 
F-statistic: 96.64 on 4 and 45 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-model-selection&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bayesian model selection&lt;/h1&gt;
&lt;p&gt;A statistical model is by definition a low-dimensional (over simplification) representation of what is really likely to be a very complex system. As a result, no model is right. Some models however can provide useful insights into some of the processes operating on the system. Frequentist statistics have various methods (model selection, dredging, lasso, cross validation) for selecting parsimonious models. These are models that provide a good comprimise between minimizing unexplained patterns and minimizing model complexity. The basic premise is that since no model can hope to capture the full complexity of a system with all its subtleties, only the very major patterns can be estimated. Overly complex models are likely to be representing artificial complexity present only in the specific observed data (not the general population). The Bayesian approach is to apply priors to the non-variance parameters such that parameters close to zero are further shrunk towards zero whilst priors on parameters further away from zero are less effected. The most popular form of prior for sparsity is the &lt;em&gt;horseshoe prior&lt;/em&gt;, so called because the shape of a component of this prior resembles a horseshoe (with most of the mass either close to &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; or close to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Rather than apply weakly informative Gaussian priors on parameters as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\sigma^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the horseshoe prior is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2\lambda_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tau \sim \text{Cauchy}(0,1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j \sim \text{Cauchy}(0,1)\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(j=1,\ldots,D\)&lt;/span&gt;. Using this prior, &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is the number of (non-intercept or variance) parameters, &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; represents the global scale that weights or shrinks all parameters towards zero and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j\)&lt;/span&gt; are thick tailed local scales that allow some of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; parameters to escape shrinkage. More recently, &lt;span class=&#34;citation&#34;&gt;Piironen, Vehtari, and others (2017)&lt;/span&gt; have argued that whilst the above horseshoe priors do guarantee that strong effects (parameters) will not be over-shrunk, there is the potential for weekly identified effects (those based on relatively little data) to be misrepresented in the posteriors. As an alternative they advocated the use of regularised horseshoe priors in which the amount of shrinkage applied to the largest effects can be controlled. The prior is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2 \tilde{\lambda}_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tilde{\lambda}_j^2 = \frac{c^2\lambda^2_j}{c^2+\tau^2 \lambda^2_j}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is (slab width, actually variance) is a constant. For small effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;lt; c^2\)&lt;/span&gt;) the prior approaches a regular prior. However, for large effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;gt; c^2\)&lt;/span&gt;) the prior approaches &lt;span class=&#34;math inline&#34;&gt;\(N(0,c^2)\)&lt;/span&gt;. Finally, they recommend applying a inverse-gamma prior on &lt;span class=&#34;math inline&#34;&gt;\(c^2\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ c^2 \sim \text{Inv-Gamma}(\alpha,\beta),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\alpha=v/2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta=vs^2/2\)&lt;/span&gt;, which translates to a &lt;span class=&#34;math inline&#34;&gt;\(\text{Student-t}_ν(0, s^2)\)&lt;/span&gt; slab for the coefficients far from zero and is typically a good default choice for a weakly informative prior.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-piironen2017sparsity&#34;&gt;
&lt;p&gt;Piironen, Juho, Aki Vehtari, and others. 2017. “Sparsity Information and Regularization in the Horseshoe and Other Shrinkage Priors.” &lt;em&gt;Electronic Journal of Statistics&lt;/em&gt; 11 (2): 5018–51.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Single Factor Anova - STAN</title>
      <link>/stan/single-factor-anova-stan/single-factor-anova-stan/</link>
      <pubDate>Tue, 04 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/stan/single-factor-anova-stan/single-factor-anova-stan/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;STAN&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman, Lee, and Guo (2015)&lt;/span&gt;) using the package &lt;code&gt;rstan&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Stan Development Team (2018)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Single factor Analysis of Variance&lt;/em&gt; (ANOVA), also known as single factor classification, is used to investigate the effect of a single factor comprising two or more groups (treatment levels) from a completely randomised design. Completely randomised refers to the absence of restrictions on the random allocation of experimental or sampling units to factor levels.&lt;/p&gt;
&lt;p&gt;For example, consider a situation in which three types of treatments (A, B and C) are applied to replicate sampling units across the sampling domain. Importantly, the treatments are applied at the scale of the sampling units and the treatments applied to each sampling unit do not extend to any other neighbouring sampling units. Another possible situation is where the scale of a treatment is far larger than that of a sampling unit. This design features two treatments, each replicated three times. Note that additional sampling units within each Site (the scale at which the treatment occurs) would NOT constitute additional replication. Rather, these would be sub-replicates. That is, they would be replicates of the Sites, not the treatments (since the treatments occur at the level of whole sites). In order to genuinely increase the number of replicates, it is necessary to have more Sites. The random allocation of sampling units within the sampling domain (such as population) is appropriate provided either the underlying response is reasonably homogenous throughout the domain, or else, there is a large number of sampling units. If the conditions are relatively hetrogenous, then the exact location of the sampling units is likely to be highly influential and may mask any detectable effects of treatments.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fixed-and-random-effects&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fixed and random effects&lt;/h2&gt;
&lt;p&gt;From a frequentist perspective, &lt;em&gt;fixed factors&lt;/em&gt; are factors whose levels represent the specific populations of interest. For example, a factor that comprises “high”, “medium” and “low” temperature treatments is a fixed factor - we are only interested in comparing those three populations. Conclusions about the effects of a fixed factor are restricted to the specific treatment levels investigated and for any subsequent experiments to be comparable, the same specific treatments of the factor would need to be used. By contrast, &lt;em&gt;random factors&lt;/em&gt; are factors whose levels are randomly chosen from all the possible levels of populations and are used as random representatives of the populations. For example, five random temperature treatments could be used to represent a full spectrum of temperature treatments. In this case, conclusions are extrapolated to all the possible treatment (temperature) levels and for subsequent experiments, a new random set of treatments of the factor would be selected.&lt;/p&gt;
&lt;p&gt;Other common examples of random factors include sites and subjects - factors for which we are attempting to generalise over. Furthermore, the nature of random factors means that we have no indication of how a new level of that factor (such as another subject or site) are likely to respond and thus it is not possible to predict new observations from random factors. These differences between fixed and random factors are reflected in the way their respective null hypotheses are formulated and interpreted. Whilst fixed factors contrast the effects of the different levels of the factor, random factors are modelled as the amount of additional variability they introduce. Random factors are modelled with a mean of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and their variance is estimated as the effect coefficient.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear model&lt;/h2&gt;
&lt;p&gt;The linear model for single factor classification is similar to that of multiple linear regression. The linear model can thus be represented by either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Means parameterisation&lt;/strong&gt; - in which the regression slopes represent the means of each treatment group and the intercept is removed (to prevent over-parameterisation).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \beta_1(\text{level}_1)_{ij} + \beta_2(\text{level}_2)_{ij} + \ldots + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; respectively represent the means response of treatment level &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;. This is often simplified to &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\alpha_i + \epsilon_{ij}\)&lt;/span&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Effects parameterisation&lt;/strong&gt; - the intercept represents a property such as the mean of one of the treatment groups (treatment contrasts) or the overall mean (sum contrasts), and the slope parameters represent effects (differences between each other group and the reference mean for example).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \mu + \beta_2(\text{level}_2)_{ij} + \beta_3(\text{level}_3)_{ij} + \ldots + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the mean of the first treatment group, &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_3\)&lt;/span&gt; respectively represent the effects (change from level &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;) of level &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; on the mean response. This is often simplified to: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \epsilon_{ij}\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1=0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since we are traditionally interested in investigating effects (differences) rather than treatment means, effects parameterisation is far more common (particularly when coupled with hypothesis testing). In a Bayesian framework, it does not really matter whether models are fit with means or effects parameterisation since the posterior likelihood can be querried in any way and repeatedly - thus enabling us to explore any specific effects after the model has been fit. Nevertheless, to ease comparisons with frequentist approaches, we will stick with effects paramterisation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis-fixed-factor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis: fixed factor&lt;/h2&gt;
&lt;p&gt;We can associate a null hypothesis test with each estimated parameter. For example, in a cell for each estimated mean in a means model we could test a null hypothesis that the population mean is equal to zero (e.g. &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\alpha_2=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\ldots\)&lt;/span&gt;). However, this rarely would be of much interest. By contrast, individual null hypotheses associated with each parameter of the effects model can be used to investigate the differences between each group and a reference group (for example). In addition to the individual null hypothesis tests, a single fixed factor ANOVA tests the collective &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; that there are no differences between the population group means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt; (the population group means are all equal). That is, that the mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to one another - no effect of the factor on the response. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the mean of the first group (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu_1\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0 : \alpha_2=\alpha_3=\ldots=\alpha_i=0\)&lt;/span&gt; (the effect of each group equals zero). If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), there is evidence that the null hypothesis is not true indicating that the factor does affect the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis-random-factor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis: random factor&lt;/h2&gt;
&lt;p&gt;The collective &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; for a random factor is that the variance between all possible treatment groups equals zero:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0 : \sigma^2_{\alpha}=0\)&lt;/span&gt; (added variance due to this factor equals zero).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that whilst the null hypotheses for fixed and random factors are different (fixed: population group means all equal, random: variances between populations all equal zero), the linear model fitted for fixed and random factors in single factor ANOVA models is identical. For more complex multi-factor ANOVA models however, the distinction between fixed and random factors has important consequences for building and interpreting statistical models and null hypotheses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;When the null hypothesis is true (and the populations are identical), the amount of variation among observations within groups should be similar to the amount of variation in observations between groups. However, when the null hypothesis is false (and some means are different from other means), the amount of variation among observations might be expected to be less than the amount of variation within groups. Analysis of variance, or ANOVA, partitions the total variance in the response (dependent) variable into a component of the variance that is explained by combinations of one or more categorical predictor variables (called factors) and a component of the variance that cannot be explained (residual). The variance ratio (F-ratio) from this partitioning can then be used to test the null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;) that the population group or treatment means are all equal. Ttotal variation can be decomposed into components explained by the groups (&lt;span class=&#34;math inline&#34;&gt;\(MS_{groups}\)&lt;/span&gt;) and and unexplained (&lt;span class=&#34;math inline&#34;&gt;\(MS_{residual}\)&lt;/span&gt;) by the groups. The gray arrows in b) depict the relative amounts explained by the groups. The proposed groupings generally explain why the first few points are higher on the y-axis than the last three points. The probability of collecting our sample, and thus generating the sample ratio of explained to unexplained variation (or one more extreme), when the null hypothesis is true (and population means are equal) is the area under the F-distribution beyond our sample ratio (&lt;span class=&#34;math inline&#34;&gt;\(\text{F-ratio}=\frac{MS_{groups}}{MS_{residual}}\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;When the null hypothesis is true (and the test assumptions have not been violated), the ratio (F-ratio) of explained to unexplained variance follows a theoretical probability distribution (F-distribution). When the null hypothesis is true, and there is no effect of the treatment on the response variable, the ratio of explained variability to unexplained variability is expected to be &lt;span class=&#34;math inline&#34;&gt;\(\leq 1\)&lt;/span&gt;. Since the denominator should represent the expected numerator in the absence of an effect. Importantly, the denominator in an F-ratio calculation essentially represents what we would expect the numerator to be in the absence of a treatment effect. For simple analyses, identifying what these expected values are is relatively straightforward (equivalent to the degree of within group variability). However, in more complex designs (particularly involving random factors and hierarchical treatment levels), the logical “groups” can be more difficult (and in some cases impossible) to identify. In such cases, nominating the appropriate F-ratio denominator for estimating an specific effect requires careful consideration. The following table depicts the anatomy of the single factor ANOVA table&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova_table
         df       MS       F-ratio          
Factor A &amp;quot;a-1&amp;quot;    &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;
Residual &amp;quot;(n-1)a&amp;quot; &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;               &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and corresponding &lt;code&gt;R&lt;/code&gt; syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(DV ~ A, dataset))
&amp;gt; # OR
&amp;gt; anova(aov(DV ~ A, dataset))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An F-ratio substantially greater than &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; suggests that the model relating the response variable to the categorical variable explains substantially more variability than is left unexplained. In turn, this implies that the linear model does represent the data well and that differences between observations can be explained largely by differences in treatment levels rather than purely the result of random variation. If the probability of getting the observed (sample) F-ratio or one more extreme is less than some predefined critical value (typically &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% or &lt;span class=&#34;math inline&#34;&gt;\(0.05\)&lt;/span&gt;), we conclude that it is highly unlikely that the observed samples could have been collected from populations in which the treatment has no effect and therefore we would reject the null hypothesis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;An F-ratio from real data can only reliably relate to a theoretical F-distribution when the data conform to certain assumptions. Hypothesis testing for a single factor ANOVA model assumes that the residuals (and therefore the response variable for each of the treatment levels) are all:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;normally distributed&lt;/strong&gt; - although ANOVA is robust to non-normality provided sample sizes and variances are equal. Boxplots should be used to explore normality, skewness, bimodality and outliers. In the event of homogeneity of variance issues (see below), a Q-Q normal plot can also be useful for exploring normality (as this might be the cause of non-homogeneity). Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;equally varied&lt;/strong&gt; - provided sample sizes are equal and the largest to smallest variance ratio does not exceed 3:1 (9:1 for sd), ANOVA is reasonably robust to this assumption, however, relationships between variance and mean and/or sample size are of particular concern as they elevate the Type I error rate. Boxplots and plots of means against variance should be used to explore the spread of values. Residual plots should reveal no patterns. Since unequal variances are often the result of non-normality, transformations that improve normality will also improve variance homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;independent of one another&lt;/strong&gt; - this assumption must be addressed at the design and collection stages and cannot be compensated for later (unless a model is used that specifically accounts for particular types of non-independent data, such as that introduced with hierarchical designs or autocorrelation)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Violations of these assumptions reduce the reliability of the analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Lets say we had set up a natural experiment in which we measured a response from &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; sampling units (replicates) from each of &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; treatments. Hence, we have a single categorical factor with &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; levels - we might have five different locations, or five different habitat types or substrates etc. In statistical speak, we have sampled from &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; different populations. We have then randomly selected &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; independent and random (representative) units of each population to sample. That is, we have &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; samples (replicates) of each population. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; ngroups &amp;lt;- 5  #number of populations
&amp;gt; nsample &amp;lt;- 10  #number of reps in each
&amp;gt; pop.means &amp;lt;- c(40, 45, 55, 40, 30)  #population mean length
&amp;gt; sigma &amp;lt;- 3  #residual standard deviation
&amp;gt; n &amp;lt;- ngroups * nsample  #total sample size
&amp;gt; eps &amp;lt;- rnorm(n, 0, sigma)  #residuals
&amp;gt; x &amp;lt;- gl(ngroups, nsample, n, lab = LETTERS[1:5])  #factor
&amp;gt; means &amp;lt;- rep(pop.means, rep(nsample, ngroups))
&amp;gt; X &amp;lt;- model.matrix(~x - 1)  #create a design matrix
&amp;gt; y &amp;lt;- as.numeric(X %*% pop.means + eps)
&amp;gt; data &amp;lt;- data.frame(y, x)
&amp;gt; head(data)  #print out the first six rows of the data set
         y x
1 38.31857 A
2 39.30947 A
3 44.67612 A
4 40.21153 A
5 40.38786 A
6 45.14519 A
&amp;gt; 
&amp;gt; write.csv(data, &amp;quot;simpleAnova.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type.&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Normality and Homogeneity of variance&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ x, data)
&amp;gt; 
&amp;gt; # OR via ggplot2
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/exp_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = y, x = x)) + geom_boxplot() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/exp_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity. Obvious violations could be addressed either by, for example, transforming the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0+\boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the mean of the first group and the set of &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;’s represent the differences between each other group and the first group. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. We proceed to code the model into &lt;code&gt;STAN&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   //Likelihood
+   y~normal(mu,sigma);
+   
+   //Priors
+   beta ~ normal(0,1000);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString, con = &amp;quot;anovaModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~x, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = Xmat, nX = ncol(Xmat), n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;log_lik&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 500
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 2000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 1500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now compile and run the Stan code via the &lt;code&gt;rstan&lt;/code&gt; interface. Note that the first time &lt;code&gt;stan&lt;/code&gt; is run after the &lt;code&gt;rstan&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;During the warmup stage, the No-U-Turn sampler (NUTS) attempts to determine the optimum stepsize - the stepsize that achieves the target acceptance rate (&lt;span class=&#34;math inline&#34;&gt;\(0.8\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(80\)&lt;/span&gt;% by default) without divergence (occurs when the stepsize is too large relative to the curvature of the log posterior and results in approximations that are likely to diverge and be biased) - and without hitting the maximum treedepth (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;). At each iteration of the NUTS algorithm, the number of leapfrog steps doubles (as it increases the treedepth) and only terminates when either the NUTS criterion are satisfied or the tree depth reaches the maximum (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; by default).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rstan &amp;lt;- stan(data = data.list, file = &amp;quot;anovaModel.stan&amp;quot;, chains = nChains, pars = params,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;anovaModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.05 seconds (Warm-up)
Chain 1:                0.055 seconds (Sampling)
Chain 1:                0.105 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;anovaModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.049 seconds (Warm-up)
Chain 2:                0.063 seconds (Sampling)
Chain 2:                0.112 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.rstan, par = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%   75% 97.5% n_eff Rhat
beta[1]  40.24    0.04 0.89  38.45  39.69  40.24 40.87 41.93   634 1.01
beta[2]   5.38    0.04 1.25   2.97   4.54   5.36  6.18  7.86   833 1.00
beta[3]  13.48    0.04 1.29  10.89  12.64  13.41 14.34 15.97   888 1.00
beta[4]   0.70    0.04 1.25  -1.81  -0.13   0.69  1.56  3.06   949 1.01
beta[5] -10.27    0.04 1.25 -12.57 -11.13 -10.30 -9.40 -7.85   817 1.00
sigma     2.85    0.01 0.31   2.34   2.64   2.83  3.04  3.53  1108 1.00

Samples were drawn using NUTS(diag_e) at Mon Feb 17 11:28:36 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; s = as.array(data.rstan)
&amp;gt; mcmc &amp;lt;- do.call(mcmc.list, plyr:::alply(s[, , -(length(s[1, 1, ]))], 2, as.mcmc))
&amp;gt; denplot(mcmc, parms = c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(mcmc, parms = c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(mcmc)
$`1`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

$`2`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; stan_ac(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_rhat(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_ess(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag4-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Rhat and effective sample size. In this instance, most of the parameters have reasonably high effective samples and thus there is likely to be a good range of values from which to estimate paramter properties.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model. Residuals are not computed directly within &lt;code&gt;rstan&lt;/code&gt; However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(tidyr)
&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = x)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentized residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:5]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; newdata = data.frame(x = data$x, yRep) %&amp;gt;% gather(key = Sample,
+     value = Value, -x)
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = x, fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_violin(data = data, aes(y = y, x = x,
+     fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) + geom_point(data = data, aes(y = y,
+     x = x), position = position_jitter(width = 0.1, height = 0),
+     color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(as.matrix(data.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(as.matrix(data.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.rstan, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%   75% 97.5% n_eff Rhat
beta[1]  40.24    0.04 0.89  38.45  39.69  40.24 40.87 41.93   634 1.01
beta[2]   5.38    0.04 1.25   2.97   4.54   5.36  6.18  7.86   833 1.00
beta[3]  13.48    0.04 1.29  10.89  12.64  13.41 14.34 15.97   888 1.00
beta[4]   0.70    0.04 1.25  -1.81  -0.13   0.69  1.56  3.06   949 1.01
beta[5] -10.27    0.04 1.25 -12.57 -11.13 -10.30 -9.40 -7.85   817 1.00
sigma     2.85    0.01 0.31   2.34   2.64   2.83  3.04  3.53  1108 1.00

Samples were drawn using NUTS(diag_e) at Mon Feb 17 11:28:36 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(data.rstan, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
# A tibble: 6 x 5
  term    estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]   40.2       0.895    38.4      41.9 
2 beta[2]    5.38      1.25      3.09      7.96
3 beta[3]   13.5       1.29     11.0      16.1 
4 beta[4]    0.703     1.25     -1.94      2.90
5 beta[5]  -10.3       1.25    -12.6      -7.85
6 sigma      2.85      0.306     2.33      3.50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the mean of the first group (A) is &lt;span class=&#34;math inline&#34;&gt;\(40.2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the mean of the second group (B) is &lt;span class=&#34;math inline&#34;&gt;\(5.4\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the third group (C) is &lt;span class=&#34;math inline&#34;&gt;\(13.5\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the forth group (D) is &lt;span class=&#34;math inline&#34;&gt;\(0.74\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the fifth group (E) is &lt;span class=&#34;math inline&#34;&gt;\(-10.2\)&lt;/span&gt; units greater (i.e. less) than (A)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of B, C and E do not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between group A and groups B, C and E. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[2]&amp;quot;])  # effect of (B-A)
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[3]&amp;quot;])  # effect of (C-A)
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[4]&amp;quot;])  # effect of (D-A)
[1] 0.5805
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[5]&amp;quot;])  # effect of (E-A)
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, 2:5])  # effect of (all groups)
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence that the reponse differs between the groups. There is evidence suggesting that the response of group D differs from that of group A. In a Bayesian context, we can compare models using the &lt;strong&gt;leave-one-out cross-validation&lt;/strong&gt; statistics. Leave-one-out (LOO) cross-validation explores how well a series of models can predict withheld values &lt;span class=&#34;citation&#34;&gt;Vehtari, Gelman, and Gabry (2017)&lt;/span&gt;. The LOO Information Criterion (LOOIC) is analogous to the AIC except that the LOOIC takes priors into consideration, does not assume that the posterior distribution is drawn from a multivariate normal and integrates over parameter uncertainty so as to yield a distribution of looic rather than just a point estimate. The LOOIC does however assume that all observations are equally influential (it does not matter which observations are left out). This assumption can be examined via the Pareto &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; estimate (values greater than &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt; or more conservatively &lt;span class=&#34;math inline&#34;&gt;\(0.75\)&lt;/span&gt; are considered overly influential). We can compute LOOIC if we store the loglikelihood from our &lt;code&gt;STAN&lt;/code&gt; model, which can then be extracted to compute the information criterion using the package &lt;code&gt;loo&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(loo)
&amp;gt; (full = loo(extract_log_lik(data.rstan)))

Computed from 2000 by 50 log-likelihood matrix

         Estimate   SE
elpd_loo   -125.8  5.1
p_loo         5.6  1.1
looic       251.6 10.2
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k &amp;lt; 0.5).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; # now fit a model without main factor
&amp;gt; modelString2 = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   //Likelihood
+   y~normal(mu,sigma);
+   
+   //Priors
+   beta ~ normal(0,1000);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString2, con = &amp;quot;anovaModel2.stan&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~1, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = Xmat, n = nrow(data), nX = ncol(Xmat)))
&amp;gt; data.rstan.red &amp;lt;- stan(data = data.list, file = &amp;quot;anovaModel2.stan&amp;quot;, chains = nChains,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;anovaModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.019 seconds (Warm-up)
Chain 1:                0.042 seconds (Sampling)
Chain 1:                0.061 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;anovaModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.021 seconds (Warm-up)
Chain 2:                0.094 seconds (Sampling)
Chain 2:                0.115 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; (reduced = loo(extract_log_lik(data.rstan.red)))

Computed from 2000 by 50 log-likelihood matrix

         Estimate  SE
elpd_loo   -177.8 4.4
p_loo         1.6 0.3
looic       355.6 8.7
------
Monte Carlo SE of elpd_loo is 0.0.

All Pareto k estimates are good (k &amp;lt; 0.5).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; par(mfrow = 1:2, mar = c(5, 3.8, 1, 0) + 0.1, las = 3)
&amp;gt; plot(full, label_points = TRUE)
&amp;gt; plot(reduced, label_points = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_looic-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The expected out-of-sample predictive accuracy is substantially lower for the model that includes &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. This might be used to suggest that the inferential evidence for a general effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;With appropriate use of model matrices and data wrangling, it is possible to produce a single prediction data set along with &lt;code&gt;ggplot&lt;/code&gt; syntax to produce a multi-panel figure. First we look at the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = rbind(data.frame(x = levels(data$x)))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;, &amp;quot;beta[4]&amp;quot;, &amp;quot;beta[5]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_linerange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_point() + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = as.numeric(x) - 0.1)) + geom_blank(aes(x = x)) +
+     geom_point(data = rdata, aes(y = partial.resid, x = as.numeric(x) +
+         0.1), color = &amp;quot;gray&amp;quot;) + geom_linerange(aes(ymin = conf.low, ymax = conf.high)) +
+     geom_point() + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posteriors&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Posteriors&lt;/h1&gt;
&lt;p&gt;In frequentist statistics, when we have more than two groups, we are typically not only interested in whether there is evidence for an overall “effect” of a factor - we are also interested in how various groups compare to one another. To explore these trends, we either compare each group to each other in a pairwise manner (controlling for family-wise Type I error rates) or we explore an independent subset of the possible comparisons. Although these alternate approaches can adequately address a specific research agenda, often they impose severe limitations and compromises on the scope and breadth of questions that can be asked of your data. The reason for these limitations is that in a frequentist framework, any single hypothesis carries with it a (nominally) &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% chance of a false rejection (since it is based on long-run frequency). Thus, performing multiple tests are likely to compound this error rate. The point is, that each comparison is compared to its own probability distribution (and each carries a &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% error rate). By contrast, in Bayesian statistics, all comparisons (contrasts) are drawn from the one (hopefully stable and convergent) posterior distribution and this posterior is invariant to the type and number of comparisons drawn. Hence, the theory clearly indicates that having generated our posterior distribution, we can then query this distribution in any way that we wish thereby allowing us to explore all of our research questions simultaneously.&lt;/p&gt;
&lt;p&gt;Bayesian “contrasts” can be performed either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;within the Bayesian sampling model or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;construct them from the returned MCMC samples (they are drawn from the posteriors)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Only the latter will be demonstrated as it povides a consistent approach across all routines. In order to allow direct comparison to the frequentist equivalents, I will explore the same set of planned and &lt;em&gt;Tukey&lt;/em&gt;’s test comparisons described here. For the “planned comparison” we defined two contrasts: 1) group 3 vs group 5; and 2) the average of groups 1 and 2 vs the average of groups 3, 4 and 5.&lt;/p&gt;
&lt;p&gt;Lets start by comparing each group to each other group in a pairwise manner. Arguably the most elegant way to do this is to generate a Tukey’s contrast matrix. This is a model matrix specific to comparing each group to each other group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.rstan
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:5]
&amp;gt; newdata &amp;lt;- data.frame(x = levels(data$x))
&amp;gt; # A Tukeys contrast matrix
&amp;gt; library(multcomp)
&amp;gt; # table(newdata$x) - gets the number of replicates of each level
&amp;gt; tuk.mat &amp;lt;- contrMat(n = table(newdata$x), type = &amp;quot;Tukey&amp;quot;)
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data = newdata)
&amp;gt; pairwise.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; pairwise.mat
      (Intercept) xB xC xD xE
B - A           0  1  0  0  0
C - A           0  0  1  0  0
D - A           0  0  0  1  0
E - A           0  0  0  0  1
C - B           0 -1  1  0  0
D - B           0 -1  0  1  0
E - B           0 -1  0  0  1
D - C           0  0 -1  1  0
E - C           0  0 -1  0  1
E - D           0  0  0 -1  1
&amp;gt; 
&amp;gt; mcmc_areas(coefs %*% t(pairwise.mat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/posterior1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; (comps = tidyMCMC(coefs %*% t(pairwise.mat), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 B - A    5.38       1.25     3.09      7.96
 2 C - A   13.5        1.29    11.0      16.1 
 3 D - A    0.703      1.25    -1.94      2.90
 4 E - A  -10.3        1.25   -12.6      -7.85
 5 C - B    8.10       1.28     5.71     10.8 
 6 D - B   -4.68       1.26    -7.06     -2.21
 7 E - B  -15.6        1.25   -18.3     -13.4 
 8 D - C  -12.8        1.29   -15.3     -10.1 
 9 E - C  -23.7        1.31   -26.2     -21.0 
10 E - D  -11.0        1.27   -13.5      -8.63
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/posterior1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With a couple of modifications, we could also express this as percentage changes. A percentage change represents the change (difference between groups) divided by one of the groups (determined by which group you want to express the percentage change to). Hence, we generate an additional mcmc matrix that represents the cell means for the divisor group (group we want to express change relative to). Since the &lt;code&gt;tuk.mat&lt;/code&gt; defines comparisons as &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; pairs, if we simply replace all the &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, the eventual matrix multiplication will result in estimates of the divisor cell means instread of the difference. We can then divide the original mcmc matrix above with this new divisor mcmc matrix to yeild a mcmc matrix of percentage change.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # Modify the tuk.mat to replace -1 with 0.  This will allow us to get a
&amp;gt; # mcmc matrix of ..
&amp;gt; tuk.mat[tuk.mat == -1] = 0
&amp;gt; comp.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; comp.mat
      (Intercept) xB xC xD xE
B - A           1  1  0  0  0
C - A           1  0  1  0  0
D - A           1  0  0  1  0
E - A           1  0  0  0  1
C - B           1  0  1  0  0
D - B           1  0  0  1  0
E - B           1  0  0  0  1
D - C           1  0  0  1  0
E - C           1  0  0  0  1
E - D           1  0  0  0  1
&amp;gt; 
&amp;gt; comp.mcmc = 100 * (coefs %*% t(pairwise.mat))/coefs %*% t(comp.mat)
&amp;gt; (comps = tidyMCMC(comp.mcmc, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 B - A    11.8       2.59     6.40     16.5 
 2 C - A    25.1       2.11    20.9      29.1 
 3 D - A     1.67      3.02    -4.53      7.24
 4 E - A   -34.4       4.95   -43.7     -24.9 
 5 C - B    15.1       2.20    10.9      19.6 
 6 D - B   -11.5       3.27   -17.7      -5.09
 7 E - B   -52.3       5.36   -62.5     -41.7 
 8 D - C   -31.3       3.64   -38.4     -23.7 
 9 E - C   -79.4       6.27   -90.6     -66.2 
10 E - D   -36.7       5.06   -46.9     -27.4 
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size (%)&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/posterior2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for the specific planned comparisons (Group 3 vs Group 5 and the average of Groups 1 and 2 vs the average of Groups 3, 4 and 5). This is achieved by generating our own contrast matrix (defining the contributions of each group to each contrast).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; c.mat = rbind(c(0, 0, -1, 0, 1), c(-1/2, -1/2, 1/3, 1/3, 1/3))
&amp;gt; c.mat
     [,1] [,2]       [,3]      [,4]      [,5]
[1,]  0.0  0.0 -1.0000000 0.0000000 1.0000000
[2,] -0.5 -0.5  0.3333333 0.3333333 0.3333333
&amp;gt; 
&amp;gt; mcmc = data.rstan
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:5]
&amp;gt; newdata &amp;lt;- data.frame(x = levels(data$x))
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data = newdata)
&amp;gt; c.mat = c.mat %*% Xmat
&amp;gt; c.mat
       (Intercept)   xB         xC        xD        xE
[1,]  0.000000e+00  0.0 -1.0000000 0.0000000 1.0000000
[2,] -1.110223e-16 -0.5  0.3333333 0.3333333 0.3333333
&amp;gt; 
&amp;gt; (comps = tidyMCMC(as.mcmc(coefs %*% t(c.mat)), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 2 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1    -23.7      1.31    -26.2    -21.0  
2 var2     -1.38     0.806    -2.92     0.186&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         9.94    0.532      8.89     11.0 
2 sd.resid     2.79    0.0888     2.67      2.96
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         78.3      1.06     76.0      79.7
2 sd.resid     21.7      1.06     20.3      24.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/effects_modelv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(78.3\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- as.matrix(data.rstan)
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.887    0.0126    0.863     0.905
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ x, data))

Call:
lm(formula = y ~ x, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5257 -1.9000 -0.2589  1.4935  6.5330 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.2239     0.8801  45.702  &amp;lt; 2e-16 ***
xB            5.4020     1.2447   4.340 7.97e-05 ***
xC           13.5024     1.2447  10.848 3.82e-14 ***
xD            0.7423     1.2447   0.596    0.554    
xE          -10.2500     1.2447  -8.235 1.57e-10 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 2.783 on 45 degrees of freedom
Multiple R-squared:  0.8957,    Adjusted R-squared:  0.8865 
F-statistic: 96.64 on 4 and 45 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2015stan&#34;&gt;
&lt;p&gt;Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt; 40 (5): 530–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanpackage&#34;&gt;
&lt;p&gt;Stan Development Team. 2018. “RStan: The R Interface to Stan.” &lt;a href=&#34;http://mc-stan.org/&#34;&gt;http://mc-stan.org/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vehtari2017practical&#34;&gt;
&lt;p&gt;Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and Waic.” &lt;em&gt;Statistics and Computing&lt;/em&gt; 27 (5): 1413–32.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Multiple Linear Regression - JAGS</title>
      <link>/jags/multiple-linear-regression-jags/multiple-linear-regression-jags/</link>
      <pubDate>Mon, 03 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/multiple-linear-regression-jags/multiple-linear-regression-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Multiple regression is an extension of simple linear regression whereby a response variable is modelled against a linear combination of two or more simultaneously measured predictor variables. There are two main purposes of multiple linear regression:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;To develop a better predictive model (equation) than is possible from models based on single independent variables.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;To investigate the relative individual effects of each of the multiple independent variables above and beyond (standardised across) the effects of the other variables.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Although the relationship between response variable and the additive effect of all the predictor variables is represented overall by a single multidimensional plane (surface), the individual effects of each of the predictor variables on the response variable (standardised across the other variables) can be depicted by single partial regression lines. The slope of any single partial regression line (partial regression slope) thereby represents the rate of change or effect of that specific predictor variable (holding all the other predictor variables constant to their respective mean values) on the response variable. In essence, it is the effect of one predictor variable at one specific level (the means) of all the other predictor variables (i.e. when each of the other predictors are set to their averages).&lt;/p&gt;
&lt;p&gt;Multiple regression models can be constructed additively (containing only the predictor variables themselves) or in a multiplicative design (which incorporate interactions between predictor variables in addition to the predictor variables themselves). Multiplicative models are used primarily for testing inferences about the effects of various predictor variables and their interactions on the response variable. Additive models by contrast are used for generating predictive models and estimating the relative importance of individual predictor variables more so than hypothesis testing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additive-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additive Model&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_{i1} +  \beta_2x_{i2} + \ldots + \beta_Jx_{iJ} + \epsilon_i,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the population &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept (value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; when all partial slopes equal zero), &lt;span class=&#34;math inline&#34;&gt;\(\beta_1,\beta_2,\ldots,\beta_{J}\)&lt;/span&gt; are the partial population slopes of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(X_1,X_2,\ldots,X_J\)&lt;/span&gt; respectively holding the other &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; constant. &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_i\)&lt;/span&gt; is the random unexplained error or residual component. The additive model assumes that the effect of one predictor variable (partial slope) is independent of the levels of the other predictor variables.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiplicative-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiplicative Model&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_{i1} +  \beta_2x_{i2} + \beta_3x_{i1}x_{i2} + \ldots + \beta_Jx_{iJ} + \epsilon_i,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_3x_{i1}x_{i2}\)&lt;/span&gt; is the interactive effect of &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(X_2\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; and it examines the degree to which the effect of one of the predictor variables depends on the levels of the other predictor variable(s).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Lets say we had set up a natural experiment in which we measured a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) from each of &lt;span class=&#34;math inline&#34;&gt;\(20\)&lt;/span&gt; sampling units (&lt;span class=&#34;math inline&#34;&gt;\(n=20\)&lt;/span&gt;) across a landscape. At the same time, we also measured two other continuous covariates (&lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;) from each of the sampling units. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n = 100
&amp;gt; intercept = 5
&amp;gt; temp = runif(n)
&amp;gt; nitro = runif(n) + 0.8 * temp
&amp;gt; int.eff = 2
&amp;gt; temp.eff &amp;lt;- 0.85
&amp;gt; nitro.eff &amp;lt;- 0.5
&amp;gt; res = rnorm(n, 0, 1)
&amp;gt; coef &amp;lt;- c(int.eff, temp.eff, nitro.eff, int.eff)
&amp;gt; mm &amp;lt;- model.matrix(~temp * nitro)
&amp;gt; 
&amp;gt; y &amp;lt;- t(coef %*% t(mm)) + res
&amp;gt; data &amp;lt;- data.frame(y, x1 = temp, x2 = nitro, cx1 = scale(temp,
+     scale = F), cx2 = scale(nitro, scale = F))
&amp;gt; head(data)
         y        x1        x2         cx1         cx2
1 2.426468 0.2875775 0.8300510 -0.21098147 -0.08302110
2 4.927690 0.7883051 0.9634676  0.28974614  0.05039557
3 3.176118 0.4089769 0.8157946 -0.08958207 -0.09727750
4 6.166652 0.8830174 1.6608878  0.38445841  0.74781568
5 4.788890 0.9404673 1.2352762  0.44190829  0.32220415
6 2.541536 0.0455565 0.9267954 -0.45300249  0.01372335&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the components linear predictor (continuous predictors). We could model the relationship via either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;An additive model in which the effects of each predictor contribute in an additive way to the response - we do not allow for an interaction as we consider an interaction either not of great importance or likely to be absent.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A multiplicative model in which the effects of each predictor and their interaction contribute to the response - we allow for the impact of one predictor to vary across the range of the other predictor.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;centering-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Centering the data&lt;/h2&gt;
&lt;p&gt;When a linear model contains a covariate (continuous predictor variable) in addition to another predictor (continuous or categorical), it is nearly always advisable that the continuous predictor variables are centered prior to the analysis. Centering is a process by which the mean of a variable is subtracted from each of the values such that the scale of the variable is shifted so as to be centered around &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Hence the mean of the new centered variable will be &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, yet it will retain the same variance.&lt;/p&gt;
&lt;p&gt;There are multiple reasons for this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;It provides some clinical meaning to the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept. Recall that the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is equal to zero. If &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is centered, then the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept represents the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at the mid-point of the &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; range. The &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept of an uncentered &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; typically represents a unreal value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; (as an &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; is often beyond the reasonable range of values).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In multiplicative models (in which predictors and their interactions are included), main effects and interaction terms built from centered predictors will not be correlated to one another.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For more complex models, centering the covariates can increase the likelihood that the modelling engine converges (arrives at a numerically stable and reliable outcome).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note, centering will not effect the slope estimates. In &lt;code&gt;R&lt;/code&gt;, centering is easily achieved with the &lt;code&gt;scale&lt;/code&gt; function, which centers and scales (divides by standard deviation) the data. We only really need to center the data, so we provide the argument &lt;code&gt;scale=FALSE&lt;/code&gt;. Also note that the &lt;code&gt;scale&lt;/code&gt; function attaches the pre-centered mean (and standard deviation if scaling is performed) as attributes to the scaled data in order to facilitate back-scaling to the original scale. While these attributes are often convenient, they do cause issues for some of the Bayesian routines and so we will strip these attributes using the &lt;code&gt;as.numeric&lt;/code&gt; function. Instead, we will create separate scalar variables to store the pre-scaled means.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data &amp;lt;- within(data, {
+     cx1 &amp;lt;- as.numeric(scale(x1, scale = FALSE))
+     cx2 &amp;lt;- as.numeric(scale(x2, scale = FALSE))
+ })
&amp;gt; head(data)
         y        x1        x2         cx1         cx2
1 2.426468 0.2875775 0.8300510 -0.21098147 -0.08302110
2 4.927690 0.7883051 0.9634676  0.28974614  0.05039557
3 3.176118 0.4089769 0.8157946 -0.08958207 -0.09727750
4 6.166652 0.8830174 1.6608878  0.38445841  0.74781568
5 4.788890 0.9404673 1.2352762  0.44190829  0.32220415
6 2.541536 0.0455565 0.9267954 -0.45300249  0.01372335
&amp;gt; 
&amp;gt; mean.x1 = mean(data$x1)
&amp;gt; mean.x2 = mean(data$x2)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Assumptions&lt;/h1&gt;
&lt;p&gt;The assumptions of the model are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All of the observations are independent - this must be addressed at the design and collection stages.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (and thus the residuals) should be normally distributed. A boxplot of the entire variable is usually useful for diagnosing major issues with normality.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately). Scatterplots with linear smoothers can be useful for exploring the spread of observations around the trendline. The spread of observations around the trendline should not increase (or decrease) along its length.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The predictor variables should be uniformly or normally distributed. Again, boxplots can be useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The relationships between the linear predictors (right hand side of the regression formula) and the response variable should be linear. Scatterplots with smoothers can be useful for identifying possible non-linearity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;(Multi)collinearity&lt;/strong&gt;. The number of predictor variables must be less than the number of observations otherwise the linear model will be over-parameterized (more parameters to estimate than there are independent data from which estimates are calculated).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Multi)collinearity breaks the assumption that a predictor variable must not be correlated to the combination of other predictor variables (known collectively as the linear predictor). Multicollinearity has major detrimental effects on model fitting:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Instability of the estimated partial regression slopes (small changes in the data or variable inclusion can cause dramatic changes in parameter estimates).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Inflated standard errors and confidence intervals of model parameters, thereby increasing the type II error rate (reducing power) of parameter hypothesis tests.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Multicollinearity can be diagnosed with the following situatons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Investigate pairwise correlations between all the predictor variables either by a correlation matrix or a scatterplot matrix&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Calculate the &lt;strong&gt;tolerance&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\((1−r^2)\)&lt;/span&gt; of the relationship between a predictor variable and all the other predictor variables for each of the predictor variables. Tolerance is a measure of the degree of collinearity and values less than &lt;span class=&#34;math inline&#34;&gt;\(0.2\)&lt;/span&gt; should be considered and values less than &lt;span class=&#34;math inline&#34;&gt;\(0.1\)&lt;/span&gt; should be given serious attention. &lt;strong&gt;Variance inflation factor&lt;/strong&gt; (VIF) is the inverse of tolerance and thus values greater than &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;, or worse, &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; indicate collinearity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;PCA&lt;/strong&gt; (principle components analysis) eigenvalues (from a correlation matrix for all the predictor variables) close to zero indicate collinearity and component loadings may be useful in determining which predictor variables cause collinearity.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are several approaches to dealing with collinearity (however the first two of these are likely to result in biased parameter estimates):&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Remove the highly correlated predictor variable(s), starting with the least most clinically interesting variable(s)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;PCA (principle components analysis) regression - regress the response variable against the principal components resulting from a correlation matrix for all the predictor variables. Each of these principal components by definition are completely independent, but the resulting parameter estimates must be back-calculated in order to have any clinical meaning.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Apply a regression tree - regression trees recursively partitioning (subsetting) the data in accordance to individual variables that explain the greatest remaining variance. Since at each iteration, each predictor variable is effectively evaluated in isolation, (multi)collinearity is not an issue.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;Multiple linear regression models can include predictors (terms) that are incorporated additively (no interactions) or multiplicatively (with interactions). As such we will explore these separately for each modelling tool. The observed responses (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values are themselves determined by the linear predictor. In this case, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept (value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; when all of the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;’s are equal to zero) and the set of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;’s represent the rates of change in y for every unit change in each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; (the effect) holding each other &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; constant. Note that since we should always center all predictors (by subtracting the mean of each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; from the repective values of each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;), the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept represents the value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at the average value of each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying “uninformative” priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\mu_i, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 + \boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;. Priors are specified as: &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta \sim \text{Normal}(0,1000)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. We will explore Bayesian modelling of multiple linear regression using &lt;code&gt;JAGS&lt;/code&gt;. Remember that in this software normal distributions are specified in terms of precision &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mu[i],tau)
+   mu[i] &amp;lt;- beta0 + inprod(beta[],X[i,])
+   }
+   #Priors
+   beta0 ~ dnorm(0.01,1.0E-6)
+   for (j in 1:nX) {
+   beta[j] ~ dnorm(0.01,1.0E-6)
+   }
+   tau &amp;lt;- 1 / (sigma * sigma)
+   sigma~dunif(0,100)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;ttestModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;additive-model-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additive Model&lt;/h2&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X = model.matrix(~cx1 + cx2, data = data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = X[, -1], nX = ncol(X) -
+     1, n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags.add &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;ttestModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 4
   Total graph size: 614

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags.add)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]    2.830   0.442   1.964   2.538   2.830   3.125   3.694 1.001  7400
beta[2]    1.582   0.380   0.833   1.327   1.581   1.834   2.319 1.001 14000
beta0      3.799   0.100   3.603   3.733   3.797   3.865   3.997 1.001 15000
sigma      0.996   0.074   0.864   0.944   0.992   1.043   1.154 1.001 15000
deviance 281.420   2.961 277.779 279.260 280.727 282.888 288.827 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.4 and DIC = 285.8
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;multiplicative-model-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiplicative Model&lt;/h2&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X = model.matrix(~cx1 * cx2, data = data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = X[, -1], nX = ncol(X) - 1, n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags.mult &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;ttestModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 5
   Total graph size: 715

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags.mult)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]    2.800   0.451   1.914   2.500   2.801   3.104   3.680 1.001 15000
beta[2]    1.504   0.389   0.744   1.237   1.505   1.766   2.267 1.001 15000
beta[3]    1.451   1.210  -0.933   0.643   1.456   2.238   3.849 1.001 15000
beta0      3.715   0.122   3.475   3.633   3.715   3.797   3.957 1.001  6000
sigma      0.994   0.073   0.863   0.944   0.989   1.039   1.151 1.001 15000
deviance 280.964   3.307 276.617 278.541 280.281 282.649 289.157 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 5.5 and DIC = 286.4
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;. Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags.mult, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags.mult, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags.mult)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3609  3746         0.963     
 beta[2]  2        3811  3746         1.020     
 beta[3]  2        3811  3746         1.020     
 beta0    2        3770  3746         1.010     
 deviance 2        3729  3746         0.995     
 sigma    4        4989  3746         1.330     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3729  3746         0.995     
 beta[2]  2        3730  3746         0.996     
 beta[3]  2        3811  3746         1.020     
 beta0    2        3729  3746         0.995     
 deviance 2        3751  3746         1.000     
 sigma    4        5306  3746         1.420     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
            beta[1]       beta[2]      beta[3]        beta0      deviance
Lag 0   1.000000000  1.0000000000  1.000000000  1.000000000  1.000000e+00
Lag 1  -0.007495093 -0.0002601039 -0.004404658 -0.016267523  1.340676e-01
Lag 5   0.004013980 -0.0121560194  0.004193180  0.006361847  7.319664e-05
Lag 10 -0.009167511 -0.0004423631  0.007960201  0.005194172 -5.183038e-03
Lag 50  0.001459434  0.0077668977 -0.006551273 -0.003063066 -5.021565e-03
              sigma
Lag 0   1.000000000
Lag 1   0.262166680
Lag 5  -0.020700390
Lag 10 -0.006918124
Lag 50  0.001501713&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.&lt;/p&gt;
&lt;p&gt;There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Standardised residuals&lt;/strong&gt;. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Studentised residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the residuals. Note that &lt;strong&gt;externally studentised residuals&lt;/strong&gt; are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pearson residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%) back thereby allowing us to train the model on &lt;span class=&#34;math inline&#34;&gt;\(75\)&lt;/span&gt;% of the data and then see how well the model can predict the withheld &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.&lt;/p&gt;
&lt;p&gt;Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within &lt;code&gt;JAGS&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(ggplot2)
&amp;gt; library(dplyr)
&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;% dplyr:::select(beta0,
+     contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(tidyr)
&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;% dplyr:::select(beta0,
+     contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = data %&amp;gt;% cbind(fit, resid)
&amp;gt; newdata.melt = newdata %&amp;gt;% gather(key = Pred, value = Value, cx1:cx2)
&amp;gt; ggplot(newdata.melt) + geom_point(aes(y = resid, x = Value)) + facet_wrap(~Pred)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;% dplyr:::select(beta0, 
+   contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(beta0, contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~cx1 * cx2, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:4]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; ggplot() + geom_density(data = NULL, aes(x = as.vector(yRep),
+     fill = &amp;quot;Model&amp;quot;), alpha = 0.5) + geom_density(data = data,
+     aes(x = y, fill = &amp;quot;Obs&amp;quot;), alpha = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(data.r2jags.mult$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data.r2jags.mult$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags.add)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]    2.830   0.442   1.964   2.538   2.830   3.125   3.694 1.001  7400
beta[2]    1.582   0.380   0.833   1.327   1.581   1.834   2.319 1.001 14000
beta0      3.799   0.100   3.603   3.733   3.797   3.865   3.997 1.001 15000
sigma      0.996   0.074   0.864   0.944   0.992   1.043   1.154 1.001 15000
deviance 281.420   2.961 277.779 279.260 280.727 282.888 288.827 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.4 and DIC = 285.8
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags.add), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 5 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]     2.83     0.442     1.96       3.69
2 beta[2]     1.58     0.380     0.844      2.33
3 beta0       3.80     0.1000    3.60       3.99
4 deviance  281.       2.96    277.       287.  
5 sigma       0.996    0.0742    0.857      1.14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;When &lt;code&gt;cx2&lt;/code&gt; is held constant, a one unit increase in &lt;code&gt;cx1&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(2.83\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(2.83\)&lt;/span&gt; per unit increase in &lt;code&gt;cx1&lt;/code&gt; when standardised for &lt;code&gt;cx2&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When &lt;code&gt;cx1&lt;/code&gt; is held constant, a one unit increase in &lt;code&gt;cx2&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(1.58\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(1.58\)&lt;/span&gt; per unit increase in &lt;code&gt;cx2&lt;/code&gt; when standardised for &lt;code&gt;cx1&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note, as this is an additive model, the rates associated with &lt;code&gt;cx1&lt;/code&gt; are assumed to be constant throughtout the range of &lt;code&gt;cx2&lt;/code&gt; and vice versa. The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for each partial slope does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant effects of &lt;code&gt;cx1&lt;/code&gt; and &lt;code&gt;cx2&lt;/code&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags.add$BUGSoutput$sims.matrix[, &amp;quot;beta[1]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags.add$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])
[1] 0.0001333333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of essentially &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, we would conclude that there is almost no evidence that the slope was likely to be equal to zero, suggesting there is a relationship. Next, we look at the results from the multiplicative model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags.mult)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]    2.800   0.451   1.914   2.500   2.801   3.104   3.680 1.001 15000
beta[2]    1.504   0.389   0.744   1.237   1.505   1.766   2.267 1.001 15000
beta[3]    1.451   1.210  -0.933   0.643   1.456   2.238   3.849 1.001 15000
beta0      3.715   0.122   3.475   3.633   3.715   3.797   3.957 1.001  6000
sigma      0.994   0.073   0.863   0.944   0.989   1.039   1.151 1.001 15000
deviance 280.964   3.307 276.617 278.541 280.281 282.649 289.157 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 5.5 and DIC = 286.4
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags.mult), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 6 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]     2.80     0.451     1.91       3.67
2 beta[2]     1.50     0.389     0.746      2.27
3 beta[3]     1.45     1.21     -0.976      3.79
4 beta0       3.71     0.122     3.47       3.95
5 deviance  281.       3.31    276.       287.  
6 sigma       0.994    0.0729    0.856      1.14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;At the average level of &lt;code&gt;cx2 (=0)&lt;/code&gt;, a one unit increase in &lt;code&gt;cx1&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(2.80\)&lt;/span&gt; change in y. That is, y increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(2.80\)&lt;/span&gt; per unit increase in &lt;code&gt;cx1&lt;/code&gt; when standardised for &lt;code&gt;cx2&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;At the average level of &lt;code&gt;cx1 (=0)&lt;/code&gt;, a one unit increase in &lt;code&gt;cx2&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(1.50\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(1.50\)&lt;/span&gt; per unit increase in &lt;code&gt;cx2&lt;/code&gt; when standardised for &lt;code&gt;cx1&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The degree to which the rate of change in response associated with a one unit change in &lt;code&gt;cx1&lt;/code&gt; changes over the range of &lt;code&gt;cx2&lt;/code&gt; (and vice versa) is &lt;span class=&#34;math inline&#34;&gt;\(1.45\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence intervals for the interaction partial slope does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant interaction between &lt;code&gt;cx1&lt;/code&gt; and &lt;code&gt;cx2&lt;/code&gt;. This suggests that the nature of the relationship between &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;code&gt;cx1&lt;/code&gt; depends on the level of &lt;code&gt;cx2&lt;/code&gt; (and vice versa). The estimates of the effect of &lt;code&gt;cx1&lt;/code&gt; are only appropriate when &lt;code&gt;cx2 = 0&lt;/code&gt; etc. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags.mult$BUGSoutput$sims.matrix[, &amp;quot;beta[1]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags.mult$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])
[1] 6.666667e-05
&amp;gt; mcmcpvalue(data.r2jags.mult$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])
[1] 0.2236&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of essentially &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, we would conclude that there is almost no evidence that the slope was likely to be equal to zero, suggesting there is a relationship.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;p&gt;With appropriate use of model matrices and data wrangling, it is possible to produce a single prediction data set along with &lt;code&gt;ggplot&lt;/code&gt; syntax to produce a multi-panel figure. First we look at the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags.add$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = rbind(data.frame(cx1 = seq(min(data$cx1, na.rm = TRUE), max(data$cx1,
+     na.rm = TRUE), len = 100), cx2 = 0, Pred = 1), data.frame(cx1 = 0,
+     cx2 = seq(min(data$cx2, na.rm = TRUE), max(data$cx2, na.rm = TRUE),
+         len = 100), Pred = 2))
&amp;gt; Xmat = model.matrix(~cx1 + cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)) %&amp;gt;%
+     mutate(x = dplyr:::recode(Pred, x1, x2))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X&amp;quot;) + theme_classic() + facet_wrap(~Pred)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We cannot simply add the raw data to this figure. The reason for this is that the trends represent the effect of one predictor holding the other variable constant. Therefore, the observations we represent on the figure must likewise be standardised. We can achieve this by adding the partial residuals to the figure. Partial residuals are the fitted values plus the residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = rbind(data.frame(cx1 = data$cx1, cx2 = 0, Pred = 1), data.frame(cx1 = 0,
+     cx2 = data$cx2, Pred = 2))
&amp;gt; fMat = rMat = model.matrix(~cx1 + cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2) %&amp;gt;% mutate(x = dplyr:::recode(Pred, x1,
+     x2))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = rdata, aes(y = partial.resid),
+     color = &amp;quot;gray&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low, ymax = conf.high),
+     fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) + theme_classic() +
+     facet_wrap(~Pred, strip.position = &amp;quot;bottom&amp;quot;, labeller = label_bquote(&amp;quot;x&amp;quot; *
+         .(Pred))) + theme(axis.title.x = element_blank(), strip.background = element_blank(),
+     strip.placement = &amp;quot;outside&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;However, this method (whist partially elegant) does become overly opaque if we need more extensive axes labels since the x-axes labels are actually strip labels (which must largely be defined outside of the &lt;code&gt;ggplot&lt;/code&gt; structure). The alternative is to simply produce each partial plot separately before arranging them together in the one figure using the package &lt;code&gt;gridExtra&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(gridExtra)
&amp;gt; mcmc = data.r2jags.add$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = data.frame(cx1 = seq(min(data$cx1, na.rm = TRUE), max(data$cx1,
+     na.rm = TRUE), len = 100), cx2 = 0)
&amp;gt; Xmat = model.matrix(~cx1 + cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; ## Now the partial residuals
&amp;gt; fdata = rdata = data.frame(cx1 = data$cx1, cx2 = 0)
&amp;gt; fMat = rMat = model.matrix(~cx1 + cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2)
&amp;gt; g1 = ggplot(newdata, aes(y = estimate, x = x1)) + geom_point(data = rdata,
+     aes(y = partial.resid), color = &amp;quot;grey&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X1&amp;quot;) + theme_classic()
&amp;gt; 
&amp;gt; newdata = data.frame(cx2 = seq(min(data$cx2, na.rm = TRUE), max(data$cx2,
+     na.rm = TRUE), len = 100), cx1 = 0)
&amp;gt; Xmat = model.matrix(~cx1 + cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; ## Now the partial residuals
&amp;gt; fdata = rdata = data.frame(cx1 = 0, cx2 = data$cx2)
&amp;gt; fMat = rMat = model.matrix(~cx1 + cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2)
&amp;gt; g2 = ggplot(newdata, aes(y = estimate, x = x2)) + geom_point(data = rdata,
+     aes(y = partial.resid), color = &amp;quot;grey&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X2&amp;quot;) + theme_classic()
&amp;gt; 
&amp;gt; grid.arrange(g1, g2, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_post3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the multiplicative model, we could elect to split the trends up so as to explore the effects of one predictor at several set levels of another predictor. In this example, we will explore the effects of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; is equal to its mean in the original data as well as one and two standard deviations below and above this mean.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(fields)
&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = expand.grid(cx1 = seq(min(data$cx1, na.rm = TRUE), max(data$cx1,
+     na.rm = TRUE), len = 100), cx2 = mean(data$cx2) + sd(data$cx2) %*%
+     -2:2)
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)) %&amp;gt;%
+     mutate(x2 = factor(x2, labels = paste(&amp;quot;X2:~&amp;quot;, c(-2, -1, 0, 1, 2), &amp;quot;*sigma&amp;quot;)))
&amp;gt; ## Partial residuals
&amp;gt; fdata = rdata = expand.grid(cx1 = data$cx1, cx2 = mean(data$cx2) + sd(data$cx2) *
+     -2:2)
&amp;gt; fMat = rMat = model.matrix(~cx1 * cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2)
&amp;gt; ## Partition the partial residuals such that each x1 trend only includes
&amp;gt; ## x2 data that is within that range in the observed data
&amp;gt; findNearest = function(x, y) {
+     ff = fields:::rdist(x, y)
+     apply(ff, 1, function(x) which(x == min(x)))
+ }
&amp;gt; fn = findNearest(x = data[, c(&amp;quot;x1&amp;quot;, &amp;quot;x2&amp;quot;)], y = rdata[, c(&amp;quot;x1&amp;quot;, &amp;quot;x2&amp;quot;)])
&amp;gt; rdata = rdata[fn, ] %&amp;gt;% mutate(x2 = factor(x2, labels = paste(&amp;quot;X2:~&amp;quot;, c(-2,
+     -1, 0, 1, 2), &amp;quot;*sigma&amp;quot;)))
&amp;gt; ggplot(newdata, aes(y = estimate, x = x1)) + geom_line() + geom_blank(aes(y = 9)) +
+     geom_point(data = rdata, aes(y = partial.resid), color = &amp;quot;grey&amp;quot;) +
+     geom_ribbon(aes(ymin = conf.low, ymax = conf.high), fill = &amp;quot;blue&amp;quot;,
+         alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_continuous(&amp;quot;X1&amp;quot;) +
+     facet_wrap(~x2, labeller = label_parsed, nrow = 1, scales = &amp;quot;free_y&amp;quot;) +
+     theme_classic() + theme(strip.background = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_post4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Alternatively, we could explore the interaction by plotting a two dimensional surface as a heat map.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;effect-sizes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Effect sizes&lt;/h1&gt;
&lt;p&gt;In addition to deriving the distribution means for the slope parameter, we could make use of the Bayesian framework to derive the distribution of the effect size. In so doing, effect size could be considered as either the rate of change or alternatively, the difference between pairs of values along the predictor gradient. For the latter case, there are multiple ways of calculating an effect size, but the two most common are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Raw effect size&lt;/em&gt;. The difference between two groups (as already calculated)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Cohen’s D&lt;/em&gt;. The effect size standardized by division with the pooled standard deviation: &lt;span class=&#34;math inline&#34;&gt;\(D=\frac{(\mu_A-\mu_B)}{\sigma}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Percentage change&lt;/em&gt;. Express the effect size as a percent of one of the pairs. That is, whether you expressing a percentage increase or a percentage decline depends on which of the pairs of values are considered a reference value. Care must be exercised to ensure no division by zeros occur.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For simple linear models, effect size based on a rate is essentially the same as above except that it is expressed per unit of the predictor. Of course in many instances, one unit change in the predictor represents too subtle a shift in the underlying gradient to likely yield any clinically meaningful or appreciable change in response.&lt;/p&gt;
&lt;p&gt;Probability that a change in &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; is associated with greater than a &lt;span class=&#34;math inline&#34;&gt;\(50\)&lt;/span&gt;% increase in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at various levels of &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;. Clearly, in order to explore this inference, we must first express the change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; as a percentage. This in turn requires us to calculate start and end points from which to calculate the magnitude of the effect (amount of increase in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) as well as the percentage decline. Hence, we start by predicting the distribution of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at the lowest and highest values of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; at five levels of &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; (representing two standard deviations below the &lt;code&gt;cx2&lt;/code&gt; mean, one standard deviation below the &lt;code&gt;cx2&lt;/code&gt; mean, the &lt;code&gt;cx2&lt;/code&gt; mean, one standard deviation above the &lt;code&gt;cx2&lt;/code&gt; mean and &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; standard deviations above the &lt;code&gt;cx2&lt;/code&gt; mean. For this exercise we will only use the multiplicative model. Needless to say, the process would be very similar for the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix
&amp;gt; newdata = expand.grid(cx1 = c(min(data$cx1), max(data$cx1)), cx2 = (-2:2) *
+     sd(data$cx2))
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; s1 = seq(1, 9, b = 2)
&amp;gt; s2 = seq(2, 10, b = 2)
&amp;gt; ## Raw effect size
&amp;gt; (RES = tidyMCMC(as.mcmc(fit[, s2] - fit[, s1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         1.82     0.938  -0.0378      3.64
2 4         2.30     0.616   1.13        3.54
3 6         2.78     0.448   1.90        3.65
4 8         3.26     0.586   2.12        4.42
5 10        3.74     0.899   2.02        5.55
&amp;gt; ## Cohen&amp;#39;s D
&amp;gt; cohenD = (fit[, s2] - fit[, s1])/sqrt(mcmc[, &amp;quot;sigma&amp;quot;])
&amp;gt; (cohenDES = tidyMCMC(as.mcmc(cohenD), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         1.83     0.940   0.0489      3.74
2 4         2.31     0.622   1.11        3.57
3 6         2.80     0.461   1.89        3.68
4 8         3.28     0.599   2.10        4.45
5 10        3.76     0.910   1.98        5.54
&amp;gt; # Percentage change (relative to Group A)
&amp;gt; ESp = 100 * (fit[, s2] - fit[, s1])/fit[, s1]
&amp;gt; (PES = tidyMCMC(as.mcmc(ESp), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         124.     142.     -19.5      318.
2 4         117.      45.2     33.1      205.
3 6         123.      32.9     62.1      187.
4 8         135.      50.0     48.0      230.
5 10        150.      89.1     29.4      308.
&amp;gt; # Probability that the effect is greater than 50% (an increase of &amp;gt;50%)
&amp;gt; (p50 = apply(ESp, 2, function(x) sum(x &amp;gt; 50)/length(x)))
        2         4         6         8        10 
0.7996667 0.9576667 0.9978667 0.9925333 0.9723333 
&amp;gt; ## fractional change
&amp;gt; (FES = tidyMCMC(as.mcmc(fit[, s2]/fit[, s1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         2.24     1.42     0.805      4.18
2 4         2.17     0.452    1.33       3.05
3 6         2.23     0.329    1.62       2.87
4 8         2.35     0.500    1.48       3.30
5 10        2.50     0.891    1.29       4.08&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On average, when &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; is equal to its mean, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by &lt;span class=&#34;math inline&#34;&gt;\(2.79\)&lt;/span&gt; over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the increase is between &lt;span class=&#34;math inline&#34;&gt;\(1.91\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(3.66\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Cohen’s D associated change over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(2.80\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by &lt;span class=&#34;math inline&#34;&gt;\(124\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; (at average &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;). We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the increase is between &lt;span class=&#34;math inline&#34;&gt;\(65\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(190\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The probability that &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by more than &lt;span class=&#34;math inline&#34;&gt;\(50\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; (average &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;) is &lt;span class=&#34;math inline&#34;&gt;\(0.998\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by a factor of &lt;span class=&#34;math inline&#34;&gt;\(2.24\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; (average &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;). We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between a factor of &lt;span class=&#34;math inline&#34;&gt;\(1.65\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(2.90\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 4 x 5
  term     estimate std.error   conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x1       0.798    0.129  0.544          1.05 
2 sd.x2       0.501    0.130  0.249          0.756
3 sd.x1x2     0.136    0.0877 0.00000784     0.296
4 sd.resid    0.981    0.0128 0.965          1.01 
# A tibble: 4 x 5
  term     estimate std.error  conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x1       33.1       4.97 23.4           42.7
2 sd.x2       20.8       5.14 10.4           30.3
3 sd.x1x2      5.27      3.46  0.000322      11.7
4 sd.resid    40.5       2.15 36.7           44.9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/effects_modelv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(59\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; and their interaction.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags.mult$BUGSoutput$sims.matrix
&amp;gt; Xmat = model.matrix(~cx1 * cx2, data)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.605    0.0400    0.526     0.676
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ cx1 * cx2, data))

Call:
lm(formula = y ~ cx1 * cx2, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.8173 -0.7167 -0.1092  0.5890  3.3861 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)   3.7152     0.1199  30.987  &amp;lt; 2e-16 ***
cx1           2.8072     0.4390   6.394 5.84e-09 ***
cx2           1.4988     0.3810   3.934 0.000158 ***
cx1:cx2       1.4464     1.1934   1.212 0.228476    
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 0.9804 on 96 degrees of freedom
Multiple R-squared:  0.6115,    Adjusted R-squared:  0.5994 
F-statistic: 50.37 on 3 and 96 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-model-selection&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bayesian model selection&lt;/h1&gt;
&lt;p&gt;A statistical model is by definition a low-dimensional (over simplification) representation of what is really likely to be a very complex system. As a result, no model is right. Some models however can provide useful insights into some of the processes operating on the system. Frequentist statistics have various methods (model selection, dredging, lasso, cross validation) for selecting parsimonious models. These are models that provide a good comprimise between minimizing unexplained patterns and minimizing model complexity. The basic premise is that since no model can hope to capture the full complexity of a system with all its subtleties, only the very major patterns can be estimated. Overly complex models are likely to be representing artificial complexity present only in the specific observed data (not the general population). The Bayesian approach is to apply priors to the non-variance parameters such that parameters close to zero are further shrunk towards zero whilst priors on parameters further away from zero are less effected. The most popular form of prior for sparsity is the &lt;em&gt;horseshoe prior&lt;/em&gt;, so called because the shape of a component of this prior resembles a horseshoe (with most of the mass either close to &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; or close to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Rather than apply weakly informative Gaussian priors on parameters as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\sigma^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the horseshoe prior is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2\lambda_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tau \sim \text{Cauchy}(0,1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j \sim \text{Cauchy}(0,1)\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(j=1,\ldots,D\)&lt;/span&gt;. Using this prior, &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is the number of (non-intercept or variance) parameters, &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; represents the global scale that weights or shrinks all parameters towards zero and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j\)&lt;/span&gt; are thick tailed local scales that allow some of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; parameters to escape shrinkage. More recently, &lt;span class=&#34;citation&#34;&gt;Piironen, Vehtari, and others (2017)&lt;/span&gt; have argued that whilst the above horseshoe priors do guarantee that strong effects (parameters) will not be over-shrunk, there is the potential for weekly identified effects (those based on relatively little data) to be misrepresented in the posteriors. As an alternative they advocated the use of regularised horseshoe priors in which the amount of shrinkage applied to the largest effects can be controlled. The prior is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2 \tilde{\lambda}_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tilde{\lambda}_j^2 = \frac{c^2\lambda^2_j}{c^2+\tau^2 \lambda^2_j}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is (slab width, actually variance) is a constant. For small effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;lt; c^2\)&lt;/span&gt;) the prior approaches a regular prior. However, for large effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;gt; c^2\)&lt;/span&gt;) the prior approaches &lt;span class=&#34;math inline&#34;&gt;\(N(0,c^2)\)&lt;/span&gt;. Finally, they recommend applying a inverse-gamma prior on &lt;span class=&#34;math inline&#34;&gt;\(c^2\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ c^2 \sim \text{Inv-Gamma}(\alpha,\beta),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\alpha=v/2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta=vs^2/2\)&lt;/span&gt;, which translates to a &lt;span class=&#34;math inline&#34;&gt;\(\text{Student-t}_ν(0, s^2)\)&lt;/span&gt; slab for the coefficients far from zero and is typically a good default choice for a weakly informative prior.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-piironen2017sparsity&#34;&gt;
&lt;p&gt;Piironen, Juho, Aki Vehtari, and others. 2017. “Sparsity Information and Regularization in the Horseshoe and Other Shrinkage Priors.” &lt;em&gt;Electronic Journal of Statistics&lt;/em&gt; 11 (2): 5018–51.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Multiple Linear Regression - STAN</title>
      <link>/stan/multiple-linear-regression-stan/multiple-linear-regression-stan/</link>
      <pubDate>Mon, 03 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/stan/multiple-linear-regression-stan/multiple-linear-regression-stan/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;STAN&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman, Lee, and Guo (2015)&lt;/span&gt;) using the package &lt;code&gt;rstan&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Stan Development Team (2018)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Multiple regression is an extension of simple linear regression whereby a response variable is modelled against a linear combination of two or more simultaneously measured predictor variables. There are two main purposes of multiple linear regression:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;To develop a better predictive model (equation) than is possible from models based on single independent variables.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;To investigate the relative individual effects of each of the multiple independent variables above and beyond (standardised across) the effects of the other variables.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Although the relationship between response variable and the additive effect of all the predictor variables is represented overall by a single multidimensional plane (surface), the individual effects of each of the predictor variables on the response variable (standardised across the other variables) can be depicted by single partial regression lines. The slope of any single partial regression line (partial regression slope) thereby represents the rate of change or effect of that specific predictor variable (holding all the other predictor variables constant to their respective mean values) on the response variable. In essence, it is the effect of one predictor variable at one specific level (the means) of all the other predictor variables (i.e. when each of the other predictors are set to their averages).&lt;/p&gt;
&lt;p&gt;Multiple regression models can be constructed additively (containing only the predictor variables themselves) or in a multiplicative design (which incorporate interactions between predictor variables in addition to the predictor variables themselves). Multiplicative models are used primarily for testing inferences about the effects of various predictor variables and their interactions on the response variable. Additive models by contrast are used for generating predictive models and estimating the relative importance of individual predictor variables more so than hypothesis testing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additive-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additive Model&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_{i1} +  \beta_2x_{i2} + \ldots + \beta_Jx_{iJ} + \epsilon_i,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the population &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept (value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; when all partial slopes equal zero), &lt;span class=&#34;math inline&#34;&gt;\(\beta_1,\beta_2,\ldots,\beta_{J}\)&lt;/span&gt; are the partial population slopes of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(X_1,X_2,\ldots,X_J\)&lt;/span&gt; respectively holding the other &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; constant. &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_i\)&lt;/span&gt; is the random unexplained error or residual component. The additive model assumes that the effect of one predictor variable (partial slope) is independent of the levels of the other predictor variables.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiplicative-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiplicative Model&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_{i1} +  \beta_2x_{i2} + \beta_3x_{i1}x_{i2} + \ldots + \beta_Jx_{iJ} + \epsilon_i,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_3x_{i1}x_{i2}\)&lt;/span&gt; is the interactive effect of &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(X_2\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; and it examines the degree to which the effect of one of the predictor variables depends on the levels of the other predictor variable(s).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Lets say we had set up a natural experiment in which we measured a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) from each of &lt;span class=&#34;math inline&#34;&gt;\(20\)&lt;/span&gt; sampling units (&lt;span class=&#34;math inline&#34;&gt;\(n=20\)&lt;/span&gt;) across a landscape. At the same time, we also measured two other continuous covariates (&lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;) from each of the sampling units. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n = 100
&amp;gt; intercept = 5
&amp;gt; temp = runif(n)
&amp;gt; nitro = runif(n) + 0.8 * temp
&amp;gt; int.eff = 2
&amp;gt; temp.eff &amp;lt;- 0.85
&amp;gt; nitro.eff &amp;lt;- 0.5
&amp;gt; res = rnorm(n, 0, 1)
&amp;gt; coef &amp;lt;- c(int.eff, temp.eff, nitro.eff, int.eff)
&amp;gt; mm &amp;lt;- model.matrix(~temp * nitro)
&amp;gt; 
&amp;gt; y &amp;lt;- t(coef %*% t(mm)) + res
&amp;gt; data &amp;lt;- data.frame(y, x1 = temp, x2 = nitro, cx1 = scale(temp,
+     scale = F), cx2 = scale(nitro, scale = F))
&amp;gt; head(data)
         y        x1        x2         cx1         cx2
1 2.426468 0.2875775 0.8300510 -0.21098147 -0.08302110
2 4.927690 0.7883051 0.9634676  0.28974614  0.05039557
3 3.176118 0.4089769 0.8157946 -0.08958207 -0.09727750
4 6.166652 0.8830174 1.6608878  0.38445841  0.74781568
5 4.788890 0.9404673 1.2352762  0.44190829  0.32220415
6 2.541536 0.0455565 0.9267954 -0.45300249  0.01372335&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the components linear predictor (continuous predictors). We could model the relationship via either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;An additive model in which the effects of each predictor contribute in an additive way to the response - we do not allow for an interaction as we consider an interaction either not of great importance or likely to be absent.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A multiplicative model in which the effects of each predictor and their interaction contribute to the response - we allow for the impact of one predictor to vary across the range of the other predictor.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;centering-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Centering the data&lt;/h2&gt;
&lt;p&gt;When a linear model contains a covariate (continuous predictor variable) in addition to another predictor (continuous or categorical), it is nearly always advisable that the continuous predictor variables are centered prior to the analysis. Centering is a process by which the mean of a variable is subtracted from each of the values such that the scale of the variable is shifted so as to be centered around &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Hence the mean of the new centered variable will be &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, yet it will retain the same variance.&lt;/p&gt;
&lt;p&gt;There are multiple reasons for this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;It provides some clinical meaning to the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept. Recall that the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is equal to zero. If &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is centered, then the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept represents the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at the mid-point of the &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; range. The &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept of an uncentered &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; typically represents a unreal value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; (as an &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; is often beyond the reasonable range of values).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In multiplicative models (in which predictors and their interactions are included), main effects and interaction terms built from centered predictors will not be correlated to one another.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For more complex models, centering the covariates can increase the likelihood that the modelling engine converges (arrives at a numerically stable and reliable outcome).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note, centering will not effect the slope estimates. In &lt;code&gt;R&lt;/code&gt;, centering is easily achieved with the &lt;code&gt;scale&lt;/code&gt; function, which centers and scales (divides by standard deviation) the data. We only really need to center the data, so we provide the argument &lt;code&gt;scale=FALSE&lt;/code&gt;. Also note that the &lt;code&gt;scale&lt;/code&gt; function attaches the pre-centered mean (and standard deviation if scaling is performed) as attributes to the scaled data in order to facilitate back-scaling to the original scale. While these attributes are often convenient, they do cause issues for some of the Bayesian routines and so we will strip these attributes using the &lt;code&gt;as.numeric&lt;/code&gt; function. Instead, we will create separate scalar variables to store the pre-scaled means.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data &amp;lt;- within(data, {
+     cx1 &amp;lt;- as.numeric(scale(x1, scale = FALSE))
+     cx2 &amp;lt;- as.numeric(scale(x2, scale = FALSE))
+ })
&amp;gt; head(data)
         y        x1        x2         cx1         cx2
1 2.426468 0.2875775 0.8300510 -0.21098147 -0.08302110
2 4.927690 0.7883051 0.9634676  0.28974614  0.05039557
3 3.176118 0.4089769 0.8157946 -0.08958207 -0.09727750
4 6.166652 0.8830174 1.6608878  0.38445841  0.74781568
5 4.788890 0.9404673 1.2352762  0.44190829  0.32220415
6 2.541536 0.0455565 0.9267954 -0.45300249  0.01372335
&amp;gt; 
&amp;gt; mean.x1 = mean(data$x1)
&amp;gt; mean.x2 = mean(data$x2)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Assumptions&lt;/h1&gt;
&lt;p&gt;The assumptions of the model are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All of the observations are independent - this must be addressed at the design and collection stages.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (and thus the residuals) should be normally distributed. A boxplot of the entire variable is usually useful for diagnosing major issues with normality.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately). Scatterplots with linear smoothers can be useful for exploring the spread of observations around the trendline. The spread of observations around the trendline should not increase (or decrease) along its length.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The predictor variables should be uniformly or normally distributed. Again, boxplots can be useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The relationships between the linear predictors (right hand side of the regression formula) and the response variable should be linear. Scatterplots with smoothers can be useful for identifying possible non-linearity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;(Multi)collinearity&lt;/strong&gt;. The number of predictor variables must be less than the number of observations otherwise the linear model will be over-parameterized (more parameters to estimate than there are independent data from which estimates are calculated).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Multi)collinearity breaks the assumption that a predictor variable must not be correlated to the combination of other predictor variables (known collectively as the linear predictor). Multicollinearity has major detrimental effects on model fitting:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Instability of the estimated partial regression slopes (small changes in the data or variable inclusion can cause dramatic changes in parameter estimates).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Inflated standard errors and confidence intervals of model parameters, thereby increasing the type II error rate (reducing power) of parameter hypothesis tests.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Multicollinearity can be diagnosed with the following situatons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Investigate pairwise correlations between all the predictor variables either by a correlation matrix or a scatterplot matrix&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Calculate the &lt;strong&gt;tolerance&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\((1−r^2)\)&lt;/span&gt; of the relationship between a predictor variable and all the other predictor variables for each of the predictor variables. Tolerance is a measure of the degree of collinearity and values less than &lt;span class=&#34;math inline&#34;&gt;\(0.2\)&lt;/span&gt; should be considered and values less than &lt;span class=&#34;math inline&#34;&gt;\(0.1\)&lt;/span&gt; should be given serious attention. &lt;strong&gt;Variance inflation factor&lt;/strong&gt; (VIF) is the inverse of tolerance and thus values greater than &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;, or worse, &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; indicate collinearity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;PCA&lt;/strong&gt; (principle components analysis) eigenvalues (from a correlation matrix for all the predictor variables) close to zero indicate collinearity and component loadings may be useful in determining which predictor variables cause collinearity.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are several approaches to dealing with collinearity (however the first two of these are likely to result in biased parameter estimates):&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Remove the highly correlated predictor variable(s), starting with the least most clinically interesting variable(s)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;PCA (principle components analysis) regression - regress the response variable against the principal components resulting from a correlation matrix for all the predictor variables. Each of these principal components by definition are completely independent, but the resulting parameter estimates must be back-calculated in order to have any clinical meaning.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Apply a regression tree - regression trees recursively partitioning (subsetting) the data in accordance to individual variables that explain the greatest remaining variance. Since at each iteration, each predictor variable is effectively evaluated in isolation, (multi)collinearity is not an issue.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;Multiple linear regression models can include predictors (terms) that are incorporated additively (no interactions) or multiplicatively (with interactions). As such we will explore these separately for each modelling tool. The observed responses (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values are themselves determined by the linear predictor. In this case, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept (value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; when all of the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;’s are equal to zero) and the set of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;’s represent the rates of change in y for every unit change in each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; (the effect) holding each other &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; constant. Note that since we should always center all predictors (by subtracting the mean of each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; from the repective values of each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;), the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept represents the value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at the average value of each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying “uninformative” priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\mu_i, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 + \boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;. Priors are specified as: &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta \sim \text{Normal}(0,1000)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. We will explore Bayesian modelling of multiple linear regression using &lt;code&gt;STAN&lt;/code&gt;. The minimum model in &lt;code&gt;STAN&lt;/code&gt; required to fit the above simple regression follows. Note the following modifications from the model defined in &lt;code&gt;JAGS&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The normal distribution is defined by standard deviation rather than precision&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rather than using a uniform prior for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, I am using a half-Cauchy&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;additive-model-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additive model&lt;/h2&gt;
&lt;p&gt;We now translate the likelihood for the additive model into &lt;code&gt;STAN&lt;/code&gt; code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   data { 
+   int&amp;lt;lower=1&amp;gt; n;   // total number of observations 
+   vector[n] Y;      // response variable 
+   int&amp;lt;lower=1&amp;gt; nX;  // number of effects 
+   matrix[n, nX] X;   // model matrix 
+   } 
+   transformed data { 
+   matrix[n, nX - 1] Xc;  // centered version of X 
+   vector[nX - 1] means_X;  // column means of X before centering 
+   
+   for (i in 2:nX) { 
+   means_X[i - 1] = mean(X[, i]); 
+   Xc[, i - 1] = X[, i] - means_X[i - 1]; 
+   }  
+   } 
+   parameters { 
+   vector[nX-1] beta;  // population-level effects 
+   real cbeta0;  // center-scale intercept 
+   real&amp;lt;lower=0&amp;gt; sigma;  // residual SD 
+   } 
+   transformed parameters { 
+   } 
+   model { 
+   vector[n] mu; 
+   mu = Xc * beta + cbeta0; 
+   // prior specifications 
+   beta ~ normal(0, 100); 
+   cbeta0 ~ normal(0, 100); 
+   sigma ~ cauchy(0, 5); 
+   // likelihood contribution 
+   Y ~ normal(mu, sigma); 
+   } 
+   generated quantities {
+   real beta0;  // population-level intercept 
+   vector[n] log_lik;
+   beta0 = cbeta0 - dot_product(means_X, beta);
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(Y[i] | Xc[i] * beta + cbeta0, sigma);
+   } 
+   }
+   
+   &amp;quot;
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString, con = &amp;quot;linregModeladd.stan&amp;quot;)
&amp;gt; writeLines(modelString, con = &amp;quot;linregModelmult.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X = model.matrix(~cx1 + cx2, data = data)
&amp;gt; data.list &amp;lt;- with(data, list(Y = y, X = X, nX = ncol(X), n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;beta0&amp;quot;, &amp;quot;cbeta0&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;log_lik&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 1000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 3000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 2500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now compile and run the Stan code via the &lt;code&gt;rstan&lt;/code&gt; interface. Note that the first time &lt;code&gt;stan&lt;/code&gt; is run after the &lt;code&gt;rstan&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;During the warmup stage, the No-U-Turn sampler (NUTS) attempts to determine the optimum stepsize - the stepsize that achieves the target acceptance rate (&lt;span class=&#34;math inline&#34;&gt;\(0.8\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(80\)&lt;/span&gt;% by default) without divergence (occurs when the stepsize is too large relative to the curvature of the log posterior and results in approximations that are likely to diverge and be biased) - and without hitting the maximum treedepth (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;). At each iteration of the NUTS algorithm, the number of leapfrog steps doubles (as it increases the treedepth) and only terminates when either the NUTS criterion are satisfied or the tree depth reaches the maximum (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; by default).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rstan.add &amp;lt;- stan(data = data.list, file = &amp;quot;linregModeladd.stan&amp;quot;, chains = nChains, pars = params,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps, save_dso = TRUE)

SAMPLING FOR MODEL &amp;#39;linregModeladd&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2500 [  0%]  (Warmup)
Chain 1: Iteration:  250 / 2500 [ 10%]  (Warmup)
Chain 1: Iteration:  500 / 2500 [ 20%]  (Warmup)
Chain 1: Iteration:  750 / 2500 [ 30%]  (Warmup)
Chain 1: Iteration: 1000 / 2500 [ 40%]  (Warmup)
Chain 1: Iteration: 1001 / 2500 [ 40%]  (Sampling)
Chain 1: Iteration: 1250 / 2500 [ 50%]  (Sampling)
Chain 1: Iteration: 1500 / 2500 [ 60%]  (Sampling)
Chain 1: Iteration: 1750 / 2500 [ 70%]  (Sampling)
Chain 1: Iteration: 2000 / 2500 [ 80%]  (Sampling)
Chain 1: Iteration: 2250 / 2500 [ 90%]  (Sampling)
Chain 1: Iteration: 2500 / 2500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.069 seconds (Warm-up)
Chain 1:                0.095 seconds (Sampling)
Chain 1:                0.164 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;linregModeladd&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2500 [  0%]  (Warmup)
Chain 2: Iteration:  250 / 2500 [ 10%]  (Warmup)
Chain 2: Iteration:  500 / 2500 [ 20%]  (Warmup)
Chain 2: Iteration:  750 / 2500 [ 30%]  (Warmup)
Chain 2: Iteration: 1000 / 2500 [ 40%]  (Warmup)
Chain 2: Iteration: 1001 / 2500 [ 40%]  (Sampling)
Chain 2: Iteration: 1250 / 2500 [ 50%]  (Sampling)
Chain 2: Iteration: 1500 / 2500 [ 60%]  (Sampling)
Chain 2: Iteration: 1750 / 2500 [ 70%]  (Sampling)
Chain 2: Iteration: 2000 / 2500 [ 80%]  (Sampling)
Chain 2: Iteration: 2250 / 2500 [ 90%]  (Sampling)
Chain 2: Iteration: 2500 / 2500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.068 seconds (Warm-up)
Chain 2:                0.094 seconds (Sampling)
Chain 2:                0.162 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; data.rstan.add
Inference for Stan model: linregModeladd.
2 chains, each with iter=2500; warmup=1000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

               mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]        2.83    0.01 0.45   1.95   2.52   2.82   3.13   3.72  2562    1
beta[2]        1.58    0.01 0.38   0.84   1.33   1.58   1.85   2.32  2623    1
beta0          3.80    0.00 0.10   3.60   3.73   3.80   3.87   4.00  2672    1
cbeta0         3.80    0.00 0.10   3.60   3.73   3.80   3.87   4.00  2672    1
sigma          0.99    0.00 0.07   0.86   0.94   0.99   1.04   1.15  3017    1
log_lik[1]    -1.13    0.00 0.09  -1.33  -1.19  -1.13  -1.07  -0.96  2825    1
log_lik[2]    -0.95    0.00 0.08  -1.11  -1.00  -0.95  -0.89  -0.80  2813    1
log_lik[3]    -0.94    0.00 0.07  -1.09  -0.99  -0.94  -0.89  -0.80  2983    1
log_lik[4]    -0.94    0.00 0.09  -1.13  -1.00  -0.94  -0.88  -0.78  2666    1
log_lik[5]    -1.23    0.00 0.15  -1.56  -1.32  -1.22  -1.13  -0.98  3319    1
log_lik[6]    -0.94    0.00 0.08  -1.11  -0.99  -0.93  -0.88  -0.78  2591    1
log_lik[7]    -1.26    0.00 0.15  -1.60  -1.36  -1.25  -1.15  -1.00  2637    1
log_lik[8]    -2.00    0.00 0.28  -2.59  -2.18  -1.99  -1.81  -1.54  3642    1
log_lik[9]    -1.00    0.00 0.08  -1.16  -1.05  -0.99  -0.94  -0.86  2885    1
log_lik[10]   -1.43    0.00 0.17  -1.81  -1.53  -1.41  -1.30  -1.13  2549    1
log_lik[11]   -0.94    0.00 0.09  -1.12  -0.99  -0.94  -0.88  -0.78  2568    1
log_lik[12]   -1.14    0.00 0.10  -1.35  -1.20  -1.13  -1.07  -0.97  2419    1
log_lik[13]   -2.48    0.01 0.39  -3.32  -2.73  -2.44  -2.21  -1.82  2526    1
log_lik[14]   -0.93    0.00 0.08  -1.10  -0.98  -0.93  -0.88  -0.78  2702    1
log_lik[15]   -1.16    0.00 0.14  -1.46  -1.24  -1.14  -1.06  -0.93  2584    1
log_lik[16]   -0.95    0.00 0.09  -1.14  -1.01  -0.95  -0.89  -0.79  2460    1
log_lik[17]   -0.95    0.00 0.08  -1.11  -1.00  -0.94  -0.89  -0.80  2913    1
log_lik[18]   -1.16    0.00 0.17  -1.55  -1.26  -1.14  -1.04  -0.89  2488    1
log_lik[19]   -1.25    0.00 0.10  -1.46  -1.32  -1.25  -1.18  -1.06  2670    1
log_lik[20]   -1.34    0.00 0.17  -1.73  -1.44  -1.32  -1.21  -1.04  3156    1
log_lik[21]   -0.99    0.00 0.10  -1.20  -1.05  -0.99  -0.93  -0.82  3217    1
log_lik[22]   -1.43    0.00 0.14  -1.74  -1.52  -1.42  -1.33  -1.18  2520    1
log_lik[23]   -1.07    0.00 0.09  -1.26  -1.13  -1.06  -1.01  -0.90  2655    1
log_lik[24]   -0.97    0.00 0.10  -1.18  -1.02  -0.96  -0.90  -0.80  2490    1
log_lik[25]   -2.60    0.01 0.29  -3.21  -2.78  -2.59  -2.40  -2.08  2818    1
log_lik[26]   -1.05    0.00 0.12  -1.33  -1.12  -1.04  -0.96  -0.85  2885    1
log_lik[27]   -0.95    0.00 0.08  -1.12  -1.00  -0.95  -0.89  -0.80  2646    1
log_lik[28]   -0.93    0.00 0.08  -1.09  -0.98  -0.93  -0.87  -0.78  2601    1
log_lik[29]   -1.15    0.00 0.14  -1.46  -1.24  -1.14  -1.05  -0.92  3221    1
log_lik[30]   -0.93    0.00 0.08  -1.09  -0.97  -0.92  -0.87  -0.78  2844    1
log_lik[31]   -2.54    0.01 0.39  -3.37  -2.78  -2.52  -2.27  -1.86  3492    1
log_lik[32]   -1.34    0.00 0.21  -1.82  -1.47  -1.32  -1.19  -1.00  3489    1
log_lik[33]   -0.92    0.00 0.08  -1.08  -0.97  -0.92  -0.87  -0.78  2945    1
log_lik[34]   -0.95    0.00 0.08  -1.13  -1.01  -0.95  -0.90  -0.81  2937    1
log_lik[35]   -2.25    0.01 0.34  -2.96  -2.48  -2.23  -2.01  -1.66  3180    1
log_lik[36]   -1.55    0.00 0.13  -1.83  -1.64  -1.54  -1.46  -1.32  2570    1
log_lik[37]   -1.78    0.00 0.25  -2.32  -1.93  -1.76  -1.60  -1.35  3392    1
log_lik[38]   -1.21    0.00 0.14  -1.50  -1.30  -1.20  -1.11  -0.98  2419    1
log_lik[39]   -2.57    0.01 0.42  -3.49  -2.83  -2.54  -2.28  -1.86  2458    1
log_lik[40]   -1.70    0.00 0.18  -2.08  -1.82  -1.69  -1.58  -1.37  3038    1
log_lik[41]   -1.59    0.00 0.21  -2.06  -1.73  -1.57  -1.44  -1.23  3270    1
log_lik[42]   -0.94    0.00 0.08  -1.09  -0.99  -0.94  -0.89  -0.80  2984    1
log_lik[43]   -1.97    0.01 0.32  -2.67  -2.18  -1.94  -1.74  -1.42  2786    1
log_lik[44]   -1.86    0.00 0.24  -2.37  -2.02  -1.85  -1.70  -1.45  2785    1
log_lik[45]   -2.24    0.01 0.35  -2.98  -2.47  -2.22  -1.99  -1.65  2523    1
log_lik[46]   -0.93    0.00 0.08  -1.10  -0.98  -0.93  -0.88  -0.78  2849    1
log_lik[47]   -1.58    0.00 0.20  -2.01  -1.71  -1.56  -1.43  -1.22  3202    1
log_lik[48]   -1.22    0.00 0.15  -1.56  -1.31  -1.21  -1.11  -0.97  2573    1
log_lik[49]   -3.84    0.01 0.54  -5.01  -4.18  -3.82  -3.46  -2.87  3218    1
log_lik[50]   -1.47    0.00 0.20  -1.90  -1.59  -1.45  -1.34  -1.14  3648    1
log_lik[51]   -1.33    0.00 0.20  -1.78  -1.46  -1.31  -1.18  -1.01  2469    1
log_lik[52]   -1.23    0.00 0.09  -1.42  -1.29  -1.23  -1.17  -1.07  2508    1
log_lik[53]   -0.98    0.00 0.08  -1.15  -1.03  -0.98  -0.92  -0.82  2892    1
log_lik[54]   -1.05    0.00 0.12  -1.31  -1.12  -1.03  -0.97  -0.85  3408    1
log_lik[55]   -0.94    0.00 0.08  -1.11  -0.99  -0.93  -0.88  -0.79  2682    1
log_lik[56]   -0.92    0.00 0.08  -1.08  -0.97  -0.92  -0.87  -0.78  2941    1
log_lik[57]   -1.26    0.00 0.14  -1.57  -1.35  -1.25  -1.16  -1.03  2851    1
log_lik[58]   -1.03    0.00 0.10  -1.25  -1.09  -1.02  -0.96  -0.85  2528    1
log_lik[59]   -1.53    0.00 0.19  -1.94  -1.64  -1.51  -1.40  -1.20  3250    1
log_lik[60]   -0.95    0.00 0.08  -1.12  -1.00  -0.95  -0.89  -0.80  2944    1
log_lik[61]   -1.48    0.00 0.12  -1.75  -1.56  -1.48  -1.40  -1.26  2941    1
log_lik[62]   -1.09    0.00 0.12  -1.36  -1.16  -1.08  -1.01  -0.89  3504    1
log_lik[63]   -1.74    0.00 0.16  -2.08  -1.85  -1.73  -1.62  -1.45  2551    1
log_lik[64]   -7.01    0.02 0.96  -9.02  -7.60  -6.96  -6.33  -5.26  3101    1
log_lik[65]   -1.01    0.00 0.09  -1.22  -1.07  -1.01  -0.95  -0.85  2752    1
log_lik[66]   -0.96    0.00 0.08  -1.11  -1.01  -0.96  -0.91  -0.82  2946    1
log_lik[67]   -1.29    0.00 0.15  -1.62  -1.38  -1.27  -1.18  -1.03  3487    1
log_lik[68]   -1.09    0.00 0.12  -1.35  -1.16  -1.08  -1.01  -0.89  2517    1
log_lik[69]   -1.07    0.00 0.10  -1.27  -1.13  -1.06  -1.00  -0.89  2958    1
log_lik[70]   -1.02    0.00 0.09  -1.20  -1.07  -1.01  -0.96  -0.85  2673    1
log_lik[71]   -0.93    0.00 0.08  -1.08  -0.98  -0.93  -0.88  -0.79  2896    1
log_lik[72]   -0.92    0.00 0.08  -1.08  -0.97  -0.92  -0.87  -0.78  2738    1
log_lik[73]   -0.93    0.00 0.08  -1.10  -0.98  -0.93  -0.88  -0.78  2813    1
log_lik[74]   -3.84    0.01 0.63  -5.17  -4.23  -3.80  -3.39  -2.75  2911    1
log_lik[75]   -1.22    0.00 0.10  -1.41  -1.28  -1.21  -1.15  -1.04  2633    1
log_lik[76]   -1.42    0.00 0.15  -1.73  -1.52  -1.41  -1.31  -1.16  2747    1
log_lik[77]   -0.93    0.00 0.08  -1.08  -0.97  -0.92  -0.87  -0.78  2978    1
log_lik[78]   -0.96    0.00 0.08  -1.11  -1.01  -0.96  -0.91  -0.81  3039    1
log_lik[79]   -0.99    0.00 0.10  -1.20  -1.05  -0.98  -0.93  -0.82  2575    1
log_lik[80]   -0.94    0.00 0.08  -1.11  -1.00  -0.94  -0.89  -0.80  2971    1
log_lik[81]   -1.56    0.00 0.21  -1.99  -1.69  -1.54  -1.40  -1.21  2434    1
log_lik[82]   -1.68    0.00 0.17  -2.06  -1.78  -1.67  -1.56  -1.37  2568    1
log_lik[83]   -0.99    0.00 0.08  -1.15  -1.04  -0.99  -0.94  -0.84  2818    1
log_lik[84]   -1.36    0.00 0.16  -1.72  -1.46  -1.35  -1.25  -1.09  2593    1
log_lik[85]   -0.93    0.00 0.08  -1.08  -0.97  -0.92  -0.87  -0.78  2878    1
log_lik[86]   -0.93    0.00 0.07  -1.08  -0.98  -0.93  -0.88  -0.79  2977    1
log_lik[87]   -1.62    0.00 0.25  -2.18  -1.77  -1.59  -1.44  -1.19  2899    1
log_lik[88]   -0.96    0.00 0.09  -1.15  -1.02  -0.96  -0.90  -0.80  3100    1
log_lik[89]   -1.65    0.00 0.28  -2.28  -1.82  -1.62  -1.44  -1.18  3480    1
log_lik[90]   -1.09    0.00 0.13  -1.38  -1.17  -1.07  -1.00  -0.88  2482    1
log_lik[91]   -1.18    0.00 0.14  -1.51  -1.27  -1.17  -1.08  -0.95  3154    1
log_lik[92]   -0.99    0.00 0.08  -1.17  -1.04  -0.98  -0.93  -0.84  2766    1
log_lik[93]   -0.93    0.00 0.08  -1.10  -0.98  -0.93  -0.88  -0.78  2556    1
log_lik[94]   -1.31    0.00 0.11  -1.55  -1.38  -1.31  -1.24  -1.11  3091    1
log_lik[95]   -1.96    0.01 0.30  -2.60  -2.15  -1.94  -1.74  -1.47  2459    1
log_lik[96]   -3.52    0.01 0.47  -4.52  -3.81  -3.50  -3.19  -2.69  3235    1
log_lik[97]   -1.11    0.00 0.10  -1.32  -1.18  -1.10  -1.04  -0.93  2932    1
log_lik[98]   -1.48    0.00 0.19  -1.90  -1.61  -1.47  -1.34  -1.15  2845    1
log_lik[99]   -1.08    0.00 0.11  -1.33  -1.15  -1.07  -1.00  -0.89  2761    1
log_lik[100]  -1.66    0.00 0.13  -1.94  -1.74  -1.65  -1.56  -1.42  2616    1
lp__         -48.86    0.04 1.42 -52.37 -49.58 -48.52 -47.80 -47.06  1447    1

Samples were drawn using NUTS(diag_e) at Thu Feb 13 15:27:59 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;multiplicative-model-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiplicative model&lt;/h2&gt;
&lt;p&gt;We now translate the likelihood for the multiplicative model into &lt;code&gt;STAN&lt;/code&gt; code. Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X = model.matrix(~cx1 * cx2, data = data)
&amp;gt; data.list &amp;lt;- with(data, list(Y = y, X = X, nX = ncol(X), n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;beta0&amp;quot;, &amp;quot;cbeta0&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;log_lik&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 1000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 3000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 2500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now compile and run the Stan code via the &lt;code&gt;rstan&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rstan.mult &amp;lt;- stan(data = data.list, file = &amp;quot;linregModelmult.stan&amp;quot;, chains = nChains, pars = params,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps, save_dso = TRUE)

SAMPLING FOR MODEL &amp;#39;linregModeladd&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2500 [  0%]  (Warmup)
Chain 1: Iteration:  250 / 2500 [ 10%]  (Warmup)
Chain 1: Iteration:  500 / 2500 [ 20%]  (Warmup)
Chain 1: Iteration:  750 / 2500 [ 30%]  (Warmup)
Chain 1: Iteration: 1000 / 2500 [ 40%]  (Warmup)
Chain 1: Iteration: 1001 / 2500 [ 40%]  (Sampling)
Chain 1: Iteration: 1250 / 2500 [ 50%]  (Sampling)
Chain 1: Iteration: 1500 / 2500 [ 60%]  (Sampling)
Chain 1: Iteration: 1750 / 2500 [ 70%]  (Sampling)
Chain 1: Iteration: 2000 / 2500 [ 80%]  (Sampling)
Chain 1: Iteration: 2250 / 2500 [ 90%]  (Sampling)
Chain 1: Iteration: 2500 / 2500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.079 seconds (Warm-up)
Chain 1:                0.098 seconds (Sampling)
Chain 1:                0.177 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;linregModeladd&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2500 [  0%]  (Warmup)
Chain 2: Iteration:  250 / 2500 [ 10%]  (Warmup)
Chain 2: Iteration:  500 / 2500 [ 20%]  (Warmup)
Chain 2: Iteration:  750 / 2500 [ 30%]  (Warmup)
Chain 2: Iteration: 1000 / 2500 [ 40%]  (Warmup)
Chain 2: Iteration: 1001 / 2500 [ 40%]  (Sampling)
Chain 2: Iteration: 1250 / 2500 [ 50%]  (Sampling)
Chain 2: Iteration: 1500 / 2500 [ 60%]  (Sampling)
Chain 2: Iteration: 1750 / 2500 [ 70%]  (Sampling)
Chain 2: Iteration: 2000 / 2500 [ 80%]  (Sampling)
Chain 2: Iteration: 2250 / 2500 [ 90%]  (Sampling)
Chain 2: Iteration: 2500 / 2500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.079 seconds (Warm-up)
Chain 2:                0.096 seconds (Sampling)
Chain 2:                0.175 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; data.rstan.mult
Inference for Stan model: linregModeladd.
2 chains, each with iter=2500; warmup=1000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

               mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]        2.81    0.01 0.45   1.90   2.51   2.81   3.11   3.69  3050    1
beta[2]        1.50    0.01 0.38   0.77   1.24   1.50   1.77   2.26  2954    1
beta[3]        1.41    0.02 1.22  -0.98   0.58   1.44   2.24   3.76  3328    1
beta0          3.72    0.00 0.12   3.48   3.63   3.71   3.80   3.96  3353    1
cbeta0         3.80    0.00 0.10   3.61   3.73   3.80   3.87   4.00  3449    1
sigma          0.99    0.00 0.07   0.86   0.94   0.99   1.04   1.15  3271    1
log_lik[1]    -1.10    0.00 0.09  -1.29  -1.17  -1.10  -1.04  -0.93  3407    1
log_lik[2]    -0.97    0.00 0.09  -1.15  -1.02  -0.97  -0.91  -0.82  3196    1
log_lik[3]    -0.93    0.00 0.07  -1.08  -0.98  -0.93  -0.88  -0.79  3279    1
log_lik[4]    -0.98    0.00 0.11  -1.25  -1.03  -0.96  -0.90  -0.80  2510    1
log_lik[5]    -1.31    0.00 0.18  -1.72  -1.41  -1.29  -1.18  -1.01  3885    1
log_lik[6]    -0.94    0.00 0.08  -1.12  -0.99  -0.94  -0.88  -0.79  2606    1
log_lik[7]    -1.19    0.00 0.15  -1.55  -1.28  -1.17  -1.08  -0.93  3240    1
log_lik[8]    -2.17    0.01 0.34  -2.93  -2.38  -2.14  -1.93  -1.60  4441    1
log_lik[9]    -0.97    0.00 0.08  -1.13  -1.02  -0.97  -0.92  -0.82  3225    1
log_lik[10]   -1.45    0.00 0.18  -1.85  -1.56  -1.43  -1.32  -1.14  3432    1
log_lik[11]   -1.05    0.00 0.19  -1.55  -1.13  -1.01  -0.93  -0.82  2965    1
log_lik[12]   -1.17    0.00 0.10  -1.39  -1.23  -1.16  -1.09  -0.98  3567    1
log_lik[13]   -2.26    0.01 0.41  -3.15  -2.52  -2.23  -1.96  -1.54  3444    1
log_lik[14]   -0.93    0.00 0.08  -1.09  -0.98  -0.93  -0.88  -0.79  2841    1
log_lik[15]   -1.16    0.00 0.13  -1.45  -1.24  -1.14  -1.06  -0.93  3297    1
log_lik[16]   -0.99    0.00 0.11  -1.26  -1.05  -0.98  -0.91  -0.81  2781    1
log_lik[17]   -0.95    0.00 0.08  -1.10  -1.00  -0.95  -0.89  -0.80  3330    1
log_lik[18]   -1.09    0.00 0.16  -1.46  -1.18  -1.06  -0.97  -0.84  2960    1
log_lik[19]   -1.21    0.00 0.10  -1.42  -1.27  -1.20  -1.13  -1.02  3358    1
log_lik[20]   -1.39    0.00 0.19  -1.84  -1.50  -1.37  -1.25  -1.07  3724    1
log_lik[21]   -0.96    0.00 0.09  -1.16  -1.02  -0.96  -0.90  -0.80  3449    1
log_lik[22]   -1.34    0.00 0.15  -1.69  -1.44  -1.33  -1.23  -1.08  3373    1
log_lik[23]   -1.02    0.00 0.10  -1.24  -1.08  -1.02  -0.96  -0.85  3117    1
log_lik[24]   -0.96    0.00 0.09  -1.17  -1.02  -0.95  -0.90  -0.80  2550    1
log_lik[25]   -2.77    0.01 0.35  -3.52  -3.00  -2.74  -2.53  -2.13  3713    1
log_lik[26]   -1.08    0.00 0.14  -1.40  -1.16  -1.06  -0.99  -0.86  3525    1
log_lik[27]   -0.97    0.00 0.09  -1.17  -1.02  -0.97  -0.91  -0.81  2981    1
log_lik[28]   -0.94    0.00 0.08  -1.11  -0.99  -0.94  -0.88  -0.79  2570    1
log_lik[29]   -1.26    0.00 0.18  -1.67  -1.36  -1.23  -1.13  -0.97  3476    1
log_lik[30]   -0.93    0.00 0.08  -1.08  -0.98  -0.92  -0.87  -0.78  3170    1
log_lik[31]   -2.23    0.01 0.42  -3.14  -2.51  -2.19  -1.92  -1.51  4024    1
log_lik[32]   -1.17    0.00 0.22  -1.69  -1.28  -1.12  -1.00  -0.86  3923    1
log_lik[33]   -0.93    0.00 0.07  -1.08  -0.98  -0.93  -0.87  -0.79  3259    1
log_lik[34]   -0.98    0.00 0.09  -1.16  -1.03  -0.97  -0.92  -0.81  3436    1
log_lik[35]   -2.63    0.01 0.52  -3.77  -2.96  -2.60  -2.27  -1.76  3962    1
log_lik[36]   -1.67    0.00 0.18  -2.05  -1.78  -1.66  -1.54  -1.35  3477    1
log_lik[37]   -1.86    0.00 0.27  -2.44  -2.03  -1.83  -1.67  -1.41  4335    1
log_lik[38]   -1.29    0.00 0.17  -1.67  -1.40  -1.28  -1.17  -1.01  3135    1
log_lik[39]   -2.94    0.01 0.58  -4.21  -3.31  -2.90  -2.52  -1.98  3294    1
log_lik[40]   -1.78    0.00 0.20  -2.20  -1.91  -1.76  -1.63  -1.42  3848    1
log_lik[41]   -1.38    0.00 0.24  -1.96  -1.52  -1.35  -1.21  -1.00  3613    1
log_lik[42]   -0.93    0.00 0.07  -1.08  -0.98  -0.93  -0.88  -0.79  3311    1
log_lik[43]   -2.03    0.01 0.34  -2.78  -2.24  -2.00  -1.78  -1.44  3238    1
log_lik[44]   -1.92    0.00 0.25  -2.47  -2.08  -1.90  -1.73  -1.47  3460    1
log_lik[45]   -2.08    0.01 0.34  -2.82  -2.30  -2.05  -1.84  -1.50  3103    1
log_lik[46]   -1.00    0.00 0.13  -1.31  -1.06  -0.98  -0.91  -0.81  2724    1
log_lik[47]   -1.77    0.00 0.28  -2.40  -1.95  -1.74  -1.57  -1.29  3795    1
log_lik[48]   -1.24    0.00 0.16  -1.60  -1.34  -1.22  -1.13  -0.98  3253    1
log_lik[49]   -3.58    0.01 0.54  -4.72  -3.92  -3.54  -3.20  -2.60  3539    1
log_lik[50]   -1.62    0.00 0.26  -2.21  -1.78  -1.60  -1.44  -1.20  4473    1
log_lik[51]   -1.38    0.00 0.22  -1.87  -1.51  -1.35  -1.22  -1.03  3141    1
log_lik[52]   -1.29    0.00 0.11  -1.51  -1.36  -1.28  -1.22  -1.10  3466    1
log_lik[53]   -1.00    0.00 0.09  -1.19  -1.05  -0.99  -0.94  -0.83  3475    1
log_lik[54]   -1.25    0.00 0.25  -1.85  -1.39  -1.21  -1.07  -0.90  3457    1
log_lik[55]   -0.93    0.00 0.08  -1.10  -0.98  -0.93  -0.88  -0.79  2537    1
log_lik[56]   -0.93    0.00 0.08  -1.09  -0.98  -0.93  -0.88  -0.78  3031    1
log_lik[57]   -1.21    0.00 0.14  -1.51  -1.29  -1.19  -1.11  -0.98  3535    1
log_lik[58]   -0.99    0.00 0.10  -1.22  -1.05  -0.98  -0.92  -0.82  2718    1
log_lik[59]   -1.50    0.00 0.19  -1.92  -1.61  -1.48  -1.36  -1.17  3926    1
log_lik[60]   -0.96    0.00 0.08  -1.13  -1.01  -0.95  -0.90  -0.81  3188    1
log_lik[61]   -1.56    0.00 0.15  -1.88  -1.66  -1.55  -1.45  -1.29  3824    1
log_lik[62]   -1.28    0.00 0.24  -1.84  -1.42  -1.24  -1.11  -0.93  3575    1
log_lik[63]   -1.63    0.00 0.17  -1.99  -1.75  -1.62  -1.51  -1.33  3227    1
log_lik[64]   -6.83    0.02 0.94  -8.75  -7.44  -6.78  -6.16  -5.13  3520    1
log_lik[65]   -0.99    0.00 0.09  -1.20  -1.05  -0.99  -0.93  -0.83  3065    1
log_lik[66]   -0.99    0.00 0.08  -1.15  -1.04  -0.99  -0.94  -0.85  3279    1
log_lik[67]   -1.22    0.00 0.15  -1.54  -1.31  -1.21  -1.11  -0.97  4342    1
log_lik[68]   -1.04    0.00 0.12  -1.31  -1.11  -1.03  -0.96  -0.85  2870    1
log_lik[69]   -1.09    0.00 0.10  -1.32  -1.16  -1.09  -1.02  -0.91  3711    1
log_lik[70]   -1.03    0.00 0.09  -1.22  -1.09  -1.02  -0.97  -0.87  3430    1
log_lik[71]   -0.93    0.00 0.08  -1.08  -0.98  -0.93  -0.88  -0.79  3117    1
log_lik[72]   -0.93    0.00 0.08  -1.09  -0.98  -0.93  -0.88  -0.79  2675    1
log_lik[73]   -0.93    0.00 0.08  -1.09  -0.98  -0.93  -0.87  -0.79  3199    1
log_lik[74]   -3.70    0.01 0.62  -5.03  -4.11  -3.66  -3.25  -2.63  3528    1
log_lik[75]   -1.15    0.00 0.11  -1.37  -1.22  -1.14  -1.07  -0.96  3241    1
log_lik[76]   -1.40    0.00 0.14  -1.70  -1.49  -1.39  -1.30  -1.15  3445    1
log_lik[77]   -0.93    0.00 0.07  -1.08  -0.98  -0.93  -0.88  -0.79  3260    1
log_lik[78]   -0.99    0.00 0.08  -1.15  -1.04  -0.99  -0.93  -0.84  3340    1
log_lik[79]   -1.07    0.00 0.13  -1.36  -1.14  -1.05  -0.97  -0.86  3060    1
log_lik[80]   -0.97    0.00 0.09  -1.15  -1.02  -0.96  -0.91  -0.81  3250    1
log_lik[81]   -1.42    0.00 0.21  -1.88  -1.55  -1.40  -1.27  -1.07  3112    1
log_lik[82]   -1.80    0.00 0.23  -2.30  -1.95  -1.79  -1.64  -1.40  3734    1
log_lik[83]   -0.96    0.00 0.08  -1.13  -1.01  -0.96  -0.90  -0.81  3208    1
log_lik[84]   -1.29    0.00 0.17  -1.66  -1.38  -1.27  -1.17  -1.01  3325    1
log_lik[85]   -0.93    0.00 0.08  -1.08  -0.98  -0.93  -0.87  -0.78  3030    1
log_lik[86]   -0.92    0.00 0.07  -1.07  -0.97  -0.92  -0.87  -0.78  3172    1
log_lik[87]   -1.62    0.00 0.26  -2.22  -1.78  -1.60  -1.43  -1.19  3500    1
log_lik[88]   -0.95    0.00 0.08  -1.13  -1.00  -0.94  -0.89  -0.80  3265    1
log_lik[89]   -1.41    0.00 0.30  -2.11  -1.58  -1.36  -1.18  -0.96  4135    1
log_lik[90]   -1.02    0.00 0.12  -1.31  -1.10  -1.01  -0.94  -0.82  2936    1
log_lik[91]   -1.06    0.00 0.15  -1.44  -1.13  -1.03  -0.95  -0.83  3111    1
log_lik[92]   -0.96    0.00 0.08  -1.14  -1.01  -0.96  -0.91  -0.81  2933    1
log_lik[93]   -0.96    0.00 0.09  -1.17  -1.01  -0.95  -0.89  -0.80  2348    1
log_lik[94]   -1.27    0.00 0.11  -1.52  -1.34  -1.26  -1.18  -1.07  3617    1
log_lik[95]   -1.74    0.01 0.32  -2.44  -1.93  -1.70  -1.51  -1.21  3087    1
log_lik[96]   -3.34    0.01 0.46  -4.30  -3.63  -3.31  -3.02  -2.54  3551    1
log_lik[97]   -1.14    0.00 0.11  -1.39  -1.21  -1.14  -1.06  -0.95  3744    1
log_lik[98]   -1.53    0.00 0.20  -1.97  -1.65  -1.51  -1.38  -1.18  3594    1
log_lik[99]   -1.07    0.00 0.11  -1.31  -1.13  -1.06  -0.99  -0.87  3345    1
log_lik[100]  -1.56    0.00 0.15  -1.87  -1.65  -1.54  -1.45  -1.30  3334    1
lp__         -48.64    0.04 1.58 -52.44 -49.52 -48.28 -47.44 -46.52  1457    1

Samples were drawn using NUTS(diag_e) at Thu Feb 13 15:28:01 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; s = as.array(data.rstan.mult)
&amp;gt; mcmc &amp;lt;- do.call(mcmc.list, plyr:::alply(s[, , -(length(s[1, 1, ]))], 2, as.mcmc))
&amp;gt; denplot(mcmc, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;,&amp;quot;cbeta0&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(mcmc, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;,&amp;quot;cbeta0&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(mcmc)
$`1`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

$`2`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; stan_ac(data.rstan.mult, pars = c(&amp;quot;beta&amp;quot;,&amp;quot;beta0&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_diag3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_ac(data.rstan.mult, pars = c(&amp;quot;beta&amp;quot;,&amp;quot;beta0&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_diag4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_ess(data.rstan.mult, pars = c(&amp;quot;beta&amp;quot;,&amp;quot;beta0&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_diag4-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Rhat and effective sample size. In this instance, most of the parameters have reasonably high effective samples and thus there is likely to be a good range of values from which to estimate paramter properties.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model. Residuals are not computed directly within &lt;code&gt;rstan&lt;/code&gt; However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(ggplot2)
&amp;gt; library(dplyr)
&amp;gt; mcmc = as.data.frame(data.rstan.mult) %&amp;gt;% dplyr:::select(beta0, starts_with(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(tidyr)
&amp;gt; mcmc = as.data.frame(data.rstan.mult) %&amp;gt;% dplyr:::select(beta0, starts_with(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = data %&amp;gt;% cbind(fit, resid)
&amp;gt; newdata.melt = newdata %&amp;gt;% gather(key = Pred, value = Value, cx1:cx2)
&amp;gt; ggplot(newdata.melt) + geom_point(aes(y = resid, x = Value)) + facet_wrap(~Pred)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data.rstan.mult) %&amp;gt;% dplyr:::select(beta0, starts_with(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentized residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data.rstan.mult) %&amp;gt;% dplyr:::select(beta0,
+     starts_with(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~cx1 * cx2, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:4]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; ggplot() + geom_density(data = NULL, aes(x = as.vector(yRep),
+     fill = &amp;quot;Model&amp;quot;), alpha = 0.5) + geom_density(data = data,
+     aes(x = y, fill = &amp;quot;Obs&amp;quot;), alpha = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(as.matrix(data.rstan.mult), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(as.matrix(data.rstan.mult), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.rstan.add, pars = c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: linregModeladd.
2 chains, each with iter=2500; warmup=1000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

        mean se_mean   sd 2.5%  25%  50%  75% 97.5% n_eff Rhat
beta0   3.80    0.00 0.10 3.60 3.73 3.80 3.87  4.00  2672    1
beta[1] 2.83    0.01 0.45 1.95 2.52 2.82 3.13  3.72  2562    1
beta[2] 1.58    0.01 0.38 0.84 1.33 1.58 1.85  2.32  2623    1
sigma   0.99    0.00 0.07 0.86 0.94 0.99 1.04  1.15  3017    1

Samples were drawn using NUTS(diag_e) at Thu Feb 13 15:27:59 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(data.rstan.add, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;,
+     pars = c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
# A tibble: 4 x 5
  term    estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta0      3.80     0.101     3.59       3.99
2 beta[1]    2.83     0.445     1.93       3.69
3 beta[2]    1.58     0.377     0.823      2.31
4 sigma      0.994    0.0740    0.856      1.15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;When &lt;code&gt;cx2&lt;/code&gt; is held constant, a one unit increase in &lt;code&gt;cx1&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(2.83\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(2.83\)&lt;/span&gt; per unit increase in &lt;code&gt;cx1&lt;/code&gt; when standardised for &lt;code&gt;cx2&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When &lt;code&gt;cx1&lt;/code&gt; is held constant, a one unit increase in &lt;code&gt;cx2&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(1.58\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(1.58\)&lt;/span&gt; per unit increase in &lt;code&gt;cx2&lt;/code&gt; when standardised for &lt;code&gt;cx1&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note, as this is an additive model, the rates associated with &lt;code&gt;cx1&lt;/code&gt; are assumed to be constant throughtout the range of &lt;code&gt;cx2&lt;/code&gt; and vice versa. The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for each partial slope does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant effects of &lt;code&gt;cx1&lt;/code&gt; and &lt;code&gt;cx2&lt;/code&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue(as.matrix(data.rstan.add)[, &amp;quot;beta[1]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan.add)[, &amp;quot;beta[2]&amp;quot;])
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of essentially &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, we would conclude that there is almost no evidence that the slope was likely to be equal to zero, suggesting there is a relationship. Next, we look at the results from the multiplicative model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.rstan.mult, pars = c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: linregModeladd.
2 chains, each with iter=2500; warmup=1000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

        mean se_mean   sd  2.5%  25%  50%  75% 97.5% n_eff Rhat
beta0   3.72    0.00 0.12  3.48 3.63 3.71 3.80  3.96  3353    1
beta[1] 2.81    0.01 0.45  1.90 2.51 2.81 3.11  3.69  3050    1
beta[2] 1.50    0.01 0.38  0.77 1.24 1.50 1.77  2.26  2954    1
beta[3] 1.41    0.02 1.22 -0.98 0.58 1.44 2.24  3.76  3328    1
sigma   0.99    0.00 0.07  0.86 0.94 0.99 1.04  1.15  3271    1

Samples were drawn using NUTS(diag_e) at Thu Feb 13 15:28:01 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(data.rstan.mult, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;,
+     pars = c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
# A tibble: 5 x 5
  term    estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta0      3.72     0.124     3.48       3.96
2 beta[1]    2.81     0.455     1.96       3.73
3 beta[2]    1.50     0.385     0.769      2.26
4 beta[3]    1.41     1.22     -0.985      3.76
5 sigma      0.993    0.0725    0.850      1.13&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;At the average level of &lt;code&gt;cx2 (=0)&lt;/code&gt;, a one unit increase in &lt;code&gt;cx1&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(2.80\)&lt;/span&gt; change in y. That is, y increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(2.80\)&lt;/span&gt; per unit increase in &lt;code&gt;cx1&lt;/code&gt; when standardised for &lt;code&gt;cx2&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;At the average level of &lt;code&gt;cx1 (=0)&lt;/code&gt;, a one unit increase in &lt;code&gt;cx2&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(1.50\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(1.50\)&lt;/span&gt; per unit increase in &lt;code&gt;cx2&lt;/code&gt; when standardised for &lt;code&gt;cx1&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The degree to which the rate of change in response associated with a one unit change in &lt;code&gt;cx1&lt;/code&gt; changes over the range of &lt;code&gt;cx2&lt;/code&gt; (and vice versa) is &lt;span class=&#34;math inline&#34;&gt;\(1.45\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence intervals for the interaction partial slope does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant interaction between &lt;code&gt;cx1&lt;/code&gt; and &lt;code&gt;cx2&lt;/code&gt;. This suggests that the nature of the relationship between &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;code&gt;cx1&lt;/code&gt; depends on the level of &lt;code&gt;cx2&lt;/code&gt; (and vice versa). The estimates of the effect of &lt;code&gt;cx1&lt;/code&gt; are only appropriate when &lt;code&gt;cx2 = 0&lt;/code&gt; etc. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(as.matrix(data.rstan.mult)[, &amp;quot;beta[1]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan.mult)[, &amp;quot;beta[2]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan.mult)[, &amp;quot;beta[3]&amp;quot;])
[1] 0.2476667&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of essentially &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, we would conclude that there is almost no evidence that the slope was likely to be equal to zero, suggesting there is a relationship. An alternative way of quantifying the impact of an interaction is to compare models with and without the interactions. In a Bayesian context, this can be achieved by comparing the &lt;strong&gt;leave-one-out cross-validation&lt;/strong&gt; statistics. Leave-one-out (LOO) cross-validation explores how well a series of models can predict withheld values &lt;span class=&#34;citation&#34;&gt;Vehtari, Gelman, and Gabry (2017)&lt;/span&gt;. The LOO Information Criterion (LOOIC) is analogous to the AIC except that the LOOIC takes priors into consideration, does not assume that the posterior distribution is drawn from a multivariate normal and integrates over parameter uncertainty so as to yield a distribution of looic rather than just a point estimate. The LOOIC does however assume that all observations are equally influential (it does not matter which observations are left out). This assumption can be examined via the Pareto &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; estimate (values greater than &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt; or more conservatively &lt;span class=&#34;math inline&#34;&gt;\(0.75\)&lt;/span&gt; are considered overly influential). We can compute LOOIC if we store the loglikelihood from our &lt;code&gt;STAN&lt;/code&gt; model, which can then be extracted to compute the information criterion using the package &lt;code&gt;loo&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; library(loo)
&amp;gt; (full = loo(extract_log_lik(data.rstan.mult)))

Computed from 3000 by 100 log-likelihood matrix

         Estimate   SE
elpd_loo   -143.3  8.5
p_loo         5.2  1.1
looic       286.5 17.0
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k &amp;lt; 0.5).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; (reduced = loo(extract_log_lik(data.rstan.add)))

Computed from 3000 by 100 log-likelihood matrix

         Estimate   SE
elpd_loo   -143.1  8.7
p_loo         4.4  1.1
looic       286.1 17.4
------
Monte Carlo SE of elpd_loo is 0.0.

All Pareto k estimates are good (k &amp;lt; 0.5).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; par(mfrow = 1:2, mar = c(5, 3.8, 1, 0) + 0.1, las = 3)
&amp;gt; plot(full, label_points = TRUE)
&amp;gt; plot(reduced, label_points = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_loo-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The expected out-of-sample predictive accuracy is very similar (slightly lower) for the additive model compared to the multiplicative model (model containing the interaction). This might be used to suggest that the inferential evidence for an interaction is low.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;With appropriate use of model matrices and data wrangling, it is possible to produce a single prediction data set along with &lt;code&gt;ggplot&lt;/code&gt; syntax to produce a multi-panel figure. First we look at the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan.add)
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = rbind(data.frame(cx1 = seq(min(data$cx1, na.rm = TRUE), max(data$cx1,
+     na.rm = TRUE), len = 100), cx2 = 0, Pred = 1), data.frame(cx1 = 0,
+     cx2 = seq(min(data$cx2, na.rm = TRUE), max(data$cx2, na.rm = TRUE),
+         len = 100), Pred = 2))
&amp;gt; Xmat = model.matrix(~cx1 + cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)) %&amp;gt;%
+     mutate(x = dplyr:::recode(Pred, x1, x2))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X&amp;quot;) + theme_classic() + facet_wrap(~Pred)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We cannot simply add the raw data to this figure. The reason for this is that the trends represent the effect of one predictor holding the other variable constant. Therefore, the observations we represent on the figure must likewise be standardised. We can achieve this by adding the partial residuals to the figure. Partial residuals are the fitted values plus the residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = rbind(data.frame(cx1 = data$cx1, cx2 = 0, Pred = 1), data.frame(cx1 = 0,
+     cx2 = data$cx2, Pred = 2))
&amp;gt; fMat = rMat = model.matrix(~cx1 + cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2) %&amp;gt;% mutate(x = dplyr:::recode(Pred, x1,
+     x2))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = rdata, aes(y = partial.resid),
+     color = &amp;quot;gray&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low, ymax = conf.high),
+     fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) + theme_classic() +
+     facet_wrap(~Pred, strip.position = &amp;quot;bottom&amp;quot;, labeller = label_bquote(&amp;quot;x&amp;quot; *
+         .(Pred))) + theme(axis.title.x = element_blank(), strip.background = element_blank(),
+     strip.placement = &amp;quot;outside&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;However, this method (whist partially elegant) does become overly opaque if we need more extensive axes labels since the x-axes labels are actually strip labels (which must largely be defined outside of the &lt;code&gt;ggplot&lt;/code&gt; structure). The alternative is to simply produce each partial plot separately before arranging them together in the one figure using the package &lt;code&gt;gridExtra&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(gridExtra)
&amp;gt; mcmc = as.matrix(data.rstan.add)
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = data.frame(cx1 = seq(min(data$cx1, na.rm = TRUE), max(data$cx1,
+     na.rm = TRUE), len = 100), cx2 = 0)
&amp;gt; Xmat = model.matrix(~cx1 + cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; ## Now the partial residuals
&amp;gt; fdata = rdata = data.frame(cx1 = data$cx1, cx2 = 0)
&amp;gt; fMat = rMat = model.matrix(~cx1 + cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2)
&amp;gt; g1 = ggplot(newdata, aes(y = estimate, x = x1)) + geom_point(data = rdata,
+     aes(y = partial.resid), color = &amp;quot;grey&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X1&amp;quot;) + theme_classic()
&amp;gt; 
&amp;gt; newdata = data.frame(cx2 = seq(min(data$cx2, na.rm = TRUE), max(data$cx2,
+     na.rm = TRUE), len = 100), cx1 = 0)
&amp;gt; Xmat = model.matrix(~cx1 + cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; ## Now the partial residuals
&amp;gt; fdata = rdata = data.frame(cx1 = 0, cx2 = data$cx2)
&amp;gt; fMat = rMat = model.matrix(~cx1 + cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2)
&amp;gt; g2 = ggplot(newdata, aes(y = estimate, x = x2)) + geom_point(data = rdata,
+     aes(y = partial.resid), color = &amp;quot;grey&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X2&amp;quot;) + theme_classic()
&amp;gt; 
&amp;gt; grid.arrange(g1, g2, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_post3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the multiplicative model, we could elect to split the trends up so as to explore the effects of one predictor at several set levels of another predictor. In this example, we will explore the effects of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; is equal to its mean in the original data as well as one and two standard deviations below and above this mean.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(fields)
&amp;gt; mcmc = as.matrix(data.rstan.mult)
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = expand.grid(cx1 = seq(min(data$cx1, na.rm = TRUE), max(data$cx1,
+     na.rm = TRUE), len = 100), cx2 = mean(data$cx2) + sd(data$cx2) %*%
+     -2:2)
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)) %&amp;gt;%
+     mutate(x2 = factor(x2, labels = paste(&amp;quot;X2:~&amp;quot;, c(-2, -1, 0, 1, 2), &amp;quot;*sigma&amp;quot;)))
&amp;gt; ## Partial residuals
&amp;gt; fdata = rdata = expand.grid(cx1 = data$cx1, cx2 = mean(data$cx2) + sd(data$cx2) *
+     -2:2)
&amp;gt; fMat = rMat = model.matrix(~cx1 * cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2)
&amp;gt; ## Partition the partial residuals such that each x1 trend only includes
&amp;gt; ## x2 data that is within that range in the observed data
&amp;gt; findNearest = function(x, y) {
+     ff = fields:::rdist(x, y)
+     apply(ff, 1, function(x) which(x == min(x)))
+ }
&amp;gt; fn = findNearest(x = data[, c(&amp;quot;x1&amp;quot;, &amp;quot;x2&amp;quot;)], y = rdata[, c(&amp;quot;x1&amp;quot;, &amp;quot;x2&amp;quot;)])
&amp;gt; rdata = rdata[fn, ] %&amp;gt;% mutate(x2 = factor(x2, labels = paste(&amp;quot;X2:~&amp;quot;, c(-2,
+     -1, 0, 1, 2), &amp;quot;*sigma&amp;quot;)))
&amp;gt; ggplot(newdata, aes(y = estimate, x = x1)) + geom_line() + geom_blank(aes(y = 9)) +
+     geom_point(data = rdata, aes(y = partial.resid), color = &amp;quot;grey&amp;quot;) +
+     geom_ribbon(aes(ymin = conf.low, ymax = conf.high), fill = &amp;quot;blue&amp;quot;,
+         alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_continuous(&amp;quot;X1&amp;quot;) +
+     facet_wrap(~x2, labeller = label_parsed, nrow = 1, scales = &amp;quot;free_y&amp;quot;) +
+     theme_classic() + theme(strip.background = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/mcmc_post4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Alternatively, we could explore the interaction by plotting a two dimensional surface as a heat map.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;effect-sizes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Effect sizes&lt;/h1&gt;
&lt;p&gt;In addition to deriving the distribution means for the slope parameter, we could make use of the Bayesian framework to derive the distribution of the effect size. In so doing, effect size could be considered as either the rate of change or alternatively, the difference between pairs of values along the predictor gradient. For the latter case, there are multiple ways of calculating an effect size, but the two most common are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Raw effect size&lt;/em&gt;. The difference between two groups (as already calculated)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Cohen’s D&lt;/em&gt;. The effect size standardized by division with the pooled standard deviation: &lt;span class=&#34;math inline&#34;&gt;\(D=\frac{(\mu_A-\mu_B)}{\sigma}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Percentage change&lt;/em&gt;. Express the effect size as a percent of one of the pairs. That is, whether you expressing a percentage increase or a percentage decline depends on which of the pairs of values are considered a reference value. Care must be exercised to ensure no division by zeros occur.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For simple linear models, effect size based on a rate is essentially the same as above except that it is expressed per unit of the predictor. Of course in many instances, one unit change in the predictor represents too subtle a shift in the underlying gradient to likely yield any clinically meaningful or appreciable change in response.&lt;/p&gt;
&lt;p&gt;Probability that a change in &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; is associated with greater than a &lt;span class=&#34;math inline&#34;&gt;\(50\)&lt;/span&gt;% increase in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at various levels of &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;. Clearly, in order to explore this inference, we must first express the change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; as a percentage. This in turn requires us to calculate start and end points from which to calculate the magnitude of the effect (amount of increase in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) as well as the percentage decline. Hence, we start by predicting the distribution of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at the lowest and highest values of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; at five levels of &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; (representing two standard deviations below the &lt;code&gt;cx2&lt;/code&gt; mean, one standard deviation below the &lt;code&gt;cx2&lt;/code&gt; mean, the &lt;code&gt;cx2&lt;/code&gt; mean, one standard deviation above the &lt;code&gt;cx2&lt;/code&gt; mean and &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; standard deviations above the &lt;code&gt;cx2&lt;/code&gt; mean. For this exercise we will only use the multiplicative model. Needless to say, the process would be very similar for the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan.mult)
&amp;gt; newdata = expand.grid(cx1 = c(min(data$cx1), max(data$cx1)), cx2 = (-2:2) *
+     sd(data$cx1))
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; s1 = seq(1, 9, b = 2)
&amp;gt; s2 = seq(2, 10, b = 2)
&amp;gt; ## Raw effect size
&amp;gt; (RES = tidyMCMC(as.mcmc(fit[, s2] - fit[, s1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         1.99     0.846    0.278      3.59
2 4         2.39     0.583    1.29       3.58
3 6         2.79     0.452    1.94       3.71
4 8         3.19     0.554    2.11       4.21
5 10        3.59     0.806    2.09       5.18
&amp;gt; ## Cohen&amp;#39;s D
&amp;gt; cohenD = (fit[, s2] - fit[, s1])/sqrt(mcmc[, &amp;quot;sigma&amp;quot;])
&amp;gt; (cohenDES = tidyMCMC(as.mcmc(cohenD), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         2.00     0.849    0.283      3.60
2 4         2.40     0.590    1.26       3.56
3 6         2.81     0.465    1.91       3.73
4 8         3.21     0.570    2.14       4.33
5 10        3.61     0.820    1.90       5.10
&amp;gt; # Percentage change (relative to Group A)
&amp;gt; ESp = 100 * (fit[, s2] - fit[, s1])/fit[, s1]
&amp;gt; (PES = tidyMCMC(as.mcmc(ESp), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         121.      80.0    -1.23      277.
2 4         119.      41.4    38.8       200.
3 6         124.      33.1    64.6       190.
4 8         132.      46.6    54.8       225.
5 10        144.      73.2    37.8       282.
&amp;gt; # Probability that the effect is greater than 50% (an increase of &amp;gt;50%)
&amp;gt; (p50 = apply(ESp, 2, function(x) sum(x &amp;gt; 50)/length(x)))
        2         4         6         8        10 
0.8586667 0.9740000 0.9983333 0.9940000 0.9793333 
&amp;gt; ## fractional change
&amp;gt; (FES = tidyMCMC(as.mcmc(fit[, s2]/fit[, s1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         2.21     0.800    0.988      3.77
2 4         2.19     0.414    1.39       3.00
3 6         2.24     0.331    1.65       2.90
4 8         2.32     0.466    1.55       3.25
5 10        2.44     0.732    1.38       3.82&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On average, when &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; is equal to its mean, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by &lt;span class=&#34;math inline&#34;&gt;\(2.79\)&lt;/span&gt; over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the increase is between &lt;span class=&#34;math inline&#34;&gt;\(1.91\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(3.66\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Cohen’s D associated change over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(2.80\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by &lt;span class=&#34;math inline&#34;&gt;\(124\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; (at average &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;). We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the increase is between &lt;span class=&#34;math inline&#34;&gt;\(65\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(190\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The probability that &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by more than &lt;span class=&#34;math inline&#34;&gt;\(50\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; (average &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;) is &lt;span class=&#34;math inline&#34;&gt;\(0.998\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by a factor of &lt;span class=&#34;math inline&#34;&gt;\(2.24\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; (average &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;). We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between a factor of &lt;span class=&#34;math inline&#34;&gt;\(1.65\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(2.90\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x1       0.800    0.130  0.558        1.06 
2 sd.x2       0.501    0.128  0.256        0.754
3 sd.x1x2     0.134    0.0873 0.000182     0.291
4 sd.resid    0.981    0.0125 0.966        1.01 
# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x1       33.2       5.00 22.5          42.1
2 sd.x2       20.8       5.11 11.2          30.9
3 sd.x1x2      5.16      3.44  0.00805      11.5
4 sd.resid    40.5       2.13 36.7          45.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/effects_modelv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(59\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; and their interaction.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- as.matrix(data.rstan.mult)
&amp;gt; Xmat = model.matrix(~cx1 * cx2, data)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.605    0.0390    0.531     0.678
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ cx1 * cx2, data))

Call:
lm(formula = y ~ cx1 * cx2, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.8173 -0.7167 -0.1092  0.5890  3.3861 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)   3.7152     0.1199  30.987  &amp;lt; 2e-16 ***
cx1           2.8072     0.4390   6.394 5.84e-09 ***
cx2           1.4988     0.3810   3.934 0.000158 ***
cx1:cx2       1.4464     1.1934   1.212 0.228476    
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 0.9804 on 96 degrees of freedom
Multiple R-squared:  0.6115,    Adjusted R-squared:  0.5994 
F-statistic: 50.37 on 3 and 96 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-model-selection&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bayesian model selection&lt;/h1&gt;
&lt;p&gt;A statistical model is by definition a low-dimensional (over simplification) representation of what is really likely to be a very complex system. As a result, no model is right. Some models however can provide useful insights into some of the processes operating on the system. Frequentist statistics have various methods (model selection, dredging, lasso, cross validation) for selecting parsimonious models. These are models that provide a good comprimise between minimizing unexplained patterns and minimizing model complexity. The basic premise is that since no model can hope to capture the full complexity of a system with all its subtleties, only the very major patterns can be estimated. Overly complex models are likely to be representing artificial complexity present only in the specific observed data (not the general population). The Bayesian approach is to apply priors to the non-variance parameters such that parameters close to zero are further shrunk towards zero whilst priors on parameters further away from zero are less effected. The most popular form of prior for sparsity is the &lt;em&gt;horseshoe prior&lt;/em&gt;, so called because the shape of a component of this prior resembles a horseshoe (with most of the mass either close to &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; or close to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Rather than apply weakly informative Gaussian priors on parameters as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\sigma^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the horseshoe prior is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2\lambda_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tau \sim \text{Cauchy}(0,1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j \sim \text{Cauchy}(0,1)\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(j=1,\ldots,D\)&lt;/span&gt;. Using this prior, &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is the number of (non-intercept or variance) parameters, &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; represents the global scale that weights or shrinks all parameters towards zero and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j\)&lt;/span&gt; are thick tailed local scales that allow some of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; parameters to escape shrinkage. More recently, &lt;span class=&#34;citation&#34;&gt;Piironen, Vehtari, and others (2017)&lt;/span&gt; have argued that whilst the above horseshoe priors do guarantee that strong effects (parameters) will not be over-shrunk, there is the potential for weekly identified effects (those based on relatively little data) to be misrepresented in the posteriors. As an alternative they advocated the use of regularised horseshoe priors in which the amount of shrinkage applied to the largest effects can be controlled. The prior is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2 \tilde{\lambda}_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tilde{\lambda}_j^2 = \frac{c^2\lambda^2_j}{c^2+\tau^2 \lambda^2_j}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is (slab width, actually variance) is a constant. For small effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;lt; c^2\)&lt;/span&gt;) the prior approaches a regular prior. However, for large effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;gt; c^2\)&lt;/span&gt;) the prior approaches &lt;span class=&#34;math inline&#34;&gt;\(N(0,c^2)\)&lt;/span&gt;. Finally, they recommend applying a inverse-gamma prior on &lt;span class=&#34;math inline&#34;&gt;\(c^2\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ c^2 \sim \text{Inv-Gamma}(\alpha,\beta),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\alpha=v/2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta=vs^2/2\)&lt;/span&gt;, which translates to a &lt;span class=&#34;math inline&#34;&gt;\(\text{Student-t}_ν(0, s^2)\)&lt;/span&gt; slab for the coefficients far from zero and is typically a good default choice for a weakly informative prior. This prior can be encoded into &lt;code&gt;STAN&lt;/code&gt; using the following code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelStringHP = &amp;quot;
+                        data {
+                        int &amp;lt; lower =0 &amp;gt; n; // number of observations
+                        int &amp;lt; lower =0 &amp;gt; nX; // number of predictors
+                        vector [ n] Y; // outputs
+                        matrix [n ,nX] X; // inputs
+                        real &amp;lt; lower =0 &amp;gt; scale_icept ; // prior std for the intercept
+                        real &amp;lt; lower =0 &amp;gt; scale_global ; // scale for the half -t prior for tau
+                        real &amp;lt; lower =1 &amp;gt; nu_global ; // degrees of freedom for the half -t priors for tau
+                        real &amp;lt; lower =1 &amp;gt; nu_local ; // degrees of freedom for the half - t priors for lambdas
+                        real &amp;lt; lower =0 &amp;gt; slab_scale ; // slab scale for the regularized horseshoe
+                        real &amp;lt; lower =0 &amp;gt; slab_df ; // slab degrees of freedom for the regularized horseshoe
+                        }
+                        transformed data {
+                        matrix[n, nX - 1] Xc;  // centered version of X 
+                        vector[nX - 1] means_X;  // column means of X before centering 
+                        for (i in 2:nX) { 
+                        means_X[i - 1] = mean(X[, i]); 
+                        Xc[, i - 1] = X[, i] - means_X[i - 1]; 
+                        }  
+                        }
+                        parameters {
+                        real logsigma ;
+                        real cbeta0 ;
+                        vector [ nX-1] z;
+                        real &amp;lt; lower =0 &amp;gt; tau ; // global shrinkage parameter
+                        vector &amp;lt; lower =0 &amp;gt;[ nX-1] lambda ; // local shrinkage parameter
+                        real &amp;lt; lower =0 &amp;gt; caux ;
+                        }
+                        transformed parameters {
+                        real &amp;lt; lower =0 &amp;gt; sigma ; // noise std
+                        vector &amp;lt; lower =0 &amp;gt;[ nX-1] lambda_tilde ; // truncated local shrinkage parameter
+                        real &amp;lt; lower =0 &amp;gt; c; // slab scale
+                        vector [ nX-1] beta ; // regression coefficients
+                        vector [ n] mu; // latent function values
+                        sigma = exp ( logsigma );
+                        c = slab_scale * sqrt ( caux );
+                        lambda_tilde = sqrt ( c ^2 * square ( lambda ) ./ (c ^2 + tau ^2* square ( lambda )) );
+                        beta = z .* lambda_tilde * tau ;
+                        mu = cbeta0 + Xc* beta ;
+                        }
+                        model {
+                        // half -t priors for lambdas and tau , and inverse - gamma for c ^2
+                        z ~ normal (0 , 1);
+                        lambda ~ student_t ( nu_local , 0, 1);
+                        tau ~ student_t ( nu_global , 0 , scale_global * sigma );
+                        caux ~ inv_gamma (0.5* slab_df , 0.5* slab_df );
+                        cbeta0 ~ normal (0 , scale_icept );
+                        Y ~ normal (mu , sigma );
+                        }
+                        generated quantities { 
+                        real beta0;  // population-level intercept 
+                        vector[n] log_lik;
+                        beta0 = cbeta0 - dot_product(means_X, beta);
+                        for (i in 1:n) {
+                        log_lik[i] = normal_lpdf(Y[i] | Xc[i] * beta + cbeta0, sigma);
+                        }
+                        }
+   
+   &amp;quot;
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelStringHP, con = &amp;quot;linregModelHP.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now try to refit the model (additive) using this new specification.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X = model.matrix(~cx1 + cx2, data = data)
&amp;gt; data.list &amp;lt;- with(data, list(Y = y, X = X, nX = ncol(X), n = nrow(data),
+     scale_icept = 100, scale_global = 1, nu_global = 1, nu_local = 1, slab_scale = 2,
+     slab_df = 4))
&amp;gt; 
&amp;gt; data.rstan.sparsity &amp;lt;- stan(data = data.list, file = &amp;quot;linregModelHP.stan&amp;quot;, pars = params,
+     chains = nChains, iter = nIter, warmup = burnInSteps, thin = thinSteps, save_dso = TRUE)

SAMPLING FOR MODEL &amp;#39;linregModelHP&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2500 [  0%]  (Warmup)
Chain 1: Iteration:  250 / 2500 [ 10%]  (Warmup)
Chain 1: Iteration:  500 / 2500 [ 20%]  (Warmup)
Chain 1: Iteration:  750 / 2500 [ 30%]  (Warmup)
Chain 1: Iteration: 1000 / 2500 [ 40%]  (Warmup)
Chain 1: Iteration: 1001 / 2500 [ 40%]  (Sampling)
Chain 1: Iteration: 1250 / 2500 [ 50%]  (Sampling)
Chain 1: Iteration: 1500 / 2500 [ 60%]  (Sampling)
Chain 1: Iteration: 1750 / 2500 [ 70%]  (Sampling)
Chain 1: Iteration: 2000 / 2500 [ 80%]  (Sampling)
Chain 1: Iteration: 2250 / 2500 [ 90%]  (Sampling)
Chain 1: Iteration: 2500 / 2500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.364 seconds (Warm-up)
Chain 1:                0.484 seconds (Sampling)
Chain 1:                0.848 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;linregModelHP&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2500 [  0%]  (Warmup)
Chain 2: Iteration:  250 / 2500 [ 10%]  (Warmup)
Chain 2: Iteration:  500 / 2500 [ 20%]  (Warmup)
Chain 2: Iteration:  750 / 2500 [ 30%]  (Warmup)
Chain 2: Iteration: 1000 / 2500 [ 40%]  (Warmup)
Chain 2: Iteration: 1001 / 2500 [ 40%]  (Sampling)
Chain 2: Iteration: 1250 / 2500 [ 50%]  (Sampling)
Chain 2: Iteration: 1500 / 2500 [ 60%]  (Sampling)
Chain 2: Iteration: 1750 / 2500 [ 70%]  (Sampling)
Chain 2: Iteration: 2000 / 2500 [ 80%]  (Sampling)
Chain 2: Iteration: 2250 / 2500 [ 90%]  (Sampling)
Chain 2: Iteration: 2500 / 2500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.328 seconds (Warm-up)
Chain 2:                0.444 seconds (Sampling)
Chain 2:                0.772 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; tidyMCMC(data.rstan.sparsity, pars = c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;), conf.int = TRUE,
+     conf.type = &amp;quot;HPDinterval&amp;quot;, rhat = TRUE, ess = TRUE)
# A tibble: 2 x 7
  term    estimate std.error conf.low conf.high  rhat   ess
  &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
1 beta[1]     2.75     0.446    1.86       3.61 0.999  3138
2 beta[2]     1.56     0.379    0.816      2.30 1.000  2782
&amp;gt; 
&amp;gt; mcmc_areas(as.matrix(data.rstan.sparsity), regex_par = &amp;quot;beta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/multiple-linear-regression-stan/2020-02-01-multiple-linear-regression-stan_files/figure-html/model_HP_fit-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Obviously, these data are not really appropriate for model selection as there are only two predictors. Both predictors have substantial effects mass larger than zero.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2015stan&#34;&gt;
&lt;p&gt;Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt; 40 (5): 530–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-piironen2017sparsity&#34;&gt;
&lt;p&gt;Piironen, Juho, Aki Vehtari, and others. 2017. “Sparsity Information and Regularization in the Horseshoe and Other Shrinkage Priors.” &lt;em&gt;Electronic Journal of Statistics&lt;/em&gt; 11 (2): 5018–51.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanpackage&#34;&gt;
&lt;p&gt;Stan Development Team. 2018. “RStan: The R Interface to Stan.” &lt;a href=&#34;http://mc-stan.org/&#34;&gt;http://mc-stan.org/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vehtari2017practical&#34;&gt;
&lt;p&gt;Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and Waic.” &lt;em&gt;Statistics and Computing&lt;/em&gt; 27 (5): 1413–32.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simple Linear Regression - JAGS</title>
      <link>/jags/simple-linear-regression-jags/simple-linear-regression-jags/</link>
      <pubDate>Sun, 02 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/simple-linear-regression-jags/simple-linear-regression-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Many clinicians get a little twitchy and nervous around mathematical and statistical formulae and nomenclature. Whilst it is possible to perform basic statistics without too much regard for the actual equation (model) being employed, as the complexity of the analysis increases, the need to understand the underlying model becomes increasingly important. Moreover, model specification in &lt;code&gt;BUGS/JAGS/STAN&lt;/code&gt; (the language used to program Bayesian modelling) aligns very closely to the underlying formulae. Hence a good understanding of the underlying model is vital to be able to create a sensible Bayesian model. Consequently, I will always present the linear model formulae along with the analysis.&lt;/p&gt;
&lt;p&gt;To introduce the philosophical and mathematical differences between classical (frequentist) and Bayesian statistics, based on previous works, we present a provocative yet compelling trend analysis of two hypothetical populations (A vs B). The temporal trend of population A shows very little variability from a very subtle linear decline (&lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{slope}=-0.10\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{p-value}=0.048\)&lt;/span&gt;). By contrast, the B population appears to decline more dramatically, yet has substantially more variability (&lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{slope}=-10.23\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{p-value}=0.058\)&lt;/span&gt;). From a traditional frequentist perspective, we would conclude that there is a “significant” relationship in Population A (&lt;span class=&#34;math inline&#34;&gt;\(p&amp;lt;0.05\)&lt;/span&gt;), yet not in Population B (&lt;span class=&#34;math inline&#34;&gt;\(p&amp;gt;0.05\)&lt;/span&gt;). However, if we consider a third population C which is exactly the same as populstion B but with a higher number of observations, then we may end up with a completely different conclusion compared with that based on population B (&lt;span class=&#34;math inline&#34;&gt;\(n=100\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{slope}=-10.47\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{p-value}&amp;lt;0.001\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;The above illustrates a couple of things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;statistical significance does not necessarily translate into clinical importance. Indeed, population B is declining at nearly &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; times the rate of population A. That sounds rather important, yet on the basis of the hypothesis test, we would dismiss the decline in population B.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;that a p-value is just the probability of detecting an effect or relationship - what is the probability that the sample size is large enough to pick up a difference.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let us now look at it from a Bayesian perspective, with a focus on population A and B. We would conclude that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the mean (plus or minus CI) slopes for Population A and B are &lt;span class=&#34;math inline&#34;&gt;\(-0.1 (-0.21,0)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(-10.08 (-20.32,0.57)\)&lt;/span&gt; respectively&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the Bayesian approach allows us to query the posterior distribution is many other ways in order to ask sensible clinical questions. For example, we might consider that a rate of change of &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% or greater represents an important biological impact. For population A and B, the probability that the rate is &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% or greater is &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(0.85\)&lt;/span&gt; respectively.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear regression&lt;/h2&gt;
&lt;p&gt;Simple linear regression is a linear modelling process that models a continuous response against a single continuous predictor. The linear model is expressed as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_i + \epsilon_i, \;\;\; \epsilon_i \sim \text{Normal}(0,\sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; is the response variable for each of the &lt;span class=&#34;math inline&#34;&gt;\(i=1\ldots,n\)&lt;/span&gt; observations, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the intercept (value when &lt;span class=&#34;math inline&#34;&gt;\(x=0\)&lt;/span&gt;), &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is the slope (rate of change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; per unit change in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;), &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; is the predictor variable, &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_i\)&lt;/span&gt; is the residual value (difference between the observed value and the value expected by the model). The parameters of the trendline &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta=(\beta_0,\beta_1)\)&lt;/span&gt; are determined by &lt;em&gt;Ordinary Least Squares&lt;/em&gt; (OLS) in which the sum of the squared residuals is minimized. A non-zero population slope is indicative of a relationship.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Lets say we had set up an experiment in which we applied a continuous treatment (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) ranging in magnitude from &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(16\)&lt;/span&gt; to a total of &lt;span class=&#34;math inline&#34;&gt;\(16\)&lt;/span&gt; sampling units (&lt;span class=&#34;math inline&#34;&gt;\(n=16\)&lt;/span&gt;) and then measured a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) from each unit. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n &amp;lt;- 16
&amp;gt; a &amp;lt;- 40  #intercept
&amp;gt; b &amp;lt;- -1.5  #slope
&amp;gt; sigma2 &amp;lt;- 25  #residual variance (sd=5)
&amp;gt; x &amp;lt;- 1:n  #values of the year covariate
&amp;gt; eps &amp;lt;- rnorm(n, mean = 0, sd = sqrt(sigma2))  #residuals
&amp;gt; y &amp;lt;- a + b * x + eps  #response variable
&amp;gt; # OR
&amp;gt; y &amp;lt;- (model.matrix(~x) %*% c(a, b)) + eps
&amp;gt; data &amp;lt;- data.frame(y, x)  #dataset
&amp;gt; head(data)  #print out the first six rows of the data set
         y x
1 35.69762 1
2 35.84911 2
3 43.29354 3
4 34.35254 4
5 33.14644 5
6 39.57532 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the linear predictor (single continuous predictor).&lt;/p&gt;
&lt;div id=&#34;centering-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Centering the data&lt;/h2&gt;
&lt;p&gt;When a linear model contains a covariate (continuous predictor variable) in addition to another predictor (continuous or categorical), it is nearly always advisable that the continuous predictor variables are centered prior to the analysis. Centering is a process by which the mean of a variable is subtracted from each of the values such that the scale of the variable is shifted so as to be centered around &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Hence the mean of the new centered variable will be &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, yet it will retain the same variance.&lt;/p&gt;
&lt;p&gt;There are multiple reasons for this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;It provides some clinical meaning to the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept. Recall that the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is equal to zero. If &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is centered, then the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept represents the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at the mid-point of the &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; range. The &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept of an uncentered &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; typically represents a unreal value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; (as an &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; is often beyond the reasonable range of values).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In multiplicative models (in which predictors and their interactions are included), main effects and interaction terms built from centered predictors will not be correlated to one another.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For more complex models, centering the covariates can increase the likelihood that the modelling engine converges (arrives at a numerically stable and reliable outcome).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note, centering will not effect the slope estimates. In &lt;code&gt;R&lt;/code&gt;, centering is easily achieved with the &lt;code&gt;scale&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data &amp;lt;- within(data, {
+     cx &amp;lt;- as.numeric(scale(x, scale = FALSE))
+ })
&amp;gt; head(data)
         y x   cx
1 35.69762 1 -7.5
2 35.84911 2 -6.5
3 43.29354 3 -5.5
4 34.35254 4 -4.5
5 33.14644 5 -3.5
6 39.57532 6 -2.5&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Exploratory data analysis&lt;/h1&gt;
&lt;div id=&#34;normality&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Normality&lt;/h2&gt;
&lt;p&gt;Estimation and inference testing in linear regression assumes that the response is normally distributed in each of the populations. In this case, the populations are all possible measurements that could be collected at each level of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; - hence there are &lt;span class=&#34;math inline&#34;&gt;\(16\)&lt;/span&gt; populations. Typically however, we only collect a single observation from each population (as is also the case here). How then can be evaluate whether each of these populations are likely to have been normal? For a given response, the population distributions should follow much the same distribution shapes. Therefore provided the single samples from each population are unbiased representations of those populations, a boxplot of all observations should reflect the population distributions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;homogeneity-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Homogeneity of variance&lt;/h2&gt;
&lt;p&gt;Simple linear regression also assumes that each of the populations are equally varied. Actually, it is prospect of a relationship between the mean and variance of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-values across x-values that is of the greatest concern. Strictly the assumption is that the distribution of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; values at each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; value are equally varied and that there is no relationship between mean and variance. However, as we only have a single &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-value for each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;-value, it is difficult to directly determine whether the assumption of &lt;em&gt;homogeneity of variance&lt;/em&gt; is likely to have been violated (mean of one value is meaningless and variability can’t be assessed from a single value). If we then plot the residuals (difference between observed values and those predicted by the trendline) against the predict values and observe a definite presence of a pattern, then it is indicative of issues with the assumption of homogeneity of variance.&lt;/p&gt;
&lt;p&gt;Hence looking at the spread of values around a trendline on a scatterplot of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; against &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is a useful way of identifying gross violations of homogeneity of variance. Residual plots provide an even better diagnostic. The presence of a &lt;em&gt;wedge shape&lt;/em&gt; is indicative that the population mean and variance are related.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linearity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linearity&lt;/h2&gt;
&lt;p&gt;Linear regression fits a straight (linear) line through the data. Therefore, prior to fitting such a model, it is necessary to establish whether this really is the most sensible way of describing the relationship. That is, does the relationship appear to be linearly related or could some other non-linear function describe the relationship better. Scatterplots and residual plots are useful diagnostics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model assumptions&lt;/h2&gt;
&lt;p&gt;The typical assumptions which need to be checked when fitting a standard linear regression model are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All of the observations are independent - this must be addressed at the design and collection stages&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (and thus the residuals) should be normally distributed&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The relationship between the linear predictor (right hand side of the regression formula) and the link function should be linear. A scatterplot with smoother can be useful for identifying possible non-linearity.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So lets explore normality, homogeneity of variances and linearity by constructing a scatterplot of the relationship between the response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) and the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). We will also include a range of smoothers (linear and lowess) and marginal boxplots on the scatterplot to assist in exploring linearity and normality respectively.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # scatterplot
&amp;gt; library(car)
&amp;gt; scatterplot(y ~ x, data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/scatter-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;There is no evidence that the response variable is non-normal. The spread of values around the trendline seems fairly even (hence it there is no evidence of non-homogeneity). The data seems well represented by the linear trendline. Furthermore, the lowess smoother does not appear to have a consistent shift trajectory. Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Consider a non-linear linear predictor (such as a polynomial, spline or other non-linear function)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Transform the scale of the response variables (e.g. to address normality)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The purpose of fitting a model in this case is to explore the relationship between &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Since both &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; are continuous, a simple regression line is a good start. The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0+\beta_1\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept (value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is equal to zero) and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; represents the rate of change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; for every unit change in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; (the effect).&lt;/p&gt;
&lt;p&gt;Note that in this form, the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept is of little interest. Indeed for many applications, a value of x would be outside the domain of the collected data, outside the logical bounds of the actual variable or else outside the domain of interest. If however, we center the predictor variable (by subtracting the mean of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; from each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, then the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept represents the value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at the average value of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. This certainly has more meaning. Note that centering the predictor does not effect the estimate of slope. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying “uninformative” priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important.&lt;/p&gt;
&lt;p&gt;For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (1000) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=25\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\mu_i, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0+\beta_1x_i\)&lt;/span&gt;. Priors are specified as: &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta \sim \text{Normal}(0,1000)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,25)\)&lt;/span&gt;. We will explore Bayesian modelling of simple linear regression using &lt;code&gt;JAGS&lt;/code&gt;. Remember that in this software normal distributions are specified in terms of precision &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;. In addition, we will derive the following quantities.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The percentage decline &lt;span class=&#34;math inline&#34;&gt;\(\left(100 \times \frac{(\text{max}(x) - \text{min}(x))\beta_1 + \text{min}(y)}{\text{min}(y)} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The probability that &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; decline by more than &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The finite-population variance components&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mu[i],tau)
+   mu[i] &amp;lt;- beta0+beta1*x[i]
+   y.err[i] &amp;lt;- y[i] - mu[i]
+   }
+   
+   #Priors
+   beta0 ~ dnorm(0.01,1.0E-6)
+   beta1 ~ dnorm(0,1.0E-6)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   sigma~dunif(0,100)
+   
+   #Other Derived parameters 
+   p.decline &amp;lt;- 1-step(beta1)
+   ymin&amp;lt;-beta0+beta1*min(x)                  
+   xrange &amp;lt;- max(x) - min(x)       
+   decline &amp;lt;- 100*((xrange*beta1)+ymin)/ymin 
+   p.decline25 &amp;lt;- step(decline-25)
+   
+   #finite-population variance components
+   sd.x &amp;lt;- abs(beta1)*sd(x[])
+   sd.resid &amp;lt;- sd(y.err)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;ttestModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.list &amp;lt;- with(data, list(y = y, x = x, n = nrow(data)))
&amp;gt; data.list
$y
 [1] 35.69762 35.84911 43.29354 34.35254 33.14644 39.57532 31.80458 21.67469
 [9] 23.06574 22.77169 29.62041 23.79907 22.50386 19.55341 14.72079 24.93457

$x
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16

$n
[1] 16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the initial values for the chain. Reasonable starting points can be gleaned from the data themselves.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; inits &amp;lt;- rep(list(list(beta0 = mean(data$y), beta1 = diff(tapply(data$y,
+     data$x, mean)), sigma = sd(data$y))), 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;, &amp;quot;sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When using the &lt;code&gt;jags&lt;/code&gt; function (&lt;code&gt;R2jags&lt;/code&gt; package), it is not necessary to provide initial values. However, if they are to be supplied, the inital values must be provided as a list of the same length as the number of chains. Then print the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params, model.file = &amp;quot;ttestModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter, n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 16
   Unobserved stochastic nodes: 3
   Total graph size: 109

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%   97.5%  Rhat n.eff
beta0     40.332   2.779 34.814 38.547 40.341 42.142  45.768 1.001 15000
beta1     -1.390   0.283 -1.957 -1.571 -1.390 -1.209  -0.822 1.001 15000
sigma      5.187   1.125  3.549  4.399  5.009  5.772   7.848 1.001 14000
deviance  96.319   2.919 93.005 94.208 95.578 97.595 103.875 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.3 and DIC = 100.6
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    3        4115  3746         1.10      
 beta1    2        3855  3746         1.03      
 deviance 3        4026  3746         1.07      
 sigma    4        4907  3746         1.31      


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    2        3938  3746         1.05      
 beta1    2        3770  3746         1.01      
 deviance 2        3811  3746         1.02      
 sigma    4        4853  3746         1.30      &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
              beta0         beta1     deviance       sigma
Lag 0   1.000000000  1.0000000000  1.000000000  1.00000000
Lag 1  -0.007010696  0.0009369893  0.397147648  0.46491253
Lag 5   0.002086800  0.0011849092  0.049133264  0.05413994
Lag 10  0.005430778  0.0054667236  0.008226042  0.01218053
Lag 50 -0.011848951 -0.0054465800 -0.014357351 -0.01271746&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model.&lt;/p&gt;
&lt;p&gt;Although residuals can be computed directly within &lt;code&gt;R2jags&lt;/code&gt;, we can calculate them manually from the posteriors to be consistent across other approaches.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(ggplot2)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = data$x))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentized residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentized residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; ggplot() + geom_density(data = NULL, aes(x = as.vector(yRep),
+     fill = &amp;quot;Model&amp;quot;), alpha = 0.5) + geom_density(data = data,
+     aes(x = y, fill = &amp;quot;Obs&amp;quot;), alpha = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%   97.5%  Rhat n.eff
beta0     40.332   2.779 34.814 38.547 40.341 42.142  45.768 1.001 15000
beta1     -1.390   0.283 -1.957 -1.571 -1.390 -1.209  -0.822 1.001 15000
sigma      5.187   1.125  3.549  4.399  5.009  5.772   7.848 1.001 14000
deviance  96.319   2.919 93.005 94.208 95.578 97.595 103.875 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.3 and DIC = 100.6
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta0       40.3      2.78     34.9     45.8  
2 beta1       -1.39     0.283    -1.94    -0.812
3 deviance    96.3      2.92     92.8    102.   
4 sigma        5.19     1.13      3.31     7.38 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A one unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(-1.39\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; declines at a rate of &lt;span class=&#34;math inline&#34;&gt;\(-1.39\)&lt;/span&gt; per unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the slope does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }
&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta1&amp;quot;)])
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of essentially &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, we would conclude that there is almost no evidence that the slope was likely to be equal to zero, suggesting there is a relationship.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group. We do this by loading functions in the package &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = data.frame(x = seq(min(data$x, na.rm = TRUE), max(data$x, na.rm = TRUE),
+     len = 1000))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you wanted to represent sample data on the figure in such a simple example (single predictor) we could simply over- (or under-) lay the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = data, aes(y = y,
+     x = x), color = &amp;quot;gray&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A more general solution would be to add the partial residuals to the figure. Partial residuals are the fitted values plus the residuals. In this simple case, that equates to exactly the same as the raw observations since &lt;span class=&#34;math inline&#34;&gt;\(\text{resid}=\text{obs}−\text{fitted}\)&lt;/span&gt; and the fitted values depend only on the single predictor we are interested in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = rdata, aes(y = partial.resid),
+     color = &amp;quot;gray&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low, ymax = conf.high),
+     fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_continuous(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_post3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;effect-sizes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Effect sizes&lt;/h1&gt;
&lt;p&gt;Lets explore a range of effect sizes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Raw effect size&lt;/em&gt; between the largest and smallest &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Cohen’s D&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Percentage change&lt;/em&gt; between the largest and smallest &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Fractional change&lt;/em&gt; between the largest and smallest &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Probability&lt;/em&gt; that a change in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is associated with greater than a &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;% decline in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Clearly, in order to explore this inference, we must first express the change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; as a percentage. This in turn requires us to calculate start and end points from which to calculate the magnitude of the effect (amount of decline in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) as well as the percentage decline. Hence, we start by predicting the distribution of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at the lowest and highest values of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; newdata = data.frame(x = c(min(data$x, na.rm = TRUE), max(data$x, na.rm = TRUE)))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## Raw effect size
&amp;gt; (RES = tidyMCMC(as.mcmc(fit[, 2] - fit[, 1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     -20.9      4.24    -29.2     -12.2
&amp;gt; ## Cohen&amp;#39;s D
&amp;gt; cohenD = (fit[, 2] - fit[, 1])/mcmc[, &amp;quot;sigma&amp;quot;]
&amp;gt; (cohenDES = tidyMCMC(as.mcmc(cohenD), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     -4.19      1.14    -6.40     -1.94
&amp;gt; # Percentage change (relative to Group A)
&amp;gt; ESp = 100 * (fit[, 2] - fit[, 1])/fit[, 1]
&amp;gt; (PES = tidyMCMC(as.mcmc(ESp), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     -53.2      8.25    -69.4     -36.5
&amp;gt; # Probability that the effect is greater than 25% (a decline of &amp;gt;25%)
&amp;gt; sum(-1 * ESp &amp;gt; 25)/length(ESp)
[1] 0.9964667
&amp;gt; ## fractional change
&amp;gt; fit = fit[fit[, 2] &amp;gt; 0, ]
&amp;gt; (FES = tidyMCMC(as.mcmc(fit[, 2]/fit[, 1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.468    0.0825    0.306     0.635&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by &lt;span class=&#34;math inline&#34;&gt;\(-20.9\)&lt;/span&gt; over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between &lt;span class=&#34;math inline&#34;&gt;\(-29.2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(-12.2\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Cohen’s D associated with a change over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(-4.19\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by &lt;span class=&#34;math inline&#34;&gt;\(-53.2\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between &lt;span class=&#34;math inline&#34;&gt;\(-69.4\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(-36.5\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The probability that &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by more than &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(0.996\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by a factor of &lt;span class=&#34;math inline&#34;&gt;\(0.468\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between a factor of &lt;span class=&#34;math inline&#34;&gt;\(0.306\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(0.635\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         6.62     1.35      3.87      9.26
2 sd.resid     4.72     0.279     4.54      5.28
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         59.3      5.71     46.6      63.9
2 sd.resid     40.7      5.71     36.1      53.4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/effects_modelv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(59.3\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.649     0.106    0.433     0.758
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ x, data))

Call:
lm(formula = y ~ x, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5427 -3.3510 -0.3309  2.0411  7.5791 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.3328     2.4619  16.382 1.58e-10 ***
x            -1.3894     0.2546  -5.457 8.45e-05 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 4.695 on 14 degrees of freedom
Multiple R-squared:  0.6802,    Adjusted R-squared:  0.6574 
F-statistic: 29.78 on 1 and 14 DF,  p-value: 8.448e-05&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simple Linear Regression - STAN</title>
      <link>/stan/simple-linear-regression-stan/simple-linear-regression-stan/</link>
      <pubDate>Sun, 02 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/stan/simple-linear-regression-stan/simple-linear-regression-stan/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;STAN&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman, Lee, and Guo (2015)&lt;/span&gt;) using the package &lt;code&gt;rstan&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Stan Development Team (2018)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Many clinicians get a little twitchy and nervous around mathematical and statistical formulae and nomenclature. Whilst it is possible to perform basic statistics without too much regard for the actual equation (model) being employed, as the complexity of the analysis increases, the need to understand the underlying model becomes increasingly important. Moreover, model specification in &lt;code&gt;BUGS/JAGS/STAN&lt;/code&gt; (the language used to program Bayesian modelling) aligns very closely to the underlying formulae. Hence a good understanding of the underlying model is vital to be able to create a sensible Bayesian model. Consequently, I will always present the linear model formulae along with the analysis.&lt;/p&gt;
&lt;p&gt;To introduce the philosophical and mathematical differences between classical (frequentist) and Bayesian statistics, based on previous works, we present a provocative yet compelling trend analysis of two hypothetical populations (A vs B). The temporal trend of population A shows very little variability from a very subtle linear decline (&lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{slope}=-0.10\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{p-value}=0.048\)&lt;/span&gt;). By contrast, the B population appears to decline more dramatically, yet has substantially more variability (&lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{slope}=-10.23\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{p-value}=0.058\)&lt;/span&gt;). From a traditional frequentist perspective, we would conclude that there is a “significant” relationship in Population A (&lt;span class=&#34;math inline&#34;&gt;\(p&amp;lt;0.05\)&lt;/span&gt;), yet not in Population B (&lt;span class=&#34;math inline&#34;&gt;\(p&amp;gt;0.05\)&lt;/span&gt;). However, if we consider a third population C which is exactly the same as populstion B but with a higher number of observations, then we may end up with a completely different conclusion compared with that based on population B (&lt;span class=&#34;math inline&#34;&gt;\(n=100\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{slope}=-10.47\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{p-value}&amp;lt;0.001\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;The above illustrates a couple of things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;statistical significance does not necessarily translate into clinical importance. Indeed, population B is declining at nearly &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; times the rate of population A. That sounds rather important, yet on the basis of the hypothesis test, we would dismiss the decline in population B.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;that a p-value is just the probability of detecting an effect or relationship - what is the probability that the sample size is large enough to pick up a difference.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let us now look at it from a Bayesian perspective, with a focus on population A and B. We would conclude that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the mean (plus or minus CI) slopes for Population A and B are &lt;span class=&#34;math inline&#34;&gt;\(-0.1 (-0.21,0)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(-10.08 (-20.32,0.57)\)&lt;/span&gt; respectively&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the Bayesian approach allows us to query the posterior distribution is many other ways in order to ask sensible clinical questions. For example, we might consider that a rate of change of &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% or greater represents an important biological impact. For population A and B, the probability that the rate is &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% or greater is &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(0.85\)&lt;/span&gt; respectively.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear regression&lt;/h2&gt;
&lt;p&gt;Simple linear regression is a linear modelling process that models a continuous response against a single continuous predictor. The linear model is expressed as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_i + \epsilon_i, \;\;\; \epsilon_i \sim \text{Normal}(0,\sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; is the response variable for each of the &lt;span class=&#34;math inline&#34;&gt;\(i=1\ldots,n\)&lt;/span&gt; observations, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the intercept (value when &lt;span class=&#34;math inline&#34;&gt;\(x=0\)&lt;/span&gt;), &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is the slope (rate of change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; per unit change in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;), &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; is the predictor variable, &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_i\)&lt;/span&gt; is the residual value (difference between the observed value and the value expected by the model). The parameters of the trendline &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta=(\beta_0,\beta_1)\)&lt;/span&gt; are determined by &lt;em&gt;Ordinary Least Squares&lt;/em&gt; (OLS) in which the sum of the squared residuals is minimized. A non-zero population slope is indicative of a relationship.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Lets say we had set up an experiment in which we applied a continuous treatment (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) ranging in magnitude from &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(16\)&lt;/span&gt; to a total of &lt;span class=&#34;math inline&#34;&gt;\(16\)&lt;/span&gt; sampling units (&lt;span class=&#34;math inline&#34;&gt;\(n=16\)&lt;/span&gt;) and then measured a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) from each unit. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n &amp;lt;- 16
&amp;gt; a &amp;lt;- 40  #intercept
&amp;gt; b &amp;lt;- -1.5  #slope
&amp;gt; sigma2 &amp;lt;- 25  #residual variance (sd=5)
&amp;gt; x &amp;lt;- 1:n  #values of the year covariate
&amp;gt; eps &amp;lt;- rnorm(n, mean = 0, sd = sqrt(sigma2))  #residuals
&amp;gt; y &amp;lt;- a + b * x + eps  #response variable
&amp;gt; # OR
&amp;gt; y &amp;lt;- (model.matrix(~x) %*% c(a, b)) + eps
&amp;gt; data &amp;lt;- data.frame(y, x)  #dataset
&amp;gt; head(data)  #print out the first six rows of the data set
         y x
1 35.69762 1
2 35.84911 2
3 43.29354 3
4 34.35254 4
5 33.14644 5
6 39.57532 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the linear predictor (single continuous predictor).&lt;/p&gt;
&lt;div id=&#34;centering-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Centering the data&lt;/h2&gt;
&lt;p&gt;When a linear model contains a covariate (continuous predictor variable) in addition to another predictor (continuous or categorical), it is nearly always advisable that the continuous predictor variables are centered prior to the analysis. Centering is a process by which the mean of a variable is subtracted from each of the values such that the scale of the variable is shifted so as to be centered around &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Hence the mean of the new centered variable will be &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, yet it will retain the same variance.&lt;/p&gt;
&lt;p&gt;There are multiple reasons for this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;It provides some clinical meaning to the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept. Recall that the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is equal to zero. If &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is centered, then the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept represents the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at the mid-point of the &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; range. The &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept of an uncentered &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; typically represents a unreal value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; (as an &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; is often beyond the reasonable range of values).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In multiplicative models (in which predictors and their interactions are included), main effects and interaction terms built from centered predictors will not be correlated to one another.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For more complex models, centering the covariates can increase the likelihood that the modelling engine converges (arrives at a numerically stable and reliable outcome).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note, centering will not effect the slope estimates. In &lt;code&gt;R&lt;/code&gt;, centering is easily achieved with the &lt;code&gt;scale&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data &amp;lt;- within(data, {
+     cx &amp;lt;- as.numeric(scale(x, scale = FALSE))
+ })
&amp;gt; head(data)
         y x   cx
1 35.69762 1 -7.5
2 35.84911 2 -6.5
3 43.29354 3 -5.5
4 34.35254 4 -4.5
5 33.14644 5 -3.5
6 39.57532 6 -2.5&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Exploratory data analysis&lt;/h1&gt;
&lt;div id=&#34;normality&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Normality&lt;/h2&gt;
&lt;p&gt;Estimation and inference testing in linear regression assumes that the response is normally distributed in each of the populations. In this case, the populations are all possible measurements that could be collected at each level of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; - hence there are &lt;span class=&#34;math inline&#34;&gt;\(16\)&lt;/span&gt; populations. Typically however, we only collect a single observation from each population (as is also the case here). How then can be evaluate whether each of these populations are likely to have been normal? For a given response, the population distributions should follow much the same distribution shapes. Therefore provided the single samples from each population are unbiased representations of those populations, a boxplot of all observations should reflect the population distributions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;homogeneity-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Homogeneity of variance&lt;/h2&gt;
&lt;p&gt;Simple linear regression also assumes that each of the populations are equally varied. Actually, it is prospect of a relationship between the mean and variance of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-values across x-values that is of the greatest concern. Strictly the assumption is that the distribution of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; values at each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; value are equally varied and that there is no relationship between mean and variance. However, as we only have a single &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-value for each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;-value, it is difficult to directly determine whether the assumption of &lt;em&gt;homogeneity of variance&lt;/em&gt; is likely to have been violated (mean of one value is meaningless and variability can’t be assessed from a single value). If we then plot the residuals (difference between observed values and those predicted by the trendline) against the predict values and observe a definite presence of a pattern, then it is indicative of issues with the assumption of homogeneity of variance.&lt;/p&gt;
&lt;p&gt;Hence looking at the spread of values around a trendline on a scatterplot of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; against &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is a useful way of identifying gross violations of homogeneity of variance. Residual plots provide an even better diagnostic. The presence of a &lt;em&gt;wedge shape&lt;/em&gt; is indicative that the population mean and variance are related.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linearity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linearity&lt;/h2&gt;
&lt;p&gt;Linear regression fits a straight (linear) line through the data. Therefore, prior to fitting such a model, it is necessary to establish whether this really is the most sensible way of describing the relationship. That is, does the relationship appear to be linearly related or could some other non-linear function describe the relationship better. Scatterplots and residual plots are useful diagnostics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model assumptions&lt;/h2&gt;
&lt;p&gt;The typical assumptions which need to be checked when fitting a standard linear regression model are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All of the observations are independent - this must be addressed at the design and collection stages&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (and thus the residuals) should be normally distributed&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The relationship between the linear predictor (right hand side of the regression formula) and the link function should be linear. A scatterplot with smoother can be useful for identifying possible non-linearity.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So lets explore normality, homogeneity of variances and linearity by constructing a scatterplot of the relationship between the response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) and the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). We will also include a range of smoothers (linear and lowess) and marginal boxplots on the scatterplot to assist in exploring linearity and normality respectively.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # scatterplot
&amp;gt; library(car)
&amp;gt; scatterplot(y ~ x, data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/scatter-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;There is no evidence that the response variable is non-normal. The spread of values around the trendline seems fairly even (hence it there is no evidence of non-homogeneity). The data seems well represented by the linear trendline. Furthermore, the lowess smoother does not appear to have a consistent shift trajectory. Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Consider a non-linear linear predictor (such as a polynomial, spline or other non-linear function)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Transform the scale of the response variables (e.g. to address normality)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;Whilst Gibbs sampling provides an elegantly simple MCMC sampling routine, very complex hierarchical models can take enormous numbers of iterations (often prohibitory large) to converge on a stable posterior distribution. To address this, Andrew Gelman (and other collaborators) have implemented a variation on &lt;em&gt;Hamiltonian Monte Carlo&lt;/em&gt; (HMC): a sampler that selects subsequent samples in a way that reduces the correlation between samples, thereby speeding up convergence) called the &lt;em&gt;No-U-Turn&lt;/em&gt; (NUTS) sampler. All of these developments are brought together into a tool called &lt;em&gt;Stan&lt;/em&gt;. By design (to appeal to the vast &lt;code&gt;BUGS/JAGS&lt;/code&gt; users), &lt;code&gt;STAN&lt;/code&gt; models are defined in a manner reminiscent of &lt;code&gt;BUGS/JAGS&lt;/code&gt;. &lt;code&gt;STAN&lt;/code&gt; first converts these models into &lt;code&gt;C++&lt;/code&gt; code which is then compiled to allow very rapid computation. Consistent with this, the model must be accompanied by variable declarations for all inputs and parameters.&lt;/p&gt;
&lt;p&gt;Note the following important characteristics of a &lt;code&gt;STAN&lt;/code&gt; code:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A &lt;code&gt;STAN&lt;/code&gt; model file comprises a number of blocks (not all of which are compulsory).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;code&gt;STAN&lt;/code&gt; language is an intermediary between (&lt;code&gt;R/BUGS&lt;/code&gt; and &lt;code&gt;c++&lt;/code&gt;) and requires all types (integers, vectors, matrices etc) to be declared prior to use and it uses &lt;code&gt;c++&lt;/code&gt; commenting (&lt;code&gt;//&lt;/code&gt; and &lt;code&gt;/* */&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Code order is important, objects must be declared before they are used. When a type is declared in one block, it is available in subsequent blocks.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;
                      data {
                      // declare the input data / parameters
                      }
                      transformed data {
                      // optional - for transforming/scaling input data
                      }
                      parameters {
                      // define model parameters
                      }
                      transformed parameters {
                      // optional - for deriving additional non-model parameters
                      //            note however, as they are part of the sampling chain
                      //            transformed parameters slow sampling down.
                      }
                      model {
                      // specifying priors and likelihood as well as the linear predictor
                      }
                      generated quantities {
                      // optional - derivatives (posteriors) of the samples
                      }
            &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The minimum model in &lt;code&gt;STAN&lt;/code&gt; required to fit the above simple regression follows. Note the following modifications from the model defined in &lt;code&gt;JAGS&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The normal distribution is defined by standard deviation rather than precision&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rather than using a uniform prior for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, I am using a half-Cauchy&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We now translate the likelihood model into &lt;code&gt;STAN&lt;/code&gt; code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   data {
+   int&amp;lt;lower=0&amp;gt; n;
+   vector [n] y;
+   vector [n] x;
+   }
+   parameters {
+   real beta0;
+   real beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   model {
+   vector [n] mu;
+   #Priors
+   beta0 ~ normal(0,10000);
+   beta ~ normal(0,10000);
+   sigma ~ cauchy(0,5);
+  
+   mu = beta0+beta*x;
+   
+   #Likelihood
+   y~normal(mu,sigma);
+   }
+   
+   &amp;quot;
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString, con = &amp;quot;linregModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The No-U-Turn sampler operates much more efficiently if all predictors are centered. Although it is possible to pre-center all predictors that are passed to &lt;code&gt;STAN&lt;/code&gt;, it is then often necessary to later convert back to the original scale for graphing and further analyses. Since centering is a routine procedure, arguably it should be built into the &lt;code&gt;STAN&lt;/code&gt; we generate. Furthermore, we should also include the back-scaling as well. In this version, the data are to be supplied as a model matrix (so as to leverage various vectorized and matrix multiplier routines). The transformed data block is used to center the non-intercept columns of the predictor model matrix. The model is fit on centered data thereby generating a slope and intercept. This intercept parameter is also expressed back on the non-centered scale (generated properties block).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelStringv2 = &amp;quot;
+ data { 
+   int&amp;lt;lower=1&amp;gt; n;   // total number of observations 
+   vector[n] Y;      // response variable 
+   int&amp;lt;lower=1&amp;gt; nX;  // number of effects 
+   matrix[n, nX] X;   // model matrix 
+   } 
+   transformed data { 
+   matrix[n, nX - 1] Xc;  // centered version of X 
+   vector[nX - 1] means_X;  // column means of X before centering 
+   
+   for (i in 2:nX) { 
+   means_X[i - 1] = mean(X[, i]); 
+   Xc[, i - 1] = X[, i] - means_X[i - 1]; 
+   } 
+   }  
+   parameters { 
+   vector[nX-1] beta;  // population-level effects 
+   real cbeta0;  // center-scale intercept 
+   real&amp;lt;lower=0&amp;gt; sigma;  // residual SD 
+   } 
+   transformed parameters { 
+   } 
+   model { 
+   vector[n] mu; 
+   mu = Xc * beta + cbeta0; 
+   // prior specifications 
+   beta ~ normal(0, 100); 
+   cbeta0 ~ normal(0, 100); 
+   sigma ~ cauchy(0, 5); 
+   // likelihood contribution 
+   Y ~ normal(mu, sigma); 
+   } 
+   generated quantities { 
+   real beta0;  // population-level intercept 
+   beta0 = cbeta0 - dot_product(means_X, beta); 
+   }
+   
+   &amp;quot;
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelStringv2, con = &amp;quot;linregModelv2.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~x, data = data)
&amp;gt; data.list &amp;lt;- with(data, list(Y = y, X = Xmat, nX = ncol(Xmat), n = nrow(data)))
&amp;gt; data.list
$Y
 [1] 35.69762 35.84911 43.29354 34.35254 33.14644 39.57532 31.80458 21.67469
 [9] 23.06574 22.77169 29.62041 23.79907 22.50386 19.55341 14.72079 24.93457

$X
   (Intercept)  x
1            1  1
2            1  2
3            1  3
4            1  4
5            1  5
6            1  6
7            1  7
8            1  8
9            1  9
10           1 10
11           1 11
12           1 12
13           1 13
14           1 14
15           1 15
16           1 16
attr(,&amp;quot;assign&amp;quot;)
[1] 0 1

$nX
[1] 2

$n
[1] 16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the initial values for the chain. Reasonable starting points can be gleaned from the data themselves.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; inits &amp;lt;- rep(list(list(beta0 = mean(data$y), beta1 = diff(tapply(data$y,
+     data$x, mean)), sigma = sd(data$y))), 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;beta0&amp;quot;, &amp;quot;cbeta0&amp;quot;, &amp;quot;sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; nChains = 2
&amp;gt; burnInSteps = 1000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 3000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 2500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;STAN&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;rstan&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When using the &lt;code&gt;stan&lt;/code&gt; function (&lt;code&gt;rstan&lt;/code&gt; package), it is not necessary to provide initial values. However, if they are to be supplied, the inital values must be provided as a list of the same length as the number of chains.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rstan &amp;lt;- stan(data = data.list, file = &amp;quot;linregModelv2.stan&amp;quot;, 
+     chains = nChains, iter = nIter, warmup = burnInSteps,
+     thin = thinSteps, save_dso = TRUE)

SAMPLING FOR MODEL &amp;#39;linregModelv2&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2500 [  0%]  (Warmup)
Chain 1: Iteration:  250 / 2500 [ 10%]  (Warmup)
Chain 1: Iteration:  500 / 2500 [ 20%]  (Warmup)
Chain 1: Iteration:  750 / 2500 [ 30%]  (Warmup)
Chain 1: Iteration: 1000 / 2500 [ 40%]  (Warmup)
Chain 1: Iteration: 1001 / 2500 [ 40%]  (Sampling)
Chain 1: Iteration: 1250 / 2500 [ 50%]  (Sampling)
Chain 1: Iteration: 1500 / 2500 [ 60%]  (Sampling)
Chain 1: Iteration: 1750 / 2500 [ 70%]  (Sampling)
Chain 1: Iteration: 2000 / 2500 [ 80%]  (Sampling)
Chain 1: Iteration: 2250 / 2500 [ 90%]  (Sampling)
Chain 1: Iteration: 2500 / 2500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.027 seconds (Warm-up)
Chain 1:                0.035 seconds (Sampling)
Chain 1:                0.062 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;linregModelv2&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2500 [  0%]  (Warmup)
Chain 2: Iteration:  250 / 2500 [ 10%]  (Warmup)
Chain 2: Iteration:  500 / 2500 [ 20%]  (Warmup)
Chain 2: Iteration:  750 / 2500 [ 30%]  (Warmup)
Chain 2: Iteration: 1000 / 2500 [ 40%]  (Warmup)
Chain 2: Iteration: 1001 / 2500 [ 40%]  (Sampling)
Chain 2: Iteration: 1250 / 2500 [ 50%]  (Sampling)
Chain 2: Iteration: 1500 / 2500 [ 60%]  (Sampling)
Chain 2: Iteration: 1750 / 2500 [ 70%]  (Sampling)
Chain 2: Iteration: 2000 / 2500 [ 80%]  (Sampling)
Chain 2: Iteration: 2250 / 2500 [ 90%]  (Sampling)
Chain 2: Iteration: 2500 / 2500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.028 seconds (Warm-up)
Chain 2:                0.034 seconds (Sampling)
Chain 2:                0.062 seconds (Total)
Chain 2: &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; s = as.array(data.rstan)
&amp;gt; mcmc &amp;lt;- do.call(mcmc.list, plyr:::alply(s[, , -(length(s[1, 1, ]))], 2, as.mcmc))
&amp;gt; denplot(mcmc, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;,&amp;quot;cbeta0&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(mcmc, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;,&amp;quot;cbeta0&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space. We can also look at just the density plot computed from the &lt;code&gt;bayesplot&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_dens(as.array(data.rstan))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/mcmc_diag2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Density plots sugggest mean or median would be appropriate to describe the fixed posteriors and median is appropriate for the &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; posterior.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model.&lt;/p&gt;
&lt;p&gt;Although residuals can be computed directly within &lt;code&gt;rstan&lt;/code&gt;, we can calculate them manually from the posteriors to be consistent across other approaches.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(ggplot2)
&amp;gt; mcmc = as.matrix(data.rstan)[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = data$x))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentized residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentized residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i, ], mcmc[i,
+     &amp;quot;sigma&amp;quot;]))
&amp;gt; ggplot() + geom_density(data = NULL, aes(x = as.vector(yRep), fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_density(data = data, aes(x = y, fill = &amp;quot;Obs&amp;quot;),
+     alpha = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; summary(data.rstan)
$summary
              mean     se_mean        sd       2.5%        25%        50%
beta[1]  -1.386241 0.005409925 0.2628701  -1.928032  -1.556143  -1.390692
cbeta0   28.526455 0.025241285 1.2563021  26.053580  27.679148  28.517154
sigma     4.938850 0.022620333 0.9747690   3.433777   4.255653   4.800261
beta0    40.309502 0.051054981 2.5104697  35.305689  38.660487  40.321813
lp__    -32.392865 0.038016453 1.2930877 -35.617366 -32.976932 -32.063282
               75%       97.5%    n_eff      Rhat
beta[1]  -1.216324  -0.8695824 2361.021 1.0010917
cbeta0   29.358476  31.0250363 2477.224 1.0000293
sigma     5.472441   7.1969472 1856.972 1.0020160
beta0    41.901624  45.2722391 2417.874 0.9999759
lp__    -31.431890 -30.9164925 1156.945 1.0014468

$c_summary
, , chains = chain:1

         stats
parameter       mean        sd       2.5%        25%        50%        75%
  beta[1]  -1.395354 0.2663176  -1.938168  -1.570786  -1.397259  -1.224694
  cbeta0   28.499907 1.2671111  25.965301  27.665662  28.499904  29.339459
  sigma     4.974297 1.0354718   3.403207   4.248213   4.814835   5.545663
  beta0    40.360414 2.4961956  35.294178  38.744797  40.418903  41.921210
  lp__    -32.448925 1.3633114 -35.893989 -33.121738 -32.073215 -31.438407
         stats
parameter       97.5%
  beta[1]  -0.8701744
  cbeta0   31.0552336
  sigma     7.3827875
  beta0    45.2489270
  lp__    -30.9157752

, , chains = chain:2

         stats
parameter       mean        sd       2.5%        25%        50%        75%
  beta[1]  -1.377128 0.2591452  -1.911379  -1.544377  -1.385973  -1.203797
  cbeta0   28.553004 1.2452556  26.163699  27.717229  28.540569  29.378535
  sigma     4.903404 0.9089921   3.457094   4.261745   4.785809   5.423194
  beta0    40.258590 2.5244684  35.319104  38.595264  40.250020  41.864964
  lp__    -32.336805 1.2167003 -35.405972 -32.883087 -32.042686 -31.424106
         stats
parameter       97.5%
  beta[1]  -0.8699495
  cbeta0   31.0050930
  sigma     7.0778361
  beta0    45.2803661
  lp__    -30.9173256
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(data.rstan, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;, rhat = TRUE, ess = TRUE)
# A tibble: 4 x 7
  term    estimate std.error conf.low conf.high  rhat   ess
  &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
1 beta[1]    -1.39     0.263    -1.90    -0.856 1.00   2361
2 cbeta0     28.5      1.26     26.2     31.1   1.00   2477
3 sigma       4.94     0.975     3.31     6.96  1.00   1857
4 beta0      40.3      2.51     35.3     45.2   1.000  2418&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A one unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(-1.39\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; declines at a rate of &lt;span class=&#34;math inline&#34;&gt;\(-1.39\)&lt;/span&gt; per unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the slope does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;p&gt;Also note that since our &lt;code&gt;STAN&lt;/code&gt; model incorporated predictor centering, we have estimates of the intercept based on both centered (&lt;code&gt;cbeta0&lt;/code&gt;) and uncentered data (&lt;code&gt;beta0&lt;/code&gt;). Since the intercept from uncentered data is beyond the domain of our sampling data it has very little interpretability. However, the intercept based on centered data can be interpreted as the estimate of the response at the mean predictor (in this case &lt;span class=&#34;math inline&#34;&gt;\(28.5\)&lt;/span&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }
&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, c(&amp;quot;beta[1]&amp;quot;)])
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of essentially &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, we would conclude that there is almost no evidence that the slope was likely to be equal to zero, suggesting there is a relationship.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group. We do this by loading functions in the package &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = data.frame(x = seq(min(data$x, na.rm = TRUE), max(data$x, na.rm = TRUE),
+     len = 1000))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you wanted to represent sample data on the figure in such a simple example (single predictor) we could simply over- (or under-) lay the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = data, aes(y = y,
+     x = x), color = &amp;quot;gray&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A more general solution would be to add the partial residuals to the figure. Partial residuals are the fitted values plus the residuals. In this simple case, that equates to exactly the same as the raw observations since &lt;span class=&#34;math inline&#34;&gt;\(\text{resid}=\text{obs}−\text{fitted}\)&lt;/span&gt; and the fitted values depend only on the single predictor we are interested in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = rdata, aes(y = partial.resid),
+     color = &amp;quot;gray&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low, ymax = conf.high),
+     fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_continuous(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/mcmc_post3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;effect-sizes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Effect sizes&lt;/h1&gt;
&lt;p&gt;Lets explore a range of effect sizes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Raw effect size&lt;/em&gt; between the largest and smallest &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Cohen’s D&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Percentage change&lt;/em&gt; between the largest and smallest &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Fractional change&lt;/em&gt; between the largest and smallest &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Probability&lt;/em&gt; that a change in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is associated with greater than a &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;% decline in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Clearly, in order to explore this inference, we must first express the change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; as a percentage. This in turn requires us to calculate start and end points from which to calculate the magnitude of the effect (amount of decline in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) as well as the percentage decline. Hence, we start by predicting the distribution of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at the lowest and highest values of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; newdata = data.frame(x = c(min(data$x, na.rm = TRUE), max(data$x, na.rm = TRUE)))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## Raw effect size
&amp;gt; (RES = tidyMCMC(as.mcmc(fit[, 2] - fit[, 1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     -20.8      3.94    -28.5     -12.8
&amp;gt; ## Cohen&amp;#39;s D
&amp;gt; cohenD = (fit[, 2] - fit[, 1])/mcmc[, &amp;quot;sigma&amp;quot;]
&amp;gt; (cohenDES = tidyMCMC(as.mcmc(cohenD), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     -4.37      1.14    -6.68     -2.27
&amp;gt; # Percentage change (relative to Group A)
&amp;gt; ESp = 100 * (fit[, 2] - fit[, 1])/fit[, 1]
&amp;gt; (PES = tidyMCMC(as.mcmc(ESp), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     -53.1      7.81    -68.5     -37.5
&amp;gt; # Probability that the effect is greater than 25% (a decline of &amp;gt;25%)
&amp;gt; sum(-1 * ESp &amp;gt; 25)/length(ESp)
[1] 0.998
&amp;gt; ## fractional change
&amp;gt; fit = fit[fit[, 2] &amp;gt; 0, ]
&amp;gt; (FES = tidyMCMC(as.mcmc(fit[, 2]/fit[, 1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.469    0.0781    0.315     0.625&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by &lt;span class=&#34;math inline&#34;&gt;\(-20.8\)&lt;/span&gt; over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between &lt;span class=&#34;math inline&#34;&gt;\(-28.5\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(-12.8\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Cohen’s D associated with a change over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(-4.37\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by &lt;span class=&#34;math inline&#34;&gt;\(-53.1\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between &lt;span class=&#34;math inline&#34;&gt;\(-68.5\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(-37.5\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The probability that &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by more than &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(0.998\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by a factor of &lt;span class=&#34;math inline&#34;&gt;\(0.469\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between a factor of &lt;span class=&#34;math inline&#34;&gt;\(0.315\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(0.625\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         6.60     1.25      4.07      9.04
2 sd.resid     4.70     0.243     4.54      5.18
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         59.3      5.30     47.8      63.9
2 sd.resid     40.7      5.30     36.1      52.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/simple-linear-regression-stan/2020-02-01-simple-linear-regression-stan_files/figure-html/effects_modelv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(59.3\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- as.matrix(data.rstan)
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.652    0.0982    0.456     0.758
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ x, data))

Call:
lm(formula = y ~ x, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5427 -3.3510 -0.3309  2.0411  7.5791 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.3328     2.4619  16.382 1.58e-10 ***
x            -1.3894     0.2546  -5.457 8.45e-05 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 4.695 on 14 degrees of freedom
Multiple R-squared:  0.6802,    Adjusted R-squared:  0.6574 
F-statistic: 29.78 on 1 and 14 DF,  p-value: 8.448e-05&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2015stan&#34;&gt;
&lt;p&gt;Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt; 40 (5): 530–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanpackage&#34;&gt;
&lt;p&gt;Stan Development Team. 2018. “RStan: The R Interface to Stan.” &lt;a href=&#34;http://mc-stan.org/&#34;&gt;http://mc-stan.org/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Comparing Two Populations - JAGS</title>
      <link>/jags/comparing-two-populations-jags/comparing-two-populations-jags/</link>
      <pubDate>Sat, 01 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/comparing-two-populations-jags/comparing-two-populations-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to explore differences between two populations. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of R, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;BUGS/JAGS/STAN&lt;/code&gt; languages and algorithms are very powerful and flexible. However, the cost of this power and flexibility is complexity and the need for a firm understanding of the model you wish to fit as well as the priors to be used. The algorithms requires the following inputs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Within the model:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The likelihood function relating the response to the predictors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The definition of the priors.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Chain properties:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The number of chains.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The length of chains (number of iterations).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The burn-in length (number of initial iterations to ignore).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The thinning rate (number of iterations to count on before storing a sample).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The initial estimates to start an MCMC chain. If there are multiple chains, these starting values can differ between chains.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The list of model parameters and derivatives to monitor (and return the posterior distributions of)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;We will start by generating a random data set. Note, I am creating two versions of the predictor variable (a numeric version and a factorial version).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; nA &amp;lt;- 60  #sample size from Population A
&amp;gt; nB &amp;lt;- 40  #sample size from Population B
&amp;gt; muA &amp;lt;- 105  #population mean of Population A
&amp;gt; muB &amp;lt;- 77.5  #population mean of Population B
&amp;gt; sigma &amp;lt;- 3  #standard deviation of both populations (equally varied)
&amp;gt; yA &amp;lt;- rnorm(nA, muA, sigma)  #Population A sample
&amp;gt; yB &amp;lt;- rnorm(nB, muB, sigma)  #Population B sample
&amp;gt; y &amp;lt;- c(yA, yB)
&amp;gt; x &amp;lt;- factor(rep(c(&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;), c(nA, nB)))  #categorical listing of the populations
&amp;gt; xn &amp;lt;- as.numeric(x)  #numerical version of the population category for means parameterization. # Should not start at 0.
&amp;gt; data &amp;lt;- data.frame(y, x, xn)  # dataset&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let inspect the first few rows of the dataset using the command &lt;code&gt;head&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; head(data)
         y x xn
1 103.3186 A  1
2 104.3095 A  1
3 109.6761 A  1
4 105.2115 A  1
5 105.3879 A  1
6 110.1452 A  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also perform some exploratory data analysis - in this case, a boxplot of the response for each level of the predictor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ x, data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/boxplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-one-sample-t-test&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The One Sample t-test&lt;/h1&gt;
&lt;p&gt;A &lt;em&gt;t-test&lt;/em&gt; is essentially just a simple regression model in which the categorical predictor is represented by a binary variable in which one level is coded as &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and the other &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;. For the model itself, the observed response &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; are assumed to be drawn from a normal distribution with a given mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. The expected values are themselves determined by the linear predictor &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0+\beta_1x_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the mean of the first treatment group and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; represents the difference between the mean of the first group and the mean of the second group (the effect of interest).&lt;/p&gt;
&lt;p&gt;MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying “uninformative” priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(1000\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (scale=&lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;) for the standard deviation (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim \text{Normal}(\mu_i, \sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0+\beta_1x_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Priors are defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim \text{Normal}(0,1000),  \;\;\; \text{and} \;\;\; \sigma \sim \text{Cauchy}(0,25),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for &lt;span class=&#34;math inline&#34;&gt;\(j=0,1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;fitting-the-model-in-jags&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fitting the model in JAGS&lt;/h2&gt;
&lt;p&gt;Broadly, there are two ways of parameterising (expressing the unknown (to be estimated) components of a model) a model. Either we can estimate the means of each group (&lt;em&gt;Means parameterisation&lt;/em&gt;) or we can estimate the mean of one group and the difference between this group and the other group(s) (&lt;em&gt;Effects parameterisation&lt;/em&gt;). The latter is commonly used for frequentist null hypothesis testing as its parameters are more consistent with the null hypothesis of interest (that the difference between the two groups equals zero).&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Effects parameterisation&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_{j}x_i + \epsilon_i, \;\;\; \text{with} \;\;\; \epsilon_i \sim \text{Normal}(0,\sigma).  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Each &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; is modelled by an intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; (mean of group A) plus a difference parameter &lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt; (difference between mean of group A and group B) multiplied by an indicator of which group the observation came from (&lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;), plus a residual drawn from a normal distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Actually, there are as many &lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt; parameters as there are groups but one of them (typically the first) is set to be equal to zero (to avoid over-parameterization). Expected values of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; are modelled assuming they are drawn from a normal distribution whose mean is determined by a linear combination of effect parameters and whose variance is defined by the degree of variability in this mean. The parameters are: &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Means parameterisation&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_{j} + \epsilon_i, \;\;\; \text{with} \;\;\; \epsilon_i \sim \text{Normal}(0,\sigma).  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Each &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; is modelled as the mean &lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt; of each group (&lt;span class=&#34;math inline&#34;&gt;\(j=1,2\)&lt;/span&gt;) plus a residual drawn from a normal distribution with a mean of zero and a standard deviation of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Actually, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; is a set of &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; coefficients corresponding to the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; dummy coded factor levels. Expected values of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; are modelled assuming they are drawn from a normal distribution whose mean is determined by a linear combination of means parameters and whose variance is defined by the degree of variability in this mean. The parameters are: &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;JAGS&lt;/code&gt;, distributions are defined by their precision &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than their standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Precision is just the inverse of variance (&lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;) and are chosen as they permit the gamma distribution to be used as the conjugate prior of the variance of a normal distribution. Bayesian analyses require that priors are specified for all the parameters. We will define vague (non-informative) priors for each of the parameters such that the posterior distributions are almost entirely influenced by the likelihood (and thus the data). Hence, appropriate (conjugate) priors for the effects parameterisation could be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta \sim \text{Normal}(0,1.0\text{E-}6)\)&lt;/span&gt; - a very flat normal distribution centered around zero. Note, &lt;span class=&#34;math inline&#34;&gt;\(1.0\text{E-}6\)&lt;/span&gt; is scientific notation for &lt;span class=&#34;math inline&#34;&gt;\(0.000001\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\tau \sim \text{Gamma}(0.1,0.1)\)&lt;/span&gt; a vague gamma distribution with a shape parameter close to zero (must be greater than &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;JAGS&lt;/code&gt; language very closely matches the above model and prior definitions - hence the importance on understanding the model you wish to fit. The &lt;code&gt;JAGS&lt;/code&gt; language resembles &lt;code&gt;R&lt;/code&gt; in many respects. It basically consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;stochastic nodes - those that appear on the left hand side of &lt;span class=&#34;math inline&#34;&gt;\(\sim\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;deterministic nodes - those that appear on the left hand side of &lt;code&gt;&amp;lt;-&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;-like for loops and functions to transform and summarise the data&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That said, &lt;code&gt;JAGS&lt;/code&gt; is based on a declarative language, which means: the order with which statements appear in the model definition are not important; nodes should not be defined more than once (you cannot change a value).We are now in a good position to define the model (Likelihood function and prior distributions).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Effects Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;  
+  model {
+   #Likelihood
+   for (i in 1:n) {
+     y[i]~dnorm(mu[i],tau)
+     mu[i] &amp;lt;- beta0+beta[x[i]]
+   }
+  
+   #Priors
+   beta0 ~ dnorm(0,1.0E-06)
+   beta[1] &amp;lt;- 0
+   beta[2] ~ dnorm(0,1.0E-06)
+   tau ~ dgamma(0.1,0.1)
+   sigma&amp;lt;-1/sqrt(tau)
+ 
+   #Other Derived parameters 
+   # Group means (note, beta is a vector)
+   Group.means &amp;lt;-beta0+beta  
+  }
+  &amp;quot;
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;ttestModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Means Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString.means = &amp;quot;  
+   model {
+    #Likelihood 
+    for (i in 1:n) {
+      y[i]~dnorm(mu[i],tau)
+      mu[i] &amp;lt;- beta[x[i]]
+    }
+  
+    #Priors
+    for (j in min(x):max(x)) {
+      beta[j] ~ dnorm(0,0.001)
+    }
+  
+    tau~dgamma(0.1,0.1)
+    sigma&amp;lt;-1/sqrt(tau)
+  
+    #Other Derived parameters 
+    effect &amp;lt;-beta[2]-beta[1]
+  }
+  &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString.means, con = &amp;quot;ttestModelMeans.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). Note, all variables must be numeric, therefore we use the numeric version of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Furthermore, the first level must be &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.list &amp;lt;- with(data, list(y = y, x = xn, n = nrow(data)))
&amp;gt; data.list.means &amp;lt;- with(data, list(y = y, x = xn, n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the initial values for the chain. Reasonable starting points can be gleaned from the data themselves.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; inits &amp;lt;- list(beta0 = mean(data$y), beta = c(NA, diff(tapply(data$y,
+     data$x, mean))), sigma = sd(data$y/2))
&amp;gt; inits.means &amp;lt;- list(beta = tapply(data$y, data$x, mean), sigma = sd(data$y/2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;Group.means&amp;quot;)
&amp;gt; params.means &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;effect&amp;quot;, &amp;quot;sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; adaptSteps = 1000  # the number of steps over which to establish a good stepping distance
&amp;gt; burnInSteps = 2000  # the number of initial samples to discard
&amp;gt; nChains = 2  # the number of independed sampling chains to perform 
&amp;gt; numSavedSteps = 50000  # the total number of samples to store
&amp;gt; thinSteps = 1  # the thinning rate
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When using the &lt;code&gt;jags&lt;/code&gt; function (&lt;code&gt;R2jags&lt;/code&gt; package), it is not necessary to provide initial values. However, if they are to be supplied, the inital values must be provided as a list of the same length as the number of chains.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Effects Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data=data.list,
+ inits=NULL, #or inits=list(inits,inits) # since there are two chains
+ parameters.to.save=params,
+ model.file=&amp;quot;ttestModel.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 3
   Total graph size: 214

Initializing model
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
               mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat
Group.means[1] 105.200   0.357 104.497 104.959 105.201 105.441 105.900 1.001
Group.means[2]  77.882   0.438  77.018  77.589  77.882  78.174  78.746 1.001
beta[1]          0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000
beta[2]        -27.318   0.563 -28.426 -27.696 -27.315 -26.943 -26.212 1.001
beta0          105.200   0.357 104.497 104.959 105.201 105.441 105.900 1.001
sigma            2.771   0.202   2.408   2.630   2.759   2.900   3.198 1.001
deviance       487.192   2.485 484.376 485.370 486.547 488.331 493.506 1.001
               n.eff
Group.means[1] 46000
Group.means[2] 15000
beta[1]            1
beta[2]        35000
beta0          46000
sigma          46000
deviance       46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.1 and DIC = 490.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Means Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags.means &amp;lt;- jags(data=data.list.means,
+ inits=NULL, #or inits=list(inits.means,inits.means) # since there are two chains
+ parameters.to.save=params.means,
+ model.file=&amp;quot;ttestModelMeans.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 3
   Total graph size: 211

Initializing model
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.r2jags.means)
Inference for Bugs model at &amp;quot;ttestModelMeans.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]  105.184   0.357 104.481 104.947 105.184 105.423 105.884 1.001 46000
beta[2]   77.867   0.439  77.001  77.575  77.866  78.160  78.736 1.001 39000
effect   -27.317   0.566 -28.433 -27.696 -27.317 -26.940 -26.197 1.001 46000
sigma      2.768   0.201   2.408   2.626   2.755   2.897   3.192 1.001 34000
deviance 487.195   2.498 484.360 485.377 486.540 488.323 493.721 1.001 46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.1 and DIC = 490.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If &lt;code&gt;inits=NULL&lt;/code&gt; the &lt;code&gt;jags&lt;/code&gt; function will generate vaguely sensible initial values for each chain based on the data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In addition to the mean and quantiles of each of the sample nodes, the &lt;code&gt;jags&lt;/code&gt; function will calculate.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The &lt;em&gt;effective sample size&lt;/em&gt; for each sample - if &lt;code&gt;n.eff&lt;/code&gt; for a node is substantially less than the number of iterations, then it suggests poor mixing.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;em&gt;Potential scale reduction factor&lt;/em&gt; or &lt;code&gt;Rhat&lt;/code&gt; values for each sample - these are a convergence diagnostic (values of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; indicate full convergence, values greater than &lt;span class=&#34;math inline&#34;&gt;\(1.01\)&lt;/span&gt; are indicative of non-convergence.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;An &lt;em&gt;information criteria&lt;/em&gt; (DIC) for model selection.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The total number samples collected is &lt;span class=&#34;math inline&#34;&gt;\(46000\)&lt;/span&gt;. That is, there are &lt;span class=&#34;math inline&#34;&gt;\(46000\)&lt;/span&gt; samples collected from the multidimensional posterior distribution and thus, &lt;span class=&#34;math inline&#34;&gt;\(46000\)&lt;/span&gt; samples collected from the posterior distributions of each parameter. The effective number of samples column indicates the number of independent samples represented in the total. It is clear that for all parameters the chains were well mixed.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta[2]&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta[2]&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model.&lt;/p&gt;
&lt;p&gt;Residuals are not computed directly within &lt;code&gt;R2jags&lt;/code&gt;. However, we can calculate them manually form the posteriors and plot them using the package &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(ggplot2)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is no evidence that the mcmc chain did not converge on a stable posterior distribution. We are now in a position to examine the summaries of the parameters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 7 x 5
  term           estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 Group.means[1]   105.       0.357   105.      106.  
2 Group.means[2]    77.9      0.438    77.0      78.7 
3 beta[1]            0        0         0         0   
4 beta[2]          -27.3      0.563   -28.4     -26.2 
5 beta0            105.       0.357   105.      106.  
6 deviance         487.       2.49    484.      492.  
7 sigma              2.77     0.202     2.39      3.17&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Group A is typically &lt;span class=&#34;math inline&#34;&gt;\(27.3\)&lt;/span&gt; units greater than Group B. The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the difference between Group A and B does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between the two groups.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group. We do this by loading functions in the package &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = data.frame(x = levels(data$x))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you wanted to represent sample data on the figure in such a simple example (single predictor) we could simply over- (or under-) lay the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = data, aes(y = y,
+     x = x), color = &amp;quot;gray&amp;quot;) + geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
+     scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A more general solution would be to add the partial residuals to the figure. Partial residuals are the fitted values plus the residuals. In this simple case, that equates to exactly the same as the raw observations since &lt;span class=&#34;math inline&#34;&gt;\(\text{resid}=\text{obs}−\text{fitted}\)&lt;/span&gt; and the fitted values depend only on the single predictor we are interested in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = rdata, aes(y = partial.resid),
+     color = &amp;quot;gray&amp;quot;) + geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
+     scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_post3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;effect-sizes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Effect sizes&lt;/h1&gt;
&lt;p&gt;In addition to deriving the distribution means for the second group, we could make use of the Bayesian framework to derive the distribution of the effect size. There are multiple ways of calculating an effect size, but the most common are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Raw effect size&lt;/em&gt; - the difference between two groups (as already calculated)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Cohen’s D&lt;/em&gt; - the effect size standardised by division with the pooled standard deviation&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Percent&lt;/em&gt; - the effect size expressed as a percent of the reference group mean&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Calculating the percent effect size involves division by an estimate of &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;. The very first sample collected of each parameter (including &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;) is based on the initial values supplied. If &lt;code&gt;inits=NULL&lt;/code&gt; the &lt;code&gt;jags&lt;/code&gt; function appears to generate initial values from the priors. Recall that in the previous model definition, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; was deemed to be distributed as a normal distribution with a mean of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Hence, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; would initially be assigned a value of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Division by zero is of course illegal and thus an error would be thrown. There are two ways to overcome this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Modify the prior such that it has a mean close to zero (and thus the first &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; sample is not zero), yet not actually zero (such as &lt;span class=&#34;math inline&#34;&gt;\(0.0001\)&lt;/span&gt;). This is the method used here.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Define initial values that are based on the observed data (and not zero).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; paramsv2 &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;Group.means&amp;quot;, &amp;quot;cohenD&amp;quot;, &amp;quot;ES&amp;quot;, &amp;quot;p10&amp;quot;)
&amp;gt; data.r2jagsv2 &amp;lt;- jags(data=data.list,
+ inits=NULL, #or inits=list(inits,inits) # since there are two chains
+ parameters.to.save=paramsv2,
+ model.file=&amp;quot;ttestModelv2.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 3
   Total graph size: 224

Initializing model
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.r2jagsv2)
Inference for Bugs model at &amp;quot;ttestModelv2.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
               mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat
ES             -25.965   0.488 -26.918 -26.294 -25.967 -25.637 -24.992 1.001
Group.means[1] 105.197   0.358 104.495 104.957 105.199 105.437 105.900 1.001
Group.means[2]  77.881   0.439  77.020  77.586  77.882  78.174  78.748 1.001
beta[1]          0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000
beta[2]        -27.316   0.567 -28.428 -27.696 -27.317 -26.934 -26.191 1.001
beta0          105.197   0.358 104.495 104.957 105.199 105.437 105.900 1.001
cohenD          -9.914   0.736 -11.390 -10.402  -9.905  -9.413  -8.503 1.001
p10              1.000   0.000   1.000   1.000   1.000   1.000   1.000 1.000
sigma            2.770   0.199   2.413   2.631   2.758   2.897   3.190 1.001
deviance       487.184   2.473 484.372 485.370 486.546 488.317 493.572 1.001
               n.eff
ES             46000
Group.means[1] 46000
Group.means[2] 46000
beta[1]            1
beta[2]        46000
beta0          46000
cohenD         46000
p10                1
sigma          46000
deviance       46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.1 and DIC = 490.2
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Cohen’s D value is &lt;span class=&#34;math inline&#34;&gt;\(-9.91\)&lt;/span&gt;. This value is far greater than the nominal “large effect” guidelines outlined by Cohen and thus we might proclaim the treatment as having a large negative effect. The effect size expressed as a percentage of the Group A mean is &lt;span class=&#34;math inline&#34;&gt;\(-27.3\)&lt;/span&gt;. Hence the treatment was associated with a &lt;span class=&#34;math inline&#34;&gt;\(27.3\)&lt;/span&gt;% reduction.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;probability-statements&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Probability statements&lt;/h1&gt;
&lt;p&gt;Bayesian statistics provide a natural means to generate probability statements. For example, we could calculate the probability that there is an effect of the treatment. Moreover, we could calculate the probability that the treatment effect exceeds some threshold (which might be based on a measure of clinically important difference or other compliance guidelines for example).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jagsv2$BUGSoutput$sims.matrix
&amp;gt; # Percentage change (relative to Group A)
&amp;gt; ES = 100 * mcmc[, &amp;quot;beta[2]&amp;quot;]/mcmc[, &amp;quot;beta0&amp;quot;]
&amp;gt; hist(ES)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/prob_stat-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; # Probability that the effect is greater than 10% (a decline of &amp;gt;10%)
&amp;gt; sum(-1 * ES &amp;gt; 10)/length(ES)
[1] 1
&amp;gt; # Probability that the effect is greater than 25% (a decline of &amp;gt;25%)
&amp;gt; sum(-1 * ES &amp;gt; 25)/length(ES)
[1] 0.9741304&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have defined two additional probability derivatives, both of which utilize the step function (which generates a binary vector based on whether values evaluate less than zero or not).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P0 - the probability (mean of 1-step()) that the raw effect is greater than zero.&lt;/li&gt;
&lt;li&gt;P25 - the probability (mean of 1-step()) that the percent effect size is greater than &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; paramsv3 &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;Group.means&amp;quot;, &amp;quot;cohenD&amp;quot;, &amp;quot;ES&amp;quot;, &amp;quot;P0&amp;quot;, &amp;quot;P25&amp;quot;)
&amp;gt; data.r2jagsv3 &amp;lt;- jags(data=data.list,
+ inits=NULL, #or inits=list(inits,inits) # since there are two chains
+ parameters.to.save=paramsv3,
+ model.file=&amp;quot;ttestModelv3.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 3
   Total graph size: 225

Initializing model
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.r2jagsv3)
Inference for Bugs model at &amp;quot;ttestModelv3.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
               mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat
ES             -25.964   0.489 -26.920 -26.293 -25.965 -25.637 -24.999 1.001
Group.means[1] 105.197   0.359 104.485 104.959 105.196 105.435 105.897 1.001
Group.means[2]  77.882   0.441  77.022  77.585  77.881  78.178  78.748 1.001
P0               1.000   0.000   1.000   1.000   1.000   1.000   1.000 1.000
P25              0.975   0.156   0.000   1.000   1.000   1.000   1.000 1.001
beta[1]          0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000
beta[2]        -27.315   0.568 -28.427 -27.696 -27.314 -26.935 -26.195 1.001
beta0          105.197   0.359 104.485 104.959 105.196 105.435 105.897 1.001
cohenD          -9.912   0.740 -11.385 -10.405  -9.903  -9.412  -8.477 1.001
sigma            2.770   0.200   2.411   2.631   2.758   2.896   3.198 1.001
deviance       487.202   2.492 484.364 485.378 486.557 488.334 493.696 1.001
               n.eff
ES             46000
Group.means[1] 46000
Group.means[2] 46000
P0                 1
P25            46000
beta[1]            1
beta[2]        46000
beta0          46000
cohenD         37000
sigma          27000
deviance       46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.1 and DIC = 490.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;It is often useful to be able to estimate the relative amount of variability associated with each predictor (or term) in a model. This can provide a sort of relative importance measure for each predictor.&lt;/p&gt;
&lt;p&gt;In frequentist statistics, such measures are only available for so called random factors (factors whose observational levels are randomly selected to represent all possible levels rather than to represent specific treatment levels). For such random factors, the collective variances (or standard deviation) of each factor are known as the variance components. Each component can also be expressed as a percentage of the total so as to provide a percentage breakdown of the relative contributions of each scale of sampling. Frequentist approaches model random factors according to the variance they add to the model, whereas fixed factors are modelled according to their effects (deviations from reference means). The model does not seek to generalise beyond the observed levels of a given fixed factor (such as control vs treatment) and thus it apparently does not make sense to estimate the population variability between levels (which is what variance components estimate).&lt;/p&gt;
&lt;p&gt;The notion of “fixed” and “random” factors is somewhat arbitrary and does not really have any meaning within a Bayesian context (as all parameters and thus factors are considered random). Instead, the spirit of what many consider is that the difference between fixed and random factors can be captured by conceptualising whether the levels of a factor are drawn from a &lt;em&gt;finite population&lt;/em&gt; (from which the observed factor levels are the only ones possible) or a &lt;em&gt;superpopulation&lt;/em&gt; (from which the observed factor levels are just a random selection of the infinite possible levels possible). Hence, variance components could be defined in terms of either finite population or superpopulation standard deviations. Superpopulation standard deviations have traditionally been used to describe the relative scale of sampling variation (e.g. where is the greatest source of variability; plots, subplots within plots, individual quadrats within subplots, …. or years, months within years, weeks within months, days within weeks, …) and are most logically applicable to factors that have a relatively large number of levels (such as spatial or temporal sampling units). On the other hand, finite population standard deviations can be used to explore the relative impact or effect of a set of (fixed) treatments.&lt;/p&gt;
&lt;p&gt;Calculate the amount of unexplained (residual) variance absorbed by the factor. This is generated by fitting a model with (full model) and without (reduced model) the term and subtracting the standard deviations of the residuals one another.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \sigma_A = \sigma_{reduced} - \sigma_{full} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This approach works fine for models that only include fixed factors (indeed it is somewhat analogous to the partitioning of variance employed by an ANOVA table), but cannot be used when the model includes random factors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.lmFull &amp;lt;- lm(y ~ x, data)
&amp;gt; data.lmRed &amp;lt;- lm(y ~ 1, data)
&amp;gt; sd.a &amp;lt;- sd(data.lmRed$resid) - sd(data.lmFull$resid)
&amp;gt; sd.resid &amp;lt;- sd(data.lmFull$resid)
&amp;gt; sds &amp;lt;- c(sd.a, sd.resid)
&amp;gt; 100 * sds/sum(sds)
[1] 80.05772 19.94228&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, options are somewhat limiting if we want to estimate the relative impacts of a mixture of “fixed” and “random” terms. For example, we may wish to explore the relative importance of a treatment compared to the spatial and/or temporal sampling heterogeneity. The Bayesian framework provides a relatively simple way to generate both finite population and superpopulation standard deviation estimates for all factors.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Finite populations&lt;/strong&gt;. The standard deviations of the MCMC samples across each of the parameters associated with a factor (eg, &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; in the effects parameterisation model) provide natural estimates of the variability between group levels (and thus the finite population standard deviation).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Superpopulation&lt;/strong&gt;. The mechanism of defining priors also provides a mechanism for calculating infinite population standard deviations. Recall that in the means model, the prior for &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; specifies that each of the &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; values are drawn from a normal distribution with a particular mean and a certain level of precision (reciprocal of variability). We could further parameterise this prior into an estimatable mean and precision via hyperpriors &lt;span class=&#34;math inline&#34;&gt;\(\beta_0 \sim \text{Normal}(\mu,\tau)\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\mu \sim \text{Normal}(0,1.0\text{E}-6)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tau \sim \text{Gamma}(0.1,0.1)\)&lt;/span&gt;. Since the normal distribution in line one above represents the distribution from which the (infinite) population means are drawn, &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; provides a direct measure of the variability of the population from which the means are drawn.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When the number of levels of a factor are large, the finite population and superpopulation standard deviation point estimates will be very similar. However, when the number of factor levels is small (such as two levels), the finite population estimate will be very precise whereas the superpopulation standard deviation estimate will be very imprecise (highly varied). For this reason, if the purpose of estimating standard deviations is to compare relative contributions of various predictors (some of which have small numbers of levels and others large), then it is best to use finite population standard deviation estimates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; paramsv4 &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;sd.a&amp;quot;, &amp;quot;sd.resid&amp;quot;, &amp;quot;sigma.a&amp;quot;)
&amp;gt; data.r2jagsv4 &amp;lt;- jags(data=data.list,
+ inits=NULL, #or inits=list(inits,inits) # since there are two chains
+ parameters.to.save=paramsv4,
+ model.file=&amp;quot;ttestModelv4.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 4
   Total graph size: 319

Initializing model
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.r2jagsv4)
Inference for Bugs model at &amp;quot;ttestModelv4.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
               mu.vect      sd.vect    2.5%     25%     50%     75%
beta[1]   0.000000e+00 0.000000e+00   0.000   0.000   0.000   0.000
beta[2]  -2.731400e+01 5.670000e-01 -28.417 -27.694 -27.314 -26.937
beta0     1.051970e+02 3.590000e-01 104.490 104.955 105.198 105.440
sd.a      1.931400e+01 4.010000e-01  18.521  19.047  19.314  19.583
sd.resid  2.751000e+00 2.000000e-02   2.737   2.738   2.743   2.755
sigma     2.769000e+00 1.990000e-01   2.411   2.629   2.757   2.895
sigma.a   1.095446e+22 1.956638e+24   0.323   1.712  13.394 440.403
deviance  4.871890e+02 2.480000e+00 484.365 485.386 486.550 488.303
                97.5%  Rhat n.eff
beta[1]         0.000 1.000     1
beta[2]       -26.193 1.001 46000
beta0         105.899 1.001 46000
sd.a           20.094 1.001 46000
sd.resid        2.808 1.001 46000
sigma           3.187 1.001 46000
sigma.a  43469187.743 1.001 46000
deviance      493.637 1.001 46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.1 and DIC = 490.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The between group (finite population) standard deviation is &lt;span class=&#34;math inline&#34;&gt;\(20.1\)&lt;/span&gt; whereas the within group standard deviation is &lt;span class=&#34;math inline&#34;&gt;\(2.81\)&lt;/span&gt;. These equate to respectively. Compared to the finite population standard deviation, the superpopulation between group standard deviation estimate (&lt;span class=&#34;math inline&#34;&gt;\(\sigma_a\)&lt;/span&gt;) is both very large and highly variable. This is to be expected, whilst the finite population standard deviation represents the degree of variation between the observed levels, the superpopulation standard deviation seeks to estimate the variability of the population from which the group means of the observed levels &lt;strong&gt;AND&lt;/strong&gt; all other possible levels are drawn. There are only two levels from which to estimate this standard deviation and therefore, its value and variability are going to be higher than those pertaining only to the scope of the current data.&lt;/p&gt;
&lt;p&gt;Examination of the quantiles for &lt;span class=&#34;math inline&#34;&gt;\(\sigma_a\)&lt;/span&gt; suggest that its samples are not distributed normally. Consequently, the mean is not an appropriate measure of its location. We will instead characterise the superpopulation between group and within group standard deviations via their respective medians and as percent medians. The contrast between finite population and superpopulation standard deviations is also emphasised by the respective estimates for the residuals. The residuals are of course a “random” factor with a large number of observed levels. It is therefore not surprising that the point estimates for the residuals variance components are very similar. However, also notice that the precision of the finite population standard deviation estimate is substantially higher (lower standard deviation of the standard deviation estimate) than that of the superpopulation estimate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;unequally-varied-populations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Unequally varied populations&lt;/h1&gt;
&lt;p&gt;We can also generate data assuming two populations with different variances, e.g. between male and female subgroups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n1 &amp;lt;- 60  #sample size from population 1
&amp;gt; n2 &amp;lt;- 40  #sample size from population 2
&amp;gt; mu1 &amp;lt;- 105  #population mean of population 1
&amp;gt; mu2 &amp;lt;- 77.5  #population mean of population 2
&amp;gt; sigma1 &amp;lt;- 3  #standard deviation of population 1
&amp;gt; sigma2 &amp;lt;- 2  #standard deviation of population 2
&amp;gt; n &amp;lt;- n1 + n2  #total sample size
&amp;gt; y1 &amp;lt;- rnorm(n1, mu1, sigma1)  #population 1 sample
&amp;gt; y2 &amp;lt;- rnorm(n2, mu2, sigma2)  #population 2 sample
&amp;gt; y &amp;lt;- c(y1, y2)
&amp;gt; x &amp;lt;- factor(rep(c(&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;), c(n1, n2)))  #categorical listing of the populations
&amp;gt; xn &amp;lt;- rep(c(0, 1), c(n1, n2))  #numerical version of the population category
&amp;gt; data2 &amp;lt;- data.frame(y, x, xn)  # dataset
&amp;gt; head(data2)  #print out the first six rows of the data set
         y x xn
1 103.3186 A  0
2 104.3095 A  0
3 109.6761 A  0
4 105.2115 A  0
5 105.3879 A  0
6 110.1452 A  0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start by defining the model&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_i + \epsilon, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_1 \sim \text{Normal}(0,\sigma_1)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(x_1=0\)&lt;/span&gt; (females), and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_2 \sim \text{Normal}(0,\sigma_2)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(x_2=1\)&lt;/span&gt; (males). In &lt;code&gt;JAGS&lt;/code&gt; code, the model becomes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelStringv5=&amp;quot;
+  model {
+  #Likelihood
+  for (i in 1:n1) {
+  y1[i]~dnorm(mu1,tau1)
+  }
+  for (i in 1:n2) {
+  y2[i]~dnorm(mu2,tau2)
+  }
+  
+  #Priors
+  mu1 ~ dnorm (0,0.001)
+  mu2 ~ dnorm(0,0.001)
+  tau1 &amp;lt;- 1 / (sigma1 * sigma1)
+  sigma1~dunif(0,100)
+  tau2 &amp;lt;- 1 / (sigma2 * sigma2)
+  sigma2~dunif(0,100)
+  
+  #Other Derived parameters 
+  delta &amp;lt;- mu2 - mu1
+  }
+  &amp;quot;
&amp;gt; ## write the model to a text file 
&amp;gt; writeLines(modelStringv5,con=&amp;quot;ttestModelv5.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We specify priors directly on &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_2\)&lt;/span&gt; using Uniform distributions between &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;, and then express &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; as a deterministic function of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Next, arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;) and define the MCMC parameters. Note, all variables must be numeric, therefore we use the numeric version of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Define the initial values for two chains so that the initial values list must include two elements (if provided).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data2.list &amp;lt;- with(data2,list(y1=y[xn==0], y2=y[xn==1], 
+   n1=length(y[xn==0]), n2=length(y[xn==1])))
&amp;gt; inits &amp;lt;- list(list(mu1=rnorm(1), mu2=rnorm(1), sigma1=rlnorm(1), sigma2=rlnorm(1)),
+ list(mu1=rnorm(1), mu2=rnorm(1), sigma1=rlnorm(1), sigma2=rlnorm(1)))
&amp;gt; paramsv5 &amp;lt;- c(&amp;quot;mu1&amp;quot;,&amp;quot;mu2&amp;quot;,&amp;quot;delta&amp;quot;,&amp;quot;sigma1&amp;quot;,&amp;quot;sigma2&amp;quot;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 2000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 50000
&amp;gt; thinSteps = 1
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, fit the model in &lt;code&gt;JAGS&lt;/code&gt; and print the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data2.r2jagsv5 &amp;lt;- jags(data=data2.list,
+ inits=NULL, #or inits=list(inits,inits) # since there are two chains
+ parameters.to.save=paramsv5,
+ model.file=&amp;quot;ttestModelv5.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=1)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 4
   Total graph size: 115

Initializing model
&amp;gt; 
&amp;gt; print(data2.r2jagsv5)
Inference for Bugs model at &amp;quot;ttestModelv5.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
delta    -27.435   0.473 -28.367 -27.755 -27.433 -27.116 -26.508 1.001 27000
mu1      105.181   0.360 104.478 104.937 105.181 105.422 105.891 1.001 44000
mu2       77.746   0.306  77.142  77.543  77.748  77.948  78.347 1.001 46000
sigma1     2.787   0.265   2.328   2.602   2.767   2.951   3.361 1.001 16000
sigma2     1.913   0.225   1.534   1.753   1.893   2.049   2.414 1.001 21000
deviance 455.879   2.945 452.217 453.714 455.215 457.354 463.257 1.001 46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.3 and DIC = 460.2
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2006prior&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2006. “Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by Browne and Draper).” &lt;em&gt;Bayesian Analysis&lt;/em&gt; 1 (3): 515–34.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Comparing Two Populations - STAN</title>
      <link>/stan/comparing-two-populations-stan/comparing-two-populations-stan/</link>
      <pubDate>Sat, 01 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/stan/comparing-two-populations-stan/comparing-two-populations-stan/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to explore differences between two populations. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of R, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;BUGS/JAGS/STAN&lt;/code&gt; languages and algorithms are very powerful and flexible. However, the cost of this power and flexibility is complexity and the need for a firm understanding of the model you wish to fit as well as the priors to be used. The algorithms requires the following inputs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Within the model:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The likelihood function relating the response to the predictors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The definition of the priors.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Chain properties:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The number of chains.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The length of chains (number of iterations).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The burn-in length (number of initial iterations to ignore).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The thinning rate (number of iterations to count on before storing a sample).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The initial estimates to start an MCMC chain. If there are multiple chains, these starting values can differ between chains.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The list of model parameters and derivatives to monitor (and return the posterior distributions of)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;STAN&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman, Lee, and Guo (2015)&lt;/span&gt;) using the package &lt;code&gt;rstan&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Stan Development Team (2018)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;We will start by generating a random data set. Note, I am creating two versions of the predictor variable (a numeric version and a factorial version).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; nA &amp;lt;- 60  #sample size from Population A
&amp;gt; nB &amp;lt;- 40  #sample size from Population B
&amp;gt; muA &amp;lt;- 105  #population mean of Population A
&amp;gt; muB &amp;lt;- 77.5  #population mean of Population B
&amp;gt; sigma &amp;lt;- 3  #standard deviation of both populations (equally varied)
&amp;gt; yA &amp;lt;- rnorm(nA, muA, sigma)  #Population A sample
&amp;gt; yB &amp;lt;- rnorm(nB, muB, sigma)  #Population B sample
&amp;gt; y &amp;lt;- c(yA, yB)
&amp;gt; x &amp;lt;- factor(rep(c(&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;), c(nA, nB)))  #categorical listing of the populations
&amp;gt; xn &amp;lt;- as.numeric(x)  #numerical version of the population category for means parameterization. # Should not start at 0.
&amp;gt; data &amp;lt;- data.frame(y, x, xn)  # dataset&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let inspect the first few rows of the dataset using the command &lt;code&gt;head&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; head(data)
         y x xn
1 103.3186 A  1
2 104.3095 A  1
3 109.6761 A  1
4 105.2115 A  1
5 105.3879 A  1
6 110.1452 A  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also perform some exploratory data analysis - in this case, a boxplot of the response for each level of the predictor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ x, data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/boxplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-one-sample-t-test&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The One Sample t-test&lt;/h1&gt;
&lt;p&gt;A &lt;em&gt;t-test&lt;/em&gt; is essentially just a simple regression model in which the categorical predictor is represented by a binary variable in which one level is coded as &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and the other &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;. For the model itself, the observed response &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; are assumed to be drawn from a normal distribution with a given mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. The expected values are themselves determined by the linear predictor &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0+\beta_1x_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the mean of the first treatment group and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; represents the difference between the mean of the first group and the mean of the second group (the effect of interest).&lt;/p&gt;
&lt;p&gt;MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying “uninformative” priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(1000\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (scale=&lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;) for the standard deviation (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim \text{Normal}(\mu_i, \sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0+\beta_1x_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Priors are defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim \text{Normal}(0,1000),  \;\;\; \text{and} \;\;\; \sigma \sim \text{Cauchy}(0,25),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for &lt;span class=&#34;math inline&#34;&gt;\(j=0,1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;fitting-the-model-in-stan&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fitting the model in STAN&lt;/h2&gt;
&lt;p&gt;Broadly, there are two ways of parameterising (expressing the unknown (to be estimated) components of a model) a model. Either we can estimate the means of each group (&lt;em&gt;Means parameterisation&lt;/em&gt;) or we can estimate the mean of one group and the difference between this group and the other group(s) (&lt;em&gt;Effects parameterisation&lt;/em&gt;). The latter is commonly used for frequentist null hypothesis testing as its parameters are more consistent with the null hypothesis of interest (that the difference between the two groups equals zero).&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Effects parameterisation&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_{j}x_i + \epsilon_i, \;\;\; \text{with} \;\;\; \epsilon_i \sim \text{Normal}(0,\sigma).  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Each &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; is modelled by an intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; (mean of group A) plus a difference parameter &lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt; (difference between mean of group A and group B) multiplied by an indicator of which group the observation came from (&lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;), plus a residual drawn from a normal distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Actually, there are as many &lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt; parameters as there are groups but one of them (typically the first) is set to be equal to zero (to avoid over-parameterization). Expected values of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; are modelled assuming they are drawn from a normal distribution whose mean is determined by a linear combination of effect parameters and whose variance is defined by the degree of variability in this mean. The parameters are: &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Means parameterisation&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_{j} + \epsilon_i, \;\;\; \text{with} \;\;\; \epsilon_i \sim \text{Normal}(0,\sigma).  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Each &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; is modelled as the mean &lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt; of each group (&lt;span class=&#34;math inline&#34;&gt;\(j=1,2\)&lt;/span&gt;) plus a residual drawn from a normal distribution with a mean of zero and a standard deviation of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Actually, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; is a set of &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; coefficients corresponding to the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; dummy coded factor levels. Expected values of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; are modelled assuming they are drawn from a normal distribution whose mean is determined by a linear combination of means parameters and whose variance is defined by the degree of variability in this mean. The parameters are: &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Whilst the &lt;code&gt;STAN&lt;/code&gt; language broadly resembles &lt;code&gt;BUGS/JAGS&lt;/code&gt;, there are numerous important differences. Some of these differences are to support translation to &lt;code&gt;c++&lt;/code&gt; for compilation (such as declaring variables). Others reflect leveraging of vectorization to speed up run time. Here are some important notes about &lt;code&gt;STAN&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All variables must be declared&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Variables declared in the parameters block will be collected&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Anything in the transformed block will be collected as samples. Also, checks will be made every loop&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now I will demonstrate fitting the models with &lt;code&gt;STAN&lt;/code&gt;. Note, I am using the &lt;code&gt;refresh=0&lt;/code&gt; option so as to suppress the larger regular output in the interest of keeping output to what is necessary for this tutorial. When running outside of a tutorial context, the regular verbose output is useful as it provides a way to gauge progress.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Effects Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stanString = &amp;quot; 
+ data {
+  int n;
+  vector [n] y;
+  vector [n] x;
+  }
+  parameters {
+  real &amp;lt;lower=0, upper=100&amp;gt; sigma;
+  real beta0;
+  real beta;
+  }
+  transformed parameters {
+  }
+  model {
+  vector [n] mu;
+  
+  //Priors
+  beta0 ~ normal(0,1000);
+  beta ~ normal(0,1000);
+  sigma ~ cauchy(0,25);
+  
+  mu = beta0 + beta*x;
+  //Likelihood
+  y ~ normal(mu, sigma);
+  }
+  generated quantities {
+  vector [2] Group_means;
+  real CohensD;
+  //Other Derived parameters 
+  //# Group means (note, beta is a vector)
+  Group_means[1] = beta0;
+  Group_means[2] = beta0+beta;
+  
+  CohensD = beta /sigma;  
+  }
+  
+  &amp;quot;
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(stanString, con = &amp;quot;ttestModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Means Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stanString.means = &amp;quot;  
+  data {
+  int n;
+  int nX;
+  vector [n] y;
+  matrix [n,nX] x;
+  }
+  parameters {
+  real &amp;lt;lower=0, upper=100&amp;gt; sigma;
+  vector [nX] beta;
+  }
+  transformed parameters {
+  }
+  model {
+  vector [n] mu;
+  
+  //Priors
+  beta ~ normal(0,1000);
+  sigma ~ cauchy(0,25);
+  
+  mu = x*beta;
+  //Likelihood
+  y ~ normal(mu, sigma);
+  }
+  generated quantities {
+  vector [2] Group_means;
+  real CohensD;
+  
+  //Other Derived parameters 
+  Group_means[1] = beta[1];
+  Group_means[2] = beta[1]+beta[2];
+  
+  CohensD = beta[2] /sigma;  
+  }
+  
+  &amp;quot;
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(stanString.means, con = &amp;quot;ttestModelMeans.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.list &amp;lt;- with(data, list(y = y, x = (xn - 1), n = nrow(data)))
&amp;gt; X &amp;lt;- model.matrix(~x, data)
&amp;gt; data.list.means = with(data, list(y = y, x = X, n = nrow(data), nX = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the initial values for the chain. Reasonable starting points can be gleaned from the data themselves.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; inits &amp;lt;- list(beta0 = mean(data$y), beta = c(NA, diff(tapply(data$y,
+     data$x, mean))), sigma = sd(data$y/2))
&amp;gt; inits.means &amp;lt;- list(beta = tapply(data$y, data$x, mean), sigma = sd(data$y/2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;Group_means&amp;quot;, &amp;quot;CohensD&amp;quot;)
&amp;gt; params.means &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;Group_means&amp;quot;,&amp;quot;CohensD&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; burnInSteps = 500  # the number of initial samples to discard
&amp;gt; nChains = 2  # the number of independed sampling chains to perform 
&amp;gt; thinSteps = 1  # the thinning rate
&amp;gt; nIter = 2000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;STAN&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;rstan&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When using the &lt;code&gt;stan&lt;/code&gt; function (&lt;code&gt;rtsan&lt;/code&gt; package), it is not necessary to provide initial values. However, if they are to be supplied, the inital values must be provided as a list of the same length as the number of chains.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Effects Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.stan = stan(file = &amp;quot;ttestModel.stan&amp;quot;, 
+   data = data.list, 
+   pars = params,
+   iter = nIter,
+   warmup = burnInSteps, 
+   chains = nChains, 
+   thin = thinSteps, 
+   init = &amp;quot;random&amp;quot;, #or inits=list(inits,inits)
+   refresh = 0)
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.stan)
Inference for Stan model: ttestModel.
2 chains, each with iter=2000; warmup=500; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

                  mean se_mean   sd    2.5%     25%     50%     75%   97.5%
beta0           105.20    0.01 0.36  104.47  104.95  105.20  105.44  105.91
beta            -27.32    0.01 0.57  -28.43  -27.72  -27.33  -26.93  -26.22
sigma             2.79    0.00 0.21    2.41    2.64    2.77    2.92    3.23
Group_means[1]  105.20    0.01 0.36  104.47  104.95  105.20  105.44  105.91
Group_means[2]   77.88    0.01 0.45   77.01   77.59   77.87   78.18   78.76
CohensD          -9.85    0.02 0.75  -11.36  -10.35   -9.86   -9.35   -8.36
lp__           -150.78    0.04 1.25 -154.05 -151.31 -150.44 -149.88 -149.34
               n_eff Rhat
beta0           1802    1
beta            1731    1
sigma           2187    1
Group_means[1]  1802    1
Group_means[2]  2826    1
CohensD         2238    1
lp__            1272    1

Samples were drawn using NUTS(diag_e) at Mon Feb 10 14:10:29 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Means Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.stan.means = stan(file = &amp;quot;ttestModelMeans.stan&amp;quot;, 
+   data = data.list.means, 
+   pars = params.means,
+   iter = nIter,
+   warmup = burnInSteps, 
+   chains = nChains, 
+   thin = thinSteps, 
+   init = &amp;quot;random&amp;quot;, #or inits=list(inits.means,inits.means)
+   refresh = 0)
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.stan.means)
Inference for Stan model: ttestModelMeans.
2 chains, each with iter=2000; warmup=500; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

                  mean se_mean   sd    2.5%     25%     50%     75%   97.5%
beta[1]         105.21    0.01 0.37  104.51  104.96  105.20  105.44  105.92
beta[2]         -27.33    0.01 0.58  -28.47  -27.71  -27.31  -26.93  -26.23
sigma             2.78    0.00 0.20    2.43    2.64    2.76    2.90    3.22
Group_means[1]  105.21    0.01 0.37  104.51  104.96  105.20  105.44  105.92
Group_means[2]   77.88    0.01 0.44   77.02   77.59   77.88   78.17   78.77
CohensD          -9.88    0.02 0.74  -11.35  -10.40   -9.89   -9.40   -8.40
lp__           -150.74    0.03 1.26 -153.85 -151.33 -150.42 -149.83 -149.33
               n_eff Rhat
beta[1]         1439    1
beta[2]         1654    1
sigma           1955    1
Group_means[1]  1439    1
Group_means[2]  3595    1
CohensD         2056    1
lp__            1397    1

Samples were drawn using NUTS(diag_e) at Mon Feb 10 14:11:08 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If &lt;code&gt;inits=&#34;random&#34;&lt;/code&gt; the &lt;code&gt;stan&lt;/code&gt; function will randomly generate initial values between &lt;span class=&#34;math inline&#34;&gt;\(-2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; on the &lt;em&gt;unconstrained support&lt;/em&gt;. The optional additional parameter &lt;code&gt;init_r&lt;/code&gt; can be set to some value other than &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; to change the range of the randomly generated inits. Other available options include: set &lt;code&gt;inits=&#34;0&#34;&lt;/code&gt; to initialize all parameters to zero on the unconstrained support; set inital values by providing a list equal in length to the number of chains; set initial values by providing a function that returns a list for specifying the initial values of parameters for a chain.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In addition to the mean and quantiles of each of the sample nodes, the &lt;code&gt;stan&lt;/code&gt; function will calculate.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The &lt;em&gt;effective sample size&lt;/em&gt; for each sample - if &lt;code&gt;n.eff&lt;/code&gt; for a node is substantially less than the number of iterations, then it suggests poor mixing.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;em&gt;Potential scale reduction factor&lt;/em&gt; or &lt;code&gt;Rhat&lt;/code&gt; values for each sample - these are a convergence diagnostic (values of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; indicate full convergence, values greater than &lt;span class=&#34;math inline&#34;&gt;\(1.01\)&lt;/span&gt; are indicative of non-convergence.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The total number samples collected is &lt;span class=&#34;math inline&#34;&gt;\(3000\)&lt;/span&gt;. That is, there are &lt;span class=&#34;math inline&#34;&gt;\(3000\)&lt;/span&gt; samples collected from the multidimensional posterior distribution and thus, &lt;span class=&#34;math inline&#34;&gt;\(3000\)&lt;/span&gt; samples collected from the posterior distributions of each parameter. The effective number of samples column indicates the number of independent samples represented in the total. It is clear that for all parameters the chains were well mixed.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;Again, prior to examining the summaries, we should have explored the convergence diagnostics. There are numerous ways of working with &lt;code&gt;STAN&lt;/code&gt; model fits (for exploring diagnostics and summarisation).&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;extract the mcmc samples and convert them into a mcmc.list to leverage the various &lt;code&gt;mcmcplots&lt;/code&gt; routines&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;use the numerous routines that come with the &lt;code&gt;rstan&lt;/code&gt; package&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;use the routines that come with the &lt;code&gt;bayesplot&lt;/code&gt; package&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will explore all of these.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;mcmcplots&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, we need to convert the &lt;code&gt;rtsan&lt;/code&gt; object into an &lt;code&gt;mcmc.list&lt;/code&gt; object to apply the functions in the &lt;code&gt;mcmcplots&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; s = as.array(data.stan.means)
&amp;gt; mcmc &amp;lt;- do.call(mcmc.list, plyr:::alply(s[, , -(length(s[1, 1, ]))], 2, as.mcmc))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we look at density and trace plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(mcmc, parms = c(&amp;quot;Group_means&amp;quot;, &amp;quot;CohensD&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/mcmc_diagv2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(mcmc, parms = c(&amp;quot;Group_means&amp;quot;, &amp;quot;CohensD&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/mcmc_diagv2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;rstan&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MCMC diagnostic measures that can be directly applied to &lt;code&gt;rstan&lt;/code&gt; objects via the &lt;code&gt;rstan&lt;/code&gt; package include: traceplots, autocorrelation, effective sample size and Rhat diagnostics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #traceplots
&amp;gt; stan_trace(data.stan.means, pars = c(&amp;quot;Group_means&amp;quot;, &amp;quot;CohensD&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/mcmc_diagv3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #autocorrelation
&amp;gt; stan_ac(data.stan.means, pars = c(&amp;quot;Group_means&amp;quot;, &amp;quot;CohensD&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/mcmc_diagv3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #rhat
&amp;gt; stan_rhat(data.stan.means, pars = c(&amp;quot;Group_means&amp;quot;, &amp;quot;CohensD&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/mcmc_diagv3-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #ess
&amp;gt; stan_ess(data.stan.means, pars = c(&amp;quot;Group_means&amp;quot;, &amp;quot;CohensD&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/mcmc_diagv3-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Rhat values are a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of 1.05 or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentiall slower than it could have been, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ESS indicates the number samples (or proportion of samples that the sampling algorithm) deamed effective. The sampler rejects samples on the basis of certain criterion and when it does so, the previous sample value is used. Hence while the MCMC sampling chain may contain &lt;span class=&#34;math inline&#34;&gt;\(1000\)&lt;/span&gt; samples, if there are only &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; effective samples (&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;%), the estimated properties are not likely to be reliable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;bayesplot&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another alternative is to use the package &lt;code&gt;bayesplot&lt;/code&gt;, which provides a range of standardised diagnostic measures for assessing MCMC convergence and issues, which can be directly applied to the &lt;code&gt;rstan&lt;/code&gt; object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; 
&amp;gt; #density and trace plots
&amp;gt; mcmc_combo(as.array(data.stan.means), regex_pars = &amp;quot;Group_means|CohensD&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/mcmc_diagv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Residuals are not computed directly within &lt;code&gt;rstan&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(ggplot2)
&amp;gt; mcmc = as.matrix(data.stan.means)[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is no evidence that the mcmc chain did not converge on a stable posterior distribution. We are now in a position to examine the summaries of the parameters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;A quick look at posterior summaries can be obtained through the command &lt;code&gt;summary&lt;/code&gt; which can be directly applied to our &lt;code&gt;rstan&lt;/code&gt; object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; summary(data.stan.means)
$summary
                      mean     se_mean        sd        2.5%        25%
beta[1]         105.205981 0.009650332 0.3660680  104.512893  104.95847
beta[2]         -27.327670 0.014175541 0.5765494  -28.471465  -27.70858
sigma             2.779295 0.004564259 0.2017951    2.425126    2.63877
Group_means[1]  105.205981 0.009650332 0.3660680  104.512893  104.95847
Group_means[2]   77.878310 0.007293288 0.4372737   77.017179   77.58974
CohensD          -9.883908 0.016318680 0.7398548  -11.345145  -10.39596
lp__           -150.744310 0.033765022 1.2622380 -153.847632 -151.32845
                       50%         75%       97.5%    n_eff      Rhat
beta[1]         105.197887  105.442341  105.923970 1438.928 1.0006369
beta[2]         -27.313058  -26.929462  -26.228003 1654.222 0.9996207
sigma             2.761057    2.904130    3.220382 1954.702 1.0008448
Group_means[1]  105.197887  105.442341  105.923970 1438.928 1.0006369
Group_means[2]   77.881198   78.173471   78.765424 3594.677 0.9997923
CohensD          -9.893648   -9.396558   -8.403284 2055.526 1.0013095
lp__           -150.420841 -149.826519 -149.327836 1397.489 1.0006469

$c_summary
, , chains = chain:1

                stats
parameter               mean        sd        2.5%         25%         50%
  beta[1]         105.194598 0.3722763  104.485138  104.943830  105.189222
  beta[2]         -27.316749 0.5909082  -28.503315  -27.700926  -27.303076
  sigma             2.787113 0.2017944    2.439039    2.649487    2.769964
  Group_means[1]  105.194598 0.3722763  104.485138  104.943830  105.189222
  Group_means[2]   77.877849 0.4452879   76.953676   77.589838   77.884335
  CohensD          -9.851471 0.7306980  -11.291742  -10.351622   -9.856804
  lp__           -150.774304 1.3031195 -154.143552 -151.358639 -150.446011
                stats
parameter                75%       97.5%
  beta[1]         105.430335  105.928130
  beta[2]         -26.900706  -26.189346
  sigma             2.905763    3.220038
  Group_means[1]  105.430335  105.928130
  Group_means[2]   78.167639   78.777570
  CohensD          -9.358039   -8.394201
  lp__           -149.844014 -149.328052

, , chains = chain:2

                stats
parameter               mean        sd        2.5%         25%         50%
  beta[1]         105.217363 0.3595164  104.544008  104.970466  105.208509
  beta[2]         -27.338592 0.5618086  -28.444722  -27.716894  -27.323423
  sigma             2.771476 0.2015598    2.417028    2.631247    2.750654
  Group_means[1]  105.217363 0.3595164  104.544008  104.970466  105.208509
  Group_means[2]   77.878771 0.4292579   77.031912   77.589743   77.878030
  CohensD          -9.916344 0.7477366  -11.431004  -10.435551   -9.924630
  lp__           -150.714316 1.2196850 -153.673281 -151.305580 -150.383196
                stats
parameter                75%       97.5%
  beta[1]         105.450568  105.916257
  beta[2]         -26.963106  -26.265061
  sigma             2.898644    3.219905
  Group_means[1]  105.450568  105.916257
  Group_means[2]   78.179664   78.753253
  CohensD          -9.430001   -8.422613
  lp__           -149.795340 -149.327597&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Group A is typically &lt;span class=&#34;math inline&#34;&gt;\(27.3\)&lt;/span&gt; units greater than Group B. The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the difference between Group A and B does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between the two groups.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group. We do this by loading functions in the package &lt;code&gt;broom&lt;/code&gt; and &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(broom)
&amp;gt; library(dplyr)
&amp;gt; mcmc = as.matrix(data.stan.means)
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = data.frame(x = levels(data$x))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; newdata
  x  estimate std.error  conf.low conf.high
1 A 105.20598 0.3660680 104.52503 105.93588
2 B  77.87831 0.4372737  76.99792  78.74455
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you wanted to represent sample data on the figure in such a simple example (single predictor) we could simply over- (or under-) lay the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = data, aes(y = y,
+     x = x), color = &amp;quot;gray&amp;quot;) + geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
+     scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A more general solution would be to add the partial residuals to the figure. Partial residuals are the fitted values plus the residuals. In this simple case, that equates to exactly the same as the raw observations since &lt;span class=&#34;math inline&#34;&gt;\(\text{resid}=\text{obs}−\text{fitted}\)&lt;/span&gt; and the fitted values depend only on the single predictor we are interested in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = rdata, aes(y = partial.resid),
+     color = &amp;quot;gray&amp;quot;) + geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
+     scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/mcmc_post3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;effect-sizes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Effect sizes&lt;/h1&gt;
&lt;p&gt;We can compute summaries for our effect size of interest (e.g. Cohen’s or the percentage ES) by post-processing our posterior distributions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.stan.means)
&amp;gt; ## Cohen&amp;#39;s D
&amp;gt; cohenD = mcmc[, &amp;quot;beta[2]&amp;quot;]/mcmc[, &amp;quot;sigma&amp;quot;]
&amp;gt; tidyMCMC(as.mcmc(cohenD), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     -9.88     0.740    -11.3     -8.38
&amp;gt; 
&amp;gt; # Percentage change (relative to Group A)
&amp;gt; ES = 100 * mcmc[, &amp;quot;beta[2]&amp;quot;]/mcmc[, &amp;quot;beta[1]&amp;quot;]
&amp;gt; 
&amp;gt; # Probability that the effect is greater than 10% (a decline of &amp;gt;10%)
&amp;gt; sum(-1 * ES &amp;gt; 10)/length(ES)
[1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;probability-statements&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Probability statements&lt;/h1&gt;
&lt;p&gt;Any sort of probability statements of interest about our effect size can be computed in a relatively easy way by playing around with the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.stan.means)
&amp;gt; 
&amp;gt; # Percentage change (relative to Group A)
&amp;gt; ES = 100 * mcmc[, &amp;quot;beta[2]&amp;quot;]/mcmc[, &amp;quot;beta[1]&amp;quot;]
&amp;gt; hist(ES)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/comparing-two-populations-stan/2020-02-01-comparing-two-populations-stan_files/figure-html/prob_stat-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; # Probability that the effect is greater than 10% (a decline of &amp;gt;10%)
&amp;gt; sum(-1 * ES &amp;gt; 10)/length(ES)
[1] 1
&amp;gt; 
&amp;gt; # Probability that the effect is greater than 25% (a decline of &amp;gt;25%)
&amp;gt; sum(-1 * ES &amp;gt; 25)/length(ES)
[1] 0.978&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Estimates for the variability associated with between and within group differences can also be easily obtained.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x        19.3     0.408     18.5      20.1 
2 sd.resid     2.75    0.0207     2.74      2.79
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         87.5     0.238     87.1      87.8
2 sd.resid     12.5     0.238     12.2      12.9&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;unequally-varied-populations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Unequally varied populations&lt;/h1&gt;
&lt;p&gt;We can also generate data assuming two populations with different variances, e.g. between male and female subgroups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n1 &amp;lt;- 60  #sample size from population 1
&amp;gt; n2 &amp;lt;- 40  #sample size from population 2
&amp;gt; mu1 &amp;lt;- 105  #population mean of population 1
&amp;gt; mu2 &amp;lt;- 77.5  #population mean of population 2
&amp;gt; sigma1 &amp;lt;- 3  #standard deviation of population 1
&amp;gt; sigma2 &amp;lt;- 2  #standard deviation of population 2
&amp;gt; n &amp;lt;- n1 + n2  #total sample size
&amp;gt; y1 &amp;lt;- rnorm(n1, mu1, sigma1)  #population 1 sample
&amp;gt; y2 &amp;lt;- rnorm(n2, mu2, sigma2)  #population 2 sample
&amp;gt; y &amp;lt;- c(y1, y2)
&amp;gt; x &amp;lt;- factor(rep(c(&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;), c(n1, n2)))  #categorical listing of the populations
&amp;gt; xn &amp;lt;- rep(c(0, 1), c(n1, n2))  #numerical version of the population category
&amp;gt; data2 &amp;lt;- data.frame(y, x, xn)  # dataset
&amp;gt; head(data2)  #print out the first six rows of the data set
         y x xn
1 103.3186 A  0
2 104.3095 A  0
3 109.6761 A  0
4 105.2115 A  0
5 105.3879 A  0
6 110.1452 A  0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start by defining the model&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_i + \epsilon, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_1 \sim \text{Normal}(0,\sigma_1)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(x_1=0\)&lt;/span&gt; (females), and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_2 \sim \text{Normal}(0,\sigma_2)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(x_2=1\)&lt;/span&gt; (males). In &lt;code&gt;STAN&lt;/code&gt; code, the model becomes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stanStringv3 = &amp;quot; 
+  data {
+  int n;
+  vector [n] y;
+  vector [n] x;
+  int&amp;lt;lower=1,upper=2&amp;gt; xn[n];
+  }
+  parameters {
+  vector &amp;lt;lower=0, upper=100&amp;gt;[2] sigma;
+  real beta0;
+  real beta;
+  }
+  transformed parameters {
+  }
+  model {
+  vector [n] mu;
+  //Priors
+  beta0 ~ normal(0,1000);
+  beta ~ normal(0,1000);
+  sigma ~ cauchy(0,25);
+ 
+  mu = beta0 + beta*x;
+  //Likelihood
+  for (i in 1:n) y[i] ~ normal(mu[i], sigma[xn[i]]);
+  }
+  generated quantities {
+  vector [2] Group_means;
+  real CohensD;
+  real CLES;
+ 
+  Group_means[1] = beta0;
+  Group_means[2] = beta0+beta;
+  CohensD = beta /(sum(sigma)/2);
+  CLES = normal_cdf(beta /sum(sigma),0,1);  
+  }
+  
+  &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file 
&amp;gt; writeLines(stanStringv3,con=&amp;quot;ttestModelv3.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We specify priors directly on &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_2\)&lt;/span&gt; using Cauchy distributions with a scale of &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;. Next, arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;) and define the MCMC parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data2.list &amp;lt;- with(data, list(y = y, x = (xn - 1), xn = xn, n = nrow(data)))
&amp;gt; paramsv3 &amp;lt;- c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;Group_means&amp;quot;,&amp;quot;CohensD&amp;quot;, &amp;quot;CLES&amp;quot;)
&amp;gt; burnInSteps = 500
&amp;gt; nChains = 2
&amp;gt; thinSteps = 1
&amp;gt; nIter = 2000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, fit the model in &lt;code&gt;STAN&lt;/code&gt; and print the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.stanv3 = stan(file = &amp;quot;ttestModelv3.stan&amp;quot;, 
+   data = data2.list, 
+   pars = paramsv3,
+   iter = nIter,
+   warmup = burnInSteps, 
+   chains = nChains, 
+   thin = thinSteps, 
+   init = &amp;quot;random&amp;quot;, #or inits=list(inits,inits)
+   refresh = 0)
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.stanv3)
Inference for Stan model: ttestModelv3.
2 chains, each with iter=2000; warmup=500; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

                  mean se_mean   sd    2.5%     25%     50%     75%   97.5%
beta0           105.21    0.01 0.36  104.51  104.97  105.21  105.44  105.92
beta            -27.34    0.01 0.57  -28.45  -27.71  -27.35  -26.96  -26.21
sigma[1]          2.79    0.01 0.27    2.31    2.60    2.77    2.97    3.38
sigma[2]          2.88    0.01 0.34    2.31    2.63    2.84    3.07    3.65
Group_means[1]  105.21    0.01 0.36  104.51  104.97  105.21  105.44  105.92
Group_means[2]   77.86    0.01 0.44   77.00   77.57   77.86   78.15   78.75
CohensD          -9.70    0.02 0.76  -11.23  -10.23   -9.69   -9.17   -8.26
CLES              0.00    0.00 0.00    0.00    0.00    0.00    0.00    0.00
lp__           -150.30    0.04 1.42 -153.88 -151.02 -149.99 -149.25 -148.53
               n_eff Rhat
beta0           2426    1
beta            2359    1
sigma[1]        2166    1
sigma[2]        2547    1
Group_means[1]  2426    1
Group_means[2]  3478    1
CohensD         2468    1
CLES            1875    1
lp__            1277    1

Samples were drawn using NUTS(diag_e) at Mon Feb 10 14:11:55 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2015stan&#34;&gt;
&lt;p&gt;Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt; 40 (5): 530–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2006prior&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2006. “Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by Browne and Draper).” &lt;em&gt;Bayesian Analysis&lt;/em&gt; 1 (3): 515–34.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanpackage&#34;&gt;
&lt;p&gt;Stan Development Team. 2018. “RStan: The R Interface to Stan.” &lt;a href=&#34;http://mc-stan.org/&#34;&gt;http://mc-stan.org/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Finally here ...</title>
      <link>/post/update-february/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/update-february/</guid>
      <description>&lt;p&gt;The new year is finally taking off for me and I have a couple of updates. First, I would like to remind everyone about the exciting new course &amp;ldquo;understanding health economics in clinical trials&amp;rdquo; that me and 
the rest of our research team &lt;a href=&#34;https://hearteam.blogspot.com/&#34;&gt;HEART&lt;/a&gt; have put together to support the dissemination of health economics among all people involved in the design and analysis of clinical trials.
I look forward to deliver this one-day short course together with my colleagues from the &lt;a href=&#34;https://www.ucl.ac.uk/epidemiology-health-care/research/pcph&#34;&gt;UCL PCPH department&lt;/a&gt; which will be structured into different sessions
during the day of Feb 11th at the &lt;a href=&#34;https://www.ucl.ac.uk/comprehensive-clinical-trials-unit/contact-us&#34;&gt;UCL CCTU&lt;/a&gt; - 2nd Floor, 90 High Holborn, London. The course is specifically intended for those who would like to know more 
about health economics, which has become an important component in the design, analysis and most crucially, for the funding approval of clinical trials. The course will focus on the following aspects:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A short intorduction to the basic concepts of health economics and why these can be relevent to different people&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A review of different types of intruments and tools used to collect health economic data in clinical trials&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A quick look at decision models with some examples&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A summary of the typical results from health economic analyses and how to interpret them&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The course is still in its pilot form and therfore it is free of charge. If there are still places available, you are very welcome to join and give us your feedback!.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/RMTQiRYAuvvJb1k6al/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Second, I am happy to announce that my recent paper about the use of &lt;a href=&#34;https://www.tandfonline.com/doi/full/10.1080/02664763.2020.1723506&#34;&gt;Bayesian Hierarchical Models for the Prediction of Volleyball Results&lt;/a&gt; has finally 
been published on the &lt;a href=&#34;https://www.tandfonline.com/loi/cjas20&#34;&gt;Journal of Applied Statistics&lt;/a&gt;. I am really proud of this paper as it is my first solo paper publiched and because I have always been very invested in the general topic of 
predicting sport results using probability models. To be able to publish something about this based on my own efforts is very rewarding in terms of the (small) contribution to research that I hope I was able to provide.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/l0He0cVv8lGggpruo/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Finally, I have submitted an abstract to the &lt;a href=&#34;https://euhea.eu/welcome_conference_2020.html&#34;&gt;2020 European Health Economics Association Conference&lt;/a&gt;, which this year will be held in Oslo, Norway.&lt;br&gt;
I have now to patiently wait for the review of the abstracts and see if my work made it, either as an oral presenation or as a poster. Fingers crossed!.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Let us do some work</title>
      <link>/post/update-january2/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/update-january2/</guid>
      <description>&lt;p&gt;After the terrible start of this year, things are going ok now and I am quite busy with different projects that I left a bit behind. First, I can confirm that me and my colleagues from the &lt;a href=&#34;https://hearteam.blogspot.com/&#34;&gt;HEART group&lt;/a&gt;
are going to give an introductory course to health economic evaluations next month for different groups of people from academia and clinical trial units. The course has been generally structured based on our &amp;ldquo;pilot&amp;rdquo; we gave last year (which went really well by the way)
and involves many different topics that will cover the entire day of February 11th. The attending list is already full and thw waiting list is also quite big; happy to see so much interest in economic evaluations.&lt;/p&gt;
&lt;p&gt;Second, I will give a talk at the PRIMENT statistics and health economics and methodology seminar about an on-going project on missing data in trial-based analysis on Tuesday 28th, at UCL &lt;a href=&#34;https://www.ucl.ac.uk/priment/&#34;&gt;PRIMENT CTU&lt;/a&gt;.
I am really happy to be back at these seminars which I feel I really nice and where you have the opportunity to interact with people from different backgrounds and job positions who may give some useful feedback on my work. Hopefully, 
people will find my research interesting!. I would also like to mention the fact that one of my HEART colleague, &lt;a href=&#34;https://iris.ucl.ac.uk/iris/browse/profile?upi=MCCLE13&#34;&gt;Marie&lt;/a&gt;, will give another talk at the same seminar just before me.
Her topic is the economic analysis plan for a trial she has been involved with and I think she is really good, so may worth check her presentaiton out.&lt;/p&gt;
&lt;p&gt;Third, I have finalised a long-waited submission for a paper which has been discussed, written and re-written many times. I really hope we can get some useful feedback on it as 
I personally worked very hard to keep this work alive. Let see if my efforts have not been in vain and fingers crossed!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/4KxeicCUTvhrW/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Fourth, as a side note, I have recently bought a new book on missing data called &lt;a href=&#34;https://www.springer.com/gp/book/9780387324487&#34;&gt;Semiparametric Thoery and Missing Data&lt;/a&gt; by Tsiatis, which looks very interesting.
To be honest, the book is quite technical with many theoretical concpets and proofs which sometimes I find hard to follow. However, so far it gives a nice introduction to semiparametric models and I look forward to see 
how it approaches the missing data topic from a non likelihood-based approach. If you are into non/semiparametric statistics and want to find out more about this, I recommend the reading.&lt;/p&gt;
&lt;p&gt;Finally, more work is also coming up in the next weeks and some of this is not going to be very enjoyable, I think. Anyway, let us go through this busy period at our best and see how things will go.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Not a very good start...</title>
      <link>/post/update-january/</link>
      <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/update-january/</guid>
      <description>&lt;p&gt;After some nice holiday break, I came back to work ready for an exciting 2020 &amp;hellip; or so I thought. Unfortunately, I have recently been caught by a terrible flu which forced me to postpone my flight back to London of a week. 
The worst part is that I was basically a dead corpse moving around with high fever and an awful condition for more than 4 days. It was quite a bad experience which I rarely had in my life. I am just glad I survived this.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/12Eo3WBLbH9HRS/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Going back to more interesting news. Before my cursed period, I was smart enough to work on different things and I am happy to announce a new update for my &lt;code&gt;missingHE&lt;/code&gt; package, which is available both on my &lt;a href=&#34;https://github.com/AnGabrio/missingHE&#34;&gt;GitHub page&lt;/a&gt; and on the &lt;a href=&#34;https://cran.r-project.org/web/packages/missingHE&#34;&gt;CRAN repository&lt;/a&gt;. 
Its new version is 1.3.2 and has the nice addition of making available more choices for the parametric distributions that can be selected in all main functions of the package to handle missing data in trial-based economic evaluations. In particular, it is now possible
to choose among new probability distributions for the health outcomes, including continuous (Gamma, Weibull, Exponential, Logistic), discrete (Poisson, Negative Binomial) and binary (Bernoulli) distributions. These may be useful when the analysis is not based on utilities scores but some other
types of effects, such as survival time, number of events or binary outcomes. I have also included some examples for each type of outcome in the MenSS dataset (available directly once installed the package on your machine) so that people can play around with the new distributions.&lt;/p&gt;
&lt;p&gt;Another good news is that the last paper written with &lt;a href=&#34;http://users.stat.ufl.edu/~daniels/&#34;&gt;Michael&lt;/a&gt; about missing data handling in economic evaluations will soon be publiched in the February issue of JRSSA, which will make the final and official version of the article that can be cited, I think.&lt;/p&gt;
&lt;p&gt;Finally, an announcement about the one-day course I am holding together with my mates from the &lt;a href=&#34;https://hearteam.blogspot.com/&#34;&gt;HEART group&lt;/a&gt; about an introduction to economic evaluations to people who are not familiar with health economics. The course will take place next month, I believe on Feb 11th, 
in central London (soon an update about the exact location) and, as the previous edition, I am happy to see that all spots have been taken and everything is sold out (well, to be precise the course is free &amp;hellip;). Need to meet up with the others to make the last changes and prepare the slides but I am quite excited about this, given also the good response we got last time.&lt;/p&gt;
&lt;p&gt;Now I am (hopefully) ready to start the new year and there are many things already piling up on my list of things to do in the next days. Let&amp;rsquo;s try again 2020.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Too many things, again....</title>
      <link>/post/update-november/</link>
      <pubDate>Sat, 09 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/update-november/</guid>
      <description>&lt;p&gt;I did not have much time to post anything this month until now as it has been a quite busy period. I have been involved in many different works and I have also involved other people in what I think could be some very interesting new projects. Not that I complain about having many different things to do (most of them are actually cool) but doing everything in a short period is not the best.&lt;/p&gt;
&lt;p&gt;A couple of things have come/are coming up. First, I have seriously started working on the coding of a decision model for some health economic evaluation project I have been involved in since last year. Everything seems ok after I spent lots of days and time fixing some small bugs in my code. I am about half way through the model and I hope I will be able to finish it before Christmas (I doubt it though).&lt;/p&gt;
&lt;p&gt;Second, I have finished reviewing an interesting paper about some new methods for improving current practice for dealing with missing data, which I kinda enjoy reading (very good!).&lt;/p&gt;
&lt;p&gt;Third, I would like to quickly summarise my first experience at &lt;a href=&#34;https://www.ispor.org/conferences-education/conferences/past-conferences/ispor-europe-2019&#34;&gt;ISPOR Europe&lt;/a&gt; in Copenhagen. I was really excited to attend this conference which, as expected, revealed itself as huge with people coming from all over the world and with many interesting sessions and discussion topics. I had the chance to meet new and old people, such as professor &lt;a href=&#34;https://www.york.ac.uk/che/staff/research/andrea-manca/&#34;&gt;Andrea Manca&lt;/a&gt; and the always very kind &lt;a href=&#34;https://www.ohe.org/about-us/meet-team/chris-sampson&#34;&gt;Chris Sampson&lt;/a&gt; for whom I was like a stalker asking for more and more information about himself and his work. I also met some of my old collegues from MapiGroup, now under &lt;a href=&#34;https://iconplc.com/&#34;&gt;ICON plc&lt;/a&gt;. It was very fun to hang out with these old friends and see what they have been up to during this time. Among them, I gladly caught up with my dear friend &lt;a href=&#34;https://www.iqce.uni-hamburg.de/people/iqce-fellows/ryan-pulleyblank.html&#34;&gt;Ryan Pulleyblank&lt;/a&gt;, now doing a PhD at the University of Southern Denmark. My poster was a success with (unexpectedly) many people stopping by and asking for more information on my work. I was genuinely surprised by this as ISPOR is mostly a conference dedicated to companies rather than academic works and networking. To sum up, it was a very nice and fun experience and despite the level of statistical methodology was not particularly high I enjoyed my time there and I also had the chance to visit Copenhagen for the first time.&lt;/p&gt;
&lt;p&gt;Finally, as a side note, I have found the time to upload on my arXiv page a nice application of &lt;a href=&#34;https://arxiv.org/abs/1911.08791&#34;&gt;Bayesian hierarchical models for the prediction of volleyball matches&lt;/a&gt; which I have been working on the past summer, taking inspiration from the work of Gianluca about &lt;a href=&#34;https://www.tandfonline.com/doi/abs/10.1080/02664760802684177?journalCode=cjas20&#34;&gt;predicting football macthes&lt;/a&gt;. I hope my work can turn out in something cool as well.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/oWA8lD03GUew8/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;This is all for the moment but soon I will be heading back to another quite busy period for me. I hope this will be the last for some time, especially given that Christmas is coming and I would like to have some free time to properly enjoy this period, which I really like, even more than Christmas itself.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Copenhagen, I am coming ...</title>
      <link>/post/update3-october/</link>
      <pubDate>Mon, 28 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/update3-october/</guid>
      <description>&lt;p&gt;Finally the time of &lt;a href=&#34;https://www.ispor.org/conferences-education/conferences/upcoming-conferences/ispor-europe-2019&#34;&gt;ISPOR Europe 2019&lt;/a&gt; has arrived and I will depart in a few days for 
Copenhagen, where the conference is held this year. I am actually looking forward to this as I am curious to see what type of conference ISPOR is, that is, whether I will be able to find
some interesting works and have some &amp;ldquo;applied statistics&amp;rdquo;-related discussions or the attention is more placed on &amp;ldquo;economics and clinical&amp;rdquo; matters. From what I heard by other people who 
routinely attend the conference, there should be a bit of both sides, even though I really hope I will be able to see some intersting methods and engage in discussion with some authors.&lt;/p&gt;
&lt;p&gt;I know the conference is mainly related to address the needs of pharmaceutical and consultancy companies, but I hope I will be able to see some familiar faces there. Well, to be
honest I know that some people I already know are going, which is good considering that their work is really cool. As for me, I will present the same work that I showed at ICTMC 2019 (some slides available &lt;a href=&#34;https://www.luminpdf.com/viewer/5dbd43939a40480018633f2e&#34;&gt;here&lt;/a&gt;),
but this time in the format of a poster, of which I am kind of very proud in terms of the final output, if I may say so.&lt;/p&gt;
&lt;p&gt;Apart from this nice event, there are many things coming up when I will be back from the conference, which I really need to start working on. Mostly, these are related to some
routine work for some trial analyses at &lt;a href=&#34;https://www.ucl.ac.uk/priment/&#34;&gt;PRIMENT&lt;/a&gt;, which by the way is advertising a new health economist &lt;a href=&#34;https://www.jobs.ac.uk/job/BWK840/research-fellow-in-health-economics&#34;&gt;job vacancy&lt;/a&gt; for those who might be interested. 
Other tasks include writing down and code a decision model on which I have been working since ages, papers review, other collaborations with different people, starting my co-supervison for a new PhD student at stats and, after I can find some free time, do some reasearch work on my beloved missing data. 
Am I ready? not sure about that &amp;hellip;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/fy0gLJtIkZj8I/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Conferences updates and news</title>
      <link>/post/update2-october/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/update2-october/</guid>
      <description>&lt;p&gt;Just a quick update about some talks I gave/am about to give to advertise my research work. The one in Brighton, which I gave a couple of weeks a go at &lt;a href=&#34;https://ictmc2019.com/&#34;&gt;ICTMC&lt;/a&gt;, went really well and I was glad to hear that some people were very interested in what I presented. For more info, here a &lt;a href=&#34;https://www.luminpdf.com/viewer/5daad5f7ad8625001932b9a4&#34;&gt;link&lt;/a&gt; to my presentation about missing data methods for trial-based economic evaluations that I discussed.
Honestly, since the conference was mainly directed towards people working in clinical trials, I did not expect a huge interest in the use of Bayesian methods for economic evaluations, but apparently (and I am happy about that) I was wrong.&lt;/p&gt;
&lt;p&gt;I had the chance to chat a bit with few people that I did not know, including &lt;a href=&#34;http://www.bristol.ac.uk/social-community-medicine/people/william-hollingworth/overview.html&#34;&gt;William Hollingworth&lt;/a&gt; from Bristol and &lt;a href=&#34;https://www.ndorms.ox.ac.uk/team/ines-rombach&#34;&gt;Ines Rombach&lt;/a&gt; from Oxford, with whom I had very nice conversations about my work and other interesting topics.
I was also glad to meet some known faces, including the always lovely &lt;a href=&#34;https://cheme.bangor.ac.uk/CatrinPlumptonBiography.php&#34;&gt;Catrin Plumpton&lt;/a&gt; from Bangor University, who I met for the first time at HESG this summer and with whom I share the interest in missing data methods (even though she is a STATA and multiple imputation user, sadly). 
I am also glad that I met my previous PhD secondary supervisor, &lt;a href=&#34;https://www.lshtm.ac.uk/aboutus/people/mason.alexina&#34;&gt;Alexina Mason&lt;/a&gt;, with whom it is always a pleasure to talk with. Unfortunately, we both missed the talk of each other becuase of time problems but it was good to catch up with her again. I am also sad that I could
not attend &lt;a href=&#34;https://www.lshtm.ac.uk/aboutus/people/leurent.baptiste&#34;&gt;Baptiste&lt;/a&gt;&amp;lsquo;s presentation which was the last day of the conference (I had to leave the same day of my talk, the first day) and I was not also able to actually meet him. I hope we will be able to see him soon at some other conference in the near future.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/YATNr2oXRo0IE/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Given this past experience, I am now looking forward to meet new people at my next conference at the Bella Center in Copenhagen (thumbnail) where this year &lt;a href=&#34;https://www.ispor.org/conferences-education/conferences/upcoming-conferences/ispor-europe-2019&#34;&gt;ISPOR Europe 2019&lt;/a&gt; will be held. However, I believe this will be a much larger conference and therefore I will probably not have many chances to talk with people as I did at ICTMC.
Plus I am only preseting a poster this time, so it will be less likely that some people will actually notice my work, especially given the typically huge amount of presenters of this type of conferences. In the wrost case, I will enjoy Copenhagen and meet up with some old friends who live in Denmark and who will come at ISPOR to present some other work.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>More good news...</title>
      <link>/post/update-october/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/update-october/</guid>
      <description>&lt;p&gt;I have got two news coming up. First, the paper I wrote with Michael and Gianluca on Bayesian methdos for longitudinal data in trial-based economic evaluations has finally been published as early view on &lt;a href=&#34;https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssa.12522&#34;&gt;JRSSA&lt;/a&gt;. As I said in some earlier posts, I am super happy about this collaboration and I hope I can continue working on similar projects in the future.&lt;/p&gt;
&lt;p&gt;Second, I will soon give a talk about this work at the &lt;a href=&#34;https://ictmc2019.com/&#34;&gt;ICTMC&lt;/a&gt; conference in Brighton, next Monday. This will be the first time at this conference and unfortunately I will only be able to remain around for one day as I need to go back to London pretty soon. I hope I will be able to enjoy my day at the conference, even though I will miss the talks of &lt;a href=&#34;https://www.lshtm.ac.uk/aboutus/people/leurent.baptiste&#34;&gt;Baptiste&lt;/a&gt; and &lt;a href=&#34;https://www.lshtm.ac.uk/aboutus/people/mason.alexina&#34;&gt;Alexina&lt;/a&gt; which are scheduled for the last day of the conference. I hope I can at least have a quick chat with them the day I am around.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/efDT7dqlF5N2LVHG8C/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I am also excited to visit &lt;a href=&#34;https://en.wikipedia.org/wiki/Brighton&#34;&gt;Brighton&lt;/a&gt;, since many people keep telling me that I should go and visit this sort of british version of &amp;ldquo;Rimini&amp;rdquo;. To be honest, I do not expect to find a nice wheather, given that in this period it is raining a lot in London, but I hope I will be lucky and get the only sunny day of the week.&lt;/p&gt;
&lt;p&gt;Finally, I have started a rubric called &lt;a href=&#34;https://agabrioblog.onrender.com/missingdata/&#34;&gt;missing data&lt;/a&gt; on my website, where I try to describe some of the most popular methods to handle missing data and to provide some references for anyone who could be interested in this field. I am really fascinated by statistical methods for dealing with missingness, perhaps because it was the main focus of my PhD, but I am eager to review different methods and see if I can find something really interesting. Of course, to complete this it will take more time, which I hope I will be able to find in the next months.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MissingHE 1.2.1</title>
      <link>/post/missinghe-version121/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/missinghe-version121/</guid>
      <description>&lt;p&gt;I have finally found some time to update the version for my R package &lt;a href=&#34;https://agabrioblog.onrender.com/missingHE/&#34;&gt;missingHE&lt;/a&gt;, for which version 1.2.1 is now available on &lt;a href=&#34;https://cran.r-project.org/web/packages/missingHE/&#34;&gt;CRAN&lt;/a&gt;. 
I included two main features to the previous version of the package.&lt;/p&gt;
&lt;p&gt;First, I have added a new type of identifying restriction when fitting pattern mixture models through the function &amp;ldquo;pattern&amp;rdquo;. Before, only the complete case
restriction was available, which identifies the distributions of the missing data with those from the completers. Now the alternative available case restriction is can also be selected, which relies on the distributions that can be identified 
among the non-completers to identify the distributions of the missing data. In this way, people can choose among at least two options for the type of restrictions and compare how this choice may affect the final estimates.&lt;/p&gt;
&lt;p&gt;Second, I added a new accessory function called &amp;ldquo;ppc&amp;rdquo;, which allows to perform posterior predictive checks using the conditional parameters saved from the fitted model to generate replications of the data at each posterior iteration of the model.
The function implements a relatively large number of checks, mostly taken from the R package &lt;a href=&#34;https://cran.r-project.org/web/packages/bayesplot/&#34;&gt;bayesplot&lt;/a&gt;, which allow to assess the fit of the model to the observed data by type of outcome (effects and costs) and treatment group (control and intervention).
For example, overalyed density plots can be generated to compare the empirical and replicated densities of the data to detect possible failures of the model.&lt;/p&gt;



  




&lt;figure&gt;

&lt;img src=&#34;/img/plotec.png&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;Density plots for the observed and replicated data&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;I feel this is very important as when fitting a Bayesian model it is crucial to assess whether the model seems to adequately capture the different characteristics of the observed data (e.g. skewness, structural values, etc.). 
A wide range of predictive checks are available, including histograms (see thumbnail pciture), scatterplots, error intervals, empirical cumulative distribution fucntions, statistcis of interest and many others. In addition ,
these checks can be performed for each type of missingness model and parametric distribution chosen within missingHE.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/NEvPzZ8bd1V4Y/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Of course, it is important to remember that, when dealing with missing data the fit of the model can only be checked with respect to the observed values and therefore this 
check is only partial since the fit to the unibserved values can never be checked. This is also why it is not meaningful to assess the fit of a model fitted under a missing not at random assumption
because this is based on information which is not directly available from the data at hand and thus impossible to check.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Discussing my thesis</title>
      <link>/post/update-interview/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/update-interview/</guid>
      <description>&lt;p&gt;I have been kindly invited by the amazing person &lt;a href=&#34;https://www.ohe.org/about-us/meet-team/chris-sampson&#34;&gt;Chris Sampson&lt;/a&gt; to talk about the work I inlcuded in my PhD thesis for his monthly rubric entitled  &amp;ldquo;Thesis Thursday&amp;rdquo; on the &lt;a href=&#34;https://aheblog.com/&#34;&gt;The Academic Health Economists blog&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I happily accepted Chris&amp;rsquo;s invitation as I beleive this initiative is really interesting and represents a nice way for newly graduated PhD students to advertise their work while also giving the chance to people interested in health economics to read about some academic work which is typically freely available to everyone.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://aheblog.com/2019/09/19/thesis-thursday-andrea-gabrio/&#34;&gt;Here&lt;/a&gt; you can find the full interview, which is not very long and resolves around 5 questions that Chris asked me about my work. I already new this blog but I have never had a proper chance to read through its posts carefully, which is a shame.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/13lTgtSUmqMrlu/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I shall promise myself to try to check it more often from now on, using this interview as a nice motivation to do so.
In fact, there are not many blogs around health economics matters (here a &lt;a href=&#34;https://blog.feedspot.com/health_economics_blogs/&#34;&gt;non-comprehensive list&lt;/a&gt;), among which The Academic Health Economists and &lt;a href=&#34;http://www.statistica.it/gianluca/blog/&#34;&gt;Gianluca&amp;rsquo;s blog&lt;/a&gt; are my favourites.&lt;/p&gt;
&lt;p&gt;I hope I will be able to find some time to write some nice posts about some health economic applications of my work in the next future as this is still the most interesting field for me at the moment. I am also the maintainer of another small blog called the &lt;a href=&#34;https://hearteam.blogspot.com/&#34;&gt;Health Economics Analysis and Research Methods Team (HEART) blog&lt;/a&gt;, where I occasionally write some posts on health economics together with my colleagues from the UCL department of &lt;a href=&#34;https://www.ucl.ac.uk/epidemiology-health-care/research/pcph&#34;&gt;Primary Care and Population Health&lt;/a&gt;. The blog is still new but I hope it can become more active in the next months.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Some good news...</title>
      <link>/post/update-september/</link>
      <pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/update-september/</guid>
      <description>&lt;p&gt;With the approaching of the new academic here I have received some good news for my most recently submitted paper on Bayesian parametric modelling in health economics for missing longitudinal data, which at the moment is only available on &lt;a href=&#34;https://arxiv.org/abs/1805.07147&#34;&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am happy to announce that, after a couple of rounds of reviews, the paper has been finally accepted for publication in &lt;a href=&#34;https://rss.onlinelibrary.wiley.com/journal/1467985X&#34;&gt;JSS: Series A&lt;/a&gt;. I believe that the reviewers provided a very nice feedback for improving the work and I am quite satisfied with the final version of the article which, I hope, will be of interest for anyone involved in the analsysi of partially-observed longitudinal data. I hope the pre-print of the paper will be available soon and I will &amp;ldquo;advertise&amp;rdquo; my work in two conferences in the next couple of months, where I will present the content of the paper, namely &lt;a href=&#34;https://ictmc2019.com/&#34;&gt;ICTMC&lt;/a&gt; this October in Brighton, and &lt;a href=&#34;http://www.ispor.org/conferences-education/conferences/upcoming-conferences/ispor-europe-2019&#34;&gt;ISPOR Europe&lt;/a&gt; this November in Copenhagen.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/vMEjhlxsBR7Fe/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I am really excited about this paper which represented the last part of my PhD thesis and on which I worked really hard in the last year of my studies. &lt;a href=&#34;https://agabrioblog.onrender.com/project/missing-data/&#34;&gt;Here&lt;/a&gt; you can find a general summary of the content of the article, while &lt;a href=&#34;https://www.ucl.ac.uk/statistics/sites/statistics/files/presentation_priment_1.pdf&#34;&gt;here&lt;/a&gt; there are some slides that describe the main idea behind the proposed model.&lt;/p&gt;
&lt;p&gt;I just want to conlcude with some thanks with my co-authors of the paper, &lt;a href=&#34;http://users.stat.ufl.edu/~daniels/&#34;&gt;Michael&lt;/a&gt; and &lt;a href=&#34;https://www.ucl.ac.uk/statistics/people/gianlucabaio&#34;&gt;Ginaluca&lt;/a&gt;, without whom I would have not been able to write this paper. This was my first work with Mike, with whom I had a wonderful collaboration and I was able to visit the beatiful city of &lt;a href=&#34;https://en.wikipedia.org/wiki/Gainesville,_Florida&#34;&gt;Gainesville&lt;/a&gt; (FL) during my first visiting period at the &lt;a href=&#34;https://www.ufl.edu/&#34;&gt;University of Florida&lt;/a&gt; (see thumbnail picture). I hope this will be the first of many works together in the furture!.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The P value fallacy</title>
      <link>/post/p-value-fallacy/</link>
      <pubDate>Sat, 03 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/p-value-fallacy/</guid>
      <description>&lt;p&gt;Today, I would like to briefly comment an interesting research article written by &lt;a href=&#34;https://jhu.pure.elsevier.com/en/publications/toward-evidence-based-medical-statistics-1-the-p-value-fallacy-4&#34;&gt;Goodman&lt;/a&gt;, who provided a clear and exemplary discussion about the typical incorrect interpretation of a standard frequentist analysis in the field of medical research. I will now briefly summarise the main argument of the paper and then add some personal comments.&lt;/p&gt;
&lt;p&gt;Essentially, the article describes the characteristics of the dominant school of medical statistics and highlights the logical fallacy at the heart of the typical frequentist analysis in clinical studies. This is based on a &lt;em&gt;deductive&lt;/em&gt; inferential approach, which starts with a given hypothesis and makes conclusions under the assumption that the hypothesis is true. This is in contrast with a &lt;em&gt;inductive&lt;/em&gt; approach, which uses the observed evidence to evaluate what hypothesis is most tenable. The two most popular methods of the frequentist paradigm are the &lt;em&gt;P value&lt;/em&gt; proposed by &lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_6&#34;&gt;Fisher&lt;/a&gt; and the &lt;em&gt;hypothesis testing&lt;/em&gt; developed by &lt;a href=&#34;https://royalsocietypublishing.org/doi/abs/10.1098/rsta.1933.0009?casa_token=sbSkualIaPYAAAAA%3ACxPsFTFEUK7vaxMPi5dJwUr4HoUWjrkxNh7Hl2q0owjtcU2wJHnakG-Xug7y95v1Tyqbbc8Mymaq_Q&amp;amp;&#34;&gt;Neyman and Pearson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The P value is defined as the probability, under the assumption of no effect (null hypothesis), of obtaining a result equal to or more extreme than what was actually observed. Fisher proposed it as an informal index to be used as a measure of discrepancy between the data and the null hypothesis and therefore should not be interpreted as a formal inferential method. For example, since the P value can only be calculated on the assumption that the null hypothesis is true, it cannot be a direct measure of the probability that the null hypothesis is false. However, the main criticism to the P value is perhaps that it does not take into account the size of the observed effect, i.e. a small effect in a study with a large sample size can have the same P value as a large effect in a small study.&lt;/p&gt;
&lt;p&gt;Hypothesis testing was proposed by Neyman and Pearson as an alternative approach to the P value, which assumes the existence of a null hypothesis (e.g. no effect) and an alternative hypothesis (e.g. nonzero effect). The outcome of the test is then simply to reject one hypothesis in favour of the other, solely based on the data. This exposes the researcher to two types of errors: type I error or false-positive ($\alpha$) and type II error or false-negative ($\beta$) result. Rather than focussing on single experiments, like the P value, hypothesis testing is effectively based on a deductive approach to minimise the errors over a large number of experiments. However, the price to pay to obtain this &lt;em&gt;objectivity&lt;/em&gt; is the impossibility to make any inferential statement about a single experiment. The procedure only guarantees that in the long run, i.e. after considering many experiments, we shall not often be wrong.&lt;/p&gt;
&lt;p&gt;Over time a combination between the P value and hypothesis testing was developed under the assumption that the two approaches can be complementary. The idea was that the P value could be used to measure evidence in a single experiment while not violating the long run logic of hypothesis testing. The combined method is characterized by setting $\alpha$ and power $\beta$ before the experiment, then calculating a P value and rejecting the null hypothesis if the P value is less than the preset type I error rate. This means that the P value is considered a false-positive error rate specific to the data and also a measure of evidence against the null hypothesis. The &lt;strong&gt;P value fallacy&lt;/strong&gt; is born from this statement, which assumes that an event can be seen simultaneously from a long run perspective (where the observed results are put together with other results that might have occurred in hypothetical repetitions of the experiment) and from a short run perspective (where the observed results are interpreted only with respect to the single experiment). However, these views are not reconcilable since a result cannot be at the same time an interchangeable (long-run) and unique (short-run) member of a group of results.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/JszzkKOlV6gTK/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I personally find this discussion fascinating and I believe that it is important to recognise the inconsistencies between the two alternative approaches to inference. The original authors of the two paradigms were well aware of the implications of their methods and never supported the combination of these. However, the combined approach has somehow become widely accepted in practice while its internal inconsistencies and conceptual limitations are hardly recognised.&lt;/p&gt;
&lt;p&gt;I feel that, since the two methods are perceived as &amp;ldquo;objective&amp;rdquo;, it is generally accepted that, if combined, they can produce reliable conclusions. This, however, is not necessarily true. Accepting at face value the significance result as a binary indicator of whether or not a relation is real is dangeroues and potentially misleading. This practice wants to show that conclusions are being drawn directly from the data, without any external influence, because direct inference from data to hypothesis is thought to result in mistaken conclusions only rarely and is therefore regarded as &amp;ldquo;scientific&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;This misguided approach has led to a much stronger emphasis towards the quantitative results alone (without any external input). In contrast, I believe that such perspective has the serious drawback of ignoring potentially useful information which is available (e.g. relevant medical knowledge or historical data) and which should be included in the analysis. Of course, I am aware of the potential issues that may arise from the selection and incorporation of external evidence, but I believe this should not be considered as &amp;ldquo;less reliable&amp;rdquo; or &amp;ldquo;more prone to mistakes&amp;rdquo; compared with the evidence from the available data. It is important that an agreement is reached about the selection of the type of evidence and methods to be used to perform the analysis solely based on their relevance with respect to the context analysed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Super basic introduction to STAN</title>
      <link>/stan/basic-introduction-to-stan/super-basic-introduction-to-stan/</link>
      <pubDate>Wed, 03 Jul 2019 21:13:14 -0500</pubDate>
      
      <guid>/stan/basic-introduction-to-stan/super-basic-introduction-to-stan/</guid>
      <description>


&lt;p&gt;The focus of this simple tutorial is to provide a brief introduction and overview about how to fit Bayesian models using &lt;code&gt;STAN&lt;/code&gt; via &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Prerequisites:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The latest version of &lt;code&gt;R&lt;/code&gt;, which can be downloaded and installed for Windows, Mac or Linux OS from the &lt;a href=&#34;https://www.r-project.org/%7D&#34;&gt;CRAN&lt;/a&gt; website&lt;/li&gt;
&lt;li&gt;I also &lt;strong&gt;strongly&lt;/strong&gt; recommend to download and install &lt;a href=&#34;https://www.rstudio.com/&#34;&gt;Rstudio&lt;/a&gt;, an integrated development environment which provides an “user-friendly” interaction with &lt;code&gt;R&lt;/code&gt; (e.g. many drop-down menus, tabs, customisation options)&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;preliminaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preliminaries&lt;/h1&gt;
&lt;div id=&#34;what-is-stan&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is STAN?&lt;/h2&gt;
&lt;p&gt;Stan provides full Bayesian inference for continuous-variable models through Markov Chain Monte Carlo methods such as the No-U-Turn sampler, an adaptive form of Hamiltonian Monte Carlo sampling&lt;/p&gt;
&lt;p&gt;&lt;code&gt;STAN&lt;/code&gt; is a program for analysis of Bayesian models using Markov Chain Monte Carlo (MCMC) methods (&lt;span class=&#34;citation&#34;&gt;Gelman, Lee, and Guo (2015)&lt;/span&gt;). &lt;code&gt;STAN&lt;/code&gt; is a free software and a probabilistic programming language for specifying statistical models using a specific class of MCMC algorithms known as &lt;strong&gt;H&lt;/strong&gt;amiltonian &lt;strong&gt;M&lt;/strong&gt;onte &lt;strong&gt;C&lt;/strong&gt;arlo methods (HMC). The latest version of &lt;code&gt;STAN&lt;/code&gt; can be dowloaded from the web &lt;a href=&#34;https://mc-stan.org/users/interfaces/&#34;&gt;repository&lt;/a&gt; and is available for different OS. There are different &lt;code&gt;R&lt;/code&gt; packages which function as frontends for &lt;code&gt;STAN&lt;/code&gt;. These packages make it easy to process the output of Bayesian models and present it in publication-ready form. In this brief introduction, I will specifically focus on the &lt;code&gt;rstan&lt;/code&gt; package (&lt;span class=&#34;citation&#34;&gt;Stan Development Team (2018)&lt;/span&gt;) and show how to fit &lt;code&gt;STAN&lt;/code&gt; models using this package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;installing-stan-and-rstan&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installing STAN and rstan&lt;/h2&gt;
&lt;p&gt;Unlike other Bayesian software, such as &lt;code&gt;JAGS&lt;/code&gt; or &lt;code&gt;OpenBUGS&lt;/code&gt;, it is not required to separately install the program and the corresponding frontend &lt;code&gt;R&lt;/code&gt; package. Indeed, installing the &lt;code&gt;R&lt;/code&gt; package &lt;code&gt;rstan&lt;/code&gt; will automatically install &lt;code&gt;STAN&lt;/code&gt; on your machine. However, you will also need to make sure to having installed on your pc a &lt;code&gt;C++&lt;/code&gt; compiler which is used by &lt;code&gt;rstan&lt;/code&gt; to fit the models. Under a Windows OS, for example, this can be done by installing &lt;code&gt;Rtools&lt;/code&gt;, a collection of resources for building packages for &lt;code&gt;R&lt;/code&gt;, which is freely available from the web &lt;a href=&#34;https://cran.r-project.org/bin/windows/Rtools/&#34;&gt;repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Next, install the package &lt;code&gt;rstan&lt;/code&gt; from within &lt;code&gt;R&lt;/code&gt; or &lt;code&gt;Rstudio&lt;/code&gt;, via the package installer or by typing in the command line&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; install.packages(&amp;quot;rstan&amp;quot;, dependencies = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;dependencies = TRUE&lt;/code&gt; option will automatically install all the packages on which the functions in the &lt;code&gt;rstan&lt;/code&gt; package rely.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;basic-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Basic model&lt;/h1&gt;
&lt;div id=&#34;simulate-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulate data&lt;/h2&gt;
&lt;p&gt;For an example dataset, I simulate my own data in &lt;code&gt;R&lt;/code&gt;. I create a continuous outcome variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; as a function of one predictor &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and a disturbance term &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;. I simulate a dataset with 100 observations. Create the error term, the predictor and the outcome using a linear form with an intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; and slope &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; coefficients, i.e.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y = \beta_0 + \beta_1 x + \epsilon  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;R&lt;/code&gt; commands which I use to simulate the data are the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; n_sim=100; set.seed(123)
&amp;gt; x=rnorm(n_sim, mean = 5, sd = 2)
&amp;gt; epsilon=rnorm(n_sim, mean = 0, sd = 1)
&amp;gt; beta0=1.5
&amp;gt; beta1=1.2
&amp;gt; y=beta0 + beta1 * x + epsilon
&amp;gt; n_sim=as.integer(n_sim)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, I define all the data for &lt;code&gt;STAN&lt;/code&gt; in a list object&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; datalist=list(&amp;quot;y&amp;quot;=y,&amp;quot;x&amp;quot;=x,&amp;quot;n_sim&amp;quot;=n_sim)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-file&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model file&lt;/h2&gt;
&lt;p&gt;Now, I write the model for &lt;code&gt;STAN&lt;/code&gt; and save it as a stan file named &lt;code&gt;&#34;basic.mod.stan&#34;&lt;/code&gt; in the current working directory&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; basic.mod= &amp;quot;
+ data {
+ int&amp;lt;lower=0&amp;gt; n_sim;
+ vector[n_sim] y;
+ vector[n_sim] x;
+ }
+ parameters {
+ real beta0;
+ real beta1;
+ real&amp;lt;lower=0&amp;gt; sigma;
+ }
+ transformed parameters {
+ vector[n_sim] mu;
+ mu=beta0 + beta1*x;
+ } 
+ model {
+ sigma~uniform(0,100);
+ beta0~normal(0,1000);
+ beta1~normal(0,1000);
+ y~normal(mu,sigma);
+ }
+ 
+ &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;STAN&lt;/code&gt; models are written using an imperative programming language, which means that the order in which you write the elements in your model file matters, i.e. you first need to define your variables (e.g. integers, vectors, matrices, etc.), the constraints which define the range of values your variable can take (e.g. only positive values for standard deviations), and finally define the relationship among the variables (e.g. one is a liner function of another).&lt;/p&gt;
&lt;p&gt;A Stan model is defined by six program blocks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data (required). The &lt;em&gt;data block&lt;/em&gt; reads external information – e.g. data vectors, matrices, integers, etc.&lt;/li&gt;
&lt;li&gt;Transformed data (optional). The &lt;em&gt;transformed data block&lt;/em&gt; allows for preprocessing of the data – e.g. transformation or rescaling of the data.&lt;/li&gt;
&lt;li&gt;Parameters (required). The &lt;em&gt;parameters block&lt;/em&gt; defines the sampling space – e.g. parameters to which prior distributions must be assigned.&lt;/li&gt;
&lt;li&gt;Transformed parameters (optional). The &lt;em&gt;transformed parameters block&lt;/em&gt; allows for parameter processing before the posterior is computed – e.g. tranformation or rescaling of the parameters.&lt;/li&gt;
&lt;li&gt;Model (required). In the &lt;em&gt;model block&lt;/em&gt; we define our posterior distributions – e.g. choice of distributions for all variables.&lt;/li&gt;
&lt;li&gt;Generated quantities (optional). The &lt;em&gt;generated quantities block&lt;/em&gt; allows for postprocessing – e.g. backtranformation of the parameters using the posterior samples.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For this introduction I consider a very simple model which only requires the specification of four blocks in the &lt;code&gt;STAN&lt;/code&gt; model. In the data block, I first define the size of the sample &lt;code&gt;n_sim&lt;/code&gt; as a positive integer number using the expression &lt;code&gt;int&amp;lt;lower=0&amp;gt; n_sim&lt;/code&gt;; then I declare the two variables &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;x&lt;/code&gt; as reals (or vectors) with length equal to N. In the parameters block, I define the coefficients for the linear regression &lt;code&gt;beta0&lt;/code&gt; and &lt;code&gt;beta1&lt;/code&gt; (as two real numbers) and the standard deviation parameter &lt;code&gt;sigma&lt;/code&gt; (as a positive real number). In the transformed parameters block, I define the conditional mean &lt;code&gt;mu&lt;/code&gt; (a real vector of length &lt;code&gt;N&lt;/code&gt;) as a linear function of the intercept &lt;code&gt;beta0&lt;/code&gt;, the slope &lt;code&gt;beta1&lt;/code&gt;, and the covariate &lt;code&gt;x&lt;/code&gt;. Finally, in the model block, I assign weakly informative priors to the regression coefficients and the standard deviation parameters, and I model the outcome data &lt;code&gt;y&lt;/code&gt; using a normal distribution indexed by the conditional mean &lt;code&gt;mu&lt;/code&gt; and the standard deviation &lt;code&gt;sigma&lt;/code&gt; parameters. In many cases, &lt;code&gt;STAN&lt;/code&gt; uses sampling statements which can be vectorised, i.e. you do not need to use for loop statements.&lt;/p&gt;
&lt;p&gt;To write and save the model as the text file “basic.mod.stan” in the current working directory, I use the &lt;code&gt;writeLines&lt;/code&gt; function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; writeLines(basic.mod, &amp;quot;basic.mod.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pre-processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pre-processing&lt;/h2&gt;
&lt;p&gt;Define the parameters whose posterior distribtuions we are interested in summarising later and set up the initial values for the MCMC sampler in &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params=c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;)
&amp;gt; inits=function(){list(&amp;quot;beta0&amp;quot;=rnorm(1), &amp;quot;beta1&amp;quot;=rnorm(1))}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function creates a list that contains one element for each parameter, which gets assigned a random draw from a normal distribution as a strating value for each chain in the model. For simple models like this, it is generally easy to define the intial values for all parameters in the object &lt;code&gt;inits&lt;/code&gt; which is then passed to the &lt;code&gt;stan&lt;/code&gt; function in &lt;code&gt;rstan&lt;/code&gt;. However, for more complex models, this may not be immediate and a lot of trial and error may be required. However, &lt;code&gt;STAN&lt;/code&gt; can automatically select the initial values for all parameters randomly. This can be achieved by setting &lt;code&gt;inits=&#34;random&#34;&lt;/code&gt;, which is then passed to the &lt;code&gt;stan&lt;/code&gt; function in &lt;code&gt;rstan&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Before using &lt;code&gt;rstan&lt;/code&gt; for the first time, you need to load the package, and you may want to set a random seed number for making your estimates replicable&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(rstan)
&amp;gt; set.seed(123)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit the model&lt;/h2&gt;
&lt;p&gt;Now, we can fit the model in &lt;code&gt;STAN&lt;/code&gt; using the &lt;code&gt;stan&lt;/code&gt; function in the &lt;code&gt;rstan&lt;/code&gt; package and save it in the object &lt;code&gt;basic.mod&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; basic.mod&amp;lt;-stan(data = datalist, pars = params, iter = 9000, 
+   warmup = 1000, init = inits, chains = 2, file = &amp;quot;basic.mod.stan&amp;quot;)

SAMPLING FOR MODEL &amp;#39;basic&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 9000 [  0%]  (Warmup)
Chain 1: Iteration:  900 / 9000 [ 10%]  (Warmup)
Chain 1: Iteration: 1001 / 9000 [ 11%]  (Sampling)
Chain 1: Iteration: 1900 / 9000 [ 21%]  (Sampling)
Chain 1: Iteration: 2800 / 9000 [ 31%]  (Sampling)
Chain 1: Iteration: 3700 / 9000 [ 41%]  (Sampling)
Chain 1: Iteration: 4600 / 9000 [ 51%]  (Sampling)
Chain 1: Iteration: 5500 / 9000 [ 61%]  (Sampling)
Chain 1: Iteration: 6400 / 9000 [ 71%]  (Sampling)
Chain 1: Iteration: 7300 / 9000 [ 81%]  (Sampling)
Chain 1: Iteration: 8200 / 9000 [ 91%]  (Sampling)
Chain 1: Iteration: 9000 / 9000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.078 seconds (Warm-up)
Chain 1:                0.593 seconds (Sampling)
Chain 1:                0.671 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;basic&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 9000 [  0%]  (Warmup)
Chain 2: Iteration:  900 / 9000 [ 10%]  (Warmup)
Chain 2: Iteration: 1001 / 9000 [ 11%]  (Sampling)
Chain 2: Iteration: 1900 / 9000 [ 21%]  (Sampling)
Chain 2: Iteration: 2800 / 9000 [ 31%]  (Sampling)
Chain 2: Iteration: 3700 / 9000 [ 41%]  (Sampling)
Chain 2: Iteration: 4600 / 9000 [ 51%]  (Sampling)
Chain 2: Iteration: 5500 / 9000 [ 61%]  (Sampling)
Chain 2: Iteration: 6400 / 9000 [ 71%]  (Sampling)
Chain 2: Iteration: 7300 / 9000 [ 81%]  (Sampling)
Chain 2: Iteration: 8200 / 9000 [ 91%]  (Sampling)
Chain 2: Iteration: 9000 / 9000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.078 seconds (Warm-up)
Chain 2:                0.594 seconds (Sampling)
Chain 2:                0.672 seconds (Total)
Chain 2: &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Different packages are available to perform diagnostic checks for Bayesian models. Here, I install and load the &lt;code&gt;bayesplot&lt;/code&gt; package (&lt;span class=&#34;citation&#34;&gt;Gabry and Mahr (2017)&lt;/span&gt;) to obtain graphical diagnostics and results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; install.packages(&amp;quot;bayesplot&amp;quot;)
&amp;gt; library(bayesplot)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, density and trace plots can be obtained by typing&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_combo(as.array(basic.mod),regex_pars=&amp;quot;beta0|beta1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/basic-introduction-to-stan/2018-07-06-super-basic-introduction-to-stan_files/figure-html/diagnostic3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both types of graphs suggest that there are not issues in the convergence of the algorithm (smooth normal densities and hairy caterpillar graphs for both MCMC chains).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;This tutorial was simply a brief introduction on how simple linear regression models can be fitted using the Bayesian software &lt;code&gt;STAN&lt;/code&gt; via the &lt;code&gt;rstan&lt;/code&gt; package. Although this may seem a complex procedure compared with simply fitting a linear model under the frequentist framework, however, the real advantages of Bayesian methods become evident when the complexity of the analysis is increased (which is often the case in real applications). Indeed, the flexibility in Bayesian modelling allows to account for increasingly complex models in a relatively easy way. In addition, Bayesian methods are ideal when the interest is in taking into account the potential impact that different sources of uncertainty may have on the final results, as they allow the natural propagation of uncertainty throughout each quantity in the model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-gabry2017bayesplot&#34;&gt;
&lt;p&gt;Gabry, J, and T Mahr. 2017. “Bayesplot: Plotting for Bayesian Models.” &lt;em&gt;R Package Version&lt;/em&gt; 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2015stan&#34;&gt;
&lt;p&gt;Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt; 40 (5): 530–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanpackage&#34;&gt;
&lt;p&gt;Stan Development Team. 2018. “RStan: The R Interface to Stan.” &lt;a href=&#34;http://mc-stan.org/&#34;&gt;http://mc-stan.org/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Super basic introduction to OpenBUGS</title>
      <link>/openbugs/basic-introduction-to-openbugs/super-basic-introduction-to-openbugs/</link>
      <pubDate>Tue, 02 Jul 2019 21:11:14 -0500</pubDate>
      
      <guid>/openbugs/basic-introduction-to-openbugs/super-basic-introduction-to-openbugs/</guid>
      <description>


&lt;p&gt;The focus of this simple tutorial is to provide a brief introduction and overview about how to fit Bayesian models using &lt;code&gt;OpenBUGS&lt;/code&gt; via &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Prerequisites:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The latest version of &lt;code&gt;R&lt;/code&gt;, which can be downloaded and installed for Windows, Mac or Linux OS from the &lt;a href=&#34;https://www.r-project.org/%7D&#34;&gt;CRAN&lt;/a&gt; website&lt;/li&gt;
&lt;li&gt;I also &lt;strong&gt;strongly&lt;/strong&gt; recommend to download and install &lt;a href=&#34;https://www.rstudio.com/&#34;&gt;Rstudio&lt;/a&gt;, an integrated development environment which provides an “user-friendly” interaction with &lt;code&gt;R&lt;/code&gt; (e.g. many drop-down menus, tabs, customisation options)&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;preliminaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preliminaries&lt;/h1&gt;
&lt;div id=&#34;what-is-openbugs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is OpenBUGS?&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;OpenBUGS&lt;/code&gt; is a program for analysis of Bayesian models using Markov Chain Monte Carlo (MCMC) methods (&lt;span class=&#34;citation&#34;&gt;Spiegelhalter et al. (2007)&lt;/span&gt;). &lt;code&gt;OpenBUGS&lt;/code&gt; is a free software based on the &lt;strong&gt;B&lt;/strong&gt;ayesian inference &lt;strong&gt;U&lt;/strong&gt;sing &lt;strong&gt;G&lt;/strong&gt;ibbs &lt;strong&gt;S&lt;/strong&gt;ampling (informally &lt;code&gt;BUGS&lt;/code&gt;) language at the base of &lt;code&gt;WinBUGS&lt;/code&gt; but, unlike this program, is platform independent. The latest version of &lt;code&gt;OpenBUGS&lt;/code&gt; can be dowloaded from the web &lt;a href=&#34;http://www.openbugs.net/w/FrontPage&#34;&gt;repository&lt;/a&gt; and is available for different OS. There are different &lt;code&gt;R&lt;/code&gt; packages which function as frontends for &lt;code&gt;OpenBUGS&lt;/code&gt;. These packages make it easy to process the output of Bayesian models and present it in publication-ready form. In this brief introduction, I will specifically focus on the &lt;code&gt;R2OpenBUGS&lt;/code&gt; package (&lt;span class=&#34;citation&#34;&gt;Sturtz, Ligges, and Gelman (2010)&lt;/span&gt;) and show how to fit &lt;code&gt;OpenBUGS&lt;/code&gt; models using this package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;installing-openbugs-and-r2openbugs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installing OpenBUGS and R2OpenBUGS&lt;/h2&gt;
&lt;p&gt;Install the latest version of &lt;code&gt;OpenBUGS&lt;/code&gt; for your OS. Next, install the package &lt;code&gt;R2OpenBUGS&lt;/code&gt; from within &lt;code&gt;R&lt;/code&gt; or &lt;code&gt;Rstudio&lt;/code&gt;, via the package installer or by typing in the command line&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; install.packages(&amp;quot;R2OpenBUGS&amp;quot;, dependencies = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;dependencies = TRUE&lt;/code&gt; option will automatically install all the packages on which the functions in the &lt;code&gt;R2OpenBUGS&lt;/code&gt; package rely.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;basic-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Basic model&lt;/h1&gt;
&lt;div id=&#34;simulate-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulate data&lt;/h2&gt;
&lt;p&gt;For an example dataset, I simulate my own data in &lt;code&gt;R&lt;/code&gt;. I create a continuous outcome variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; as a function of one predictor &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and a disturbance term &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;. I simulate a dataset with 100 observations. Create the error term, the predictor and the outcome using a linear form with an intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; and slope &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; coefficients, i.e.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y = \beta_0 + \beta_1 x + \epsilon  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;R&lt;/code&gt; commands which I use to simulate the data are the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; n.sim=100; set.seed(123)
&amp;gt; x=rnorm(n.sim, mean = 5, sd = 2)
&amp;gt; epsilon=rnorm(n.sim, mean = 0, sd = 1)
&amp;gt; beta0=1.5
&amp;gt; beta1=1.2
&amp;gt; y=beta0 + beta1 * x + epsilon&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, I define all the data for &lt;code&gt;JAGS&lt;/code&gt; in a list object&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; datalist=list(&amp;quot;y&amp;quot;,&amp;quot;x&amp;quot;,&amp;quot;n.sim&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-file&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model file&lt;/h2&gt;
&lt;p&gt;Now, I write the model for &lt;code&gt;OpenBUGS&lt;/code&gt; and save it as a text file named &lt;code&gt;&#34;basicmodbugs.txt&#34;&lt;/code&gt; in the current working directory&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; basic.mod= &amp;quot;
+ model {
+ #model
+  for(i in 1:n.sim){
+   y[i] ~ dnorm(mu[i], tau)
+   mu[i] &amp;lt;- beta0 + beta1 * x[i]
+  }
+ #priors
+ beta0 ~ dnorm(0, 0.01)
+ beta1 ~ dnorm(0, 0.01)
+ tau ~ dgamma(0.01,0.01)
+ }
+ &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The part of the model inside the for loop denotes the likelihood, which is evaluated for each individual in the sample using a Normal distribution parameterised by some mean &lt;code&gt;mu&lt;/code&gt; and precision &lt;code&gt;tau&lt;/code&gt; (where, precision = 1/variance). The covariate &lt;code&gt;x&lt;/code&gt; is included at the mean level using a linear regression, which is indexed by the intercept &lt;code&gt;beta0&lt;/code&gt; and slope &lt;code&gt;beta1&lt;/code&gt; terms. The second part defines the prior distributions for all parameters of the model, namely the regression coefficients and the precision. Weakly informative priors are used since I assume that I do not have any prior knowledge about these parameters.&lt;/p&gt;
&lt;p&gt;To write and save the model as the text file “basicmodbugs.txt” in the current working directory, I use the &lt;code&gt;writeLines&lt;/code&gt; function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; writeLines(basic.mod, &amp;quot;basicmodbugs.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pre-processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pre-processing&lt;/h2&gt;
&lt;p&gt;Define the parameters whose posterior distribtuions we are interested in summarising later and set up the initial values for the MCMC sampler in &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params=c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;)
&amp;gt; inits=function(){list(&amp;quot;beta0&amp;quot;=rnorm(1), &amp;quot;beta1&amp;quot;=rnorm(1), &amp;quot;tau&amp;quot;=rgamma(1,1,1))}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function creates a list that contains one element for each parameter, which gets assigned a random draw from a normal distribution as a strating value for each chain in the model. For simple models like this, it is generally easy to define the intial values for all parameters in the object &lt;code&gt;inits&lt;/code&gt; which is then passed to the &lt;code&gt;bugs&lt;/code&gt; function in &lt;code&gt;R2OpenBUGS&lt;/code&gt;. However, for more complex models, this may not be immediate and a lot of trial and error may be required.&lt;/p&gt;
&lt;p&gt;Before using &lt;code&gt;R2OpenBUGS&lt;/code&gt; for the first time, you need to load the package, and you may want to set a random seed number for making your estimates replicable&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2OpenBUGS)
&amp;gt; set.seed(123)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit the model&lt;/h2&gt;
&lt;p&gt;Now, we can fit the model in &lt;code&gt;OpenBUGS&lt;/code&gt; using the &lt;code&gt;bugs&lt;/code&gt; function in the &lt;code&gt;R2openBUGS&lt;/code&gt; package and save it in the object &lt;code&gt;basic.mod&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; basic.mod.bugs=bugs(data = datalist, inits = inits, 
+   parameters.to.save = params, n.chains = 2, n.iter = 2000,
+   n.burnin = 1000, model.file = &amp;quot;basicmodbugs.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While the model is running, the function prints out some information related to the Bayesian graph (corresponding to the specification used for the model) underneath &lt;code&gt;OpenBUGS&lt;/code&gt;, such as number of observed and unobserved nodes and graph size.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;post-processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Post-processing&lt;/h2&gt;
&lt;p&gt;Once the model has finished running, a summary of the posteiror estimates and convergence diagnostics for all parameters specified can be seen by typing &lt;code&gt;print(basic.mod)&lt;/code&gt; or, alternatively,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(basic.mod.bugs$summary)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;          mean    sd   2.5%   25%   50%   75% 97.5% Rhat n.eff
beta0      1.5 0.293   0.99   1.3   1.5   1.7   2.1    1  1700
beta1      1.2 0.053   1.06   1.1   1.2   1.2   1.3    1  2000
deviance 278.8 2.439 276.00 277.1 278.2 280.0 285.2    1  2000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The posterior distribution of each parameter is summarised in terms of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The mean, sd and some percentiles&lt;/li&gt;
&lt;li&gt;Potential scale reduction factor &lt;code&gt;Rhat&lt;/code&gt; and effective sample size &lt;code&gt;n.eff&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman (2013)&lt;/span&gt;). The first is a measure to assess issues in convergence of the MCMC algorithm (typically a value below &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; for all parameters is considered ok). The second is a measure which assesses the adequacy of the posterior sample (typically values close to the total number of iterations are desirable for all parameters).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The deviance is a goodness of fit statistic and is used in the construction of the “Deviance Information Criterion” or DIC (&lt;span class=&#34;citation&#34;&gt;Spiegelhalter et al. (2014)&lt;/span&gt;), which is a &lt;em&gt;relative&lt;/em&gt; measure of model comparison. The DIC of the model can be accessed by typing&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; basic.mod.bugs$DIC
[1] 282&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;diagnostics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Diagnostics&lt;/h2&gt;
&lt;p&gt;More diagnostics are available when we convert the model output into an MCMC object using the command&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; install.packages(&amp;quot;coda&amp;quot;)
&amp;gt; library(coda)
&amp;gt; basic.mod.mcmc.bugs=as.mcmc.list(basic.mod.bugs)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Different packages are available to perform diagnostic checks for Bayesian models. Here, I install and load the &lt;code&gt;mcmcplots&lt;/code&gt; package (&lt;span class=&#34;citation&#34;&gt;Curtis (2015)&lt;/span&gt;) to obtain graphical diagnostics and results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; install.packages(&amp;quot;mcmcplots&amp;quot;)
&amp;gt; library(mcmcplots)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, density and trace plots can be obtained by typing&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(basic.mod.mcmc.bugs, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/OpenBUGS/basic-introduction-to-openbugs/2018-07-23-super-basic-introduction-to-openbugs_files/figure-html/diagnostic3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(basic.mod.mcmc.bugs, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/OpenBUGS/basic-introduction-to-openbugs/2018-07-23-super-basic-introduction-to-openbugs_files/figure-html/diagnostic3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both types of graphs suggest that there are not issues in the convergence of the algorithm (smooth normal densities and hairy caterpillar graphs for both MCMC chains).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;This tutorial was simply a brief introduction on how simple linear regression models can be fitted using the Bayesian software &lt;code&gt;OpenBUGS&lt;/code&gt; via the &lt;code&gt;R2OpenBUGS&lt;/code&gt; package. Although this may seem a complex procedure compared with simply fitting a linear model under the frequentist framework, however, the real advantages of Bayesian methods become evident when the complexity of the analysis is increased (which is often the case in real applications). Indeed, the flexibility in Bayesian modelling allows to account for increasingly complex models in a relatively easy way. In addition, Bayesian methods are ideal when the interest is in taking into account the potential impact that different sources of uncertainty may have on the final results, as they allow the natural propagation of uncertainty throughout each quantity in the model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-curtis2015mcmcplots&#34;&gt;
&lt;p&gt;Curtis, SM. 2015. “Mcmcplots: Create Plots from Mcmc Output.” &lt;em&gt;R Package Version 0.4&lt;/em&gt; 2.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2013bayesian&#34;&gt;
&lt;p&gt;Gelman, Andrew. 2013. &lt;em&gt;Bayesian Data Analysis&lt;/em&gt;. Chapman; Hall/CRC.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-spiegelhalter2014deviance&#34;&gt;
&lt;p&gt;Spiegelhalter, David J, Nicola G Best, Bradley P Carlin, and Angelika Van Der Linde. 2014. “The Deviance Information Criterion: 12 Years on.” &lt;em&gt;Journal of the Royal Statistical Society: Series B (Statistical Methodology)&lt;/em&gt; 76 (3): 485–93.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-spiegelhalter2007openbugs&#34;&gt;
&lt;p&gt;Spiegelhalter, David, Andrew Thomas, Nicky Best, and Dave Lunn. 2007. “OpenBUGS User Manual, Version 3.0. 2.” &lt;em&gt;MRC Biostatistics Unit, Cambridge&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-sturtz2010r2openbugs&#34;&gt;
&lt;p&gt;Sturtz, Sibylle, Uwe Ligges, and Andrew Gelman. 2010. “R2OpenBUGS: A Package for Running Openbugs from R.” &lt;em&gt;URL Http://Cran. Rproject. Org/Web/Packages/R2OpenBUGS/Vignettes/R2OpenBUGS. Pdf&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>HESG Summer Meeting 2019</title>
      <link>/post/hesg-summer-meeting-2019/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/hesg-summer-meeting-2019/</guid>
      <description>&lt;p&gt;I have just come back form my first Health Economists&amp;rsquo; Study Group (&lt;a href=&#34;https://hesg.org.uk/meetings/summer-2019-university-of-east-anglia/&#34;&gt;HESG&lt;/a&gt;) meeting, which this year was held at the &lt;a href=&#34;https://www.uea.ac.uk/&#34;&gt;University of East Anglia&lt;/a&gt; in the beautiful city of Norwich, 
south east of England, and where I presented some preliminary results from one of my on-going works. I have to say, it was a remarkable experience which 
I really liked thanks to a wonderful and welcoming environment. I had the pleasure to talk to many people from different research areas involved in 
health economics (both from academia and industry) and to see many different projects and works.&lt;/p&gt;
&lt;p&gt;I particularly enjoy the structure of the meeting, which requires some chair and discussant who have to present and discuss the paper of the authors, 
who are only allowed to provide some clarification if needed. At first I thought this structure of the sessions was strange, but after attending many 
sessions and experiencing this for my own paper, I feel that it is a very good way to encourage discussion about works from different people rather than 
just focussing on your own presentation. Plus, the weather and always sunny, it felt like Italy for a few days.&lt;/p&gt;



  




&lt;figure&gt;

&lt;img src=&#34;/img/Norwich.jpg&#34; &gt;



&lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; &gt;
  &lt;h4&gt;The beautiful Norwich&amp;rsquo;s cathedral&lt;/h4&gt;
  
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;Other nice people and colleagues from HEART and other UCL department came to HESG with me, including &lt;a href=&#34;https://iris.ucl.ac.uk/iris/browse/profile?upi=CSCLA53&#34;&gt;Caroline&lt;/a&gt; and &lt;a href=&#34;https://www.ucl.ac.uk/comprehensive-clinical-trials-unit/meet-team/health-economics/junior-health-economist-ekaterina-kuznetsova&#34;&gt;Ekaterina&lt;/a&gt; (aka Katia), 
you can see them in thumbnail of this post. I was also pleased to meet &lt;a href=&#34;https://www.lshtm.ac.uk/aboutus/people/leurent.baptiste&#34;&gt;Baptiste&lt;/a&gt; from &lt;a href=&#34;https://www.lshtm.ac.uk/&#34;&gt;LSHTM&lt;/a&gt;, who shares with me the interest in missing data 
methods for cost-effectiveness analysis and who presented some very nice work on that. I had the chance to give some feedback to him and he did the same for me. 
It felt so nice when we started discussing about some aspects of our analyses and after some minutes we simply lost track of time and everyone else disappeared. 
I also had the opportunity to talk about my work with the discussant of my session, &lt;a href=&#34;https://cheme.bangor.ac.uk/CatrinPlumptonBiography.php&#34;&gt;Catrin Plumpton&lt;/a&gt; from the &lt;a href=&#34;https://cheme.bangor.ac.uk/&#34;&gt;Centre for Health Economics and Medicines Evaluation&lt;/a&gt;, 
who gave me some nice feedback which I really appreciated, especially given her mathematical background.&lt;/p&gt;
&lt;p&gt;An important contribution to the success of the meeting was also given by the wonderful organisation of the event, including an accommodation located very closely 
to the main building of the meeting, plenty of food provided during each day, a nice bus tour of the city and a wonderful conference dinner. I must thank all the people, 
who organised the event who were very extremely nice to us and who were always ready to help us for whatever need we had, with a special mention for &lt;a href=&#34;https://people.uea.ac.uk/emma_mcmanus&#34;&gt;Emma Mcmanus&lt;/a&gt; who 
was amazing.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/cWnICjtVkJJsgGKhyX/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In summary, everything was good. Well, almost. Going back to the works presented, as usual, the only less positive note that I would like to make 
is the almost total absence of Bayesian applications. Some authors mentioned that they used some popular Bayesian program, such as &lt;a href=&#34;https://www.mrc-bsu.cam.ac.uk/software/bugs/the-bugs-project-winbugs/&#34;&gt;WinBUGS&lt;/a&gt;, but this was 
mainly related to the usual meta-analysis stuff which is pretty standardised. I hope next time I will be able to see more people going Bayesian as this is what I am.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understanding health economics in clinical trials</title>
      <link>/post/understanding-health-economics-in-clinical-trials/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/understanding-health-economics-in-clinical-trials/</guid>
      <description>&lt;p&gt;As member of the Health Economics Analysis and Research Methods Team (&lt;a href=&#34;https://hearteam.blogspot.com/&#34;&gt;HEART&lt;/a&gt;), together with my colleagues, on Tuesday 2 July I took part in a 1-day introductory short course entitled “Understanding health economics in clinical trials”, which was designed and delivered by the team. HEART is a new group of health economists who are based in UCL’s Institute of Clinical Trials and Methodology (ICTM), led by &lt;a href=&#34;https://iris.ucl.ac.uk/iris/browse/profile?upi=RMHUN48&#34;&gt;Rachael Hunter&lt;/a&gt;, and is involved at different levels in the economic components of clinical trials in different trial units at UCL. This short course was aimed at ICTM staff who are not health economists (e.g. trial managers, CIs/PIs, statisticians, data managers, research assistants, etc.) and was designed in response to the need we have identified over the last few years in working on trials as well as in response to colleagues across ICTM. This course was unique as it was intended specifically for non health economists working in trials, who wish to better understand the health economics in their study, and/or the health economist on their study. The course used a mix of lectures, group discussions and practical exercises to help participants consolidate their learning and see how to apply information from the sessions to real studies. No prior knowledge of health economics was assumed.&lt;/p&gt;
&lt;p&gt;I believe the course was a success both in terms of the quality/quantity of the material covered during the six sessions throughout the day, as well as in terms of the positive feedback we received from the participants (almost entirely women, with the exception of two men). Many key and typically not well understood economic topics were discussed during the day, e.g. what are and how QALYs and costs are calculated, the potential limitations and issues of an economic analysis within a trial, or the role played by the protocol and analysis plan in the economic evaluation. My session was related to reporting and interpreting health economic results and I realised that most people who do not routinely deal with health economics may find difficult to grasp certain concepts or tools used in the economic analysis (e.g. what is a cost-effectiveness acceptability curve and how it can be computed). Nevertheless, I must admit that I was surprised by how many people were very motivated to learn these concepts and these &amp;ldquo;difficult&amp;rdquo; methods, often asking questions and making good comments (despite the fact that my session was the last of the course at the end of the day).   &lt;br&gt;
We ran this course as a trial as we did not have clear ideas of what an optimal design should be or the number of topics that should be covered for this type of course. We are now confident that the course has a solid structure and that there is a clear demand to learn the basic concepts of health economics, at least among people involved in trial analyses. Following the successful delivery of the course, we are planning to replicate the experience in the future, improving certain aspects of the sessions based on the feedback we received and also considering to open the course to meet the demand of a wider audience.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/bQrVMr3CO3QaY/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I have to say that this was an extremely positive experience for me as it was the first time I was involved in this type of projects. Me and my colleagues worked hard to design and prepare the different sessions of the course over the last few months, find the best way to link the arguments across the sessions, provide interesting group activities and materials for the practicals, etc. I have to thank all my colleagues who contributed to the promotion and realisation of this project, with a special mention for &lt;a href=&#34;https://iris.ucl.ac.uk/iris/browse/profile?upi=CSCLA53&#34;&gt;Caroline Clarke&lt;/a&gt;, who spent a lot of time and effort to organise the course and who personally contributed in giving one of the session of the course. Finally, I would also like to thank my colleague and health economist &lt;a href=&#34;https://www.ucl.ac.uk/comprehensive-clinical-trials-unit/meet-team/health-economics/junior-health-economist-ekaterina-kuznetsova&#34;&gt;Ekaterina&lt;/a&gt;, with whom I had the pleasure to share the presentation and practical of my session in the course.&lt;/p&gt;
&lt;p&gt;Perhaps the only true negative aspect of the course was the absence of a Bayesian perspective, especially related to the interpretation of the results and the statistical methods that can be used to perform the analysis. Given the generally low familiarity of the people attending the course with statistics, I believe it was reasonable not to further confuse them with another new element into the picture. However, I truly hope that people will become more and more familiar with the importance of using tailored statistical methods in economic evaluations to avoid biased results, and from that point to justify a Bayesian approach, well, at least for me, the step is straightforward!.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Super basic introduction to JAGS</title>
      <link>/jags/basic-introduction-to-jags/super-basic-introduction-to-jags/</link>
      <pubDate>Mon, 01 Jul 2019 21:13:14 -0500</pubDate>
      
      <guid>/jags/basic-introduction-to-jags/super-basic-introduction-to-jags/</guid>
      <description>


&lt;p&gt;The focus of this simple tutorial is to provide a brief introduction and overview about how to fit Bayesian models using &lt;code&gt;JAGS&lt;/code&gt; via &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Prerequisites:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The latest version of &lt;code&gt;R&lt;/code&gt;, which can be downloaded and installed for Windows, Mac or Linux OS from the &lt;a href=&#34;https://www.r-project.org/%7D&#34;&gt;CRAN&lt;/a&gt; website&lt;/li&gt;
&lt;li&gt;I also &lt;strong&gt;strongly&lt;/strong&gt; recommend to download and install &lt;a href=&#34;https://www.rstudio.com/&#34;&gt;Rstudio&lt;/a&gt;, an integrated development environment which provides an “user-friendly” interaction with &lt;code&gt;R&lt;/code&gt; (e.g. many drop-down menus, tabs, customisation options)&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;preliminaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Preliminaries&lt;/h1&gt;
&lt;div id=&#34;what-is-jags&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is JAGS?&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;JAGS&lt;/code&gt; or &lt;strong&gt;J&lt;/strong&gt;ust &lt;strong&gt;A&lt;/strong&gt;nother &lt;strong&gt;G&lt;/strong&gt;ibbs &lt;strong&gt;S&lt;/strong&gt;ampler is a program for analysis of Bayesian models using Markov Chain Monte Carlo (MCMC) methods (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;). &lt;code&gt;JAGS&lt;/code&gt; is a free software based on the &lt;strong&gt;B&lt;/strong&gt;ayesian inference &lt;strong&gt;U&lt;/strong&gt;sing &lt;strong&gt;G&lt;/strong&gt;ibbs &lt;strong&gt;S&lt;/strong&gt;ampling (informally &lt;code&gt;BUGS&lt;/code&gt;) language at the base of &lt;code&gt;WinBUGS/OpenBUGS&lt;/code&gt; but, unlike these programs, it is written in &lt;code&gt;C++&lt;/code&gt; and is platform independent. The latest version of &lt;code&gt;JAGS&lt;/code&gt; can be dowloaded from Martyn Plummer’s &lt;a href=&#34;https://sourceforge.net/projects/mcmc-jags/files/JAGS/&#34;&gt;repository&lt;/a&gt; and is available for different OS. There are different &lt;code&gt;R&lt;/code&gt; packages which function as frontends for &lt;code&gt;JAGS&lt;/code&gt;. These packages make it easy to process the output of Bayesian models and present it in publication-ready form. In this brief introduction, I will specifically focus on the &lt;code&gt;R2jags&lt;/code&gt; package (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) and show how to fit &lt;code&gt;JAGS&lt;/code&gt; models using this package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;installing-jags-and-r2jags&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Installing JAGS and R2jags&lt;/h2&gt;
&lt;p&gt;Install the latest version of &lt;code&gt;JAGS&lt;/code&gt; for your OS. Next, install the package &lt;code&gt;R2jags&lt;/code&gt; from within &lt;code&gt;R&lt;/code&gt; or &lt;code&gt;Rstudio&lt;/code&gt;, via the package installer or by typing in the command line&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; install.packages(&amp;quot;R2jags&amp;quot;, dependencies = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;dependencies = TRUE&lt;/code&gt; option will automatically install all the packages on which the functions in the &lt;code&gt;R2jags&lt;/code&gt; package rely.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;basic-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Basic model&lt;/h1&gt;
&lt;div id=&#34;simulate-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulate data&lt;/h2&gt;
&lt;p&gt;For an example dataset, I simulate my own data in &lt;code&gt;R&lt;/code&gt;. I create a continuous outcome variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; as a function of one predictor &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and a disturbance term &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;. I simulate a dataset with 100 observations. Create the error term, the predictor and the outcome using a linear form with an intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; and slope &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; coefficients, i.e.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y = \beta_0 + \beta_1 x + \epsilon  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;R&lt;/code&gt; commands which I use to simulate the data are the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; n.sim=100; set.seed(123)
&amp;gt; x=rnorm(n.sim, mean = 5, sd = 2)
&amp;gt; epsilon=rnorm(n.sim, mean = 0, sd = 1)
&amp;gt; beta0=1.5
&amp;gt; beta1=1.2
&amp;gt; y=beta0 + beta1 * x + epsilon&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, I define all the data for &lt;code&gt;JAGS&lt;/code&gt; in a list object&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; datalist=list(&amp;quot;y&amp;quot;,&amp;quot;x&amp;quot;,&amp;quot;n.sim&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-file&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model file&lt;/h2&gt;
&lt;p&gt;Now, I write the model for &lt;code&gt;JAGS&lt;/code&gt; and save it as a text file named &lt;code&gt;&#34;basic.mod.txt&#34;&lt;/code&gt; in the current working directory&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; basic.mod= &amp;quot;
+ model {
+ #model
+  for(i in 1:n.sim){
+   y[i] ~ dnorm(mu[i], tau)
+   mu[i] = beta0 + beta1 * x[i]
+  }
+ #priors
+ beta0 ~ dnorm(0, 0.01)
+ beta1 ~ dnorm(0, 0.01)
+ tau ~ dgamma(0.01,0.01)
+ }
+ &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The part of the model inside the for loop denotes the likelihood, which is evaluated for each individual in the sample using a Normal distribution parameterised by some mean &lt;code&gt;mu&lt;/code&gt; and precision &lt;code&gt;tau&lt;/code&gt; (where, precision = 1/variance). The covariate &lt;code&gt;x&lt;/code&gt; is included at the mean level using a linear regression, which is indexed by the intercept &lt;code&gt;beta0&lt;/code&gt; and slope &lt;code&gt;beta1&lt;/code&gt; terms. The second part defines the prior distributions for all parameters of the model, namely the regression coefficients and the precision. Weakly informative priors are used since I assume that I do not have any prior knowledge about these parameters.&lt;/p&gt;
&lt;p&gt;To write and save the model as the text file “basic.mod.txt” in the current working directory, I use the &lt;code&gt;writeLines&lt;/code&gt; function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; writeLines(basic.mod, &amp;quot;basic.mod.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pre-processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pre-processing&lt;/h2&gt;
&lt;p&gt;Define the parameters whose posterior distribtuions we are interested in summarising later and set up the initial values for the MCMC sampler in &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params=c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;)
&amp;gt; inits=function(){list(&amp;quot;beta0&amp;quot;=rnorm(1), &amp;quot;beta1&amp;quot;=rnorm(1))}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function creates a list that contains one element for each parameter, which gets assigned a random draw from a normal distribution as a strating value for each chain in the model. For simple models like this, it is generally easy to define the intial values for all parameters. However, for more complex models, this may not be immediate and a lot of trial and error may be required. However, &lt;code&gt;JAGS&lt;/code&gt; can automatically select the initial values for all parameters in an efficient way even for relatively complex models. This can be achieved by setting &lt;code&gt;inits=NULL&lt;/code&gt;, which is then passed to the &lt;code&gt;jags&lt;/code&gt; function in &lt;code&gt;R2jags&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Before using &lt;code&gt;R2jags&lt;/code&gt; for the first time, you need to load the package, and you may want to set a random seed number for making your estimates replicable&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)
&amp;gt; set.seed(123)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit the model&lt;/h2&gt;
&lt;p&gt;Now, we can fit the model in &lt;code&gt;JAGS&lt;/code&gt; using the &lt;code&gt;jags&lt;/code&gt; function in the &lt;code&gt;R2jags&lt;/code&gt; package and save it in the object &lt;code&gt;basic.mod&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; basic.mod=jags(data = datalist, inits = inits,
+   parameters.to.save = params, n.chains = 2, n.iter = 2000, 
+   n.burnin = 1000, model.file = &amp;quot;basic.mod.txt&amp;quot;)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 3
   Total graph size: 406

Initializing model&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While the model is running, the function prints out some information related to the Bayesian graph (corresponding to the specification used for the model) underneath &lt;code&gt;JAGS&lt;/code&gt;, such as number of observed and unobserved nodes and graph size.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;post-processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Post-processing&lt;/h2&gt;
&lt;p&gt;Once the model has finished running, a summary of the posteiror estimates and convergence diagnostics for all parameters specified can be seen by typing &lt;code&gt;print(basic.mod)&lt;/code&gt; or, alternatively,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(basic.mod$BUGSoutput$summary)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;          mean    sd   2.5%   25%   50%   75% 97.5% Rhat n.eff
beta0      1.5 0.294   0.95   1.3   1.5   1.7   2.1    1  2000
beta1      1.2 0.054   1.07   1.1   1.2   1.2   1.3    1  2000
deviance 278.8 2.475 276.03 277.1 278.2 279.9 285.1    1  2000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The posterior distribution of each parameter is summarised in terms of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The mean, sd and some percentiles&lt;/li&gt;
&lt;li&gt;Potential scale reduction factor &lt;code&gt;Rhat&lt;/code&gt; and effective sample size &lt;code&gt;n.eff&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman (2013)&lt;/span&gt;). The first is a measure to assess issues in convergence of the MCMC algorithm (typically a value below &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; for all parameters is considered ok). The second is a measure which assesses the adequacy of the posterior sample (typically values close to the total number of iterations are desirable for all parameters).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The deviance is a goodness of fit statistic and is used in the construction of the “Deviance Information Criterion” or DIC (&lt;span class=&#34;citation&#34;&gt;Spiegelhalter et al. (2014)&lt;/span&gt;), which is a &lt;em&gt;relative&lt;/em&gt; measure of model comparison. The DIC of the model can be accessed by typing&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; basic.mod$BUGSoutput$DIC
[1] 282&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;diagnostics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Diagnostics&lt;/h2&gt;
&lt;p&gt;More diagnostics are available when we convert the model output into an MCMC object using the command&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; basic.mod.mcmc=as.mcmc(basic.mod)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Different packages are available to perform diagnostic checks for Bayesian models. Here, I install and load the &lt;code&gt;mcmcplots&lt;/code&gt; package (&lt;span class=&#34;citation&#34;&gt;Curtis (2015)&lt;/span&gt;) to obtain graphical diagnostics and results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; install.packages(&amp;quot;mcmcplots&amp;quot;)
&amp;gt; library(mcmcplots)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, density and trace plots can be obtained by typing&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(basic.mod.mcmc, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/basic-introduction-to-jags/2018-08-23-super-basic-introduction-to-jags_files/figure-html/diagnostic3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(basic.mod.mcmc, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/basic-introduction-to-jags/2018-08-23-super-basic-introduction-to-jags_files/figure-html/diagnostic3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both types of graphs suggest that there are not issues in the convergence of the algorithm (smooth normal densities and hairy caterpillar graphs for both MCMC chains).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;This tutorial was simply a brief introduction on how simple linear regression models can be fitted using the Bayesian software &lt;code&gt;JAGS&lt;/code&gt; via the &lt;code&gt;R2jags&lt;/code&gt; package. Although this may seem a complex procedure compared with simply fitting a linear model under the frequentist framework, however, the real advantages of Bayesian methods become evident when the complexity of the analysis is increased (which is often the case in real applications). Indeed, the flexibility in Bayesian modelling allows to account for increasingly complex models in a relatively easy way. In addition, Bayesian methods are ideal when the interest is in taking into account the potential impact that different sources of uncertainty may have on the final results, as they allow the natural propagation of uncertainty throughout each quantity in the model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-curtis2015mcmcplots&#34;&gt;
&lt;p&gt;Curtis, SM. 2015. “Mcmcplots: Create Plots from Mcmc Output.” &lt;em&gt;R Package Version 0.4&lt;/em&gt; 2.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2013bayesian&#34;&gt;
&lt;p&gt;Gelman, Andrew. 2013. &lt;em&gt;Bayesian Data Analysis&lt;/em&gt;. Chapman; Hall/CRC.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-spiegelhalter2014deviance&#34;&gt;
&lt;p&gt;Spiegelhalter, David J, Nicola G Best, Bradley P Carlin, and Angelika Van Der Linde. 2014. “The Deviance Information Criterion: 12 Years on.” &lt;em&gt;Journal of the Royal Statistical Society: Series B (Statistical Methodology)&lt;/em&gt; 76 (3): 485–93.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
