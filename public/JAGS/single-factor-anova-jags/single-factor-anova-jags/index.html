<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.3.1">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Andrea Gabrio">

  
  
  
    
  
  <meta name="description" content="This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. BUGS (Bayesian inference Using Gibbs Sampling) is an algorithm and supporting language (resembling R) dedicated to performing the Gibbs sampling implementation of Markov Chain Monte Carlo (MCMC) method. Dialects of the BUGS language are implemented within three main projects:
OpenBUGS - written in component pascal.
JAGS - (Just Another Gibbs Sampler) - written in C&#43;&#43;.">

  
  <link rel="alternate" hreflang="en-us" href="/jags/single-factor-anova-jags/single-factor-anova-jags/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:450,700|Oswald+Sans:600,700|Roboto+Mono:550,700">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.a71200610c21759266bff163bb521d95.css">

  
    
    
    
    
      
    
    
    
    <link rel="stylesheet" href="/css/academic.3f1befffb0882d6c3372ec9dda375740.css">
  

  
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/jags/single-factor-anova-jags/single-factor-anova-jags/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Andrea Gabrio">
  <meta property="og:url" content="/jags/single-factor-anova-jags/single-factor-anova-jags/">
  <meta property="og:title" content="Single Factor Anova - JAGS | Andrea Gabrio">
  <meta property="og:description" content="This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. BUGS (Bayesian inference Using Gibbs Sampling) is an algorithm and supporting language (resembling R) dedicated to performing the Gibbs sampling implementation of Markov Chain Monte Carlo (MCMC) method. Dialects of the BUGS language are implemented within three main projects:
OpenBUGS - written in component pascal.
JAGS - (Just Another Gibbs Sampler) - written in C&#43;&#43;."><meta property="og:image" content="/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2020-02-04T21:13:14-05:00">
  
  <meta property="article:modified_time" content="2020-02-04T21:13:14-05:00">
  

  


  





  <title>Single Factor Anova - JAGS | Andrea Gabrio</title>

</head>


<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Andrea Gabrio</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/post/"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/research/"><span>Research</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/publication/"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/talk/"><span>Talks</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Software</span><span class="caret"></span>
          </a>
          <ul class="dropdown-menu">
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/missingHE/"><span>missingHE</span></a>
            </li>
            
          </ul>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Tutorials</span><span class="caret"></span>
          </a>
          <ul class="dropdown-menu">
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/JAGS/"><span>JAGS</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/OpenBUGS/"><span>OpenBUGS</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/STAN/"><span>STAN</span></a>
            </li>
            
          </ul>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/missingdata/"><span>Missing Data</span></a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        

      </ul>

    </div>
  </div>
</nav>


  <article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Single Factor Anova - JAGS</h1>

  

  
    



<meta content="2020-02-04 21:13:14 -0500 -0500" itemprop="datePublished">
<meta content="2020-02-04 21:13:14 -0500 -0500" itemprop="dateModified">

<div class="article-metadata">

  
  
  
  
  <div>
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a>Andrea Gabrio</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    <time>Feb 4, 2020</time>
  </span>
  

  

  

  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder"></i>
    <a href="/categories/r/">R</a>, <a href="/categories/anova/">anova</a>, <a href="/categories/jags/">JAGS</a>, <a href="/categories/facor-analysis/">facor analysis</a></span>
  

  
    

  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. <code>BUGS</code> (Bayesian inference Using <em>Gibbs Sampling</em>) is an algorithm and supporting language (resembling <code>R</code>) dedicated to performing the Gibbs sampling implementation of <em>Markov Chain Monte Carlo</em> (MCMC) method. Dialects of the <code>BUGS</code> language are implemented within three main projects:</p>
<ol style="list-style-type: decimal">
<li><p><strong>OpenBUGS</strong> - written in component pascal.</p></li>
<li><p><strong>JAGS</strong> - (Just Another Gibbs Sampler) - written in <code>C++</code>.</p></li>
<li><p><strong>STAN</strong> - a dedicated Bayesian modelling framework written in <code>C++</code> and implementing <em>Hamiltonian</em> MCMC samplers.</p></li>
</ol>
<p>Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of <code>R</code>, and thus, they are best accessed from within <code>R</code> itself. As such there are multiple packages devoted to interfacing with the various software implementations:</p>
<ul>
<li><p><em>R2OpenBUGS</em> - interfaces with <code>OpenBUGS</code></p></li>
<li><p><em>R2jags</em> - interfaces with <code>JAGS</code></p></li>
<li><p><em>rstan</em> - interfaces with <code>STAN</code></p></li>
</ul>
<p>This tutorial will demonstrate how to fit models in <code>JAGS</code> (<span class="citation">Plummer (2004)</span>) using the package <code>R2jags</code> (<span class="citation">Su et al. (2015)</span>) as interface, which also requires to load some other packages.</p>
<div id="overview" class="section level1">
<h1>Overview</h1>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p><em>Single factor Analysis of Variance</em> (ANOVA), also known as single factor classification, is used to investigate the effect of a single factor comprising two or more groups (treatment levels) from a completely randomised design. Completely randomised refers to the absence of restrictions on the random allocation of experimental or sampling units to factor levels.</p>
<p>For example, consider a situation in which three types of treatments (A, B and C) are applied to replicate sampling units across the sampling domain. Importantly, the treatments are applied at the scale of the sampling units and the treatments applied to each sampling unit do not extend to any other neighbouring sampling units. Another possible situation is where the scale of a treatment is far larger than that of a sampling unit. This design features two treatments, each replicated three times. Note that additional sampling units within each Site (the scale at which the treatment occurs) would NOT constitute additional replication. Rather, these would be sub-replicates. That is, they would be replicates of the Sites, not the treatments (since the treatments occur at the level of whole sites). In order to genuinely increase the number of replicates, it is necessary to have more Sites. The random allocation of sampling units within the sampling domain (such as population) is appropriate provided either the underlying response is reasonably homogenous throughout the domain, or else, there is a large number of sampling units. If the conditions are relatively hetrogenous, then the exact location of the sampling units is likely to be highly influential and may mask any detectable effects of treatments.</p>
</div>
<div id="fixed-and-random-effects" class="section level2">
<h2>Fixed and random effects</h2>
<p>From a frequentist perspective, <em>fixed factors</em> are factors whose levels represent the specific populations of interest. For example, a factor that comprises “high”, “medium” and “low” temperature treatments is a fixed factor - we are only interested in comparing those three populations. Conclusions about the effects of a fixed factor are restricted to the specific treatment levels investigated and for any subsequent experiments to be comparable, the same specific treatments of the factor would need to be used. By contrast, <em>random factors</em> are factors whose levels are randomly chosen from all the possible levels of populations and are used as random representatives of the populations. For example, five random temperature treatments could be used to represent a full spectrum of temperature treatments. In this case, conclusions are extrapolated to all the possible treatment (temperature) levels and for subsequent experiments, a new random set of treatments of the factor would be selected.</p>
<p>Other common examples of random factors include sites and subjects - factors for which we are attempting to generalise over. Furthermore, the nature of random factors means that we have no indication of how a new level of that factor (such as another subject or site) are likely to respond and thus it is not possible to predict new observations from random factors. These differences between fixed and random factors are reflected in the way their respective null hypotheses are formulated and interpreted. Whilst fixed factors contrast the effects of the different levels of the factor, random factors are modelled as the amount of additional variability they introduce. Random factors are modelled with a mean of <span class="math inline">\(0\)</span> and their variance is estimated as the effect coefficient.</p>
</div>
<div id="linear-model" class="section level2">
<h2>Linear model</h2>
<p>The linear model for single factor classification is similar to that of multiple linear regression. The linear model can thus be represented by either:</p>
<ul>
<li><strong>Means parameterisation</strong> - in which the regression slopes represent the means of each treatment group and the intercept is removed (to prevent over-parameterisation).</li>
</ul>
<p><span class="math display">\[ y_{ij} = \beta_1(\text{level}_1)_{ij} + \beta_2(\text{level}_2)_{ij} + \ldots + \epsilon_{ij},\]</span></p>
<p>where <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> respectively represent the means response of treatment level <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span>. This is often simplified to <span class="math inline">\(y_{ij}=\alpha_i + \epsilon_{ij}\)</span>.</p>
<ul>
<li><strong>Effects parameterisation</strong> - the intercept represents a property such as the mean of one of the treatment groups (treatment contrasts) or the overall mean (sum contrasts), and the slope parameters represent effects (differences between each other group and the reference mean for example).</li>
</ul>
<p><span class="math display">\[ y_{ij} = \mu + \beta_2(\text{level}_2)_{ij} + \beta_3(\text{level}_3)_{ij} + \ldots + \epsilon_{ij},\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the mean of the first treatment group, <span class="math inline">\(\beta_2\)</span> and <span class="math inline">\(\beta_3\)</span> respectively represent the effects (change from level <span class="math inline">\(1\)</span>) of level <span class="math inline">\(2\)</span> and <span class="math inline">\(3\)</span> on the mean response. This is often simplified to: <span class="math inline">\(y_{ij}=\mu + \alpha_i + \epsilon_{ij}\)</span>, with <span class="math inline">\(\alpha_1=0\)</span>.</p>
<p>Since we are traditionally interested in investigating effects (differences) rather than treatment means, effects parameterisation is far more common (particularly when coupled with hypothesis testing). In a Bayesian framework, it does not really matter whether models are fit with means or effects parameterisation since the posterior likelihood can be querried in any way and repeatedly - thus enabling us to explore any specific effects after the model has been fit. Nevertheless, to ease comparisons with frequentist approaches, we will stick with effects paramterisation.</p>
</div>
<div id="null-hypothesis-fixed-factor" class="section level2">
<h2>Null hypothesis: fixed factor</h2>
<p>We can associate a null hypothesis test with each estimated parameter. For example, in a cell for each estimated mean in a means model we could test a null hypothesis that the population mean is equal to zero (e.g. <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\alpha_1=0\)</span>, <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\alpha_2=0\)</span>, <span class="math inline">\(\ldots\)</span>). However, this rarely would be of much interest. By contrast, individual null hypotheses associated with each parameter of the effects model can be used to investigate the differences between each group and a reference group (for example). In addition to the individual null hypothesis tests, a single fixed factor ANOVA tests the collective <span class="math inline">\(H_0\)</span> that there are no differences between the population group means:</p>
<ul>
<li><p><span class="math inline">\(H_0: \mu_1=\mu_2=\ldots=\mu_i=\mu\)</span> (the population group means are all equal). That is, that the mean of population <span class="math inline">\(1\)</span> is equal to that of population <span class="math inline">\(2\)</span> and so on, and thus all population means are equal to one another - no effect of the factor on the response. If the effect of the <span class="math inline">\(i\)</span>-th group is the difference between the <span class="math inline">\(i\)</span>-th group mean and the mean of the first group (<span class="math inline">\(\alpha_i=\mu_i-\mu_1\)</span>) then the <span class="math inline">\(H_0\)</span> can alternatively be written as:</p></li>
<li><p><span class="math inline">\(H_0 : \alpha_2=\alpha_3=\ldots=\alpha_i=0\)</span> (the effect of each group equals zero). If one or more of the <span class="math inline">\(\alpha_i\)</span> are different from zero (the response mean for this treatment differs from the overall response mean), there is evidence that the null hypothesis is not true indicating that the factor does affect the response variable.</p></li>
</ul>
</div>
<div id="null-hypothesis-random-factor" class="section level2">
<h2>Null hypothesis: random factor</h2>
<p>The collective <span class="math inline">\(H_0\)</span> for a random factor is that the variance between all possible treatment groups equals zero:</p>
<ul>
<li><span class="math inline">\(H_0 : \sigma^2_{\alpha}=0\)</span> (added variance due to this factor equals zero).</li>
</ul>
<p>Note that whilst the null hypotheses for fixed and random factors are different (fixed: population group means all equal, random: variances between populations all equal zero), the linear model fitted for fixed and random factors in single factor ANOVA models is identical. For more complex multi-factor ANOVA models however, the distinction between fixed and random factors has important consequences for building and interpreting statistical models and null hypotheses.</p>
</div>
<div id="analysis-of-variance" class="section level2">
<h2>Analysis of variance</h2>
<p>When the null hypothesis is true (and the populations are identical), the amount of variation among observations within groups should be similar to the amount of variation in observations between groups. However, when the null hypothesis is false (and some means are different from other means), the amount of variation among observations might be expected to be less than the amount of variation within groups. Analysis of variance, or ANOVA, partitions the total variance in the response (dependent) variable into a component of the variance that is explained by combinations of one or more categorical predictor variables (called factors) and a component of the variance that cannot be explained (residual). The variance ratio (F-ratio) from this partitioning can then be used to test the null hypothesis (<span class="math inline">\(H_0\)</span>) that the population group or treatment means are all equal. Ttotal variation can be decomposed into components explained by the groups (<span class="math inline">\(MS_{groups}\)</span>) and and unexplained (<span class="math inline">\(MS_{residual}\)</span>) by the groups. The gray arrows in b) depict the relative amounts explained by the groups. The proposed groupings generally explain why the first few points are higher on the y-axis than the last three points. The probability of collecting our sample, and thus generating the sample ratio of explained to unexplained variation (or one more extreme), when the null hypothesis is true (and population means are equal) is the area under the F-distribution beyond our sample ratio (<span class="math inline">\(\text{F-ratio}=\frac{MS_{groups}}{MS_{residual}}\)</span>).</p>
<p>When the null hypothesis is true (and the test assumptions have not been violated), the ratio (F-ratio) of explained to unexplained variance follows a theoretical probability distribution (F-distribution). When the null hypothesis is true, and there is no effect of the treatment on the response variable, the ratio of explained variability to unexplained variability is expected to be <span class="math inline">\(\leq 1\)</span>. Since the denominator should represent the expected numerator in the absence of an effect. Importantly, the denominator in an F-ratio calculation essentially represents what we would expect the numerator to be in the absence of a treatment effect. For simple analyses, identifying what these expected values are is relatively straightforward (equivalent to the degree of within group variability). However, in more complex designs (particularly involving random factors and hierarchical treatment levels), the logical “groups” can be more difficult (and in some cases impossible) to identify. In such cases, nominating the appropriate F-ratio denominator for estimating an specific effect requires careful consideration. The following table depicts the anatomy of the single factor ANOVA table</p>
<pre class="r"><code>&gt; anova_table
         df       MS       F-ratio          
Factor A &quot;a-1&quot;    &quot;MS A&quot;   &quot;(MS A)/(MS res)&quot;
Residual &quot;(n-1)a&quot; &quot;MS res&quot; &quot;&quot;               </code></pre>
<p>and corresponding <code>R</code> syntax.</p>
<pre class="r"><code>&gt; anova(lm(DV ~ A, dataset))
&gt; # OR
&gt; anova(aov(DV ~ A, dataset))</code></pre>
<p>An F-ratio substantially greater than <span class="math inline">\(1\)</span> suggests that the model relating the response variable to the categorical variable explains substantially more variability than is left unexplained. In turn, this implies that the linear model does represent the data well and that differences between observations can be explained largely by differences in treatment levels rather than purely the result of random variation. If the probability of getting the observed (sample) F-ratio or one more extreme is less than some predefined critical value (typically <span class="math inline">\(5\)</span>% or <span class="math inline">\(0.05\)</span>), we conclude that it is highly unlikely that the observed samples could have been collected from populations in which the treatment has no effect and therefore we would reject the null hypothesis.</p>
</div>
<div id="assumptions" class="section level2">
<h2>Assumptions</h2>
<p>An F-ratio from real data can only reliably relate to a theoretical F-distribution when the data conform to certain assumptions. Hypothesis testing for a single factor ANOVA model assumes that the residuals (and therefore the response variable for each of the treatment levels) are all:</p>
<ul>
<li><p><strong>normally distributed</strong> - although ANOVA is robust to non-normality provided sample sizes and variances are equal. Boxplots should be used to explore normality, skewness, bimodality and outliers. In the event of homogeneity of variance issues (see below), a Q-Q normal plot can also be useful for exploring normality (as this might be the cause of non-homogeneity). Scale transformations are often useful.</p></li>
<li><p><strong>equally varied</strong> - provided sample sizes are equal and the largest to smallest variance ratio does not exceed 3:1 (9:1 for sd), ANOVA is reasonably robust to this assumption, however, relationships between variance and mean and/or sample size are of particular concern as they elevate the Type I error rate. Boxplots and plots of means against variance should be used to explore the spread of values. Residual plots should reveal no patterns. Since unequal variances are often the result of non-normality, transformations that improve normality will also improve variance homogeneity.</p></li>
<li><p><strong>independent of one another</strong> - this assumption must be addressed at the design and collection stages and cannot be compensated for later (unless a model is used that specifically accounts for particular types of non-independent data, such as that introduced with hierarchical designs or autocorrelation)</p></li>
</ul>
<p>Violations of these assumptions reduce the reliability of the analysis.</p>
</div>
</div>
<div id="data-generation" class="section level1">
<h1>Data generation</h1>
<p>Lets say we had set up a natural experiment in which we measured a response from <span class="math inline">\(10\)</span> sampling units (replicates) from each of <span class="math inline">\(5\)</span> treatments. Hence, we have a single categorical factor with <span class="math inline">\(5\)</span> levels - we might have five different locations, or five different habitat types or substrates etc. In statistical speak, we have sampled from <span class="math inline">\(5\)</span> different populations. We have then randomly selected <span class="math inline">\(10\)</span> independent and random (representative) units of each population to sample. That is, we have <span class="math inline">\(10\)</span> samples (replicates) of each population. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.</p>
<pre class="r"><code>&gt; set.seed(123)
&gt; ngroups &lt;- 5  #number of populations
&gt; nsample &lt;- 10  #number of reps in each
&gt; pop.means &lt;- c(40, 45, 55, 40, 30)  #population mean length
&gt; sigma &lt;- 3  #residual standard deviation
&gt; n &lt;- ngroups * nsample  #total sample size
&gt; eps &lt;- rnorm(n, 0, sigma)  #residuals
&gt; x &lt;- gl(ngroups, nsample, n, lab = LETTERS[1:5])  #factor
&gt; means &lt;- rep(pop.means, rep(nsample, ngroups))
&gt; X &lt;- model.matrix(~x - 1)  #create a design matrix
&gt; y &lt;- as.numeric(X %*% pop.means + eps)
&gt; data &lt;- data.frame(y, x)
&gt; head(data)  #print out the first six rows of the data set
         y x
1 38.31857 A
2 39.30947 A
3 44.67612 A
4 40.21153 A
5 40.38786 A
6 45.14519 A
&gt; 
&gt; write.csv(data, &quot;simpleAnova.csv&quot;)</code></pre>
<p>With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type.</p>
<div id="exploratory-data-analysis" class="section level2">
<h2>Exploratory data analysis</h2>
<ul>
<li><em>Normality and Homogeneity of variance</em></li>
</ul>
<pre class="r"><code>&gt; boxplot(y ~ x, data)
&gt; 
&gt; # OR via ggplot2
&gt; library(ggplot2)</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/exp_data-1.png" width="672" /></p>
<pre class="r"><code>&gt; ggplot(data, aes(y = y, x = x)) + geom_boxplot() +
+     theme_classic()</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/exp_data-2.png" width="672" /></p>
<p><strong>Conclusions</strong></p>
<p>There is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the <span class="math inline">\(y\)</span>-axis. Hence it there is no evidence of non-homogeneity. Obvious violations could be addressed either by, for example, transforming the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).</p>
</div>
</div>
<div id="model-fitting" class="section level1">
<h1>Model fitting</h1>
<p>The observed response (<span class="math inline">\(y_i\)</span>) are assumed to be drawn from a normal distribution with a given mean (<span class="math inline">\(\mu\)</span>) and standard deviation (<span class="math inline">\(\sigma\)</span>). The expected values (<span class="math inline">\(\mu\)</span>) are themselves determined by the linear predictor (<span class="math inline">\(\beta_0+\boldsymbol \beta \boldsymbol X_i\)</span>). In this case, <span class="math inline">\(\beta_0\)</span> represents the mean of the first group and the set of <span class="math inline">\(\boldsymbol \beta\)</span>’s represent the differences between each other group and the first group. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (<span class="math inline">\(100\)</span>) for both the intercept and the treatment effect and a wide half-cauchy (<span class="math inline">\(\text{scale}=5\)</span>) for the standard deviation.</p>
<p><span class="math display">\[y_i \sim N(\mu_i,\sigma),  \]</span></p>
<p>where <span class="math inline">\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X_i\)</span>. The assumed priors are: <span class="math inline">\(\beta \sim N(0,100)\)</span> and <span class="math inline">\(\sigma \sim \text{Cauchy}(0,5)\)</span>. We proceed to code the model into <code>JAGS</code> (remember that in this software normal distribution are parameterised in terms of precisions <span class="math inline">\(\tau\)</span> rather than variances, where <span class="math inline">\(\tau=\frac{1}{\sigma^2}\)</span>). Note the following example as group means calculated as derived posteriors.</p>
<pre class="r"><code>&gt; modelString = &quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau.res)
+   mean[i] &lt;- alpha+beta[x[i]]
+   }
+ 
+   #Priors and derivatives
+   alpha ~ dnorm(0,1.0E-6)
+   beta[1] &lt;- 0
+   for (i in 2:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) #prior
+   }
+   sigma.res ~ dunif(0, 100)
+   tau.res &lt;- 1 / (sigma.res * sigma.res)
+   sigma.group &lt;- sd(beta[])
+ 
+   #Group mean posteriors (derivatives)
+   for (i in 1:ngroups) {
+   Group.means[i] &lt;- beta[i]+alpha
+   }
+   }
+   &quot;
&gt; 
&gt; ## write the model to a text file
&gt; writeLines(modelString, con = &quot;anovaModel.txt&quot;)</code></pre>
<p>Arrange the data as a list (as required by <code>JAGS</code>). As input, <code>JAGS</code> will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.</p>
<pre class="r"><code>&gt; data.list &lt;- with(data, list(y = y, x = as.numeric(x), n = nrow(data),
+     ngroups = length(levels(data$x))))</code></pre>
<p>Define the nodes (parameters and derivatives) to monitor and the chain parameters.</p>
<pre class="r"><code>&gt; params &lt;- c(&quot;alpha&quot;, &quot;beta&quot;, &quot;sigma.res&quot;, &quot;Group.means&quot;)
&gt; nChains = 2
&gt; burnInSteps = 3000
&gt; thinSteps = 1
&gt; numSavedSteps = 15000  #across all chains
&gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&gt; nIter
[1] 10500</code></pre>
<p>Start the <code>JAGS</code> model (check the model, load data into the model, specify the number of chains and compile the model). Load the <code>R2jags</code> package.</p>
<pre class="r"><code>&gt; library(R2jags)</code></pre>
<p>Now run the <code>JAGS</code> code via the <code>R2jags</code> interface. Note that the first time jags is run after the <code>R2jags</code> package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.</p>
<pre class="r"><code>&gt; data.r2jags &lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &quot;anovaModel.txt&quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 50
   Unobserved stochastic nodes: 6
   Total graph size: 126

Initializing model
&gt; 
&gt; print(data.r2jags)
Inference for Bugs model at &quot;anovaModel.txt&quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
               mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat
Group.means[1]  40.232   0.908  38.424  39.631  40.237  40.837  41.991 1.001
Group.means[2]  45.632   0.902  43.858  45.022  45.626  46.231  47.432 1.002
Group.means[3]  53.730   0.913  51.947  53.113  53.722  54.334  55.543 1.001
Group.means[4]  40.962   0.906  39.188  40.350  40.968  41.563  42.734 1.001
Group.means[5]  29.974   0.915  28.173  29.367  29.974  30.586  31.746 1.001
alpha           40.232   0.908  38.424  39.631  40.237  40.837  41.991 1.001
beta[1]          0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000
beta[2]          5.400   1.278   2.889   4.551   5.395   6.244   7.896 1.001
beta[3]         13.498   1.286  11.017  12.639  13.485  14.354  16.049 1.001
beta[4]          0.730   1.283  -1.768  -0.122   0.722   1.582   3.261 1.001
beta[5]        -10.258   1.294 -12.820 -11.110 -10.253  -9.412  -7.721 1.001
sigma.res        2.864   0.320   2.313   2.638   2.832   3.056   3.578 1.001
deviance       245.540   3.787 240.323 242.761 244.832 247.511 254.843 1.001
               n.eff
Group.means[1] 15000
Group.means[2]  2200
Group.means[3]  3800
Group.means[4] 15000
Group.means[5] 15000
alpha          15000
beta[1]            1
beta[2]         2900
beta[3]        15000
beta[4]        15000
beta[5]        15000
sigma.res      15000
deviance       15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<div id="model-matrix-formulation" class="section level2">
<h2>Model matrix formulation</h2>
<p>For very simple models such as this example, we can write the models as:</p>
<pre class="r"><code>&gt; modelString2 = &quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau)
+   mean[i] &lt;- inprod(beta[],X[i,])
+   }
+   #Priors
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) 
+   }
+   sigma ~ dunif(0, 100)
+   tau &lt;- 1 / (sigma * sigma)
+   }
+   &quot;
&gt; 
&gt; ## write the model to a text file
&gt; writeLines(modelString2, con = &quot;anovaModel2.txt&quot;)</code></pre>
<p>Define the data to pass to <code>R2jags</code>.</p>
<pre class="r"><code>&gt; X &lt;- model.matrix(~x, data)
&gt; data.list &lt;- with(data, list(y = y, X = X, n = nrow(data), ngroups = ncol(X)))</code></pre>
<p>Define the nodes (parameters and derivatives) to monitor and the chain parameters.</p>
<pre class="r"><code>&gt; params &lt;- c(&quot;beta&quot;, &quot;sigma&quot;)
&gt; nChains = 2
&gt; burnInSteps = 3000
&gt; thinSteps = 1
&gt; numSavedSteps = 15000  #across all chains
&gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&gt; nIter
[1] 10500</code></pre>
<p>Start the <code>JAGS</code> model (check the model, load data into the model, specify the number of chains and compile the model). Run the <code>JAGS</code> code via the <code>R2jags</code> interface. Note that the first time jags is run after the <code>R2jags</code> package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.</p>
<pre class="r"><code>&gt; data.r2jags &lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &quot;anovaModel2.txt&quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 50
   Unobserved stochastic nodes: 6
   Total graph size: 370

Initializing model
&gt; 
&gt; print(data.r2jags)
Inference for Bugs model at &quot;anovaModel2.txt&quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.226   0.901  38.475  39.624  40.222  40.824  41.999 1.001  4800
beta[2]    5.401   1.272   2.906   4.552   5.397   6.242   7.900 1.001 15000
beta[3]   13.492   1.296  10.969  12.634  13.484  14.355  16.038 1.001  5100
beta[4]    0.734   1.279  -1.793  -0.114   0.740   1.582   3.263 1.001 15000
beta[5]  -10.248   1.283 -12.785 -11.108 -10.242  -9.380  -7.731 1.001  9800
sigma      2.863   0.315   2.321   2.642   2.838   3.053   3.558 1.001  6200
deviance 245.551   3.785 240.353 242.765 244.844 247.603 254.815 1.002  1800

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
</div>
</div>
<div id="mcmc-diagnostics" class="section level1">
<h1>MCMC diagnostics</h1>
<p>In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.</p>
<ul>
<li><p><em>Traceplots</em> for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.</p></li>
<li><p><em>Autocorrelation</em> plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of <span class="math inline">\(0\)</span> represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of <span class="math inline">\(1\)</span>). A lag of <span class="math inline">\(1\)</span> represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).</p></li>
<li><p><em>Potential scale reduction factor</em> (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than <span class="math inline">\(1.05\)</span>. If there are values of <span class="math inline">\(1.05\)</span> or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.</p></li>
</ul>
<p>Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package <code>mcmcplots</code> to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. <span class="math inline">\(\boldsymbol \beta\)</span>.</p>
<pre class="r"><code>&gt; library(mcmcplots)
&gt; denplot(data.r2jags, parms = c(&quot;beta&quot;))</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_diag-1.png" width="672" /></p>
<pre class="r"><code>&gt; traplot(data.r2jags, parms = c(&quot;beta&quot;))</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_diag-2.png" width="672" /></p>
<p>These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.</p>
<pre class="r"><code>&gt; data.mcmc = as.mcmc(data.r2jags)
&gt; #Raftery diagnostic
&gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3895  3746         1.040     
 beta[2]  2        3729  3746         0.995     
 beta[3]  2        3811  3746         1.020     
 beta[4]  3        4115  3746         1.100     
 beta[5]  2        3853  3746         1.030     
 deviance 2        3729  3746         0.995     
 sigma    5        5834  3746         1.560     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3853  3746         1.03      
 beta[2]  2        3918  3746         1.05      
 beta[3]  2        3811  3746         1.02      
 beta[4]  2        3853  3746         1.03      
 beta[5]  2        3853  3746         1.03      
 deviance 2        3981  3746         1.06      
 sigma    4        5306  3746         1.42      </code></pre>
<p>The Raftery diagnostics for each chain estimate that we would require no more than <span class="math inline">\(5000\)</span> samples to reach the specified level of confidence in convergence. As we have <span class="math inline">\(10500\)</span> samples, we can be confidence that convergence has occurred.</p>
<pre class="r"><code>&gt; #Autocorrelation diagnostic
&gt; autocorr.diag(data.mcmc)
             beta[1]     beta[2]       beta[3]       beta[4]      beta[5]
Lag 0   1.0000000000 1.000000000  1.0000000000  1.0000000000  1.000000000
Lag 1   0.0015561854 0.001902670 -0.0023462263  0.0063854498 -0.008928813
Lag 5  -0.0006487164 0.003556616 -0.0008267107 -0.0003892349  0.004087306
Lag 10  0.0141414517 0.012308363  0.0064688638 -0.0029210457  0.009117446
Lag 50 -0.0019115790 0.005069522  0.0072096979 -0.0030858504  0.002938152
           deviance        sigma
Lag 0   1.000000000  1.000000000
Lag 1   0.198317688  0.334172270
Lag 5  -0.001425768  0.005514213
Lag 10 -0.000422188 -0.001600486
Lag 50 -0.008805916  0.007414425</code></pre>
<p>A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).</p>
</div>
<div id="model-validation" class="section level1">
<h1>Model validation</h1>
<p>Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.</p>
<p>There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:</p>
<ul>
<li><p><strong>Standardised residuals</strong>. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).</p></li>
<li><p><strong>Studentised residuals</strong>. The raw residuals divided by the standard deviation of the residuals. Note that <strong>externally studentised residuals</strong> are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.</p></li>
<li><p><strong>Pearson residuals</strong>. The raw residuals divided by the standard deviation of the response variable.</p></li>
</ul>
<p>he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as <span class="math inline">\(25\)</span>%) back thereby allowing us to train the model on <span class="math inline">\(75\)</span>% of the data and then see how well the model can predict the withheld <span class="math inline">\(25\)</span>%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.</p>
<p>Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within <code>JAGS</code>. However, we can calculate them manually form the posteriors.</p>
<pre class="r"><code>&gt; library(dplyr)
&gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&gt;% as.data.frame %&gt;%
+     dplyr:::select(contains(&quot;beta&quot;), sigma) %&gt;% as.matrix
&gt; # generate a model matrix
&gt; newdata = data
&gt; Xmat = model.matrix(~x, newdata)
&gt; ## get median parameter estimates
&gt; coefs = apply(mcmc[, 1:5], 2, median)
&gt; fit = as.vector(coefs %*% t(Xmat))
&gt; resid = data$y - fit
&gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals-1.png" width="672" /></p>
<p>Residuals against predictors</p>
<pre class="r"><code>&gt; library(tidyr)
&gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&gt;% as.data.frame %&gt;%
+     dplyr:::select(contains(&quot;beta&quot;), sigma) %&gt;% as.matrix
&gt; # generate a model matrix
&gt; newdata = newdata
&gt; Xmat = model.matrix(~x, newdata)
&gt; ## get median parameter estimates
&gt; coefs = apply(mcmc[, 1:5], 2, median)
&gt; fit = as.vector(coefs %*% t(Xmat))
&gt; resid = data$y - fit
&gt; newdata = newdata %&gt;% cbind(fit, resid)
&gt; ggplot(newdata) + geom_point(aes(y = resid, x = x)) + theme_classic()</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals2-1.png" width="672" /></p>
<p>And now for studentised residuals</p>
<pre class="r"><code>&gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&gt;% as.data.frame %&gt;%
+     dplyr:::select(contains(&quot;beta&quot;), sigma) %&gt;% as.matrix
&gt; # generate a model matrix
&gt; newdata = data
&gt; Xmat = model.matrix(~x, newdata)
&gt; ## get median parameter estimates
&gt; coefs = apply(mcmc[, 1:5], 2, median)
&gt; fit = as.vector(coefs %*% t(Xmat))
&gt; resid = data$y - fit
&gt; sresid = resid/sd(resid)
&gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals3-1.png" width="672" /></p>
<p>For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.</p>
<pre class="r"><code>&gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&gt;% as.data.frame %&gt;%
+     dplyr:::select(contains(&quot;beta&quot;), sigma) %&gt;% as.matrix
&gt; # generate a model matrix
&gt; Xmat = model.matrix(~x, data)
&gt; ## get median parameter estimates
&gt; coefs = mcmc[, 1:5]
&gt; fit = coefs %*% t(Xmat)
&gt; ## draw samples from this model
&gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &quot;sigma&quot;]))
&gt; newdata = data.frame(x = data$x, yRep) %&gt;% gather(key = Sample,
+     value = Value, -x)
&gt; ggplot(newdata) + geom_violin(aes(y = Value, x = x, fill = &quot;Model&quot;),
+     alpha = 0.5) + geom_violin(data = data, aes(y = y, x = x,
+     fill = &quot;Obs&quot;), alpha = 0.5) + geom_point(data = data, aes(y = y,
+     x = x), position = position_jitter(width = 0.1, height = 0),
+     color = &quot;black&quot;) + theme_classic()</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep-1.png" width="672" /></p>
<p>The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.</p>
<pre class="r"><code>&gt; library(bayesplot)
&gt; mcmc_intervals(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &quot;beta|sigma&quot;)</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep2-1.png" width="672" /></p>
<pre class="r"><code>&gt; mcmc_areas(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &quot;beta|sigma&quot;)</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep2-2.png" width="672" /></p>
</div>
<div id="parameter-estimates" class="section level1">
<h1>Parameter estimates</h1>
<p>Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and <span class="math inline">\(95\)</span>% credibility intervals.</p>
<pre class="r"><code>&gt; mcmcpvalue &lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &lt;- colSums(std * std)
+         sum(sqdist[-1] &gt; sqdist[1])/length(samp)
+     } else {
+         std &lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &lt;- colSums(std * std)
+         sum(sqdist[-1] &gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }</code></pre>
<p>First, we look at the results from the additive model.</p>
<pre class="r"><code>&gt; print(data.r2jags)
Inference for Bugs model at &quot;anovaModel2.txt&quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.226   0.901  38.475  39.624  40.222  40.824  41.999 1.001  4800
beta[2]    5.401   1.272   2.906   4.552   5.397   6.242   7.900 1.001 15000
beta[3]   13.492   1.296  10.969  12.634  13.484  14.355  16.038 1.001  5100
beta[4]    0.734   1.279  -1.793  -0.114   0.740   1.582   3.263 1.001 15000
beta[5]  -10.248   1.283 -12.785 -11.108 -10.242  -9.380  -7.731 1.001  9800
sigma      2.863   0.315   2.321   2.642   2.838   3.053   3.558 1.001  6200
deviance 245.551   3.785 240.353 242.765 244.844 247.603 254.815 1.002  1800

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).
&gt; 
&gt; # OR
&gt; library(broom)
&gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &quot;HPDinterval&quot;)
# A tibble: 7 x 5
  term     estimate std.error conf.low conf.high
  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 beta[1]    40.2       0.901    38.5      42.0 
2 beta[2]     5.40      1.27      2.90      7.89
3 beta[3]    13.5       1.30     11.0      16.1 
4 beta[4]     0.734     1.28     -1.82      3.21
5 beta[5]   -10.2       1.28    -12.7      -7.68
6 deviance  246.        3.79    240.      253.  
7 sigma       2.86      0.315     2.26      3.48</code></pre>
<p><strong>Conclusions</strong></p>
<ul>
<li>the mean of the first group (A) is <span class="math inline">\(40.2\)</span></li>
<li>the mean of the second group (B) is <span class="math inline">\(5.4\)</span> units greater than (A)</li>
<li>the mean of the third group (C) is <span class="math inline">\(13.5\)</span> units greater than (A)</li>
<li>the mean of the forth group (D) is <span class="math inline">\(0.74\)</span> units greater than (A)</li>
<li>the mean of the fifth group (E) is <span class="math inline">\(-10.2\)</span> units greater (i.e. less) than (A)</li>
</ul>
<p>The <span class="math inline">\(95\)</span>% confidence interval for the effects of B, C and E do not overlap with <span class="math inline">\(0\)</span> implying a significant difference between group A and groups B, C and E. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.</p>
<pre class="r"><code>&gt; ## since values are less than zero
&gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &quot;beta[2]&quot;])  # effect of (B-A)
[1] 6.666667e-05
&gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &quot;beta[3]&quot;])  # effect of (C-A)
[1] 0
&gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &quot;beta[4]&quot;])  # effect of (D-A)
[1] 0.5576
&gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &quot;beta[5]&quot;])  # effect of (E-A)
[1] 0
&gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, 2:5])  # effect of (all groups)
[1] 0</code></pre>
<p>There is evidence that the reponse differs between the groups. There is evidence suggesting that the response of group D differs from that of group A.</p>
</div>
<div id="graphical-summaries" class="section level1">
<h1>Graphical summaries</h1>
<p>A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.</p>
<pre class="r"><code>&gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&gt; ## Calculate the fitted values
&gt; newdata = rbind(data.frame(x = levels(data$x)))
&gt; Xmat = model.matrix(~x, newdata)
&gt; coefs = mcmc[, c(&quot;beta[1]&quot;, &quot;beta[2]&quot;, &quot;beta[3]&quot;, &quot;beta[4]&quot;, &quot;beta[5]&quot;)]
&gt; fit = coefs %*% t(Xmat)
&gt; newdata = newdata %&gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &quot;HPDinterval&quot;))
&gt; 
&gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_linerange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_point() + scale_y_continuous(&quot;Y&quot;) + scale_x_discrete(&quot;X&quot;) +
+     theme_classic()</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_post1-1.png" width="672" /></p>
<p>As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.</p>
<pre class="r"><code>&gt; ## Calculate partial residuals fitted values
&gt; fdata = rdata = data
&gt; fMat = rMat = model.matrix(~x, fdata)
&gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&gt; rdata = rdata %&gt;% mutate(partial.resid = resid + fit)
&gt; 
&gt; ggplot(newdata, aes(y = estimate, x = as.numeric(x) - 0.1)) + geom_blank(aes(x = x)) +
+     geom_point(data = rdata, aes(y = partial.resid, x = as.numeric(x) +
+         0.1), color = &quot;gray&quot;) + geom_linerange(aes(ymin = conf.low, ymax = conf.high)) +
+     geom_point() + scale_y_continuous(&quot;Y&quot;) + scale_x_discrete(&quot;&quot;) + theme_classic()</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_post2-1.png" width="672" /></p>
</div>
<div id="posteriors" class="section level1">
<h1>Posteriors</h1>
<p>In frequentist statistics, when we have more than two groups, we are typically not only interested in whether there is evidence for an overall “effect” of a factor - we are also interested in how various groups compare to one another. To explore these trends, we either compare each group to each other in a pairwise manner (controlling for family-wise Type I error rates) or we explore an independent subset of the possible comparisons. Although these alternate approaches can adequately address a specific research agenda, often they impose severe limitations and compromises on the scope and breadth of questions that can be asked of your data. The reason for these limitations is that in a frequentist framework, any single hypothesis carries with it a (nominally) <span class="math inline">\(5\)</span>% chance of a false rejection (since it is based on long-run frequency). Thus, performing multiple tests are likely to compound this error rate. The point is, that each comparison is compared to its own probability distribution (and each carries a <span class="math inline">\(5\)</span>% error rate). By contrast, in Bayesian statistics, all comparisons (contrasts) are drawn from the one (hopefully stable and convergent) posterior distribution and this posterior is invariant to the type and number of comparisons drawn. Hence, the theory clearly indicates that having generated our posterior distribution, we can then query this distribution in any way that we wish thereby allowing us to explore all of our research questions simultaneously.</p>
<p>Bayesian “contrasts” can be performed either:</p>
<ul>
<li><p>within the Bayesian sampling model or</p></li>
<li><p>construct them from the returned MCMC samples (they are drawn from the posteriors)</p></li>
</ul>
<p>Only the latter will be demonstrated as it povides a consistent approach across all routines. In order to allow direct comparison to the frequentist equivalents, I will explore the same set of planned and <em>Tukey</em>’s test comparisons described here. For the “planned comparison” we defined two contrasts: 1) group 3 vs group 5; and 2) the average of groups 1 and 2 vs the average of groups 3, 4 and 5.</p>
<p>Lets start by comparing each group to each other group in a pairwise manner. Arguably the most elegant way to do this is to generate a Tukey’s contrast matrix. This is a model matrix specific to comparing each group to each other group.</p>
<pre class="r"><code>&gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&gt; coefs &lt;- as.matrix(mcmc)[, 1:5]
&gt; newdata &lt;- data.frame(x = levels(data$x))
&gt; # A Tukeys contrast matrix
&gt; library(multcomp)
&gt; # table(newdata$x) - gets the number of replicates of each level
&gt; tuk.mat &lt;- contrMat(n = table(newdata$x), type = &quot;Tukey&quot;)
&gt; Xmat &lt;- model.matrix(~x, data = newdata)
&gt; pairwise.mat &lt;- tuk.mat %*% Xmat
&gt; pairwise.mat
      (Intercept) xB xC xD xE
B - A           0  1  0  0  0
C - A           0  0  1  0  0
D - A           0  0  0  1  0
E - A           0  0  0  0  1
C - B           0 -1  1  0  0
D - B           0 -1  0  1  0
E - B           0 -1  0  0  1
D - C           0  0 -1  1  0
E - C           0  0 -1  0  1
E - D           0  0  0 -1  1
&gt; 
&gt; mcmc_areas(coefs %*% t(pairwise.mat))</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior1-1.png" width="672" /></p>
<pre class="r"><code>&gt; 
&gt; (comps = tidyMCMC(coefs %*% t(pairwise.mat), conf.int = TRUE, conf.method = &quot;HPDinterval&quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
 1 B - A    5.40       1.27     2.90      7.89
 2 C - A   13.5        1.30    11.0      16.1 
 3 D - A    0.734      1.28    -1.82      3.21
 4 E - A  -10.2        1.28   -12.7      -7.68
 5 C - B    8.09       1.29     5.58     10.7 
 6 D - B   -4.67       1.30    -7.19     -2.02
 7 E - B  -15.6        1.28   -18.1     -13.1 
 8 D - C  -12.8        1.31   -15.3     -10.2 
 9 E - C  -23.7        1.29   -26.2     -21.2 
10 E - D  -11.0        1.29   -13.5      -8.46
&gt; 
&gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) +
+     scale_y_continuous(&quot;Effect size&quot;) + scale_x_discrete(&quot;&quot;) + coord_flip() +
+     theme_classic()</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior1-2.png" width="672" /></p>
<p>With a couple of modifications, we could also express this as percentage changes. A percentage change represents the change (difference between groups) divided by one of the groups (determined by which group you want to express the percentage change to). Hence, we generate an additional mcmc matrix that represents the cell means for the divisor group (group we want to express change relative to). Since the <code>tuk.mat</code> defines comparisons as <span class="math inline">\(-1\)</span> and <span class="math inline">\(1\)</span> pairs, if we simply replace all the <span class="math inline">\(-1\)</span> with <span class="math inline">\(0\)</span>, the eventual matrix multiplication will result in estimates of the divisor cell means instread of the difference. We can then divide the original mcmc matrix above with this new divisor mcmc matrix to yeild a mcmc matrix of percentage change.</p>
<pre class="r"><code>&gt; # Modify the tuk.mat to replace -1 with 0.  This will allow us to get a
&gt; # mcmc matrix of ..
&gt; tuk.mat[tuk.mat == -1] = 0
&gt; comp.mat &lt;- tuk.mat %*% Xmat
&gt; comp.mat
      (Intercept) xB xC xD xE
B - A           1  1  0  0  0
C - A           1  0  1  0  0
D - A           1  0  0  1  0
E - A           1  0  0  0  1
C - B           1  0  1  0  0
D - B           1  0  0  1  0
E - B           1  0  0  0  1
D - C           1  0  0  1  0
E - C           1  0  0  0  1
E - D           1  0  0  0  1
&gt; 
&gt; comp.mcmc = 100 * (coefs %*% t(pairwise.mat))/coefs %*% t(comp.mat)
&gt; (comps = tidyMCMC(comp.mcmc, conf.int = TRUE, conf.method = &quot;HPDinterval&quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
 1 B - A    11.8       2.63     6.52     16.8 
 2 C - A    25.1       2.13    21.0      29.4 
 3 D - A     1.74      3.10    -4.30      7.88
 4 E - A   -34.3       5.09   -44.3     -24.4 
 5 C - B    15.0       2.24    10.4      19.2 
 6 D - B   -11.5       3.38   -18.1      -4.70
 7 E - B   -52.3       5.53   -63.2     -41.6 
 8 D - C   -31.2       3.73   -38.5     -23.9 
 9 E - C   -79.4       6.26   -91.9     -67.5 
10 E - D   -36.8       5.15   -47.1     -27.0 
&gt; 
&gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) +
+     scale_y_continuous(&quot;Effect size (%)&quot;) + scale_x_discrete(&quot;&quot;) + coord_flip() +
+     theme_classic()</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior2-1.png" width="672" /></p>
<p>And now for the specific planned comparisons (Group 3 vs Group 5 and the average of Groups 1 and 2 vs the average of Groups 3, 4 and 5). This is achieved by generating our own contrast matrix (defining the contributions of each group to each contrast).</p>
<pre class="r"><code>&gt; c.mat = rbind(c(0, 0, -1, 0, 1), c(-1/2, -1/2, 1/3, 1/3, 1/3))
&gt; c.mat
     [,1] [,2]       [,3]      [,4]      [,5]
[1,]  0.0  0.0 -1.0000000 0.0000000 1.0000000
[2,] -0.5 -0.5  0.3333333 0.3333333 0.3333333
&gt; 
&gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&gt; coefs &lt;- as.matrix(mcmc)[, 1:5]
&gt; newdata &lt;- data.frame(x = levels(data$x))
&gt; Xmat &lt;- model.matrix(~x, data = newdata)
&gt; c.mat = c.mat %*% Xmat
&gt; c.mat
       (Intercept)   xB         xC        xD        xE
[1,]  0.000000e+00  0.0 -1.0000000 0.0000000 1.0000000
[2,] -1.110223e-16 -0.5  0.3333333 0.3333333 0.3333333
&gt; 
&gt; (comps = tidyMCMC(as.mcmc(coefs %*% t(c.mat)), conf.int = TRUE, conf.method = &quot;HPDinterval&quot;))
# A tibble: 2 x 5
  term  estimate std.error conf.low conf.high
  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 var1    -23.7      1.29    -26.2    -21.2  
2 var2     -1.37     0.836    -3.01     0.273</code></pre>
</div>
<div id="finite-population-standard-deviations" class="section level1">
<h1>Finite population standard deviations</h1>
<p>Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).</p>
<p>Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (<span class="citation">Gelman and others (2005)</span>). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.</p>
<pre><code>      beta[1]  beta[2]  beta[3]    beta[4]    beta[5] deviance    sigma
[1,] 41.14988 5.425974 13.10634  0.5423808 -12.004913 245.9651 2.374957
[2,] 41.77436 3.165155 12.08478 -2.5284367 -11.070257 251.2837 3.546706
[3,] 39.87873 5.074910 13.46806  0.7805140  -7.932663 245.7947 3.020465
[4,] 41.15168 3.079048 10.80976 -0.5505218 -10.396170 249.3934 2.547300
[5,] 39.93263 4.548017 13.82126  1.2192389  -9.549601 242.2442 2.449639
[6,] 40.41198 4.705732 12.87972  2.3548628  -8.868949 250.1582 2.432338
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 sd.x         9.94    0.528      8.86     10.9 
2 sd.resid     2.79    0.0903     2.67      2.96
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 sd.x         78.3      1.07     76.0      79.7
2 sd.resid     21.7      1.07     20.3      24.0</code></pre>
<p><img src="/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/eff_pop1-1.png" width="672" /></p>
<p>Approximately <span class="math inline">\(78.3\)</span>% of the total finite population standard deviation is due to <span class="math inline">\(x\)</span>.</p>
</div>
<div id="r-squared" class="section level1">
<h1>R squared</h1>
<p>In a frequentist context, the <span class="math inline">\(R^2\)</span> value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, <span class="math inline">\(R^2\)</span> is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an <span class="math inline">\(R^2\)</span> greater than <span class="math inline">\(100\)</span>%. <span class="citation">Gelman et al. (2019)</span> proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.</p>
<p>So in the standard regression model notation of:</p>
<p><span class="math display">\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]</span></p>
<p>the <span class="math inline">\(R^2\)</span> could be formulated as</p>
<p><span class="math display">\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]</span></p>
<p>where <span class="math inline">\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)</span>, and for normal models <span class="math inline">\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)</span></p>
<pre class="r"><code>&gt; mcmc &lt;- data.r2jags$BUGSoutput$sims.matrix
&gt; Xmat = model.matrix(~x, data)
&gt; wch = grep(&quot;beta&quot;, colnames(mcmc))
&gt; coefs = mcmc[, wch]
&gt; fit = coefs %*% t(Xmat)
&gt; var_f = apply(fit, 1, var)
&gt; var_e = apply(resid, 1, var)
&gt; R2 = var_f/(var_f + var_e)
&gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &quot;HPDinterval&quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 var1     0.887    0.0127    0.862     0.905
&gt; 
&gt; # for comparison with frequentist
&gt; summary(lm(y ~ x, data))

Call:
lm(formula = y ~ x, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5257 -1.9000 -0.2589  1.4935  6.5330 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  40.2239     0.8801  45.702  &lt; 2e-16 ***
xB            5.4020     1.2447   4.340 7.97e-05 ***
xC           13.5024     1.2447  10.848 3.82e-14 ***
xD            0.7423     1.2447   0.596    0.554    
xE          -10.2500     1.2447  -8.235 1.57e-10 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.783 on 45 degrees of freedom
Multiple R-squared:  0.8957,    Adjusted R-squared:  0.8865 
F-statistic: 96.64 on 4 and 45 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="bayesian-model-selection" class="section level1">
<h1>Bayesian model selection</h1>
<p>A statistical model is by definition a low-dimensional (over simplification) representation of what is really likely to be a very complex system. As a result, no model is right. Some models however can provide useful insights into some of the processes operating on the system. Frequentist statistics have various methods (model selection, dredging, lasso, cross validation) for selecting parsimonious models. These are models that provide a good comprimise between minimizing unexplained patterns and minimizing model complexity. The basic premise is that since no model can hope to capture the full complexity of a system with all its subtleties, only the very major patterns can be estimated. Overly complex models are likely to be representing artificial complexity present only in the specific observed data (not the general population). The Bayesian approach is to apply priors to the non-variance parameters such that parameters close to zero are further shrunk towards zero whilst priors on parameters further away from zero are less effected. The most popular form of prior for sparsity is the <em>horseshoe prior</em>, so called because the shape of a component of this prior resembles a horseshoe (with most of the mass either close to <span class="math inline">\(0\)</span> or close to <span class="math inline">\(1\)</span>).</p>
<p>Rather than apply weakly informative Gaussian priors on parameters as:</p>
<p><span class="math display">\[ \beta_j \sim N(0,\sigma^2),\]</span></p>
<p>the horseshoe prior is defined as</p>
<p><span class="math display">\[ \beta_j \sim N(0,\tau^2\lambda_j^2),\]</span></p>
<p>where <span class="math inline">\(\tau \sim \text{Cauchy}(0,1)\)</span> and <span class="math inline">\(\lambda_j \sim \text{Cauchy}(0,1)\)</span>, for <span class="math inline">\(j=1,\ldots,D\)</span>. Using this prior, <span class="math inline">\(D\)</span> is the number of (non-intercept or variance) parameters, <span class="math inline">\(\tau\)</span> represents the global scale that weights or shrinks all parameters towards zero and <span class="math inline">\(\lambda_j\)</span> are thick tailed local scales that allow some of the <span class="math inline">\(j\)</span> parameters to escape shrinkage. More recently, <span class="citation">Piironen, Vehtari, and others (2017)</span> have argued that whilst the above horseshoe priors do guarantee that strong effects (parameters) will not be over-shrunk, there is the potential for weekly identified effects (those based on relatively little data) to be misrepresented in the posteriors. As an alternative they advocated the use of regularised horseshoe priors in which the amount of shrinkage applied to the largest effects can be controlled. The prior is defined as:</p>
<p><span class="math display">\[ \beta_j \sim N(0,\tau^2 \tilde{\lambda}_j^2),\]</span></p>
<p>where <span class="math inline">\(\tilde{\lambda}_j^2 = \frac{c^2\lambda^2_j}{c^2+\tau^2 \lambda^2_j}\)</span> and <span class="math inline">\(c\)</span> is (slab width, actually variance) is a constant. For small effects (when <span class="math inline">\(\tau^2 \lambda^2_j &lt; c^2\)</span>) the prior approaches a regular prior. However, for large effects (when <span class="math inline">\(\tau^2 \lambda^2_j &gt; c^2\)</span>) the prior approaches <span class="math inline">\(N(0,c^2)\)</span>. Finally, they recommend applying a inverse-gamma prior on <span class="math inline">\(c^2\)</span>:</p>
<p><span class="math display">\[ c^2 \sim \text{Inv-Gamma}(\alpha,\beta),\]</span></p>
<p>where <span class="math inline">\(\alpha=v/2\)</span> and <span class="math inline">\(\beta=vs^2/2\)</span>, which translates to a <span class="math inline">\(\text{Student-t}_ν(0, s^2)\)</span> slab for the coefficients far from zero and is typically a good default choice for a weakly informative prior.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references hanging-indent">
<div id="ref-gelman2019r">
<p>Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” <em>The American Statistician</em> 73 (3): 307–9.</p>
</div>
<div id="ref-gelman2005analysis">
<p>Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” <em>The Annals of Statistics</em> 33 (1): 1–53.</p>
</div>
<div id="ref-piironen2017sparsity">
<p>Piironen, Juho, Aki Vehtari, and others. 2017. “Sparsity Information and Regularization in the Horseshoe and Other Shrinkage Priors.” <em>Electronic Journal of Statistics</em> 11 (2): 5018–51.</p>
</div>
<div id="ref-plummer2004jags">
<p>Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”</p>
</div>
<div id="ref-su2015package">
<p>Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” <em>R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags</em>.</p>
</div>
</div>
</div>

    </div>

    

<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/tutorials/">tutorials</a>
  
  <a class="badge badge-light" href="/tags/jags/">JAGS</a>
  
  <a class="badge badge-light" href="/tags/anova/">anova</a>
  
  <a class="badge badge-light" href="/tags/facor-analysis/">facor analysis</a>
  
</div>



    
      








  
  
    
  
  





  
  
  
  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="/authors/andrea-gabrio/"></a></h5>
      
      
      <ul class="network-icon" aria-hidden="true">
        
      </ul>
    </div>
  </div>



      
      
      <div class="article-widget">
        <div class="hr-light"></div>
        <h3>Related</h3>
        <ul>
          
          <li><a href="/stan/single-factor-anova-stan/single-factor-anova-stan/">Single Factor Anova - STAN</a></li>
          
          <li><a href="/jags/multiple-linear-regression-jags/multiple-linear-regression-jags/">Multiple Linear Regression - JAGS</a></li>
          
          <li><a href="/jags/simple-linear-regression-jags/simple-linear-regression-jags/">Simple Linear Regression - JAGS</a></li>
          
          <li><a href="/jags/comparing-two-populations-jags/comparing-two-populations-jags/">Comparing Two Populations - JAGS</a></li>
          
          <li><a href="/stan/multiple-linear-regression-stan/multiple-linear-regression-stan/">Multiple Linear Regression - STAN</a></li>
          
        </ul>
      </div>
      
    

    

    


  </div>
</article>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script async defer src="//maps.googleapis.com/maps/api/js?key=AIzaSyAYShZdrjjE_TojzlN30gOZCZjvTBD3b3c"></script>
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/gmaps.js/0.4.25/gmaps.min.js" integrity="sha256-7vjlAeb8OaTrCXZkCNun9djzuB2owUsaO72kXaFDBJs=" crossorigin="anonymous"></script>
      
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.3394a224b26ce58ff36f44c54743e0ab.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">

  <p class="powered-by">
    

    &#169; Andrea Gabrio 2019. Based on the 
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
