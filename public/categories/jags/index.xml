<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>JAGS on Andrea Gabrio</title>
    <link>/categories/jags/</link>
    <description>Recent content in JAGS on Andrea Gabrio</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>`{year}`</copyright>
    <lastBuildDate>Sat, 21 Mar 2020 21:13:14 -0500</lastBuildDate>
    
	    <atom:link href="/categories/jags/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Item Response Theory Models - JAGS</title>
      <link>/jags/irt-jags/irt-jags/</link>
      <pubDate>Sat, 21 Mar 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/irt-jags/irt-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;p&gt;Item response theory (IRT) is a paradigm for investigating the relationship between an individual’s response to a single test item and their performance on an overall measure of the ability or trait that item was intended to measure. Many models exist in the IRT field for evaulating how well an item captures an underlying latent trait, but some of the most popular IRT models are &lt;em&gt;logistic IRT models&lt;/em&gt; for dichotmous responses. In particular, the main types of models are:&lt;/p&gt;
&lt;p&gt;1 &lt;strong&gt;1 parameter logistic model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2 &lt;strong&gt;2 parameter logistic model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;3 &lt;strong&gt;3 parameter logistic model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Throughout this tutorial, I assume that the reader has some basic understanding of IRT model and working knowledge of a software implementation of the &lt;code&gt;JAGS&lt;/code&gt; language. However, if this is not the case, excellent sources for learning IRT are &lt;span class=&#34;citation&#34;&gt;Baker and Kim (2004)&lt;/span&gt;, who provide a mathematically detailed introduction to IRT, and &lt;span class=&#34;citation&#34;&gt;Hambleton, Swaminathan, and Rogers (1991)&lt;/span&gt;, who give an intuitive introduction to the topic. For an in-depth description of how to implement different types of IRT models in &lt;code&gt;OpenBUGS&lt;/code&gt; and &lt;code&gt;JAGS&lt;/code&gt;, I also refer to this very nice review of &lt;span class=&#34;citation&#34;&gt;Curtis and others (2010)&lt;/span&gt; and this other online &lt;a href=&#34;https://quantdev.ssri.psu.edu/sites/qdev/files/IRT_tutorial_FA17.html#3_2-parameter_logistic_(2pl)_irt_model&#34;&gt;tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At the core of all the IRT models presented in this tutorial is the &lt;em&gt;Item Response Function&lt;/em&gt; (IRF). The IRF estimates the probability of getting item &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; “correct” as a function of item characteristics and the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th individual’s latent trait/ability level (&lt;span class=&#34;math inline&#34;&gt;\(\theta_i\)&lt;/span&gt;). These item response functions are defined by a logistic curve (i.e. an &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;-shape from &lt;span class=&#34;math inline&#34;&gt;\(0-1\)&lt;/span&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-logistic-model-1plm&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;1 parameter logistic model (1PLM)&lt;/h1&gt;
&lt;p&gt;The 1PLM is used for data collected on &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; individuals who have each given responses on &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;
different items. The items have binary outcomes, i.e. the items are scored as &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; if correct
and &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; if not. The &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th individual in the sample is assumed to have a latent ability &lt;span class=&#34;math inline&#34;&gt;\(\theta_i\)&lt;/span&gt;, and the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th individual’s response on the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th item is a random variable &lt;span class=&#34;math inline&#34;&gt;\(Y_{ij}\)&lt;/span&gt; with a Bernoulli distribution. The probability that the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th individual correctly answers the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th item (i.e. the probability that &lt;span class=&#34;math inline&#34;&gt;\(Y_{ij} = 1\)&lt;/span&gt;) is assumed to have the following IRF form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p_{ij} = P(Y_{ij}=1 \mid \theta_i,\delta_j)=\frac{1}{1+\text{exp}(\theta_i-\delta_j)},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\delta_j\)&lt;/span&gt; is the &lt;em&gt;difficulty parameter&lt;/em&gt; for item &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; of the test, and is assumed to be normally distributed according to some mean &lt;span class=&#34;math inline&#34;&gt;\(\mu_{\delta}\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\delta}\)&lt;/span&gt; which must be specified by the analyst. Each &lt;em&gt;latent ability parameter&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\theta_i\)&lt;/span&gt; is also assumed to be distributed according to a standard normal distribution.&lt;/p&gt;
&lt;div id=&#34;load-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load the data&lt;/h2&gt;
&lt;p&gt;I read in the data from the file &lt;code&gt;wideformat.csv&lt;/code&gt;, which contains (simulated) data from &lt;span class=&#34;math inline&#34;&gt;\(n=1000\)&lt;/span&gt; individuals taking a &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;-item test. Items are coded &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; for correct and &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; for incorrect responses. When we get descriptives of the data, we see that the items differ in terms of the proportion of people who answered correctly, so we expect that we have some differences in item difficulty here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data_dicho&amp;lt;-read.csv(&amp;quot;wideformat.csv&amp;quot;, sep = &amp;quot;,&amp;quot;)
&amp;gt; head(data_dicho)
       ID gender age Item.1 Item.2 Item.3 Item.4 Item.5
1 person1   Male  40      0      0      0      0      0
2 person2 Female  27      0      0      0      0      0
3 person3   Male  13      0      0      0      0      0
4 person4 Female  17      0      0      0      0      1
5 person5 Female  30      0      0      0      0      1
6 person6 Female  46      0      0      0      0      1
&amp;gt; 
&amp;gt; #check proportion of correct responses by item
&amp;gt; apply(data_dicho[,4:8], 2, sum)/nrow(data_dicho)
Item.1 Item.2 Item.3 Item.4 Item.5 
 0.924  0.709  0.553  0.763  0.870 
&amp;gt; 
&amp;gt; #summarise the data
&amp;gt; library(psych)
&amp;gt; describe(data_dicho)
        vars    n   mean     sd median trimmed    mad min  max range  skew
ID*        1 1000 500.50 288.82  500.5  500.50 370.65   1 1000   999  0.00
gender*    2 1000   1.50   0.50    2.0    1.51   0.00   1    2     1 -0.02
age        3 1000  25.37  14.43   25.0   25.36  17.79   1   50    49  0.01
Item.1     4 1000   0.92   0.27    1.0    1.00   0.00   0    1     1 -3.20
Item.2     5 1000   0.71   0.45    1.0    0.76   0.00   0    1     1 -0.92
Item.3     6 1000   0.55   0.50    1.0    0.57   0.00   0    1     1 -0.21
Item.4     7 1000   0.76   0.43    1.0    0.83   0.00   0    1     1 -1.24
Item.5     8 1000   0.87   0.34    1.0    0.96   0.00   0    1     1 -2.20
        kurtosis   se
ID*        -1.20 9.13
gender*    -2.00 0.02
age        -1.21 0.46
Item.1      8.22 0.01
Item.2     -1.16 0.01
Item.3     -1.96 0.02
Item.4     -0.48 0.01
Item.5      2.83 0.01&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit the model&lt;/h2&gt;
&lt;p&gt;We fit the 1PLM to the data. First, I rename and preprocess the data to be passed to &lt;code&gt;JAGS&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Y&amp;lt;-data_dicho[,4:8]
&amp;gt; n&amp;lt;-nrow(Y)
&amp;gt; p&amp;lt;-ncol(Y)
&amp;gt; data_list&amp;lt;-list(&amp;quot;Y&amp;quot;,&amp;quot;n&amp;quot;,&amp;quot;p&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I specify the model using the following &lt;code&gt;JAGS&lt;/code&gt; code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; model1&amp;lt;-&amp;quot;
+ model {
+  for (i in 1:n){
+   for (j in 1:p){
+    Y[i , j] ~ dbern ( prob [i , j])
+    logit ( prob [i , j]) &amp;lt;- theta [i] - delta [j]
+   }
+   theta [i] ~ dnorm (0.0 , 1.0)
+  }
+ 
+  for (j in 1:p){
+   delta [j] ~ dnorm (mu.delta , pr.delta )
+  }
+   pr.delta &amp;lt;- pow(s.delta , -2)
+   mu.delta ~ dnorm(0, 5)
+   s.delta ~ dunif(0, 10)
+   
+   for(i in 1:n){
+    for(j in 1:p){
+     Y.rep[i, j] ~ dbern(prob[i, j])
+     loglik_y[i, j]&amp;lt;-logdensity.bern(Y[i,j], prob[i, j])
+    }
+   }
+ }
+ &amp;quot;
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(model1, con = &amp;quot;model1PLM.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;delta&amp;quot;, &amp;quot;theta&amp;quot;, &amp;quot;prob&amp;quot;,&amp;quot;loglik_y&amp;quot;,&amp;quot;Y.rep&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 500
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 2500  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 1750&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface and the &lt;code&gt;jags&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)
&amp;gt; library(coda)
&amp;gt; set.seed(3456)
&amp;gt; m1.r2jags &amp;lt;- jags(data = data_list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;model1PLM.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-the-item-characteristic-curves&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot the item characteristic curves&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Item characteristic curves&lt;/em&gt; (ICC) are the logistic curves which result from the fitted models (e.g. estimated item difficulty, plugged into the item response function). Latent trait/ability is plotted on the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;-axis (higher values represent hight ability). Probability of a “correct” answer (&lt;span class=&#34;math inline&#34;&gt;\(Y_{ij}=1\)&lt;/span&gt;) to an item is plotted on the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #see average value of item difficulty
&amp;gt; diff&amp;lt;-m1.r2jags$BUGSoutput$sims.list$delta
&amp;gt; apply(diff,2,mean)
[1] -2.8583972 -1.0620835 -0.2608953 -1.3853516 -2.2159276
&amp;gt; 
&amp;gt; #plot icc for each individual with respect to each of the 5 items
&amp;gt; theta&amp;lt;-apply(m1.r2jags$BUGSoutput$sims.list$theta, 2, mean)
&amp;gt; prob&amp;lt;-apply(m1.r2jags$BUGSoutput$sims.list$prob,c(2,3),mean)
&amp;gt; plot(theta,prob[,1], type = &amp;quot;n&amp;quot;, ylab = &amp;quot;probability of correct response&amp;quot;, xlab=&amp;quot;ability&amp;quot;,
+      xlim = c(-2.5,1), ylim = c(0,1))
&amp;gt; lines(theta,prob[,1],col=&amp;quot;red&amp;quot;)
&amp;gt; lines(theta,prob[,2],col=&amp;quot;blue&amp;quot;)
&amp;gt; lines(theta,prob[,3],col=&amp;quot;orange&amp;quot;)
&amp;gt; lines(theta,prob[,4],col=&amp;quot;green&amp;quot;)
&amp;gt; lines(theta,prob[,5],col=&amp;quot;black&amp;quot;)
&amp;gt; legend(&amp;quot;bottomright&amp;quot;,legend = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;4&amp;quot;,&amp;quot;5&amp;quot;), lty = c(1), col=c(&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;orange&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;black&amp;quot;), bty = &amp;quot;n&amp;quot;, cex = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/icc1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that item &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; is the most difficult item (it’s curve is farthest to the right), and item &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is the easiest (it’s curve is farthest to the left). The same conclusions can be drawn by checking the difficulty estimates above.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-the-item-information-curves&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot the item information curves&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Item information curves&lt;/em&gt; (IIC) show how much “information” about the latent trait ability an item gives. Mathematically, these are the &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;st derivatives of the ICCs or, equivalently, to the product of the probability of correct and incorrect response. Item information curves peak at the difficulty value (point where the item has the highest discrimination), with less information at ability levels farther from the difficulty estimate. Practially speaking, we can see how a very difficult item will provide very little information about persons with low ability (because the item is already too hard), and very easy items will provide little information about persons with high ability levels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #plot iic for each individual with respect to each of the 5 items
&amp;gt; neg_prob&amp;lt;-1-prob
&amp;gt; information&amp;lt;-prob*neg_prob
&amp;gt; plot(theta,information[,1], type = &amp;quot;n&amp;quot;, ylab = &amp;quot;information&amp;quot;, xlab=&amp;quot;ability&amp;quot;,
+      xlim = c(-2.5,1), ylim = c(0,0.3))
&amp;gt; lines(theta,information[,1],col=&amp;quot;red&amp;quot;)
&amp;gt; lines(theta,information[,2],col=&amp;quot;blue&amp;quot;)
&amp;gt; lines(theta,information[,3],col=&amp;quot;orange&amp;quot;)
&amp;gt; lines(theta,information[,4],col=&amp;quot;green&amp;quot;)
&amp;gt; lines(theta,information[,5],col=&amp;quot;black&amp;quot;)
&amp;gt; legend(&amp;quot;bottomleft&amp;quot;,legend = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;4&amp;quot;,&amp;quot;5&amp;quot;), lty = c(1), col=c(&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;orange&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;black&amp;quot;), bty = &amp;quot;n&amp;quot;, cex = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/iic1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Similar to the ICCs, we see that item &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; provides the most information about high ability levels (the peak of its IIC is farthest to the right) and item &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; provides the most information about lower ability levels (the peak of its IIC is farthest to the left). We have seen that all ICCs and IICs for the items have the same shape in the 1PL model (i.e. all items are equally good at providing information about the latent trait). In the 2PL and 3PL models, we will see that this does not have to be the case.&lt;/p&gt;
&lt;p&gt;Next, we plot the information curve for the whole test. This is simply the sum of the individual IICs above. Ideally, we want a test which provides fairly good covereage of a wide range of latent ability levels. Otherwise, the test is only good at identifying a limited range of ability levels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #plot iic for each individual with respect to whole test
&amp;gt; information_test&amp;lt;-apply(information,1,sum)
&amp;gt; plot(theta,information_test, type = &amp;quot;n&amp;quot;, ylab = &amp;quot;information (test)&amp;quot;, xlab=&amp;quot;ability&amp;quot;,
+      xlim = c(-2.5,1), ylim = c(0,1.5))
&amp;gt; lines(theta,information_test,col=&amp;quot;black&amp;quot;,lty=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/iic1tot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; summary(information_test)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.5472  0.5710  0.7669  0.7756  0.9305  1.0786 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that this test provides the most information about low ability levels (the peak is around ability level &lt;span class=&#34;math inline&#34;&gt;\(-1.5\)&lt;/span&gt;), and less information about very high ability levels.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assess-fit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assess fit&lt;/h2&gt;
&lt;p&gt;We perform posterior predictive checks to test whether individual items fit the 1PLM by comparing quantities computed from the predictions of the model with those from the observed data. If these match reasonably well, then there is indication that the model has a good fit.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; library(ggplot2)
&amp;gt; Y.rep&amp;lt;-m1.r2jags$BUGSoutput$sims.list$Y.rep
&amp;gt; 
&amp;gt; #Bar plot of y with yrep medians and uncertainty intervals superimposed on the bars
&amp;gt; ppc_bars(Y[,1],Y.rep[1:8,,1]) + ggtitle(&amp;quot;Item 1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,2],Y.rep[1:8,,2]) + ggtitle(&amp;quot;Item 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,3],Y.rep[1:8,,3]) + ggtitle(&amp;quot;Item 3&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m1-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,4],Y.rep[1:8,,4]) + ggtitle(&amp;quot;Item 4&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m1-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,5],Y.rep[1:8,,5]) + ggtitle(&amp;quot;Item 5&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m1-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-ability-scores&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot ability scores&lt;/h2&gt;
&lt;p&gt;We can conclude by summarising and plotting the latent ability scores of the participants&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #summary stats for theta across both iterations and individuals
&amp;gt; summary(theta)
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-2.074587 -0.483828  0.078138  0.001189  0.692185  0.763989 
&amp;gt; 
&amp;gt; #histogram and kernel density plot of theta averaged across iterations
&amp;gt; dens.theta&amp;lt;-density(theta, bw=0.3)
&amp;gt; hist(theta, breaks = 5, prob = T)
&amp;gt; lines(dens.theta, lwd=2, col=&amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/theta1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that the mean of ability scores is around &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, and the standard deviation about &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (these are estimated ability scores are standardised).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-logistic-model-2plm&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;2 parameter logistic model (2PLM)&lt;/h1&gt;
&lt;p&gt;In the 2PLM, the probability that the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th individual correctly answers the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th item (i.e. the probability that &lt;span class=&#34;math inline&#34;&gt;\(Y_{ij} = 1\)&lt;/span&gt;) is assumed to have the following IRF form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p_{ij} = P(Y_{ij}=1 \mid \theta_i,\delta_j,\alpha_j)=\frac{1}{1+\text{exp}(\alpha_j(\theta_i-\delta_j))},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\alpha_j\)&lt;/span&gt; is the &lt;em&gt;discrimination parameter&lt;/em&gt; for item &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; of the test, and is assumed to be positive and normally distributed (truncated above zero) according to some mean &lt;span class=&#34;math inline&#34;&gt;\(\mu_{\alpha}\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\alpha}\)&lt;/span&gt; which must be specified by the analyst. The item discriminability &lt;span class=&#34;math inline&#34;&gt;\(\alpha_j\)&lt;/span&gt; indicates how well an item is able to discriminate between persons with different ability levels. Item discriminability is reflected in the steepness of the slope of the ICC.&lt;/p&gt;
&lt;div id=&#34;fit-the-model-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit the model&lt;/h2&gt;
&lt;p&gt;We fit the 2PLM to the data using the following &lt;code&gt;JAGS&lt;/code&gt; code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; model2&amp;lt;-&amp;quot;
+ model {
+  for (i in 1:n){
+   for (j in 1:p){
+    Y[i , j] ~ dbern ( prob [i , j])
+    logit ( prob [i , j]) &amp;lt;- alpha [j] * ( theta [i] - delta [j])
+   }
+   theta [i] ~ dnorm (0.0 , 1.0)
+  }
+ 
+  for (j in 1:p){
+   delta [j] ~ dnorm (m.delta , pr.delta )
+   alpha [j] ~ dnorm (m.alpha , pr.alpha ) T(0 , )
+  }
+   pr.delta &amp;lt;- pow(s.delta , -2)
+   pr.alpha &amp;lt;- pow(s.alpha , -2)
+   
+   m.delta ~ dnorm(0,5)
+   m.alpha ~ dnorm(0,5)
+   s.delta ~ dunif(0,10)
+   s.alpha ~ dunif(0,10)
+   
+   for(i in 1:n){
+    for(j in 1:p){
+     Y.rep[i, j] ~ dbern(prob[i, j])
+     loglik_y[i, j]&amp;lt;-logdensity.bern(Y[i,j], prob[i, j])
+    }
+   }
+ }
+ &amp;quot;
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(model2, con = &amp;quot;model2PLM.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;delta&amp;quot;, &amp;quot;alpha&amp;quot;,&amp;quot;theta&amp;quot;, &amp;quot;prob&amp;quot;,&amp;quot;loglik_y&amp;quot;,&amp;quot;Y.rep&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 500
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 2500  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 1750&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface and the &lt;code&gt;jags&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; m2.r2jags &amp;lt;- jags(data = data_list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;model2PLM.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-the-item-characteristic-curves-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot the item characteristic curves&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Item characteristic curves&lt;/em&gt; (ICC) are the logistic curves which result from the fitted models (e.g. estimated item difficulty, plugged into the item response function). Latent trait/ability is plotted on the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;-axis (higher values represent hight ability). Probability of a “correct” answer (&lt;span class=&#34;math inline&#34;&gt;\(Y_{ij}=1\)&lt;/span&gt;) to an item is plotted on the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; discr&amp;lt;-m2.r2jags$BUGSoutput$sims.list$alpha
&amp;gt; diff&amp;lt;-m2.r2jags$BUGSoutput$sims.list$delta
&amp;gt; #see average value of item difficulty
&amp;gt; apply(diff,2,mean)
[1] -3.4898494 -1.4275914 -0.3210807 -1.8517091 -3.0020341
&amp;gt; #see average value of item discriminability
&amp;gt; apply(discr,2,mean)
[1] 0.8300819 0.7204114 0.7766516 0.7243196 0.7142145
&amp;gt; 
&amp;gt; #plot icc for each individual with respect to each of the 5 items
&amp;gt; theta&amp;lt;-apply(m2.r2jags$BUGSoutput$sims.list$theta, 2, mean)
&amp;gt; prob&amp;lt;-apply(m2.r2jags$BUGSoutput$sims.list$prob,c(2,3),mean)
&amp;gt; plot(theta,prob[,1], type = &amp;quot;n&amp;quot;, ylab = &amp;quot;probability of correct response&amp;quot;, xlab=&amp;quot;ability&amp;quot;,
+      xlim = c(-2.5,1), ylim = c(0,1))
&amp;gt; lines(theta,prob[,1],col=&amp;quot;red&amp;quot;)
&amp;gt; lines(theta,prob[,2],col=&amp;quot;blue&amp;quot;)
&amp;gt; lines(theta,prob[,3],col=&amp;quot;orange&amp;quot;)
&amp;gt; lines(theta,prob[,4],col=&amp;quot;green&amp;quot;)
&amp;gt; lines(theta,prob[,5],col=&amp;quot;black&amp;quot;)
&amp;gt; legend(&amp;quot;bottomright&amp;quot;,legend = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;4&amp;quot;,&amp;quot;5&amp;quot;), lty = c(1), col=c(&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;orange&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;black&amp;quot;), bty = &amp;quot;n&amp;quot;, cex = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/icc2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Unlike the ICCs for the 1PLM, the ICCs for the 2PLM do not all have the same shape. Item curves which are more “spread out” indicate lower discriminability (i.e. that individuals of a range of ability levels have some probability of getting the item correct). Compare this to an item with high discriminability (steep slope): for this item, we have a better estimate of the individual’s latent ability based on whether they got the question right or wrong. Because of the differing slopes, the rank-order of item difficulty changes across different latent ability levels. We can see that item &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; is still the most difficult item (i.e. lowest probability of getting correct for most latent trait values, up until about &lt;span class=&#34;math inline&#34;&gt;\(\theta=0.2\)&lt;/span&gt;). Items &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; are the easiest.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-the-item-information-curves-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot the item information curves&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Item information curves&lt;/em&gt; (IIC) show how much “information” about the latent trait ability an item gives. Mathematically, these are the &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;st derivatives of the ICCs or, equivalently, to the product of the probability of correct and incorrect response. Item information curves peak at the difficulty value (point where the item has the highest discrimination), with less information at ability levels farther from the difficulty estimate. Practially speaking, we can see how a very difficult item will provide very little information about persons with low ability (because the item is already too hard), and very easy items will provide little information about persons with high ability levels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #plot iic for each individual with respect to each of the 5 items
&amp;gt; neg_prob&amp;lt;-1-prob
&amp;gt; information&amp;lt;-prob*neg_prob
&amp;gt; information2&amp;lt;-information*(apply(discr,2,mean))^2
&amp;gt; plot(theta,information2[,1], type = &amp;quot;n&amp;quot;, ylab = &amp;quot;information&amp;quot;, xlab=&amp;quot;ability&amp;quot;,
+      xlim = c(-2.5,1), ylim = c(0,0.3))
&amp;gt; lines(theta,information2[,1],col=&amp;quot;red&amp;quot;)
&amp;gt; lines(theta,information2[,2],col=&amp;quot;blue&amp;quot;)
&amp;gt; lines(theta,information2[,3],col=&amp;quot;orange&amp;quot;)
&amp;gt; lines(theta,information2[,4],col=&amp;quot;green&amp;quot;)
&amp;gt; lines(theta,information2[,5],col=&amp;quot;black&amp;quot;)
&amp;gt; legend(&amp;quot;bottomleft&amp;quot;,legend = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;4&amp;quot;,&amp;quot;5&amp;quot;), lty = c(1), col=c(&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;orange&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;black&amp;quot;), bty = &amp;quot;n&amp;quot;, cex = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/iic2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The item IICs demonstrate that some items provide more information about latent ability for different ability levels. The higher the item discriminability estimate, the more information an item provides about ability levels around the point where there is a &lt;span class=&#34;math inline&#34;&gt;\(50\%\)&lt;/span&gt; chance of getting the item right (i.e. the steepest point in the ICC slope). For example, item &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; (orange) clearly provides the most information at high ability levels, around &lt;span class=&#34;math inline&#34;&gt;\(\theta=-0.5\)&lt;/span&gt;, but almost no information about low ability levels (&lt;span class=&#34;math inline&#34;&gt;\(&amp;lt; -1\)&lt;/span&gt;) because the item is already too hard for those participants. In contrast, item &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (red), which has low discriminability, doesn’t give very much information overall, but covers a wide range of ability levels.&lt;/p&gt;
&lt;p&gt;Next, we plot the item information curve for the whole test. This is the sum of all the item IICs above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #plot iic for each individual with respect to whole test
&amp;gt; information_test&amp;lt;-apply(information2,1,sum)
&amp;gt; plot(theta,information_test, type = &amp;quot;n&amp;quot;, ylab = &amp;quot;information (test)&amp;quot;, xlab=&amp;quot;ability&amp;quot;,
+      xlim = c(-2.5,1), ylim = c(0,1.5))
&amp;gt; lines(theta,information_test,col=&amp;quot;black&amp;quot;,lty=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/iic2tot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; summary(information_test)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.3242  0.3973  0.4500  0.4541  0.5182  0.7528 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The IIC for the whole test shows that the test provides the most information for slightly-lower-than average ability levels (about &lt;span class=&#34;math inline&#34;&gt;\(\theta=-1\)&lt;/span&gt;), but does not provide much information about extremely high ability levels.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assess-fit-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assess fit&lt;/h2&gt;
&lt;p&gt;Next, we check how well the 2PLM fits the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Y.rep&amp;lt;-m2.r2jags$BUGSoutput$sims.list$Y.rep
&amp;gt; 
&amp;gt; #Bar plot of y with yrep medians and uncertainty intervals superimposed on the bars
&amp;gt; ppc_bars(Y[,1],Y.rep[1:8,,1]) + ggtitle(&amp;quot;Item 1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,2],Y.rep[1:8,,2]) + ggtitle(&amp;quot;Item 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,3],Y.rep[1:8,,3]) + ggtitle(&amp;quot;Item 3&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m2-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,4],Y.rep[1:8,,4]) + ggtitle(&amp;quot;Item 4&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m2-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,5],Y.rep[1:8,,5]) + ggtitle(&amp;quot;Item 5&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m2-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also compare the fit of the 1PLM and 2PLM using relative measures of fit or &lt;em&gt;information criteria&lt;/em&gt;. These are computed based on the deviance and a penalty for model complexity called the effective number of parameters &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;. Here we consider two Bayesian measures known as the &lt;em&gt;Widely Applicable&lt;/em&gt; (WAIC) and &lt;em&gt;Leave One Out&lt;/em&gt; (LOOIC) Information Criterion, which can be easily obtained through the functions &lt;code&gt;waic&lt;/code&gt; and &lt;code&gt;loo&lt;/code&gt; in the package &lt;code&gt;loo&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(loo)
&amp;gt; #extract log-likelihood
&amp;gt; loglik_m1&amp;lt;-m1.r2jags$BUGSoutput$sims.list$loglik_y
&amp;gt; loglik_m2&amp;lt;-m2.r2jags$BUGSoutput$sims.list$loglik_y
&amp;gt; 
&amp;gt; #waic
&amp;gt; waic_m1&amp;lt;-waic(loglik_m1)
&amp;gt; waic_m2&amp;lt;-waic(loglik_m2)
&amp;gt; 
&amp;gt; #looic
&amp;gt; looic_m1&amp;lt;-loo(loglik_m1)
&amp;gt; looic_m2&amp;lt;-loo(loglik_m2)
&amp;gt; 
&amp;gt; #compare
&amp;gt; table_waic&amp;lt;-rbind(waic_m1$estimates[2:3,1],waic_m2$estimates[2:3,1])
&amp;gt; table_looic&amp;lt;-rbind(looic_m1$estimates[2:3,1],looic_m2$estimates[2:3,1])
&amp;gt; rownames(table_waic)&amp;lt;-rownames(table_looic)&amp;lt;-c(&amp;quot;1PLM&amp;quot;,&amp;quot;2PLM&amp;quot;)
&amp;gt; knitr::kable(cbind(table_waic,table_looic), &amp;quot;pandoc&amp;quot;, align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;p_waic&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;waic&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;p_loo&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;looic&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1PLM&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.525000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.517631&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.867805&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7.203242&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2PLM&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.395955&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.446221&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.649366&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.953044&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Both criteria suggest that the 2PLM has a slightly better fit to the data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-ability-scores-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot ability scores&lt;/h2&gt;
&lt;p&gt;Plot the density curve of the estimated ability scores&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #summary stats for theta across both iterations and individuals
&amp;gt; summary(theta)
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-1.917888 -0.419394  0.078240  0.001822  0.608518  0.677354 
&amp;gt; 
&amp;gt; #histogram and kernel density plot of theta averaged across iterations
&amp;gt; dens.theta&amp;lt;-density(theta, bw=0.3)
&amp;gt; hist(theta, breaks = 5, prob = T)
&amp;gt; lines(dens.theta, lwd=2, col=&amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/theta2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that the mean of ability scores is around &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, and the standard deviation about &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (these are estimated ability scores are standardised).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-logistic-model-3plm&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;3 parameter logistic model (3PLM)&lt;/h1&gt;
&lt;p&gt;In the 3PLM, the probability that the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th individual correctly answers the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th item (i.e. the probability that &lt;span class=&#34;math inline&#34;&gt;\(Y_{ij} = 1\)&lt;/span&gt;) is assumed to have the following IRF form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[p_{ij} = P(Y_{ij}=1 \mid \theta_i,\delta_j,\alpha_j,\eta_j)=\eta_j + (1-\eta_j) \frac{1}{1+\text{exp}(\alpha_j(\theta_i-\delta_j))},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\eta_j\)&lt;/span&gt; is the &lt;em&gt;guessing parameter&lt;/em&gt;. Under this model, individuals with zero ability have a nonzero chance of endorsing any item, just by guessing randomly. The guessing parameter is reflected in the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept (i.e. probability) of the ICC. The parameter is normally distributed according to some mean &lt;span class=&#34;math inline&#34;&gt;\(\mu_{\eta}\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\eta}\)&lt;/span&gt; which must be specified by the analyst.&lt;/p&gt;
&lt;div id=&#34;fit-the-model-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit the model&lt;/h2&gt;
&lt;p&gt;We fit the 3PLM to the data using the following &lt;code&gt;JAGS&lt;/code&gt; code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; model3&amp;lt;-&amp;quot;
+ model {
+  for (i in 1:n){
+   for (j in 1:p){
+    Y[i , j] ~ dbern ( prob [i , j])
+    logit ( prob.star [i , j]) &amp;lt;- alpha [j]*( theta [i] - delta [j])
+    prob [i , j] &amp;lt;- eta[j ] + (1 - eta[j]) * prob.star [i , j]
+   }
+   theta [i] ~ dnorm (0.0 , 1.0)
+  }
+ 
+  for (j in 1:p){
+   delta [j] ~ dnorm (m.delta , pr.delta )
+   alpha [j] ~ dnorm (m.alpha , pr.alpha ) T(0 , )
+   eta[j] ~ dbeta (a.eta , b.eta)
+  }
+   pr.delta &amp;lt;- pow(s.delta , -2)
+   pr.alpha &amp;lt;- pow(s.alpha , -2)
+   
+   m.delta ~ dnorm(0,5)
+   m.alpha ~ dnorm(0,5)
+   s.delta ~ dunif(0,10)
+   s.alpha ~ dunif(0,10)
+   a.eta ~ dunif(0,100)
+   b.eta ~ dunif(0,100)
+     
+   for(i in 1:n){
+    for(j in 1:p){
+     Y.rep[i, j] ~ dbern(prob[i, j])
+     loglik_y[i, j]&amp;lt;-logdensity.bern(Y[i,j], prob[i, j])
+    }
+   }
+ }
+ &amp;quot;
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(model3, con = &amp;quot;model3PLM.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;delta&amp;quot;, &amp;quot;alpha&amp;quot;, &amp;quot;eta&amp;quot;,&amp;quot;theta&amp;quot;, &amp;quot;prob&amp;quot;,&amp;quot;loglik_y&amp;quot;,&amp;quot;Y.rep&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 500
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 2500  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 1750&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface and the &lt;code&gt;jags&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; m3.r2jags &amp;lt;- jags(data = data_list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;model3PLM.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-the-item-characteristic-curves-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot the item characteristic curves&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Item characteristic curves&lt;/em&gt; (ICC) are the logistic curves which result from the fitted models (e.g. estimated item difficulty, plugged into the item response function). Latent trait/ability is plotted on the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;-axis (higher values represent hight ability). Probability of a “correct” answer (&lt;span class=&#34;math inline&#34;&gt;\(Y_{ij}=1\)&lt;/span&gt;) to an item is plotted on the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; discr&amp;lt;-m3.r2jags$BUGSoutput$sims.list$alpha
&amp;gt; diff&amp;lt;-m3.r2jags$BUGSoutput$sims.list$delta
&amp;gt; gues&amp;lt;-m3.r2jags$BUGSoutput$sims.list$eta
&amp;gt; #see average value of item difficulty
&amp;gt; apply(diff,2,mean)
[1] -2.8361776 -0.6672983  0.3323608 -1.0648926 -2.1758250
&amp;gt; #see average value of item discriminability
&amp;gt; apply(discr,2,mean)
[1] 0.9249227 1.1278880 1.4997368 0.8733855 0.8561385
&amp;gt; #see average value of item guessing
&amp;gt; apply(gues,2,mean)
[1] 0.2446947 0.2360422 0.2150625 0.2438348 0.2395731
&amp;gt; 
&amp;gt; #plot icc for each individual with respect to each of the 5 items
&amp;gt; theta&amp;lt;-apply(m3.r2jags$BUGSoutput$sims.list$theta, 2, mean)
&amp;gt; prob&amp;lt;-apply(m3.r2jags$BUGSoutput$sims.list$prob,c(2,3),mean)
&amp;gt; plot(theta,prob[,1], type = &amp;quot;n&amp;quot;, ylab = &amp;quot;probability of correct response&amp;quot;, xlab=&amp;quot;ability&amp;quot;,
+      xlim = c(-2.5,1), ylim = c(0,1))
&amp;gt; lines(theta,prob[,1],col=&amp;quot;red&amp;quot;)
&amp;gt; lines(theta,prob[,2],col=&amp;quot;blue&amp;quot;)
&amp;gt; lines(theta,prob[,3],col=&amp;quot;orange&amp;quot;)
&amp;gt; lines(theta,prob[,4],col=&amp;quot;green&amp;quot;)
&amp;gt; lines(theta,prob[,5],col=&amp;quot;black&amp;quot;)
&amp;gt; legend(&amp;quot;bottomright&amp;quot;,legend = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;4&amp;quot;,&amp;quot;5&amp;quot;), lty = c(1), col=c(&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;orange&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;black&amp;quot;), bty = &amp;quot;n&amp;quot;, cex = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/icc3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The slopes of the ICCs look very similar to those of the 2PLM. We can see that all items have &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercepts greater than zero, so that even at very low ability levels, there is some chance of getting these items correct (via guessing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-the-item-information-curves-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot the item information curves&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Item information curves&lt;/em&gt; (IIC) show how much “information” about the latent trait ability an item gives. Mathematically, these are the &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;st derivatives of the ICCs or, equivalently, to the product of the probability of correct and incorrect response. Item information curves peak at the difficulty value (point where the item has the highest discrimination), with less information at ability levels farther from the difficulty estimate. Practially speaking, we can see how a very difficult item will provide very little information about persons with low ability (because the item is already too hard), and very easy items will provide little information about persons with high ability levels.&lt;/p&gt;
&lt;p&gt;Here I plot the IICs using points, rather than lines, to better display the patterns of the individuals, which vary substantially according to whether the item was correctly chosen due to chance or not.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #plot iic for each individual with respect to each of the 5 items
&amp;gt; neg_prob&amp;lt;-1-prob
&amp;gt; information.p1&amp;lt;-neg_prob/prob
&amp;gt; information.p2&amp;lt;-(prob-apply(gues,2,mean))^2/(1-apply(gues,2,mean))^2
&amp;gt; information3&amp;lt;-(apply(discr,2,mean))^2*(information.p2)*(information.p1)
&amp;gt; plot(theta,information3[,1], type = &amp;quot;n&amp;quot;, ylab = &amp;quot;information&amp;quot;, xlab=&amp;quot;ability&amp;quot;,
+      xlim = c(-2.5,1), ylim = c(0,0.7))
&amp;gt; points(theta,information3[,1],col=&amp;quot;red&amp;quot;)
&amp;gt; points(theta,information3[,2],col=&amp;quot;blue&amp;quot;)
&amp;gt; points(theta,information3[,3],col=&amp;quot;orange&amp;quot;)
&amp;gt; points(theta,information3[,4],col=&amp;quot;green&amp;quot;)
&amp;gt; points(theta,information3[,5],col=&amp;quot;black&amp;quot;)
&amp;gt; legend(&amp;quot;bottomleft&amp;quot;,legend = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;4&amp;quot;,&amp;quot;5&amp;quot;), lty = c(1), col=c(&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;orange&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;black&amp;quot;), bty = &amp;quot;n&amp;quot;, cex = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/iic3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Next, we plot the item information curve for the whole test. This is the sum of all the item IICs above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #plot iic for each individual with respect to whole test
&amp;gt; information_test&amp;lt;-apply(information3,1,sum)
&amp;gt; plot(theta,information_test, type = &amp;quot;n&amp;quot;, ylab = &amp;quot;information (test)&amp;quot;, xlab=&amp;quot;ability&amp;quot;,
+      xlim = c(-2.5,1), ylim = c(0,1.5))
&amp;gt; points(theta,information_test,col=&amp;quot;black&amp;quot;,lty=2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/iic3tot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; summary(information_test)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.3793  0.4489  0.5062  0.6978  0.7956  1.5096 &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;assess-fit-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assess fit&lt;/h2&gt;
&lt;p&gt;Next, we check how well the 3PLM fits the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Y.rep&amp;lt;-m3.r2jags$BUGSoutput$sims.list$Y.rep
&amp;gt; 
&amp;gt; #Bar plot of y with yrep medians and uncertainty intervals superimposed on the bars
&amp;gt; ppc_bars(Y[,1],Y.rep[1:8,,1]) + ggtitle(&amp;quot;Item 1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,2],Y.rep[1:8,,2]) + ggtitle(&amp;quot;Item 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,3],Y.rep[1:8,,3]) + ggtitle(&amp;quot;Item 3&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m3-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,4],Y.rep[1:8,,4]) + ggtitle(&amp;quot;Item 4&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m3-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ppc_bars(Y[,5],Y.rep[1:8,,5]) + ggtitle(&amp;quot;Item 5&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/diag_m3-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also compare the fit of the 1PLM, 2PLM and 3PLM using relative measures of fit or &lt;em&gt;information criteria&lt;/em&gt;. These are computed based on the deviance and a penalty for model complexity called the effective number of parameters &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;. Here we consider two Bayesian measures known as the &lt;em&gt;Widely Applicable&lt;/em&gt; (WAIC) and &lt;em&gt;Leave One Out&lt;/em&gt; (LOOIC) Information Criterion, which can be easily obtained through the functions &lt;code&gt;waic&lt;/code&gt; and &lt;code&gt;loo&lt;/code&gt; in the package &lt;code&gt;loo&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #extract log-likelihood
&amp;gt; loglik_m3&amp;lt;-m3.r2jags$BUGSoutput$sims.list$loglik_y
&amp;gt; 
&amp;gt; #waic
&amp;gt; waic_m3&amp;lt;-waic(loglik_m3)
&amp;gt; 
&amp;gt; #looic
&amp;gt; looic_m3&amp;lt;-loo(loglik_m3)
&amp;gt; 
&amp;gt; #compare
&amp;gt; table_waic&amp;lt;-rbind(waic_m1$estimates[2:3,1],waic_m2$estimates[2:3,1],waic_m3$estimates[2:3,1])
&amp;gt; table_looic&amp;lt;-rbind(looic_m1$estimates[2:3,1],looic_m2$estimates[2:3,1],looic_m3$estimates[2:3,1])
&amp;gt; rownames(table_waic)&amp;lt;-rownames(table_looic)&amp;lt;-c(&amp;quot;1PLM&amp;quot;,&amp;quot;2PLM&amp;quot;,&amp;quot;3PLM&amp;quot;)
&amp;gt; knitr::kable(cbind(table_waic,table_looic), &amp;quot;pandoc&amp;quot;, align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;p_waic&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;waic&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;p_loo&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;looic&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1PLM&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.525000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.517631&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.867805&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7.203242&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2PLM&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.395955&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.446221&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.649366&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.953044&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;3PLM&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.368535&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.395247&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.654432&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.967042&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Both criteria suggest that both 1PLM and 2PLM have a better fit to the data than 3PLM.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-ability-scores-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot ability scores&lt;/h2&gt;
&lt;p&gt;Plot the density curve of the estimated ability scores&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #summary stats for theta across both iterations and individuals
&amp;gt; summary(theta)
      Min.    1st Qu.     Median       Mean    3rd Qu.       Max. 
-1.7435119 -0.4170588  0.0471025  0.0006053  0.6298597  0.7189831 
&amp;gt; 
&amp;gt; #histogram and kernel density plot of theta averaged across iterations
&amp;gt; dens.theta&amp;lt;-density(theta, bw=0.3)
&amp;gt; hist(theta, breaks = 5, prob = T)
&amp;gt; lines(dens.theta, lwd=2, col=&amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/irt-jags/2020-02-01-irt-jags_files/figure-html/theta3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that the mean of ability scores is around &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, and the standard deviation about &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (these are estimated ability scores are standardised).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;The use of &lt;code&gt;JAGS&lt;/code&gt; software to estimate IRT models allows the user to alter existing
code to fit new variations of current models that cannot be fit in existing software packages. For example, longitudinal or multilevel data can easily be accommodated by small changes to existing &lt;code&gt;JAGS&lt;/code&gt; code. The &lt;code&gt;JAGS&lt;/code&gt; software takes care of the “grunt work” involved in estimating model parameters by constructing an MCMC algorithm to sample from the posterior distribution. Using &lt;code&gt;JAGS&lt;/code&gt; frees the user to experiment with different models that may be more appropriate for specialised data than the models that can currently be fit in other software packages. Of course, more complicated models involve more parameters than simpler models, and the analyst must specify prior distributions for these new parameters. This is a small price to pay, however, for the flexibility that the Bayesian framework and &lt;code&gt;JAGS&lt;/code&gt; software provide.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-baker2004item&#34;&gt;
&lt;p&gt;Baker, Frank B, and Seock-Ho Kim. 2004. &lt;em&gt;Item Response Theory: Parameter Estimation Techniques&lt;/em&gt;. CRC Press.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-curtis2010bugs&#34;&gt;
&lt;p&gt;Curtis, S McKay, and others. 2010. “BUGS Code for Item Response Theory.” &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 36 (1): 1–34.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hambleton1991fundamentals&#34;&gt;
&lt;p&gt;Hambleton, Ronald K, Hariharan Swaminathan, and H Jane Rogers. 1991. &lt;em&gt;Fundamentals of Item Response Theory&lt;/em&gt;. Sage.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Generalised Linear Mixed Models - JAGS</title>
      <link>/jags/glmm-jags/glmm-jags/</link>
      <pubDate>Sat, 15 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/glmm-jags/glmm-jags/</guid>
      <description>


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;p&gt;In some respects, &lt;em&gt;Generalized Linear Mixed effects Models&lt;/em&gt; (GLMM) are a hierarchical extension of &lt;em&gt;Generalized linear models&lt;/em&gt; (GLM) in a similar manner that Linear Mixed effects Models (LMM) are a hierarchical extension of Linear Models (LM). However, whilst the Gaussian (normal) distribution facilitates a relatively straight way of generating the marginal likelihood of the observed response by integrating likelihoods across all possible (and unobserved) levels of a random effect to yield parameter estimates, the same cannot be said for other distributions. Consequently various approximations have been developed to estimate the fixed and random parameters for GLMM’s:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Penalized quasi-likelihood&lt;/strong&gt; (PQL). This method approximates a quasi-likelihood by iterative fitting of (re)weighted linear mixed effects models based on the fit of GLM fit. Specifically, it estimates the fixed effects parameters by fitting a GLM that incorporates a correlation (variance-covariance) structure resulting from a LMM and then refits a LMM to re-estimate the variance-covariance structure by using the variance structure from the previous GLM. The cycle continues to iterate until either the fit improvement is below a threshold or a defined number of iterations has occurred. Whilst this is a relatively simple approach, that enables us to leverage methodologies for accommodating heterogeneity and spatial/temporal autocorrelation, it is known to perform poorly (estimates biased towards large variance) for Poisson distributions when the expected value is less than &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; and for binary data when the expected number of successes or failures are less than &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;. Moreover, as it approximates quasi-likelihood rather than likelihood, likelihood based inference and information criterion methods (such as likelihood ratio tests and AIC) are not appropriate with this approach. Instead, Wald tests are required for inference.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Laplace approximation&lt;/strong&gt;. This approach utilises a second-order Taylor series expansion to approximate (a mathematical technique for approximating the properties of a function around a point by taking multiple derivatives of the function and summing them together) the likelihood function. If we assume that the likelihood function is approximately normal and thus a quadratic function on a log scale, we can use second-order Taylor series expansion to approximate this likelihood. Whilst this approach is considered to be more accurate than PQL, it is considerably slower and unable to accommodate alternative variance and correlation structures.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Gauss-Hermite quadrature&lt;/strong&gt; (GHQ). This approach approximates the marginal likelihood by approximating the value of integrals at specific points (quadratures). This technique can be further adapted by allowing the number of quadratures and their weights to be optimized via a set of rules.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Markov-chain Monte-Carlo&lt;/strong&gt; (MCMC). This takes a bruit force approach by recreating the likelihood by traversing the likelihood function with sequential sampling proportional to the likelihood. Although this approach is very robust (when the posteriors have converged), they are computationally very intense. Interestingly, some (including Andrew Gelman) argue that PQL, Laplace and GHQ do not yield estimates. Rather they are only approximations of estimates. By contrast, as MCMC methods are able to integrate over all levels by bruit force, the resulting parameters are indeed true estimates.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will focus on the last approach which is the more general among the ones considered here and which is based on a Bayesian approach, which can be very flexible and accurate, yet very slow and complex.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hierarchical-poisson-regression&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Hierarchical Poisson regression&lt;/h1&gt;
&lt;p&gt;The model I will be developing is a Bayesian hierarchical Poisson regression model which I borrow from a very interesting work about modelling match results in soccer, available both as a &lt;a href=&#34;http://www.sumsar.net/papers/baath_2015_modeling_match_resluts_in_soccer.pdf&#34;&gt;technical report&lt;/a&gt; and as a series of &lt;a href=&#34;http://www.sumsar.net/blog/2013/07/modeling-match-results-in-la-liga-part-one/&#34;&gt;online posts&lt;/a&gt;. The objective of the analysis was to model the match results from the last five seasons of &lt;em&gt;La Liga&lt;/em&gt;, the premium Spanish football (soccer) league. In total there were &lt;span class=&#34;math inline&#34;&gt;\(1900\)&lt;/span&gt; rows in the dataset each with information regarding which was the home and away team, what these teams scored and what season it was. The goal outcomes of the teams are assumed to be distributed according to a Poisson distribution, while also taking into account the dependence between the goals scored by the attacking and defensive teams in each match.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;loading-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Loading the data&lt;/h1&gt;
&lt;p&gt;I start by loading libraries, reading in the data and preprocessing it for &lt;code&gt;JAGS&lt;/code&gt;. The last &lt;span class=&#34;math inline&#34;&gt;\(50\)&lt;/span&gt; matches have unknown outcomes and I create a new data frame &lt;code&gt;d&lt;/code&gt; holding only matches with known outcomes. I will come back to the unknown outcomes later when it is time to use the model for prediction. I also load a &lt;code&gt;R&lt;/code&gt; function called &lt;code&gt;plotPost&lt;/code&gt; which was previously coded in order to facilitate the plotting of the posterior results of the model. All information about the model structure, data and functions can be found on the webpage of the original post of the author or in his technical report (&lt;span class=&#34;citation&#34;&gt;Bååth (2015)&lt;/span&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)
&amp;gt; library(coda)
&amp;gt; library(mcmcplots)
&amp;gt; library(stringr)
&amp;gt; library(plyr)
&amp;gt; library(xtable)
&amp;gt; library(ggplot2)
&amp;gt; source(&amp;quot;plotPost.R&amp;quot;)
&amp;gt; set.seed(12345)  # for reproducibility
&amp;gt; 
&amp;gt; load(&amp;quot;laliga.RData&amp;quot;)
&amp;gt; 
&amp;gt; # -1 = Away win, 0 = Draw, 1 = Home win
&amp;gt; laliga$MatchResult &amp;lt;- sign(laliga$HomeGoals - laliga$AwayGoals)
&amp;gt; 
&amp;gt; # Creating a data frame d with only the complete match results
&amp;gt; d &amp;lt;- na.omit(laliga)
&amp;gt; teams &amp;lt;- unique(c(d$HomeTeam, d$AwayTeam))
&amp;gt; seasons &amp;lt;- unique(d$Season)
&amp;gt; 
&amp;gt; # A list for JAGS with the data from d where the strings are coded as
&amp;gt; # integers
&amp;gt; data_list &amp;lt;- list(HomeGoals = d$HomeGoals, AwayGoals = d$AwayGoals, HomeTeam = as.numeric(factor(d$HomeTeam,
+     levels = teams)), AwayTeam = as.numeric(factor(d$AwayTeam, levels = teams)),
+     Season = as.numeric(factor(d$Season, levels = seasons)), n_teams = length(teams),
+     n_games = nrow(d), n_seasons = length(seasons))
&amp;gt; 
&amp;gt; # Convenience function to generate the type of column names Jags outputs.
&amp;gt; col_name &amp;lt;- function(name, ...) {
+     paste0(name, &amp;quot;[&amp;quot;, paste(..., sep = &amp;quot;,&amp;quot;), &amp;quot;]&amp;quot;)
+ }
&amp;gt; data_list$n_seasons&amp;lt;-NULL
&amp;gt; data_list$Season&amp;lt;-NULL&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;modeling-match-results&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Modeling Match Results&lt;/h1&gt;
&lt;div id=&#34;data-check&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data check&lt;/h2&gt;
&lt;p&gt;How are the number of goals for each team in a football match distributed? Well, let’s start by assuming that all football matches are roughly equally long, that both teams have many chances at making a goal and that each team have the same probability of making a goal each goal chance. Given these assumptions the distribution of the number of goals for each team should be well captured by a Poisson distribution. A quick and dirty comparison between the actual distribution of the number of scored goals and a Poisson distribution having the same mean number of scored goals support this notion.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; par(mfcol = c(2, 1), mar = rep(2.2, 4))
&amp;gt; hist(c(d$AwayGoals, d$HomeGoals), xlim = c(-0.5, 8), breaks = -1:9 + 0.5, main = &amp;quot;Distribution of the number of goals\nscored by a team in a match.&amp;quot;)
&amp;gt; mean_goals &amp;lt;- mean(c(d$AwayGoals, d$HomeGoals))
&amp;gt; hist(rpois(9999, mean_goals), xlim = c(-0.5, 8), breaks = -1:9 + 0.5, main = &amp;quot;Random draw from a Poisson distribution with\nthe same mean as the distribution above.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/data_check-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;All teams aren’t equally good and it will be assumed that all teams have a latent skill variable and the skill of a team minus the skill of the opposing team defines the predicted outcome of a game. As the number of goals are assumed to be Poisson distributed it is natural that the skills of the teams are on the log scale of the mean of the distribution. The distribution of the number of goals for team &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; when facing team &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \text{Goals} \sim \text{Pois}(\lambda)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\log(\lambda)=\text{baseline} + \text{skill}_i - \text{skill}_j\)&lt;/span&gt;. Baseline is the log average number of goals when both teams are equally good. The goal outcome of a match between home team &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and away team &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is modeled as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \text{HomeGoals}_{ij} \sim \text{Pois}(\lambda_{\text{home},ij}),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \text{AwayGoals}_{ij} \sim \text{Pois}(\lambda_{\text{away},ij}),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \log(\lambda_{\text{home},ij}) = \text{baseline} + \text{skill}_i - \text{skill}_j, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \log(\lambda_{\text{away},ij}) = \text{baseline} + \text{skill}_j - \text{skill}_i. \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Add some priors to that and you’ve got a Bayesian model going! I set the prior distributions over the baseline to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \text{baseline} \sim N(0, 4^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and the skill of all &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; teams using a hierarchical approach to :&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \text{skill}_{1,\ldots,n} \sim N(\mu_{\text{teams}}, \sigma^2_{\text{teams}}),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;so that teams are assumed to have similar but not identical mean and variance parameters for thier skill parameters. These priors are made vague. For example, the prior on the baseline have a SD of &lt;code&gt;4&lt;/code&gt; but since this is on the log scale of the mean number of goals it corresponds to one SD from the mean &lt;code&gt;0&lt;/code&gt; covering the range of &lt;code&gt;[0.02,54.6]&lt;/code&gt; goals. Turning this into a &lt;code&gt;JAGS&lt;/code&gt; model requires some minor adjustments. The model have to loop over all the match results, which adds some for-loops. &lt;code&gt;JAGS&lt;/code&gt; parameterises the normal distribution with precision (the reciprocal of the variance) instead of variance so the hyperpriors have to be converted. Finally I have to “anchor” the skill of one team to a constant otherwise the mean skill can drift away freely (&lt;em&gt;conrner constraint&lt;/em&gt;) and the model cannot be identified. Doing these adjustments results in the following model description:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; m1_string &amp;lt;- &amp;quot;model {
+ for(i in 1:n_games) {
+   HomeGoals[i] ~ dpois(lambda_home[HomeTeam[i],AwayTeam[i]])
+   AwayGoals[i] ~ dpois(lambda_away[HomeTeam[i],AwayTeam[i]])
+ }
+ 
+ for(home_i in 1:n_teams) {
+   for(away_i in 1:n_teams) {
+     lambda_home[home_i, away_i] &amp;lt;- exp(baseline + skill[home_i] - skill[away_i])
+     lambda_away[home_i, away_i] &amp;lt;- exp(baseline + skill[away_i] - skill[home_i])
+   }
+ }
+ 
+ skill[1] &amp;lt;- 0
+ for(j in 2:n_teams) {
+   skill[j] ~ dnorm(group_skill, group_tau)
+ }  
+ 
+ group_skill ~ dnorm(0, 0.0625)
+ group_tau &amp;lt;- 1 / pow(group_sigma, 2)
+ group_sigma ~ dunif(0, 3)
+ baseline ~ dnorm(0, 0.0625)
+ }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(m1_string, con = &amp;quot;model1.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;baseline&amp;quot;, &amp;quot;skill&amp;quot;, &amp;quot;group_skill&amp;quot;, &amp;quot;group_sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface and the &lt;code&gt;jags&lt;/code&gt; function. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomisation function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; m1.r2jags &amp;lt;- jags(data = data_list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;model1.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 3700
   Unobserved stochastic nodes: 31
   Total graph size: 9151

Initializing model
&amp;gt; 
&amp;gt; print(m1.r2jags)
Inference for Bugs model at &amp;quot;model1.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
              mu.vect sd.vect      2.5%       25%       50%       75%     97.5%
baseline        0.281   0.014     0.253     0.271     0.281     0.291     0.309
group_sigma     0.225   0.034     0.169     0.201     0.222     0.246     0.302
group_skill     0.016   0.062    -0.104    -0.026     0.016     0.057     0.136
skill[1]        0.000   0.000     0.000     0.000     0.000     0.000     0.000
skill[2]        0.185   0.061     0.064     0.145     0.185     0.226     0.307
skill[3]        0.017   0.069    -0.117    -0.030     0.017     0.064     0.154
skill[4]       -0.013   0.061    -0.132    -0.054    -0.013     0.028     0.109
skill[5]       -0.180   0.098    -0.376    -0.247    -0.179    -0.113     0.008
skill[6]       -0.048   0.063    -0.170    -0.090    -0.049    -0.007     0.081
skill[7]       -0.013   0.058    -0.128    -0.051    -0.013     0.025     0.103
skill[8]        0.199   0.060     0.084     0.159     0.199     0.240     0.317
skill[9]       -0.077   0.063    -0.200    -0.119    -0.076    -0.034     0.046
skill[10]      -0.110   0.062    -0.230    -0.152    -0.110    -0.068     0.011
skill[11]       0.698   0.057     0.588     0.658     0.696     0.736     0.811
skill[12]       0.133   0.060     0.017     0.092     0.133     0.174     0.249
skill[13]       0.017   0.059    -0.096    -0.023     0.016     0.057     0.132
skill[14]       0.038   0.061    -0.078    -0.003     0.037     0.080     0.160
skill[15]      -0.008   0.060    -0.124    -0.048    -0.009     0.033     0.108
skill[16]      -0.117   0.099    -0.305    -0.186    -0.118    -0.051     0.080
skill[17]       0.606   0.058     0.495     0.566     0.606     0.646     0.720
skill[18]      -0.071   0.070    -0.205    -0.118    -0.072    -0.026     0.071
skill[19]      -0.115   0.069    -0.247    -0.162    -0.115    -0.068     0.022
skill[20]       0.075   0.064    -0.045     0.032     0.074     0.117     0.204
skill[21]      -0.104   0.065    -0.231    -0.148    -0.105    -0.060     0.027
skill[22]      -0.212   0.099    -0.403    -0.281    -0.213    -0.146    -0.017
skill[23]      -0.161   0.101    -0.360    -0.230    -0.159    -0.094     0.036
skill[24]      -0.118   0.101    -0.319    -0.186    -0.118    -0.050     0.085
skill[25]       0.009   0.071    -0.131    -0.037     0.010     0.057     0.147
skill[26]       0.058   0.069    -0.079     0.011     0.058     0.104     0.195
skill[27]      -0.061   0.080    -0.218    -0.115    -0.060    -0.005     0.088
skill[28]      -0.118   0.079    -0.272    -0.170    -0.119    -0.065     0.037
skill[29]      -0.059   0.105    -0.260    -0.130    -0.062     0.011     0.155
deviance    10912.856   7.406 10900.319 10907.610 10912.214 10917.514 10928.852
             Rhat n.eff
baseline    1.001 15000
group_sigma 1.002  1500
group_skill 1.002  1600
skill[1]    1.000     1
skill[2]    1.005   410
skill[3]    1.009   180
skill[4]    1.007   670
skill[5]    1.002  2400
skill[6]    1.001  4400
skill[7]    1.002  2400
skill[8]    1.001 11000
skill[9]    1.001 15000
skill[10]   1.009   190
skill[11]   1.001  4700
skill[12]   1.005   340
skill[13]   1.001 14000
skill[14]   1.006   310
skill[15]   1.002  2600
skill[16]   1.003 12000
skill[17]   1.001 15000
skill[18]   1.002  2700
skill[19]   1.003   880
skill[20]   1.002  1800
skill[21]   1.002  1000
skill[22]   1.001  2800
skill[23]   1.001 15000
skill[24]   1.005   380
skill[25]   1.001 15000
skill[26]   1.002  2300
skill[27]   1.001 15000
skill[28]   1.001 15000
skill[29]   1.001 13000
deviance    1.001  3900

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 27.4 and DIC = 10940.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MCMC diagnostics&lt;/h2&gt;
&lt;p&gt;Using the generated MCMC samples I can now look at the credible skill values of any team. Let’s look at the trace plot and the distribution of the skill parameters for FC Sevilla and FC Valencia.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; team_par&amp;lt;-c(which(teams == c(&amp;quot;FC Sevilla&amp;quot;)), which(teams == &amp;quot;FC Valencia&amp;quot;))
&amp;gt; denplot(m1.r2jags, parms = team_par, style = &amp;quot;plain&amp;quot;, main = c(&amp;quot;Sevilla&amp;quot;,&amp;quot;Valenica&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(m1.r2jags, parms = team_par, style = &amp;quot;plain&amp;quot;, main = c(&amp;quot;Sevilla&amp;quot;,&amp;quot;Valenica&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model validation&lt;/h2&gt;
&lt;p&gt;Seems like Sevilla and Valencia have similar skill with Valencia being slightly better. Using the MCMC samples it is not only possible to look at the distribution of parameter values but it is also straight forward to simulate matches between teams and look at the credible distribution of number of goals scored and the probability of a win for the home team, a win for the away team or a draw. The following functions simulates matches with one team as home team and one team as away team and plots the predicted result together with the actual outcomes of any matches in the &lt;code&gt;laliga&lt;/code&gt; data set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # Plots histograms over home_goals, away_goals, the difference in goals
&amp;gt; # and a barplot over match results.
&amp;gt; plot_goals &amp;lt;- function(home_goals, away_goals) {
+     n_matches &amp;lt;- length(home_goals)
+     goal_diff &amp;lt;- home_goals - away_goals
+     match_result &amp;lt;- ifelse(goal_diff &amp;lt; 0, &amp;quot;away_win&amp;quot;, ifelse(goal_diff &amp;gt; 0,
+         &amp;quot;home_win&amp;quot;, &amp;quot;equal&amp;quot;))
+     hist(home_goals, xlim = c(-0.5, 10), breaks = (0:100) - 0.5)
+     hist(away_goals, xlim = c(-0.5, 10), breaks = (0:100) - 0.5)
+     hist(goal_diff, xlim = c(-6, 6), breaks = (-100:100) - 0.5)
+     barplot(table(match_result)/n_matches, ylim = c(0, 1))
+ }
&amp;gt; 
&amp;gt; 
&amp;gt; plot_pred_comp1 &amp;lt;- function(home_team, away_team, ms) {
+     # Simulates and plots game goals scores using the MCMC samples from the m1
+     # model.
+     par(mar=c(2,2,2,2))
+     par(mfrow = c(2, 4))
+     baseline &amp;lt;- ms[, &amp;quot;baseline&amp;quot;]
+     home_skill &amp;lt;- ms[, which(teams == home_team)]
+     away_skill &amp;lt;- ms[, which(teams == away_team)]
+     home_goals &amp;lt;- rpois(nrow(ms), exp(baseline + home_skill - away_skill))
+     away_goals &amp;lt;- rpois(nrow(ms), exp(baseline + away_skill - home_skill))
+     plot_goals(home_goals, away_goals)
+     # Plots the actual distribution of goals between the two teams
+     home_goals &amp;lt;- d$HomeGoals[d$HomeTeam == home_team &amp;amp; d$AwayTeam == away_team]
+     away_goals &amp;lt;- d$AwayGoals[d$HomeTeam == home_team &amp;amp; d$AwayTeam == away_team]
+     plot_goals(home_goals, away_goals)
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s look at Valencia (home team) vs. Sevilla (away team). The graph below shows the simulation on the first row and the historical data on the second row.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ms1&amp;lt;-as.matrix(m1.r2jags$BUGSoutput$sims.matrix)
&amp;gt; plot_pred_comp1(&amp;quot;FC Valencia&amp;quot;, &amp;quot;FC Sevilla&amp;quot;, ms1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/mcmc_val2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here we discover a problem with the current model. While the simulated data looks the same, except that the home team and the away team swapped places, the historical data now shows that Sevilla often wins against Valencia when being the home team. Our model doesn’t predict this because it doesn’t considers the advantage of being the home team.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;accounting-for-home-advantage&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Accounting for home advantage&lt;/h1&gt;
&lt;p&gt;The only change to the model needed to account for the home advantage is to split the baseline into two components, a home baseline and an away baseline. The following &lt;code&gt;JAGS&lt;/code&gt; model implements this change by splitting &lt;code&gt;baseline&lt;/code&gt; into &lt;code&gt;home_baseline&lt;/code&gt; and &lt;code&gt;away_baseline&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # model 2
&amp;gt; m2_string &amp;lt;- &amp;quot;model {
+ for(i in 1:n_games) {
+   HomeGoals[i] ~ dpois(lambda_home[HomeTeam[i],AwayTeam[i]])
+   AwayGoals[i] ~ dpois(lambda_away[HomeTeam[i],AwayTeam[i]])
+ }
+ 
+ for(home_i in 1:n_teams) {
+   for(away_i in 1:n_teams) {
+     lambda_home[home_i, away_i] &amp;lt;- exp( home_baseline + skill[home_i] - skill[away_i])
+     lambda_away[home_i, away_i] &amp;lt;- exp( away_baseline + skill[away_i] - skill[home_i])
+   }
+ }
+ 
+ skill[1] &amp;lt;- 0 
+ for(j in 2:n_teams) {
+   skill[j] ~ dnorm(group_skill, group_tau)
+ }
+ 
+ group_skill ~ dnorm(0, 0.0625)
+ group_tau &amp;lt;- 1/pow(group_sigma, 2)
+ group_sigma ~ dunif(0, 3)
+ 
+ home_baseline ~ dnorm(0, 0.0625)
+ away_baseline ~ dnorm(0, 0.0625)
+ }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(m2_string, con = &amp;quot;model2.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now re-fit the model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;home_baseline&amp;quot;, &amp;quot;away_baseline&amp;quot;, &amp;quot;skill&amp;quot;, &amp;quot;group_sigma&amp;quot;, &amp;quot;group_skill&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; m2.r2jags &amp;lt;- jags(data = data_list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;model2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 3700
   Unobserved stochastic nodes: 32
   Total graph size: 10863

Initializing model
&amp;gt; 
&amp;gt; print(m2.r2jags)
Inference for Bugs model at &amp;quot;model2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
                mu.vect sd.vect      2.5%       25%       50%       75%
away_baseline     0.081   0.022     0.038     0.067     0.082     0.096
group_sigma       0.226   0.035     0.169     0.201     0.221     0.246
group_skill       0.019   0.061    -0.102    -0.022     0.019     0.060
home_baseline     0.449   0.019     0.413     0.436     0.449     0.462
skill[1]          0.000   0.000     0.000     0.000     0.000     0.000
skill[2]          0.187   0.061     0.066     0.147     0.187     0.228
skill[3]          0.017   0.068    -0.120    -0.030     0.017     0.063
skill[4]         -0.011   0.058    -0.126    -0.050    -0.011     0.028
skill[5]         -0.179   0.100    -0.375    -0.246    -0.178    -0.111
skill[6]         -0.044   0.062    -0.167    -0.087    -0.045    -0.002
skill[7]         -0.009   0.061    -0.127    -0.050    -0.009     0.033
skill[8]          0.199   0.059     0.081     0.159     0.201     0.240
skill[9]         -0.078   0.063    -0.205    -0.121    -0.077    -0.035
skill[10]        -0.108   0.064    -0.234    -0.151    -0.108    -0.066
skill[11]         0.699   0.057     0.583     0.661     0.699     0.737
skill[12]         0.132   0.059     0.019     0.092     0.132     0.173
skill[13]         0.025   0.061    -0.097    -0.016     0.025     0.065
skill[14]         0.041   0.059    -0.074     0.000     0.041     0.081
skill[15]        -0.006   0.060    -0.125    -0.046    -0.005     0.035
skill[16]        -0.115   0.099    -0.311    -0.181    -0.116    -0.049
skill[17]         0.611   0.059     0.494     0.571     0.612     0.653
skill[18]        -0.068   0.070    -0.204    -0.115    -0.069    -0.020
skill[19]        -0.114   0.070    -0.252    -0.162    -0.113    -0.065
skill[20]         0.077   0.062    -0.047     0.035     0.077     0.118
skill[21]        -0.102   0.064    -0.228    -0.145    -0.101    -0.058
skill[22]        -0.202   0.098    -0.399    -0.266    -0.201    -0.138
skill[23]        -0.167   0.098    -0.361    -0.233    -0.167    -0.102
skill[24]        -0.115   0.099    -0.306    -0.183    -0.116    -0.049
skill[25]         0.010   0.071    -0.132    -0.035     0.010     0.057
skill[26]         0.061   0.069    -0.075     0.014     0.062     0.109
skill[27]        -0.059   0.078    -0.211    -0.112    -0.060    -0.007
skill[28]        -0.113   0.082    -0.274    -0.167    -0.113    -0.058
skill[29]        -0.051   0.105    -0.265    -0.121    -0.050     0.021
deviance      10742.730   7.596 10729.548 10737.288 10742.120 10747.534
                  97.5%  Rhat n.eff
away_baseline     0.126 1.002  1600
group_sigma       0.305 1.001 15000
group_skill       0.138 1.006   330
home_baseline     0.486 1.001 15000
skill[1]          0.000 1.000     1
skill[2]          0.306 1.005   380
skill[3]          0.149 1.006   310
skill[4]          0.102 1.002  1900
skill[5]          0.013 1.002  1100
skill[6]          0.076 1.005   400
skill[7]          0.110 1.004   440
skill[8]          0.312 1.008   240
skill[9]          0.045 1.003   620
skill[10]         0.014 1.005   330
skill[11]         0.811 1.004   580
skill[12]         0.245 1.008   200
skill[13]         0.144 1.003   840
skill[14]         0.154 1.003   700
skill[15]         0.111 1.008   210
skill[16]         0.078 1.006   300
skill[17]         0.722 1.005   420
skill[18]         0.070 1.005   360
skill[19]         0.019 1.007   290
skill[20]         0.200 1.006   310
skill[21]         0.025 1.010   170
skill[22]        -0.009 1.002  1600
skill[23]         0.028 1.003   900
skill[24]         0.078 1.006   330
skill[25]         0.151 1.007   240
skill[26]         0.196 1.003   770
skill[27]         0.097 1.001  3900
skill[28]         0.051 1.002  1800
skill[29]         0.153 1.003   620
deviance      10759.025 1.004   460

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 28.8 and DIC = 10771.5
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MCMC diagnostics&lt;/h2&gt;
&lt;p&gt;Looking at the trace plots and distributions of &lt;code&gt;home_baseline&lt;/code&gt; and &lt;code&gt;away_baseline&lt;/code&gt; shows that there is a considerable home advantage.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; team_par&amp;lt;-c(&amp;quot;home_baseline&amp;quot;, &amp;quot;away_baseline&amp;quot;)
&amp;gt; denplot(m2.r2jags, parms = team_par, style = &amp;quot;plain&amp;quot;, main = c(&amp;quot;home_baseline&amp;quot;,&amp;quot;away_baseline&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/mcmc_diag_m2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(m2.r2jags, parms = team_par, style = &amp;quot;plain&amp;quot;, main = c(&amp;quot;home_baseline&amp;quot;,&amp;quot;away_baseline&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/mcmc_diag_m2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model validation&lt;/h2&gt;
&lt;p&gt;Looking at the difference between &lt;code&gt;exp(home_baseline)&lt;/code&gt; and &lt;code&gt;exp(away_baseline)&lt;/code&gt; shows that the home advantage is realised as roughly &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt; more goals for the home team.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ms2&amp;lt;-as.matrix(m2.r2jags$BUGSoutput$sims.matrix)
&amp;gt; plotPost(exp(ms2[, &amp;quot;home_baseline&amp;quot;]) - exp(ms2[, &amp;quot;away_baseline&amp;quot;]), compVal = 0,
+     xlab = &amp;quot;Home advantage in number of goals&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/mcmc_diag_post-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                       mean    median      mode hdiMass
Home advantage in number of goals 0.4822046 0.4822645 0.4831489    0.95
                                     hdiLow   hdiHigh compVal pcGTcompVal
Home advantage in number of goals 0.4096975 0.5549439       0           1
                                  ROPElow ROPEhigh pcInROPE
Home advantage in number of goals      NA       NA       NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Comparing the DIC of the of the two models also indicates that the new model is better.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dic_m1&amp;lt;-m1.r2jags$BUGSoutput$DIC
&amp;gt; dic_m2&amp;lt;-m2.r2jags$BUGSoutput$DIC
&amp;gt; diff_dic&amp;lt;-dic_m1 - dic_m2
&amp;gt; diff_dic
[1] 168.7556&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally we’ll look at the simulated results for Valencia (home team) vs Sevilla (away team) using the estimates from the new model with the first row of the graph showing the predicted outcome and the second row showing the actual data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; plot_pred_comp2 &amp;lt;- function(home_team, away_team, ms) {
+     par(mar=c(2,2,2,2))
+     par(mfrow = c(2, 4))
+     home_baseline &amp;lt;- ms[, &amp;quot;home_baseline&amp;quot;]
+     away_baseline &amp;lt;- ms[, &amp;quot;away_baseline&amp;quot;]
+     home_skill &amp;lt;- ms[, col_name(&amp;quot;skill&amp;quot;, which(teams == home_team))]
+     away_skill &amp;lt;- ms[, col_name(&amp;quot;skill&amp;quot;, which(teams == away_team))]
+     home_goals &amp;lt;- rpois(nrow(ms), exp(home_baseline + home_skill - away_skill))
+     away_goals &amp;lt;- rpois(nrow(ms), exp(away_baseline + away_skill - home_skill))
+     plot_goals(home_goals, away_goals)
+     home_goals &amp;lt;- d$HomeGoals[d$HomeTeam == home_team &amp;amp; d$AwayTeam == away_team]
+     away_goals &amp;lt;- d$AwayGoals[d$HomeTeam == home_team &amp;amp; d$AwayTeam == away_team]
+     plot_goals(home_goals, away_goals)
+ }
&amp;gt; 
&amp;gt; plot_pred_comp2(&amp;quot;FC Valencia&amp;quot;, &amp;quot;FC Sevilla&amp;quot;, ms2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/mcmc_diag_post3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And similarly Sevilla (home team) vs Valencia (away team).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; plot_pred_comp2(&amp;quot;FC Sevilla&amp;quot;, &amp;quot;FC Valencia&amp;quot;, ms2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/mcmc_diag_post4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now the results are closer to the historical data as both Sevilla and Valencia are more likely to win when playing as the home team. At this point in the modeling process I decided to try to split the skill parameter into two components, offence skill and defense skill, thinking that some teams might be good at scoring goals but at the same time be bad at keeping the opponent from scoring. This didn’t seem to result in any better fit however, perhaps because the offensive and defensive skill of a team tend to be highly related. There is however one more thing I would like to change with the model.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;allowing-for-skill-variation-over-the-season&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Allowing for skill variation over the season&lt;/h1&gt;
&lt;p&gt;The data set &lt;code&gt;laliga&lt;/code&gt; contains data from five different seasons and an assumption of the current model is that a team has the same skill during all seasons. This is probably not a realistic assumption, teams probably differ in their year-to-year performance. And what more, some teams do not even participate in all seasons in the &lt;code&gt;laliga&lt;/code&gt; data set, as a result of dropping out of the first division, as the following diagram shows:&lt;/p&gt;
&lt;div id=&#34;data-check-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data check&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; qplot(Season, HomeTeam, data = d, ylab = &amp;quot;Team&amp;quot;, xlab = &amp;quot;Particicipation by Season&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/data_check_m3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The second iteration of the model was therefore modified to include the year-to-year variability in team skill. This was done by allowing each team to have one skill parameter per season but to connect the skill parameters by using a team’s skill parameter for season &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; in the prior distribution for that team’s skill parameter for season &lt;span class=&#34;math inline&#34;&gt;\(t+1\)&lt;/span&gt; so that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \text{skill}_{t+1} \sim N(\text{skill}_t,\sigma^2_{\text{season}})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for all different &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, except the first season which is given a vague prior. Here &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{\text{season}}\)&lt;/span&gt; is a parameter estimated using the whole data set. The home and away baselines are given the same kind of priors and below is the resulting &lt;code&gt;JAGS&lt;/code&gt; model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # model 3
&amp;gt; m3_string &amp;lt;- &amp;quot;model {
+ for(i in 1:n_games) {
+   HomeGoals[i] ~ dpois(lambda_home[Season[i], HomeTeam[i],AwayTeam[i]])
+   AwayGoals[i] ~ dpois(lambda_away[Season[i], HomeTeam[i],AwayTeam[i]])
+ }
+ 
+ for(season_i in 1:n_seasons) {
+   for(home_i in 1:n_teams) {
+     for(away_i in 1:n_teams) {
+       lambda_home[season_i, home_i, away_i] &amp;lt;- exp( home_baseline[season_i] + skill[season_i, home_i] - skill[season_i, away_i])
+       lambda_away[season_i, home_i, away_i] &amp;lt;- exp( away_baseline[season_i] + skill[season_i, away_i] - skill[season_i, home_i])
+     }
+   }
+ }
+ 
+ skill[1, 1] &amp;lt;- 0 
+ for(j in 2:n_teams) {
+   skill[1, j] ~ dnorm(group_skill, group_tau)
+ }
+ 
+ group_skill ~ dnorm(0, 0.0625)
+ group_tau &amp;lt;- 1/pow(group_sigma, 2)
+ group_sigma ~ dunif(0, 3)
+ 
+ home_baseline[1] ~ dnorm(0, 0.0625)
+ away_baseline[1] ~ dnorm(0, 0.0625)
+ 
+ for(season_i in 2:n_seasons) {
+   skill[season_i, 1] &amp;lt;- 0 
+   for(j in 2:n_teams) {
+     skill[season_i, j] ~ dnorm(skill[season_i - 1, j], season_tau)
+   }
+   home_baseline[season_i] ~ dnorm(home_baseline[season_i - 1], season_tau)
+   away_baseline[season_i] ~ dnorm(away_baseline[season_i - 1], season_tau)
+ }
+ 
+ season_tau &amp;lt;- 1/pow(season_sigma, 2) 
+ season_sigma ~ dunif(0, 3) 
+ }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(m3_string, con = &amp;quot;model3.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now re-fit the model. These changes to the model unfortunately introduce quite a lot of autocorrelation when running the MCMC sampler. Also, I re-define the data list to include information for the season parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data_list_m3 &amp;lt;- list(HomeGoals = d$HomeGoals, AwayGoals = d$AwayGoals, HomeTeam = as.numeric(factor(d$HomeTeam,
+     levels = teams)), AwayTeam = as.numeric(factor(d$AwayTeam, levels = teams)),
+     Season = as.numeric(factor(d$Season, levels = seasons)), n_teams = length(teams),
+     n_games = nrow(d), n_seasons = length(seasons))
&amp;gt; params &amp;lt;- c(&amp;quot;home_baseline&amp;quot;, &amp;quot;away_baseline&amp;quot;, &amp;quot;skill&amp;quot;, &amp;quot;season_sigma&amp;quot;, &amp;quot;group_sigma&amp;quot;, &amp;quot;group_skill&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; m3.r2jags &amp;lt;- jags(data = data_list_m3, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;model3.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 3700
   Unobserved stochastic nodes: 153
   Total graph size: 26525

Initializing model
&amp;gt; 
&amp;gt; print(m3.r2jags)
Inference for Bugs model at &amp;quot;model3.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
                   mu.vect sd.vect      2.5%       25%       50%       75%
away_baseline[1]     0.105   0.038     0.030     0.079     0.103     0.130
away_baseline[2]     0.078   0.030     0.018     0.059     0.079     0.099
away_baseline[3]     0.067   0.031     0.005     0.047     0.069     0.089
away_baseline[4]     0.064   0.032    -0.001     0.043     0.065     0.087
away_baseline[5]     0.079   0.035     0.011     0.056     0.080     0.101
group_sigma          0.217   0.035     0.158     0.193     0.214     0.238
group_skill          0.018   0.060    -0.090    -0.023     0.015     0.057
home_baseline[1]     0.447   0.029     0.392     0.428     0.446     0.466
home_baseline[2]     0.437   0.026     0.383     0.421     0.438     0.454
home_baseline[3]     0.443   0.026     0.389     0.427     0.443     0.459
home_baseline[4]     0.452   0.027     0.400     0.434     0.451     0.469
home_baseline[5]     0.454   0.031     0.394     0.434     0.452     0.474
season_sigma         0.033   0.019     0.001     0.016     0.032     0.048
skill[1,1]           0.000   0.000     0.000     0.000     0.000     0.000
skill[2,1]           0.000   0.000     0.000     0.000     0.000     0.000
skill[3,1]           0.000   0.000     0.000     0.000     0.000     0.000
skill[4,1]           0.000   0.000     0.000     0.000     0.000     0.000
skill[5,1]           0.000   0.000     0.000     0.000     0.000     0.000
skill[1,2]           0.178   0.067     0.047     0.136     0.175     0.218
skill[2,2]           0.169   0.065     0.039     0.129     0.167     0.207
skill[3,2]           0.181   0.064     0.061     0.139     0.177     0.219
skill[4,2]           0.195   0.065     0.076     0.148     0.189     0.235
skill[5,2]           0.216   0.075     0.090     0.161     0.209     0.265
skill[1,3]           0.015   0.074    -0.126    -0.033     0.013     0.060
skill[2,3]           0.017   0.075    -0.127    -0.030     0.014     0.063
skill[3,3]           0.020   0.074    -0.121    -0.027     0.017     0.066
skill[4,3]           0.022   0.071    -0.111    -0.024     0.018     0.066
skill[5,3]           0.027   0.075    -0.111    -0.021     0.023     0.074
skill[1,4]          -0.008   0.066    -0.122    -0.053    -0.012     0.035
skill[2,4]          -0.011   0.063    -0.118    -0.053    -0.015     0.031
skill[3,4]          -0.010   0.063    -0.120    -0.052    -0.015     0.031
skill[4,4]          -0.020   0.065    -0.136    -0.064    -0.024     0.022
skill[5,4]          -0.022   0.069    -0.151    -0.069    -0.025     0.023
skill[1,5]          -0.174   0.098    -0.370    -0.238    -0.173    -0.107
skill[2,5]          -0.174   0.104    -0.384    -0.242    -0.174    -0.104
skill[3,5]          -0.174   0.111    -0.394    -0.247    -0.174    -0.102
skill[4,5]          -0.174   0.117    -0.408    -0.251    -0.174    -0.098
skill[5,5]          -0.174   0.123    -0.420    -0.254    -0.175    -0.095
skill[1,6]          -0.034   0.074    -0.161    -0.085    -0.039     0.017
skill[2,6]          -0.048   0.068    -0.167    -0.096    -0.052    -0.004
skill[3,6]          -0.058   0.067    -0.176    -0.106    -0.060    -0.015
skill[4,6]          -0.065   0.072    -0.193    -0.117    -0.067    -0.019
skill[5,6]          -0.071   0.075    -0.207    -0.125    -0.072    -0.025
skill[1,7]          -0.006   0.069    -0.124    -0.054    -0.013     0.038
skill[2,7]          -0.014   0.065    -0.129    -0.058    -0.021     0.027
skill[3,7]          -0.009   0.064    -0.120    -0.054    -0.016     0.031
skill[4,7]          -0.006   0.066    -0.117    -0.052    -0.013     0.035
skill[5,7]          -0.001   0.071    -0.122    -0.051    -0.009     0.044
skill[1,8]           0.200   0.067     0.069     0.155     0.198     0.242
skill[2,8]           0.206   0.063     0.086     0.162     0.203     0.246
skill[3,8]           0.209   0.063     0.090     0.164     0.206     0.250
skill[4,8]           0.204   0.064     0.082     0.158     0.202     0.244
skill[5,8]           0.195   0.069     0.059     0.151     0.194     0.239
skill[1,9]          -0.055   0.073    -0.193    -0.102    -0.057    -0.005
skill[2,9]          -0.074   0.068    -0.203    -0.119    -0.077    -0.026
skill[3,9]          -0.087   0.068    -0.219    -0.133    -0.088    -0.040
skill[4,9]          -0.105   0.074    -0.254    -0.155    -0.101    -0.057
skill[5,9]          -0.105   0.083    -0.279    -0.159    -0.100    -0.049
skill[1,10]         -0.121   0.072    -0.246    -0.175    -0.125    -0.072
skill[2,10]         -0.109   0.070    -0.224    -0.163    -0.113    -0.061
skill[3,10]         -0.102   0.071    -0.219    -0.156    -0.106    -0.051
skill[4,10]         -0.111   0.073    -0.234    -0.168    -0.116    -0.060
skill[5,10]         -0.111   0.083    -0.259    -0.173    -0.116    -0.055
skill[1,11]          0.676   0.072     0.526     0.629     0.680     0.726
skill[2,11]          0.696   0.063     0.571     0.654     0.699     0.738
skill[3,11]          0.712   0.060     0.600     0.672     0.712     0.750
skill[4,11]          0.728   0.061     0.617     0.688     0.725     0.761
skill[5,11]          0.727   0.064     0.606     0.686     0.725     0.763
skill[1,12]          0.146   0.064     0.025     0.106     0.144     0.186
skill[2,12]          0.143   0.060     0.028     0.105     0.141     0.180
skill[3,12]          0.131   0.058     0.019     0.094     0.130     0.168
skill[4,12]          0.127   0.059     0.010     0.089     0.126     0.164
skill[5,12]          0.127   0.064     0.002     0.086     0.126     0.166
skill[1,13]          0.031   0.065    -0.087    -0.014     0.028     0.071
skill[2,13]          0.035   0.062    -0.077    -0.008     0.032     0.073
skill[3,13]          0.023   0.061    -0.091    -0.019     0.020     0.062
skill[4,13]          0.017   0.062    -0.101    -0.026     0.015     0.057
skill[5,13]          0.015   0.067    -0.117    -0.030     0.014     0.057
skill[1,14]          0.028   0.064    -0.095    -0.015     0.025     0.069
skill[2,14]          0.027   0.061    -0.091    -0.014     0.024     0.065
skill[3,14]          0.030   0.059    -0.085    -0.010     0.027     0.067
skill[4,14]          0.046   0.062    -0.067     0.004     0.040     0.085
skill[5,14]          0.055   0.068    -0.064     0.008     0.049     0.099
skill[1,15]          0.015   0.065    -0.106    -0.029     0.009     0.055
skill[2,15]          0.019   0.063    -0.095    -0.024     0.012     0.058
skill[3,15]         -0.003   0.061    -0.115    -0.043    -0.005     0.034
skill[4,15]         -0.014   0.062    -0.132    -0.055    -0.015     0.024
skill[5,15]         -0.037   0.071    -0.182    -0.082    -0.034     0.009
skill[1,16]         -0.120   0.096    -0.304    -0.187    -0.122    -0.055
skill[2,16]         -0.121   0.103    -0.319    -0.192    -0.122    -0.051
skill[3,16]         -0.121   0.109    -0.329    -0.195    -0.121    -0.047
skill[4,16]         -0.121   0.116    -0.342    -0.197    -0.122    -0.044
skill[5,16]         -0.120   0.121    -0.357    -0.201    -0.121    -0.041
skill[1,17]          0.543   0.083     0.372     0.491     0.544     0.600
skill[2,17]          0.588   0.067     0.470     0.541     0.586     0.631
skill[3,17]          0.621   0.068     0.495     0.575     0.617     0.666
skill[4,17]          0.646   0.075     0.501     0.593     0.644     0.697
skill[5,17]          0.640   0.077     0.497     0.586     0.637     0.694
skill[1,18]         -0.068   0.075    -0.209    -0.122    -0.069    -0.021
skill[2,18]         -0.075   0.074    -0.219    -0.126    -0.075    -0.029
skill[3,18]         -0.068   0.078    -0.218    -0.122    -0.067    -0.019
skill[4,18]         -0.061   0.081    -0.217    -0.117    -0.060    -0.011
skill[5,18]         -0.054   0.081    -0.208    -0.110    -0.054    -0.002
skill[1,19]         -0.099   0.066    -0.220    -0.144    -0.101    -0.057
skill[2,19]         -0.106   0.065    -0.227    -0.151    -0.108    -0.064
skill[3,19]         -0.122   0.070    -0.260    -0.170    -0.121    -0.074
skill[4,19]         -0.122   0.080    -0.290    -0.174    -0.119    -0.069
skill[5,19]         -0.122   0.089    -0.312    -0.176    -0.118    -0.065
skill[1,20]          0.086   0.068    -0.034     0.038     0.083     0.130
skill[2,20]          0.083   0.065    -0.031     0.036     0.079     0.126
skill[3,20]          0.082   0.065    -0.033     0.034     0.078     0.125
skill[4,20]          0.065   0.070    -0.068     0.017     0.063     0.110
skill[5,20]          0.065   0.079    -0.094     0.014     0.064     0.115
skill[1,21]         -0.097   0.081    -0.245    -0.154    -0.103    -0.042
skill[2,21]         -0.101   0.073    -0.234    -0.152    -0.104    -0.048
skill[3,21]         -0.100   0.071    -0.230    -0.149    -0.103    -0.050
skill[4,21]         -0.107   0.070    -0.237    -0.155    -0.110    -0.059
skill[5,21]         -0.108   0.074    -0.245    -0.158    -0.114    -0.058
skill[1,22]         -0.197   0.106    -0.391    -0.269    -0.198    -0.126
skill[2,22]         -0.204   0.100    -0.389    -0.272    -0.205    -0.138
skill[3,22]         -0.204   0.107    -0.401    -0.278    -0.204    -0.134
skill[4,22]         -0.205   0.114    -0.418    -0.282    -0.205    -0.131
skill[5,22]         -0.205   0.120    -0.432    -0.287    -0.206    -0.127
skill[1,23]         -0.158   0.099    -0.343    -0.228    -0.160    -0.092
skill[2,23]         -0.164   0.094    -0.340    -0.232    -0.165    -0.102
skill[3,23]         -0.163   0.102    -0.357    -0.235    -0.165    -0.097
skill[4,23]         -0.164   0.108    -0.373    -0.239    -0.165    -0.094
skill[5,23]         -0.164   0.114    -0.386    -0.241    -0.165    -0.092
skill[1,24]         -0.102   0.105    -0.310    -0.171    -0.105    -0.033
skill[2,24]         -0.107   0.102    -0.306    -0.174    -0.108    -0.041
skill[3,24]         -0.112   0.097    -0.301    -0.177    -0.112    -0.049
skill[4,24]         -0.112   0.104    -0.317    -0.181    -0.113    -0.044
skill[5,24]         -0.112   0.111    -0.329    -0.185    -0.112    -0.041
skill[1,25]          0.009   0.086    -0.149    -0.046     0.007     0.066
skill[2,25]          0.009   0.081    -0.145    -0.044     0.006     0.061
skill[3,25]          0.008   0.074    -0.140    -0.042     0.006     0.055
skill[4,25]          0.013   0.074    -0.139    -0.038     0.011     0.060
skill[5,25]          0.003   0.077    -0.143    -0.047     0.001     0.053
skill[1,26]          0.048   0.088    -0.117    -0.019     0.046     0.108
skill[2,26]          0.049   0.083    -0.104    -0.013     0.047     0.104
skill[3,26]          0.049   0.076    -0.083    -0.009     0.047     0.099
skill[4,26]          0.068   0.075    -0.063     0.014     0.066     0.118
skill[5,26]          0.091   0.082    -0.057     0.034     0.091     0.145
skill[1,27]         -0.051   0.093    -0.236    -0.108    -0.049     0.000
skill[2,27]         -0.054   0.088    -0.231    -0.108    -0.050    -0.003
skill[3,27]         -0.055   0.084    -0.224    -0.108    -0.052    -0.006
skill[4,27]         -0.057   0.077    -0.213    -0.107    -0.054    -0.012
skill[5,27]         -0.053   0.079    -0.211    -0.104    -0.051    -0.007
skill[1,28]         -0.110   0.099    -0.292    -0.188    -0.112    -0.039
skill[2,28]         -0.113   0.094    -0.288    -0.188    -0.115    -0.046
skill[3,28]         -0.117   0.088    -0.282    -0.186    -0.120    -0.052
skill[4,28]         -0.121   0.081    -0.274    -0.186    -0.123    -0.063
skill[5,28]         -0.124   0.082    -0.278    -0.188    -0.127    -0.066
skill[1,29]         -0.057   0.129    -0.272    -0.154    -0.066     0.028
skill[2,29]         -0.059   0.127    -0.270    -0.155    -0.067     0.022
skill[3,29]         -0.061   0.124    -0.268    -0.154    -0.068     0.019
skill[4,29]         -0.062   0.121    -0.268    -0.152    -0.069     0.014
skill[5,29]         -0.063   0.117    -0.267    -0.149    -0.068     0.010
deviance         10731.636  11.981 10708.084 10723.239 10732.002 10740.556
                     97.5%  Rhat n.eff
away_baseline[1]     0.185 1.056    34
away_baseline[2]     0.135 1.004   500
away_baseline[3]     0.123 1.001  7800
away_baseline[4]     0.121 1.001  3300
away_baseline[5]     0.148 1.006   280
group_sigma          0.297 1.008   210
group_skill          0.146 1.015  5000
home_baseline[1]     0.508 1.018   260
home_baseline[2]     0.487 1.005 15000
home_baseline[3]     0.493 1.004 15000
home_baseline[4]     0.506 1.007   390
home_baseline[5]     0.516 1.011   260
season_sigma         0.069 1.323    11
skill[1,1]           0.000 1.000     1
skill[2,1]           0.000 1.000     1
skill[3,1]           0.000 1.000     1
skill[4,1]           0.000 1.000     1
skill[5,1]           0.000 1.000     1
skill[1,2]           0.323 1.003  5900
skill[2,2]           0.315 1.003 15000
skill[3,2]           0.323 1.008   880
skill[4,2]           0.338 1.012   290
skill[5,2]           0.377 1.016   130
skill[1,3]           0.170 1.017   110
skill[2,3]           0.174 1.014   150
skill[3,3]           0.175 1.013   180
skill[4,3]           0.173 1.011   250
skill[5,3]           0.185 1.004   470
skill[1,4]           0.130 1.005   510
skill[2,4]           0.121 1.004   680
skill[3,4]           0.123 1.006   380
skill[4,4]           0.117 1.003   820
skill[5,4]           0.121 1.002  1200
skill[1,5]           0.015 1.002  1400
skill[2,5]           0.033 1.002  1500
skill[3,5]           0.046 1.002  1800
skill[4,5]           0.060 1.002  2000
skill[5,5]           0.074 1.002  1900
skill[1,6]           0.116 1.008   620
skill[2,6]           0.092 1.010 15000
skill[3,6]           0.084 1.012  3500
skill[4,6]           0.085 1.011  1200
skill[5,6]           0.086 1.012   710
skill[1,7]           0.145 1.005 11000
skill[2,7]           0.133 1.011 15000
skill[3,7]           0.134 1.015 15000
skill[4,7]           0.142 1.012 15000
skill[5,7]           0.154 1.007 15000
skill[1,8]           0.337 1.001 15000
skill[2,8]           0.339 1.003 15000
skill[3,8]           0.341 1.001  6700
skill[4,8]           0.340 1.003 15000
skill[5,8]           0.338 1.003  1400
skill[1,9]           0.090 1.019   140
skill[2,9]           0.059 1.010   520
skill[3,9]           0.046 1.007 13000
skill[4,9]           0.035 1.004   790
skill[5,9]           0.047 1.003   790
skill[1,10]          0.027 1.011   150
skill[2,10]          0.032 1.016   110
skill[3,10]          0.040 1.021    98
skill[4,10]          0.037 1.011   170
skill[5,10]          0.057 1.008   200
skill[1,11]          0.815 1.035    59
skill[2,11]          0.825 1.019   110
skill[3,11]          0.839 1.006   320
skill[4,11]          0.860 1.002  1100
skill[5,11]          0.866 1.002  1000
skill[1,12]          0.279 1.002  1900
skill[2,12]          0.267 1.002  1300
skill[3,12]          0.247 1.009   300
skill[4,12]          0.244 1.012   190
skill[5,12]          0.255 1.006   280
skill[1,13]          0.168 1.002  4300
skill[2,13]          0.167 1.004 15000
skill[3,13]          0.153 1.009   350
skill[4,13]          0.148 1.014   170
skill[5,13]          0.152 1.012   210
skill[1,14]          0.159 1.007   240
skill[2,14]          0.153 1.007   240
skill[3,14]          0.156 1.006   410
skill[4,14]          0.176 1.001 15000
skill[5,14]          0.202 1.002  1400
skill[1,15]          0.155 1.001  4000
skill[2,15]          0.154 1.001  4000
skill[3,15]          0.122 1.008   210
skill[4,15]          0.113 1.013   130
skill[5,15]          0.100 1.030    58
skill[1,16]          0.071 1.004   970
skill[2,16]          0.084 1.002  1200
skill[3,16]          0.095 1.002  1000
skill[4,16]          0.108 1.002   970
skill[5,16]          0.121 1.002  1000
skill[1,17]          0.704 1.009   190
skill[2,17]          0.721 1.002 15000
skill[3,17]          0.759 1.023   100
skill[4,17]          0.800 1.049    48
skill[5,17]          0.796 1.039    58
skill[1,18]          0.086 1.011   160
skill[2,18]          0.077 1.008   220
skill[3,18]          0.089 1.010   170
skill[4,18]          0.099 1.011   160
skill[5,18]          0.108 1.014   120
skill[1,19]          0.039 1.013   130
skill[2,19]          0.028 1.016   100
skill[3,19]          0.017 1.028    62
skill[4,19]          0.036 1.020    83
skill[5,19]          0.054 1.017    98
skill[1,20]          0.229 1.006   280
skill[2,20]          0.221 1.006   300
skill[3,20]          0.220 1.004   510
skill[4,20]          0.207 1.001 15000
skill[5,20]          0.223 1.001 15000
skill[1,21]          0.063 1.006   320
skill[2,21]          0.043 1.005   390
skill[3,21]          0.042 1.007   240
skill[4,21]          0.037 1.007   250
skill[5,21]          0.044 1.009   190
skill[1,22]          0.014 1.011   150
skill[2,22]         -0.001 1.012   160
skill[3,22]          0.010 1.010   180
skill[4,22]          0.026 1.008   220
skill[5,22]          0.038 1.006   270
skill[1,23]          0.043 1.003   710
skill[2,23]          0.026 1.002  1200
skill[3,23]          0.042 1.002  1900
skill[4,23]          0.054 1.001  2600
skill[5,23]          0.070 1.002  2300
skill[1,24]          0.109 1.001 15000
skill[2,24]          0.096 1.001  5000
skill[3,24]          0.085 1.001  2700
skill[4,24]          0.098 1.001  3600
skill[5,24]          0.109 1.002  3300
skill[1,25]          0.186 1.021   480
skill[2,25]          0.174 1.030   410
skill[3,25]          0.163 1.041   410
skill[4,25]          0.169 1.041   230
skill[5,25]          0.162 1.023   310
skill[1,26]          0.228 1.010   240
skill[2,26]          0.220 1.015   170
skill[3,26]          0.203 1.026   120
skill[4,26]          0.224 1.052    49
skill[5,26]          0.257 1.078    31
skill[1,27]          0.143 1.001  3900
skill[2,27]          0.129 1.001  9900
skill[3,27]          0.118 1.001 15000
skill[4,27]          0.103 1.002  1600
skill[5,27]          0.112 1.001  3800
skill[1,28]          0.087 1.003   720
skill[2,28]          0.068 1.004   470
skill[3,28]          0.052 1.006   310
skill[4,28]          0.035 1.009   190
skill[5,28]          0.035 1.012   140
skill[1,29]          0.235 1.058   160
skill[2,29]          0.230 1.061   160
skill[3,29]          0.224 1.068   150
skill[4,29]          0.215 1.076   130
skill[5,29]          0.204 1.085   110
deviance         10752.921 1.060    31

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 69.4 and DIC = 10801.0
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MCMC diagnostics&lt;/h2&gt;
&lt;p&gt;The following graph shows the trace plot and distribution of the &lt;code&gt;season_sigma&lt;/code&gt; parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(m3.r2jags, parms = &amp;quot;season_sigma&amp;quot;, style = &amp;quot;plain&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/mcmc_diag_m3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(m3.r2jags, parms = &amp;quot;season_sigma&amp;quot;, style = &amp;quot;plain&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/mcmc_diag_m3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Calculating and comparing the DIC of this model with the former model show no substantial difference.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dic_m2&amp;lt;-m2.r2jags$BUGSoutput$DIC
&amp;gt; dic_m3&amp;lt;-m3.r2jags$BUGSoutput$DIC
&amp;gt; diff_dic&amp;lt;-dic_m2 - dic_m3
&amp;gt; diff_dic
[1] -29.50679&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, I believe the assumptions of the current model (m3) are more reasonable so I’ll stick with this model.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ranking-the-teams-of-la-liga&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Ranking the teams of La Liga&lt;/h1&gt;
&lt;p&gt;We’ll start by ranking the teams of La Liga using the estimated skill parameters from the 2012/2013 season. The values of the skill parameters are difficult to interpret as they are relative to the skill of the team that had its skill parameter “anchored” at zero. To put them on a more interpretable scale I’ll first zero center the skill parameters by subtracting the mean skill of all teams, I then add the home baseline and exponentiate the resulting values. These rescaled skill parameters are now on the scale of expected number of goals when playing home team. Below is a caterpillar plot of the median of the rescaled skill parameters together with the &lt;span class=&#34;math inline&#34;&gt;\(68\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credible intervals. The plot is ordered according to the median skill and thus also gives the ranking of the teams.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # The ranking of the teams for the 2012/13 season.
&amp;gt; ms3&amp;lt;-m3.r2jags$BUGSoutput$sims.matrix
&amp;gt; team_skill &amp;lt;- ms3[, str_detect(string = colnames(ms3), &amp;quot;skill\\[5,&amp;quot;)]
&amp;gt; team_skill &amp;lt;- (team_skill - rowMeans(team_skill)) + ms3[, &amp;quot;home_baseline[5]&amp;quot;]
&amp;gt; team_skill &amp;lt;- exp(team_skill)
&amp;gt; colnames(team_skill) &amp;lt;- teams
&amp;gt; team_skill &amp;lt;- team_skill[, order(colMeans(team_skill), decreasing = T)]
&amp;gt; par(mar = c(2, 0.7, 0.7, 0.7), xaxs = &amp;quot;i&amp;quot;)
&amp;gt; caterplot(team_skill, labels.loc = &amp;quot;above&amp;quot;, val.lim = c(0.7, 3.8), style = &amp;quot;plain&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/cat_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Two teams are clearly ahead of the rest, FC Barcelona and Real Madrid CF. Let’s look at the credible difference between the two teams.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; plotPost(team_skill[, &amp;quot;FC Barcelona&amp;quot;] - team_skill[, &amp;quot;Real Madrid CF&amp;quot;], compVal = 0,
+     xlab = &amp;quot;← Real Madrid     vs     Barcelona →&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/cat_plot2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                                      mean    median      mode
&amp;lt;U+2190&amp;gt; Real Madrid     vs     Barcelona &amp;lt;U+2192&amp;gt; 0.26639 0.2657129 0.2950102
                                                   hdiMass     hdiLow  hdiHigh
&amp;lt;U+2190&amp;gt; Real Madrid     vs     Barcelona &amp;lt;U+2192&amp;gt;    0.95 -0.1863186 0.785901
                                                   compVal pcGTcompVal ROPElow
&amp;lt;U+2190&amp;gt; Real Madrid     vs     Barcelona &amp;lt;U+2192&amp;gt;       0   0.8660667      NA
                                                   ROPEhigh pcInROPE
&amp;lt;U+2190&amp;gt; Real Madrid     vs     Barcelona &amp;lt;U+2192&amp;gt;       NA       NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;FC Barcelona is the better team with a probability of &lt;span class=&#34;math inline&#34;&gt;\(82\)&lt;/span&gt;%&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;predicting-the-end-game-of-la-liga-20122013&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Predicting the End Game of La Liga 2012/2013&lt;/h1&gt;
&lt;p&gt;In the laliga data set the results of the &lt;span class=&#34;math inline&#34;&gt;\(50\)&lt;/span&gt; last games of the 2012/2013 season was missing. Using our model we can now both predict and simulate the outcomes of these &lt;span class=&#34;math inline&#34;&gt;\(50\)&lt;/span&gt; games. The R code below calculates a number of measures for each game (both the games with known and unknown outcomes):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The mode of the simulated number of goals, that is, the most likely number of scored goals. If we were asked to bet on the number of goals in a game this is what we would use.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the simulated number of goals, this is our best guess of the average number of goals in a game.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The most likely match result for each game.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A random sample from the distributions of credible home scores, away scores and match results. This is how La Liga actually could have played out in an alternative reality.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; n &amp;lt;- nrow(ms3)
&amp;gt; m3_pred &amp;lt;- sapply(1:nrow(laliga), function(i) {
+   home_team &amp;lt;- which(teams == laliga$HomeTeam[i])
+   away_team &amp;lt;- which(teams == laliga$AwayTeam[i])
+   season &amp;lt;- which(seasons == laliga$Season[i])
+   home_skill &amp;lt;- ms3[, col_name(&amp;quot;skill&amp;quot;, season, home_team)]
+   away_skill &amp;lt;- ms3[, col_name(&amp;quot;skill&amp;quot;, season, away_team)]
+   home_baseline &amp;lt;- ms3[, col_name(&amp;quot;home_baseline&amp;quot;, season)]
+   away_baseline &amp;lt;- ms3[, col_name(&amp;quot;away_baseline&amp;quot;, season)]
+ 
+   home_goals &amp;lt;- rpois(n, exp(home_baseline + home_skill - away_skill))
+   away_goals &amp;lt;- rpois(n, exp(away_baseline + away_skill - home_skill))
+   home_goals_table &amp;lt;- table(home_goals)
+   away_goals_table &amp;lt;- table(away_goals)
+   match_results &amp;lt;- sign(home_goals - away_goals)
+   match_results_table &amp;lt;- table(match_results)
+ 
+   mode_home_goal &amp;lt;- as.numeric(names(home_goals_table)[ which.max(home_goals_table)])
+   mode_away_goal &amp;lt;- as.numeric(names(away_goals_table)[ which.max(away_goals_table)])
+   match_result &amp;lt;-  as.numeric(names(match_results_table)[which.max(match_results_table)])
+   rand_i &amp;lt;- sample(seq_along(home_goals), 1)
+ 
+   c(mode_home_goal = mode_home_goal, mode_away_goal = mode_away_goal, match_result = match_result,
+     mean_home_goal = mean(home_goals), mean_away_goal = mean(away_goals),
+     rand_home_goal = home_goals[rand_i], rand_away_goal = away_goals[rand_i],
+     rand_match_result = match_results[rand_i])
+ })
&amp;gt; m3_pred &amp;lt;- t(m3_pred)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First let’s compare the distribution of the number of goals in the data with the predicted mode, mean and randomised number of goals for all the games (focusing on the number of goals for the home team). First the actual distribution of the number of goals for the home teams.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(laliga$HomeGoals, breaks = (-1:10) + 0.5, xlim = c(-0.5, 10), main = &amp;quot;Distribution of the number of goals\nscored by a home team in a match.&amp;quot;, xlab = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/pred1_m3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This next plot shows the distribution of the modes from the predicted distribution of home goals from each game. That is, what is the most probable outcome, for the home team, in each game.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(m3_pred[, &amp;quot;mode_home_goal&amp;quot;], breaks = (-1:10) + 0.5, xlim = c(-0.5, 10),
+     main = &amp;quot;Distribution of predicted most\nprobable scoreby a home team in\na match.&amp;quot;, xlab = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/pred2_m3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For almost all games the single most likely number of goals is one. Actually, if you know nothing about a La Liga game betting on one goal for the home team is &lt;span class=&#34;math inline&#34;&gt;\(78\)&lt;/span&gt;% of the times the best bet. Lest instead look at the distribution of the predicted mean number of home goals in each game.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(m3_pred[, &amp;quot;mean_home_goal&amp;quot;], breaks = (-1:10) + 0.5, xlim = c(-0.5, 10),
+     main = &amp;quot;Distribution of predicted mean \n score by a home team in a match.&amp;quot;, xlab = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/pred3_m3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For most games the expected number of goals are &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;. That is, even if your safest bet is one goal you would expect to see around two goals. The distribution of the mode and the mean number of goals doesn’t look remotely like the actual number of goals. This was not to be expected, we would however expect the distribution of randomized goals (where for each match the number of goals has been randomly drawn from that match’s predicted home goal distribution) to look similar to the actual number of home goals. Looking at the histogram below, this seems to be the case.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(m3_pred[, &amp;quot;rand_home_goal&amp;quot;], breaks = (-1:10) + 0.5, xlim = c(-0.5, 10),
+     main = &amp;quot;Distribution of randomly draw \n score by a home team in a match.&amp;quot;, xlab = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/pred4_m3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also look at how well the model predicts the data. This should probably be done using cross validation, but as the number of effective parameters are much smaller than the number of data points a direct comparison should at least give an estimated prediction accuracy in the right ballpark.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mean(laliga$HomeGoals == m3_pred[, &amp;quot;mode_home_goal&amp;quot;], na.rm = T)
[1] 0.3318919
&amp;gt; 
&amp;gt; mean((laliga$HomeGoals - m3_pred[, &amp;quot;mean_home_goal&amp;quot;])^2, na.rm = T)
[1] 1.457061&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So on average the model predicts the correct number of home goals &lt;span class=&#34;math inline&#34;&gt;\(34\)&lt;/span&gt;% of the time and guesses the average number of goals with a mean squared error of &lt;span class=&#34;math inline&#34;&gt;\(1.45\)&lt;/span&gt;. Now we’ll look at the actual and predicted match outcomes. The graph below shows the match outcomes in the data with &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; being a home win, &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; being a draw and &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; being a win for the away team.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(laliga$MatchResult, breaks = (-2:1) + 0.5, main = &amp;quot;Actual match results.&amp;quot;, xlab = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/pred6_m3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now looking at the most probable outcomes of the matches according to the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(m3_pred[, &amp;quot;match_result&amp;quot;], breaks = (-2:1) + 0.5, main = &amp;quot;Predicted match results.&amp;quot;, xlab = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/pred7_m3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For almost all matches the safest bet is to bet on the home team. While draws are not uncommon it is never the safest bet. As in the case with the number of home goals, the randomized match outcomes have a distribution similar to the actual match outcomes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(m3_pred[, &amp;quot;rand_match_result&amp;quot;], breaks = (-2:1) + 0.5, main = &amp;quot;Randomized match results.&amp;quot;, xlab = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/pred8_m3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mean(laliga$MatchResult == m3_pred[, &amp;quot;match_result&amp;quot;], na.rm = T)
[1] 0.5637838&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The model predicts the correct match outcome &lt;span class=&#34;math inline&#34;&gt;\(56\)&lt;/span&gt;% of the time. Pretty good! Now that we’ve checked that the model reasonably predicts the La Liga history let’s predict the La Liga endgame! The code below displays the predicted mode and mean number of goals for the endgame and the predicted winner of each game.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; laliga_forecast &amp;lt;- laliga[is.na(laliga$HomeGoals), c(&amp;quot;Season&amp;quot;, &amp;quot;Week&amp;quot;, &amp;quot;HomeTeam&amp;quot;,
+     &amp;quot;AwayTeam&amp;quot;)]
&amp;gt; m3_forecast &amp;lt;- m3_pred[is.na(laliga$HomeGoals), ]
&amp;gt; laliga_forecast$mean_home_goals &amp;lt;- round(m3_forecast[, &amp;quot;mean_home_goal&amp;quot;], 1)
&amp;gt; laliga_forecast$mean_away_goals &amp;lt;- round(m3_forecast[, &amp;quot;mean_away_goal&amp;quot;], 1)
&amp;gt; laliga_forecast$mode_home_goals &amp;lt;- m3_forecast[, &amp;quot;mode_home_goal&amp;quot;]
&amp;gt; laliga_forecast$mode_away_goals &amp;lt;- m3_forecast[, &amp;quot;mode_away_goal&amp;quot;]
&amp;gt; laliga_forecast$predicted_winner &amp;lt;- ifelse(m3_forecast[, &amp;quot;match_result&amp;quot;] ==
+     1, laliga_forecast$HomeTeam, ifelse(m3_forecast[, &amp;quot;match_result&amp;quot;] == -1,
+     laliga_forecast$AwayTeam, &amp;quot;Draw&amp;quot;))
&amp;gt; 
&amp;gt; rownames(laliga_forecast) &amp;lt;- NULL
&amp;gt; knitr::kable(laliga_forecast, &amp;quot;pandoc&amp;quot;, align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Season&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Week&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;HomeTeam&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;AwayTeam&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;mean_home_goals&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;mean_away_goals&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;mode_home_goals&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;mode_away_goals&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;predicted_winner&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Espanyol Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Espanyol Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Espanyol Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Espanyol Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Espanyol Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;While these predictions are good if you want to bet on the likely winner they do not reflect how the actual endgame will play out, e.g., there is not a single draw in the predicted_winner column. So at last let’s look at a possible version of the La Liga endgame by displaying the simulated match results calculated earlier.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; laliga_sim &amp;lt;- laliga[is.na(laliga$HomeGoals), c(&amp;quot;Season&amp;quot;, &amp;quot;Week&amp;quot;, &amp;quot;HomeTeam&amp;quot;,
+     &amp;quot;AwayTeam&amp;quot;)]
&amp;gt; laliga_sim$home_goals &amp;lt;- m3_forecast[, &amp;quot;rand_home_goal&amp;quot;]
&amp;gt; laliga_sim$away_goals &amp;lt;- m3_forecast[, &amp;quot;rand_away_goal&amp;quot;]
&amp;gt; laliga_sim$winner &amp;lt;- ifelse(m3_forecast[, &amp;quot;rand_match_result&amp;quot;] == 1, laliga_forecast$HomeTeam,
+     ifelse(m3_forecast[, &amp;quot;rand_match_result&amp;quot;] == -1, laliga_forecast$AwayTeam,
+         &amp;quot;Draw&amp;quot;))
&amp;gt; 
&amp;gt; rownames(laliga_sim) &amp;lt;- NULL
&amp;gt; knitr::kable(laliga_sim, &amp;quot;pandoc&amp;quot;, align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Season&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Week&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;HomeTeam&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;AwayTeam&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;home_goals&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;away_goals&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;winner&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Draw&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Espanyol Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Espanyol Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Draw&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Espanyol Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Draw&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Draw&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Draw&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Espanyol Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Draw&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;37&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Celta Vigo&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Espanyol Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Draw&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Deportivo de La CoruÃ±a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Sociedad San Sebastian&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;MÃ¡laga CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Barcelona&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Valencia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FC Sevilla&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Granada CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Getafe CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Levante U.D.&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Betis Sevilla&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Valladolid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RCD Mallorca&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Athletic Club Bilbao&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rayo Vallecano&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;CA Osasuna&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Madrid CF&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2012/13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;38&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Real Zaragoza&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;AtlÃ©tico Madrid&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now we see a number of games resulting in a draw. We also see that Malaga manages to beat Real Madrid in week &lt;span class=&#34;math inline&#34;&gt;\(36\)&lt;/span&gt;, against all odds, even though playing as the away team.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;calculating-the-predicted-payout-for-sevilla-vs-valencia-2013-06-01&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Calculating the Predicted Payout for Sevilla vs Valencia, 2013-06-01&lt;/h1&gt;
&lt;p&gt;At the time when this model was developed (2013-05-28) most of the matches in the 2012/2013 season had been played and Barcelona was already the winner (and the most skilled team as predicted by my model). There were however some matches left, for example, Sevilla (home team) vs Valencia (away team) at the &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;st of June, 2013. One of the powers with using Bayesian modeling and MCMC sampling is that once you have the MCMC samples of the parameters it is straight forward to calculate any quantity resulting from these estimates while still retaining the uncertainty of the parameter estimates. So let’s look at the predicted distribution of the number of goals for the Sevilla vs Valencia game and see if I can use my model to make some money. I’ll start by using the MCMC samples to calculate the distribution of the number of goals for Sevilla and Valencia.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; n &amp;lt;- nrow(ms3)
&amp;gt; home_team &amp;lt;- which(teams == &amp;quot;FC Sevilla&amp;quot;)
&amp;gt; away_team &amp;lt;- which(teams == &amp;quot;FC Valencia&amp;quot;)
&amp;gt; season &amp;lt;- which(seasons == &amp;quot;2012/13&amp;quot;)
&amp;gt; home_skill &amp;lt;- ms3[, col_name(&amp;quot;skill&amp;quot;, season, home_team)]
&amp;gt; away_skill &amp;lt;- ms3[, col_name(&amp;quot;skill&amp;quot;, season, away_team)]
&amp;gt; home_baseline &amp;lt;- ms3[, col_name(&amp;quot;home_baseline&amp;quot;, season)]
&amp;gt; away_baseline &amp;lt;- ms3[, col_name(&amp;quot;away_baseline&amp;quot;, season)]
&amp;gt; 
&amp;gt; home_goals &amp;lt;- rpois(n, exp(home_baseline + home_skill - away_skill))
&amp;gt; away_goals &amp;lt;- rpois(n, exp(away_baseline + away_skill - home_skill))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looking at summary of these two distributions shows that it will be a close game but with a slight advantage for the home team Sevilla.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; par(mfrow = c(2, 2), mar = rep(2.2, 4))
&amp;gt; plot_goals(home_goals, away_goals)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glmm-jags/2020-02-01-glmm-jags_files/figure-html/pp2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When developing the model (2013-05-28) the author got the specific payouts (that is, how much would I get back if my bet was successful) for betting on the outcome of this game on a betting site. Using my simulated distribution of the number of goals I can calculate the predicted payouts of my model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 1/c(Sevilla = mean(home_goals &amp;gt; away_goals), Draw = mean(home_goals == away_goals),
+     Valencia = mean(home_goals &amp;lt; away_goals))
 Sevilla     Draw Valencia 
2.281369 3.841229 3.318584 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I should clearly bet on Sevilla as my model predicts a payout of &lt;span class=&#34;math inline&#34;&gt;\(2.24\)&lt;/span&gt; (that is, a likely win for Sevilla) while betsson.com gives me the much higher payout of &lt;span class=&#34;math inline&#34;&gt;\(3.2\)&lt;/span&gt;. It is also possible to bet on the final goal outcome so let’s calculate what payouts my model predicts for different goal outcomes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; goals_payout &amp;lt;- laply(0:6, function(home_goal) {
+     laply(0:6, function(away_goal) {
+         1/mean(home_goals == home_goal &amp;amp; away_goals == away_goal)
+     })
+ })
&amp;gt; 
&amp;gt; colnames(goals_payout) &amp;lt;- paste(&amp;quot;Valencia&amp;quot;, 0:6, sep = &amp;quot; - &amp;quot;)
&amp;gt; rownames(goals_payout) &amp;lt;- paste(&amp;quot;Sevilla&amp;quot;, 0:6, sep = &amp;quot; - &amp;quot;)
&amp;gt; goals_payout &amp;lt;- round(goals_payout, 1)
&amp;gt; knitr::kable(goals_payout, &amp;quot;pandoc&amp;quot;, align = &amp;quot;c&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Valencia - 0&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Valencia - 1&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Valencia - 2&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Valencia - 3&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Valencia - 4&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Valencia - 5&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Valencia - 6&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Sevilla - 0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;13.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;21.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;47.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;161.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;714.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2500.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Sevilla - 1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;13.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;36.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;122.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;441.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1666.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Sevilla - 2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;19.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;56.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;176.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;625.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1875.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Sevilla - 3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;26.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;22.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;39.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;97.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;500.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1363.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Inf&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Sevilla - 4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;81.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;58.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;101.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;306.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1071.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3000.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Inf&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Sevilla - 5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;211.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;223.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;319.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1000.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2500.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;15000.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Inf&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Sevilla - 6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;750.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;483.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1500.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3000.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7500.0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Inf&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Inf&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The most likely result is 1 - 1 with a predicted payout of &lt;span class=&#34;math inline&#34;&gt;\(8.4\)&lt;/span&gt; and the beeting site agrees with this also offering their lowest payout for this bet, &lt;span class=&#34;math inline&#34;&gt;\(5.3\)&lt;/span&gt;. Not good enough! Looking at the payouts at the beeting site I can see that Sevilla - Valencia: 2 - 0 gives me a payout of &lt;span class=&#34;math inline&#34;&gt;\(16.0\)&lt;/span&gt;, that’s much better than my predicted payout of &lt;span class=&#34;math inline&#34;&gt;\(13.1\)&lt;/span&gt;. I’ll go for that!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;I believe the model has a lot things going for it. It is conceptually quite simple and easy to understand, implement and extend. It captures the patterns in and distribution of the data well. It allows me to easily calculate the probability of any outcome, from a game with whichever teams from any La Liga season. Want to calculate the probability that RCD Mallorca (home team) vs Malaga CF (away team) in the Season 2009/2010 would result in a draw? Easy! What’s the probability of the total number of goals in Granada CF vs Athletic Club Bilbao being a prime number? No problemo! What if Real Madrid from 2008/2009 met Barcelona from 2012/2013 in 2010/2011 and both teams had the home advantage? Well, that’s possible. There are also a couple of things that could be improved (many which are not too hard to address). Currently there is assumed to be no dependency between the goal distributions of the home and away teams, but this might not be realistic. Maybe if one team have scored more goals the other team “looses steam” (a negative correlation between the teams’ scores) or instead maybe the other team tries harder (a positive correlation). Such dependencies could maybe be added to the model using copulas. * One of the advantages of Bayesian statistics is the possibility to used informative priors. As I have no knowledge of football I’ve been using vague priors but with the help of a more knowledgeable football fan the model could be given more informative priors. Also, the predictive performance of the model has not been as thoroughly examined and this could be remedied with a healthy dose of cross validation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-baaaath2015modeling&#34;&gt;
&lt;p&gt;Bååth, Rasmus. 2015. “Modeling Match Results in Soccer Using a Hierarchical Bayesian Poisson Model.” Technical Report LUCS minor 18, Lund University Cognitive Science, Lund, Sweden.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Generalised Linear Models part II - JAGS</title>
      <link>/jags/glm2-jags/glm2-jags/</link>
      <pubDate>Fri, 14 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/glm2-jags/glm2-jags/</guid>
      <description>


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Whilst in many instances, count data can be approximated reasonably well by a normal distribution (particularly if the counts are all above zero and the mean count is greater than about &lt;span class=&#34;math inline&#34;&gt;\(20\)&lt;/span&gt;), more typically, when count data are modelled via normal distribution certain undesirable characteristics arise that are a consequence of the nature of discrete non-negative data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Expected (predicted) values and confidence bands less than zero are illogical, yet these are entirely possible from a normal distribution&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The distribution of count data are often skewed when their mean is low (in part because the distribution is truncated to the left by zero) and variance usually increases with increasing mean (variance is typically proportional to mean in count data). By contrast, the Gaussian (normal) distribution assumes that mean and variance are unrelated and thus estimates (particularly of standard error) might well be reasonable inaccurate.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Poisson regression is a type of &lt;strong&gt;generalised linear model&lt;/strong&gt; (GLM) in which a non-negative integer (natural number) response is modelled against a linear predictor via a specific link function. The linear predictor is typically a linear combination of effects parameters. The role of the link function is to transform the expected values of the response y (which is on the scale of (&lt;span class=&#34;math inline&#34;&gt;\(0;\infty\)&lt;/span&gt;), as is the Poisson distribution from which expectations are drawn) into the scale of the linear predictor (which is &lt;span class=&#34;math inline&#34;&gt;\(-\infty;\infty\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;As implied in the name of this group of analyses, a Poisson rather than Gaussian (normal) distribution is used to represent the errors (residuals). Like count data (number of individuals, species etc), the Poisson distribution encapsulates positive integers and is bound by zero at one end. Consequently, the degree of variability is directly related the expected value (equivalent to the mean of a Gaussian distribution). Put differently, the variance is a function of the mean. Repeated observations from a Poisson distribution located close to zero will yield a much smaller spread of observations than will samples drawn from a Poisson distribution located a greater distance from zero. In the Poisson distribution, the variance has a 1:1 relationship with the mean. The canonical link function for the Poisson distribution is a log-link function.&lt;/p&gt;
&lt;p&gt;Whilst the expectation that the mean=variance (&lt;span class=&#34;math inline&#34;&gt;\(\mu=\sigma\)&lt;/span&gt;) is broadly compatible with actual count data (that variance increases at the same rate as the mean), under certain circumstances, this might not be the case. For example, when there are other unmeasured influences on the response variable, the distribution of counts might be somewhat clumped which can result in higher than expected variability (that is &lt;span class=&#34;math inline&#34;&gt;\(\sigma &amp;gt; \mu\)&lt;/span&gt;). The variance increases more rapidly than does the mean. This is referred to as &lt;strong&gt;overdispersion&lt;/strong&gt;. The degree to which the variability is greater than the mean (and thus the expected degree of variability) is called &lt;strong&gt;dispersion&lt;/strong&gt;. Effectively, the Poisson distribution has a dispersion parameter (or &lt;strong&gt;scaling factor&lt;/strong&gt;) of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;It turns out that overdispersion is very common for count data and it typically underestimates variability, standard errors and thus deflated p-values. There are a number of ways of overcoming this limitation, the effectiveness of which depend on the causes of overdispersion.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Quasi-Poisson models&lt;/strong&gt; - these introduce the dispersion parameter (&lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;) into the model. This approach does not utilize an underlying error distribution to calculate the maximum likelihood (there is no quasi-Poisson distribution). Instead, if the Newton-Ralphson iterative reweighting least squares algorithm is applied using a direct specification of the relationship between mean and variance (&lt;span class=&#34;math inline&#34;&gt;\(\text{var}(y)=\phi\mu\)&lt;/span&gt;, the estimates of the regression coefficients are identical to those of the maximum likelihood estimates from the Poisson model. This is analogous to fitting ordinary least squares on symmetrical, yet not normally distributed data - the parameter estimates are the same, however they won’t necessarily be as efficient. The standard errors of the coefficients are then calculated by multiplying the Poisson model coefficient standard errors by &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{\phi}\)&lt;/span&gt;. Unfortunately, because the quasi-poisson model is not estimated via maximum likelihood, properties such as AIC and log-likelihood cannot be derived. Consequently, quasi-poisson and Poisson model fits cannot be compared via either AIC or likelihood ratio tests (nor can they be compared via deviance as uasi-poisson and Poisson models have the same residual deviance). That said, quasi-likelihood can be obtained by dividing the likelihood from the Poisson model by the dispersion (scale) factor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Negative binomial model&lt;/strong&gt; - technically, the negative binomial distribution is a probability distribution for the number of successes before a specified number of failures. However, the negative binomial can also be defined (parameterised) in terms of a mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and scale factor (&lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;),&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ p(y_i) = \frac{\Gamma(y_i+\omega)}{\Gamma(\omega)y!} \times \frac{\mu^{y_i}_i\omega^\omega}{(\mu_i+\omega)^{\mu_i+\omega}},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the expectected value of the values &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; (the means) are (&lt;span class=&#34;math inline&#34;&gt;\(\mu_i\)&lt;/span&gt;) and the variance is &lt;span class=&#34;math inline&#34;&gt;\(y_i=\frac{\mu_i+\mu^2_i}{\omega}\)&lt;/span&gt;. In this way, the negative binomial is a two-stage hierarchical process in which the response is modeled against a Poisson distribution whose expected count is in turn modeled by a Gamma distribution with a mean of &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and constant scale parameter (&lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;). Strictly, the negative binomial is not an exponential family distribution (unless &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt; is fixed as a constant), and thus negative binomial models cannot be fit via the usual GLM iterative reweighting algorithm. Instead estimates of the regression parameters along with the scale factor (&lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;) are obtained via maximum likelihood. The negative binomial model is useful for accommodating overdispersal when it is likely caused by clumping (due to the influence of other unmeasured factors) within the response.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zero-inflated Poisson model&lt;/strong&gt; - overdispersion can also be caused by the presence of a greater number of zero’s than would otherwise be expected for a Poisson distribution. There are potentially two sources of zero counts - genuine zeros and false zeros. Firstly, there may genuinely be no individuals present. This would be the number expected by a Poisson distribution. Secondly, individuals may have been present yet not detected or may not even been possible. These are false zero’s and lead to zero inflated data (data with more zeros than expected). For example, the number of joeys accompanying an adult koala could be zero because the koala has no offspring (true zero) or because the koala is male or infertile (both of which would be examples of false zeros). Similarly, zero counts of the number of individual in a transect are due either to the absence of individuals or the inability of the observer to detect them. Whilst in the former example, the latent variable representing false zeros (sex or infertility) can be identified and those individuals removed prior to analysis, this is not the case for the latter example. That is, we cannot easily partition which counts of zero are due to detection issues and which are a true indication of the natural state.&lt;/p&gt;
&lt;p&gt;Consistent with these two sources of zeros, zero-inflated models combine a binary logistic regression model (that models count membership according to a latent variable representing observations that can only be zeros - not detectable or male koalas) with a Poisson regression (that models count membership according to a latent variable representing observations whose values could be 0 or any positive integer - fertile female koalas).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;poisson-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Poisson regression&lt;/h2&gt;
&lt;p&gt;The following equations are provided since in Bayesian modelling, it is occasionally necessary to directly define the log-likelihood calculations (particularly for zero-inflated models and other mixture models).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ f(y \mid \lambda) = \frac{\lambda^ye^{-\lambda}}{y!},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(E[Y]=Var(Y)=\lambda\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; is the mean.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Lets say we wanted to model the abundance of an item (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) against a continuous predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(8)
&amp;gt; #The number of samples
&amp;gt; n.x &amp;lt;- 20
&amp;gt; #Create x values that at uniformly distributed throughout the rate of 1 to 20
&amp;gt; x &amp;lt;- sort(runif(n = n.x, min = 1, max =20))
&amp;gt; mm &amp;lt;- model.matrix(~x)
&amp;gt; intercept &amp;lt;- 0.6
&amp;gt; slope=0.1
&amp;gt; #The linear predictor
&amp;gt; linpred &amp;lt;- mm %*% c(intercept,slope)
&amp;gt; #Predicted y values
&amp;gt; lambda &amp;lt;- exp(linpred)
&amp;gt; #Add some noise and make binomial
&amp;gt; y &amp;lt;- rpois(n=n.x, lambda=lambda)
&amp;gt; dat &amp;lt;- data.frame(y,x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the binary response variable and the linear predictor (linear combination of one or more continuous or categorical predictors).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;There are at least five main potential models we could consider fitting to these data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ordinary least squares regression (general linear model)&lt;/strong&gt; - assumes normality of residuals&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Poisson regression&lt;/strong&gt; - assumes mean=variance (dispersion&lt;span class=&#34;math inline&#34;&gt;\(=1\)&lt;/span&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Quasi-poisson regression&lt;/strong&gt; - a general solution to overdispersion. Assumes variance is a function of mean, dispersion estimated, however likelihood based statistics unavailable&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Negative binomial regression&lt;/strong&gt; - a specific solution to overdispersion caused by clumping (due to an unmeasured latent variable). Scaling factor (&lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt;) is estimated along with the regression parameters.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Zero-inflation model&lt;/strong&gt; - a specific solution to overdispersion caused by excessive zeros (due to an unmeasured latent variable). Mixture of binomial and Poisson models.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When counts are all very large (not close to &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;) and their ranges do not span orders of magnitude, they take on very Gaussian properties (symmetrical distribution and variance independent of the mean). Given that models based on the Gaussian distribution are more optimized and recognized than Generalized Linear Models, it can be prudent to adopt Gaussian models for such data. Hence it is a good idea to first explore whether a Poisson model is likely to be more appropriate than a standard Gaussian model. The potential for overdispersion can be explored by adding a rug to boxplot. The rug is simply tick marks on the inside of an axis at the position corresponding to an observation. As multiple identical values result in tick marks drawn over one another, it is typically a good idea to apply a slight amount of jitter (random displacement) to the values used by the rug.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(dat$x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; boxplot(dat$y, horizontal=TRUE)
&amp;gt; rug(jitter(dat$y), side=1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is definitely signs of non-normality that would warrant Poisson models. The rug applied to the boxplots does not indicate a series degree of clumping and there appears to be few zero. Thus overdispersion is unlikely to be an issue. Lets now explore linearity by creating a histogram of the predictor variable (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) and a scatterplot of the relationship between the response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) and the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #now for the scatterplot
&amp;gt; plot(y~x, dat, log=&amp;quot;y&amp;quot;)
&amp;gt; with(dat, lines(lowess(y~x)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) does not display any skewness or other issues that might lead to non-linearity. The lowess smoother on the scatterplot does not display major deviations from a straight line and thus linearity is satisfied. Violations of linearity could be addressed by either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;define a non-linear linear predictor (such as a polynomial, spline or other non-linear function).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;transform the scale of the predictor variables.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although we have already established that there are few zeros in the data (and thus overdispersion is unlikely to be an issue), we can also explore this by comparing the number of zeros in the data to the number of zeros that would be expected from a Poisson distribution with a mean equal to the mean count of the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #proportion of 0&amp;#39;s in the data
&amp;gt; dat.tab&amp;lt;-table(dat$y==0)
&amp;gt; dat.tab/sum(dat.tab)

FALSE 
    1 
&amp;gt; 
&amp;gt; #proportion of 0&amp;#39;s expected from a Poisson distribution
&amp;gt; mu &amp;lt;- mean(dat$y)
&amp;gt; cnts &amp;lt;- rpois(1000, mu)
&amp;gt; dat.tab &amp;lt;- table(cnts == 0)
&amp;gt; dat.tab/sum(dat.tab)

FALSE  TRUE 
0.997 0.003 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above, the value under &lt;code&gt;FALSE&lt;/code&gt; is the proportion of non-zero values in the data and the value under &lt;code&gt;TRUE&lt;/code&gt; is the proportion of zeros in the data. In this example, there are no zeros in the observed data which corresponds closely to the very low proportion expected (&lt;span class=&#34;math inline&#34;&gt;\(0.003\)&lt;/span&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Pois}(\lambda_i),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\log(\lambda_i)=\eta_i\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\eta_i=\beta_0+\beta_1x_{i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_0,\beta_1 \sim N(0, 10000)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dat.list &amp;lt;- with(dat,list(Y=y, X=x,N=nrow(dat)))
&amp;gt; modelString=&amp;quot;
+ model {
+   for (i in 1:N) {
+      Y[i] ~ dpois(lambda[i])
+      log(lambda[i]) &amp;lt;- beta0 + beta1*X[i]
+   }
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+ } 
+ &amp;quot;
&amp;gt; writeLines(modelString, con=&amp;#39;modelpois.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; library(R2jags)
&amp;gt; dat.P.jags &amp;lt;- jags(data=dat.list,model.file=&amp;#39;modelpois.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 2
   Total graph size: 105

Initializing model&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model evaluation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(dat.P.jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(dat.P.jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; raftery.diag(as.mcmc(dat.P.jags))
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    10       10830 3746         2.89      
 beta1    12       12612 3746         3.37      
 deviance 3        4410  3746         1.18      


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    12       14878 3746         3.97      
 beta1    10       11942 3746         3.19      
 deviance 2        3995  3746         1.07      
&amp;gt; 
&amp;gt; autocorr.diag(as.mcmc(dat.P.jags))
             beta0         beta1     deviance
Lag 0   1.00000000  1.0000000000  1.000000000
Lag 1   0.83977964  0.8111423616  0.508803232
Lag 5   0.43884918  0.3859514845  0.118732714
Lag 10  0.22584100  0.1883831873  0.029775648
Lag 50 -0.01164622 -0.0003926876 -0.007507996&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One very important model validation procedure is to examine a plot of residuals against predicted or fitted values (the residual plot). Ideally, residual plots should show a random scatter of points without outliers. That is, there should be no patterns in the residuals. Patterns suggest inappropriate linear predictor (or scale) and/or inappropriate residual distribution/link function. The residuals used in such plots should be standardized (particularly if the model incorporated any variance-covariance structures - such as an autoregressive correlation structure) Pearsons’s residuals standardize residuals by division with the square-root of the variance. We can generate Pearson’s residuals within the &lt;code&gt;JAGS&lt;/code&gt; model. Alternatively, we could use the parameters to generate the residuals outside of &lt;code&gt;JAGS&lt;/code&gt;. Pearson’s residuals are calculated according to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \epsilon = \frac{y_i - \mu}{\sqrt{\text{var}(y)}},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the expected value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(=\lambda\)&lt;/span&gt; for Poisson) and var(&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) is the variance of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(=\lambda\)&lt;/span&gt; for Poisson).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #extract the samples for the two model parameters
&amp;gt; coefs &amp;lt;- dat.P.jags$BUGSoutput$sims.matrix[,1:2]
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data=dat)
&amp;gt; #expected values on a log scale
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; #expected value on response scale
&amp;gt; lambda &amp;lt;- exp(eta)
&amp;gt; #Expected value and variance are both equal to lambda
&amp;gt; expY &amp;lt;- varY &amp;lt;- lambda
&amp;gt; #sweep across rows and then divide by lambda
&amp;gt; Resid &amp;lt;- -1*sweep(expY,2,dat$y,&amp;#39;-&amp;#39;)/sqrt(varY)
&amp;gt; #plot residuals vs expected values
&amp;gt; plot(apply(Resid,2,mean)~apply(eta,2,mean))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/model2_mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we will compare the sum of squared residuals to the sum of squares residuals that would be expected from a Poisson distribution matching that estimated by the model. Essentially this is estimating how well the Poisson distribution, the log-link function and the linear model approximates the observed data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; SSres&amp;lt;-apply(Resid^2,1,sum)
&amp;gt; 
&amp;gt; #generate a matrix of draws from a poisson distribution
&amp;gt; # the matrix is the same dimensions as lambda and uses the probabilities of lambda
&amp;gt; YNew &amp;lt;- matrix(rpois(length(lambda),lambda=lambda),nrow=nrow(lambda))
&amp;gt; 
&amp;gt; Resid1&amp;lt;-(lambda - YNew)/sqrt(lambda)
&amp;gt; SSres.sim&amp;lt;-apply(Resid1^2,1,sum)
&amp;gt; mean(SSres.sim&amp;gt;SSres, na.rm = T)
[1] 0.4697&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;goodness-of-fit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goodness of fit&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dat.list1 &amp;lt;- with(dat,list(Y=y, X=x,N=nrow(dat)))
&amp;gt; modelString=&amp;quot;
+ model {
+   for (i in 1:N) {
+     #likelihood function
+     Y[i] ~ dpois(lambda[i])
+     eta[i] &amp;lt;- beta0+beta1*X[i] #linear predictor
+     log(lambda[i]) &amp;lt;- eta[i]   #link function
+ 
+     #E(Y) and var(Y)
+     expY[i] &amp;lt;- lambda[i]
+     varY[i] &amp;lt;- lambda[i]
+ 
+     # Calculate RSS
+     Resid[i] &amp;lt;- (Y[i] - expY[i])/sqrt(varY[i])
+     RSS[i] &amp;lt;- pow(Resid[i],2)
+ 
+     #Simulate data from a Poisson distribution
+     Y1[i] ~ dpois(lambda[i])
+     #Calculate RSS for simulated data
+     Resid1[i] &amp;lt;- (Y1[i] - expY[i])/sqrt(varY[i])
+     RSS1[i] &amp;lt;-pow(Resid1[i],2) 
+   }
+   #Priors
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+   #Bayesian P-value
+   Pvalue &amp;lt;- mean(sum(RSS1)&amp;gt;sum(RSS))
+ } 
+ &amp;quot;
&amp;gt; 
&amp;gt; writeLines(modelString, con=&amp;#39;modelpois_gof.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;, &amp;#39;Pvalue&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.P.jags1 &amp;lt;- jags(data=dat.list,model.file=&amp;#39;modelpois_gof.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 22
   Total graph size: 272

Initializing model
&amp;gt; 
&amp;gt; print(dat.P.jags1)
Inference for Bugs model at &amp;quot;modelpois_gof.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
Pvalue     0.478   0.500  0.000  0.000  0.000  1.000  1.000 1.001 10000
beta0      0.546   0.254  0.015  0.381  0.559  0.719  1.013 1.001 10000
beta1      0.112   0.018  0.077  0.099  0.111  0.124  0.149 1.001  3200
deviance  88.372   3.041 86.373 86.883 87.671 89.075 93.868 1.006  2000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.6 and DIC = 93.0
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the Bayesian p-value is approximately &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt;, suggesting that there is a good fit of the model to the data.&lt;/p&gt;
&lt;p&gt;Unfortunately, unlike with linear models (Gaussian family), the expected distribution of data (residuals) varies over the range of fitted values for numerous (often competing) ways that make diagnosing (and attributing causes thereof) miss-specified generalized linear models from standard residual plots very difficult. The use of standardized (Pearson) residuals or deviance residuals can partly address this issue, yet they still do not offer completely consistent diagnoses across all issues (miss-specified model, over-dispersion, zero-inflation). An alternative approach is to use simulated data from the model posteriors to calculate an empirical cumulative density function from which residuals are are generated as values corresponding to the observed data along the density function. Now we will compare the sum of squared residuals to the sum of squares residuals that would be expected from a Bernoulli distribution matching that estimated by the model. Essentially this is estimating how well the Bernoulli distribution and linear model approximates the observed data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #extract the samples for the two model parameters
&amp;gt; coefs &amp;lt;- dat.P.jags$BUGSoutput$sims.matrix[,1:2]
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data=dat)
&amp;gt; #expected values on a log scale
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; #expected value on response scale
&amp;gt; lambda &amp;lt;- exp(eta)
&amp;gt; 
&amp;gt; simRes &amp;lt;- function(lambda, data,n=250, plot=T, family=&amp;#39;poisson&amp;#39;) {
+  require(gap)
+  N = nrow(data)
+  sim = switch(family,
+     &amp;#39;poisson&amp;#39; = matrix(rpois(n*N,apply(lambda,2,mean)),ncol=N, byrow=TRUE)
+  )
+  a = apply(sim + runif(n,-0.5,0.5),2,ecdf)
+  resid&amp;lt;-NULL
+  for (i in 1:nrow(data)) resid&amp;lt;-c(resid,a[[i]](data$y[i] + runif(1 ,-0.5,0.5)))
+  if (plot==T) {
+    par(mfrow=c(1,2))
+    gap::qqunif(resid,pch = 2, bty = &amp;quot;n&amp;quot;,
+    logscale = F, col = &amp;quot;black&amp;quot;, cex = 0.6, main = &amp;quot;QQ plot residuals&amp;quot;,
+    cex.main = 1, las=1)
+    plot(resid~apply(lambda,2,mean), xlab=&amp;#39;Predicted value&amp;#39;, ylab=&amp;#39;Standardized residual&amp;#39;, las=1)
+  }
+  resid
+ }
&amp;gt; 
&amp;gt; simRes(lambda,dat, family=&amp;#39;poisson&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/model2_mcmc_res2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; [1] 0.220 0.544 0.532 0.344 0.812 0.980 0.048 0.592 0.548 0.728 0.164 0.492
[13] 0.856 0.096 0.240 0.292 0.876 0.880 0.148 0.748&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The trend (black symbols) in the qq-plot does not appear to be overly non-linear (matching the ideal red line well), suggesting that the model is not overdispersed. The spread of standardized (simulated) residuals in the residual plot do not appear overly non-uniform. That is there is not trend in the residuals. Furthermore, there is not a concentration of points close to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; (which would imply overdispersion).&lt;/p&gt;
&lt;p&gt;Recall that the Poisson regression model assumes that variance=mean (var=μϕ where &lt;span class=&#34;math inline&#34;&gt;\(\phi=1\)&lt;/span&gt;) and thus dispersion (&lt;span class=&#34;math inline&#34;&gt;\(\phi=\frac{\text{var}}{\mu}=1)\)&lt;/span&gt;). However, we can also calculate approximately what the dispersion factor would be by using sum square of the residuals as a measure of variance and the model residual degrees of freedom as a measure of the mean (since the expected value of a Poisson distribution is the same as its degrees of freedom).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \phi = \frac{RSS}{df},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(df=n−k\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is the number of estimated model coefficients.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Resid &amp;lt;- -1*sweep(lambda,2,dat$y,&amp;#39;-&amp;#39;)/sqrt(lambda)
&amp;gt; RSS&amp;lt;-apply(Resid^2,1,sum)
&amp;gt; (df&amp;lt;-nrow(dat)-ncol(coefs))
[1] 18
&amp;gt; 
&amp;gt; Disp &amp;lt;- RSS/df
&amp;gt; data.frame(Median=median(Disp), Mean=mean(Disp), HPDinterval(as.mcmc(Disp)),
+            HPDinterval(as.mcmc(Disp),p=0.5))
       Median     Mean     lower    upper   lower.1  upper.1
var1 1.053527 1.110853 0.9299722 1.449502 0.9300381 1.053579&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can incorporate the dispersion statistic directly into &lt;code&gt;JAGS&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dat.list &amp;lt;- with(dat,list(Y=y, X=x,N=nrow(dat)))
&amp;gt; modelString=&amp;quot;
+ model {
+   for (i in 1:N) {
+      Y[i] ~ dpois(lambda[i])
+      eta[i] &amp;lt;- beta0 + beta1*X[i]
+      log(lambda[i]) &amp;lt;- eta[i]
+      expY[i] &amp;lt;- lambda[i]
+      varY[i] &amp;lt;- lambda[i]
+    Resid[i] &amp;lt;- (Y[i] - expY[i])/sqrt(varY[i]) 
+   }
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+   RSS &amp;lt;- sum(pow(Resid,2))
+   df &amp;lt;- N-2
+   phi &amp;lt;- RSS/df
+ } 
+ &amp;quot;
&amp;gt; 
&amp;gt; writeLines(modelString, con=&amp;#39;modelpois_disp.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;,&amp;#39;phi&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.P.jags &amp;lt;- jags(data=dat.list,model.file=&amp;#39;modelpois_disp.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 2
   Total graph size: 171

Initializing model
&amp;gt; 
&amp;gt; print(dat.P.jags)
Inference for Bugs model at &amp;quot;modelpois_disp.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
beta0      0.552   0.256  0.039  0.382  0.557  0.724  1.042 1.001 10000
beta1      0.111   0.019  0.074  0.099  0.112  0.124  0.147 1.001  2800
phi        1.105   0.246  0.934  0.977  1.048  1.169  1.581 1.001 10000
deviance  88.354   2.633 86.368 86.896 87.709 89.074 93.897 1.002  4300

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.5 and DIC = 91.8
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dispersion statistic is close to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; and thus there is no evidence that the data were overdispersed. The Poisson distribution was therefore appropriate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-the-model-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring the model parameters&lt;/h2&gt;
&lt;p&gt;If there was any evidence that the assumptions had been violated or the model was not an appropriate fit, then we would need to reconsider the model and start the process again. In this case, there is no evidence that the test will be unreliable so we can proceed to explore the test statistics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(coda)
&amp;gt; print(dat.P.jags)
Inference for Bugs model at &amp;quot;modelpois_disp.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
beta0      0.552   0.256  0.039  0.382  0.557  0.724  1.042 1.001 10000
beta1      0.111   0.019  0.074  0.099  0.112  0.124  0.147 1.001  2800
phi        1.105   0.246  0.934  0.977  1.048  1.169  1.581 1.001 10000
deviance  88.354   2.633 86.368 86.896 87.709 89.074 93.897 1.002  4300

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.5 and DIC = 91.8
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; library(plyr)
&amp;gt; adply(dat.P.jags$BUGSoutput$sims.matrix[,1:2], 2, function(x) {
+   data.frame(Median=median(x), Mean=mean(x), HPDinterval(as.mcmc(x)), HPDinterval(as.mcmc(x),p=0.5))
+ })
     X1    Median      Mean      lower     upper    lower.1   upper.1
1 beta0 0.5570252 0.5517525 0.03871735 1.0423628 0.39092213 0.7317579
2 beta1 0.1115363 0.1113176 0.07499903 0.1484004 0.09893134 0.1239861
&amp;gt; 
&amp;gt; #on original scale
&amp;gt; adply(exp(dat.P.jags$BUGSoutput$sims.matrix[,1:2]), 2, function(x) {
+   data.frame(Median=median(x), Mean=mean(x), HPDinterval(as.mcmc(x)), HPDinterval(as.mcmc(x),p=0.5))
+ })
     X1   Median     Mean     lower    upper  lower.1  upper.1
1 beta0 1.745472 1.793464 0.9803783 2.734057 1.423789 2.013575
2 beta1 1.117994 1.117948 1.0778831 1.159977 1.101510 1.129458&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: We would reject the null hypothesis of no effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. An increase in x is associated with a significant linear increase (positive slope) in the abundance of y. Every &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; results in a log &lt;span class=&#34;math inline&#34;&gt;\(0.11\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. We usually express this in terms of abundance rather than log abundance, so every &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; results in a ($e^{ 0.11} = 1.12 $) &lt;span class=&#34;math inline&#34;&gt;\(1.12\)&lt;/span&gt; unit increase in the abundance of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;explorations-of-the-trends&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Explorations of the trends&lt;/h2&gt;
&lt;p&gt;A measure of the strength of the relationship can be obtained according to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = 1 - \frac{\text{RSS}_{model}}{\text{RSS}_{null}}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~x, data=dat)
&amp;gt; #expected values on a log scale
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; #expected value on response scale
&amp;gt; lambda &amp;lt;- exp(eta)
&amp;gt; #calculate the raw SS residuals
&amp;gt; SSres &amp;lt;- apply((-1*(sweep(lambda,2,dat$y,&amp;#39;-&amp;#39;)))^2,1,sum)
&amp;gt; SSres.null &amp;lt;- sum((dat$y - mean(dat$y))^2)
&amp;gt; #OR 
&amp;gt; SSres.null &amp;lt;- crossprod(dat$y - mean(dat$y))
&amp;gt; #calculate the model r2
&amp;gt; 1-mean(SSres)/SSres.null
          [,1]
[1,] 0.6569594&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(65\)&lt;/span&gt;% of the variation in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; abundance can be explained by its relationship with &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We can also do it directly into &lt;code&gt;JAGS&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dat.list &amp;lt;- with(dat,list(Y=y, X=x,N=nrow(dat)))
&amp;gt; modelString=&amp;quot;
+ model {
+   for (i in 1:N) {
+      Y[i] ~ dpois(lambda[i])
+      eta[i] &amp;lt;- beta0 + beta1*X[i]
+      log(lambda[i]) &amp;lt;- eta[i]
+      res[i] &amp;lt;- Y[i] - lambda[i]
+      resnull[i] &amp;lt;- Y[i] - meanY
+   }
+   meanY &amp;lt;- mean(Y)
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+   RSS &amp;lt;- sum(res^2)
+   RSSnull &amp;lt;- sum(resnull^2)
+   r2 &amp;lt;- 1-RSS/RSSnull
+ } 
+ &amp;quot;
&amp;gt; 
&amp;gt; writeLines(modelString, con=&amp;#39;modelpois_disp_r2.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;,&amp;#39;r2&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.P.jags &amp;lt;- jags(data=dat.list,model.file=&amp;#39;modelpois_disp_r2.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 2
   Total graph size: 150

Initializing model
&amp;gt; 
&amp;gt; print(dat.P.jags)
Inference for Bugs model at &amp;quot;modelpois_disp_r2.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
beta0      0.547   0.257  0.024  0.379  0.556  0.721  1.032 1.001  3900
beta1      0.112   0.019  0.077  0.100  0.112  0.125  0.150 1.001  7000
r2         0.655   0.057  0.510  0.640  0.672  0.690  0.701 1.001 10000
deviance  88.383   2.776 86.372 86.904 87.733 89.122 93.692 1.003  6200

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.9 and DIC = 92.2
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we will create a summary plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; par(mar = c(4, 5, 0, 0))
&amp;gt; plot(y ~ x, data = dat, type = &amp;quot;n&amp;quot;, ann = F, axes = F)
&amp;gt; points(y ~ x, data = dat, pch = 16)
&amp;gt; xs &amp;lt;- seq(min(dat$x,na.rm=TRUE),max(dat$x,na.rm=TRUE), l = 1000)
&amp;gt; Xmat &amp;lt;- model.matrix(~xs)
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; ys &amp;lt;- exp(eta)
&amp;gt; library(plyr)
&amp;gt; library(coda)
&amp;gt; data.tab &amp;lt;- adply(ys,2,function(x) {
+   data.frame(Median=median(x), HPDinterval(as.mcmc(x)))
+ })
&amp;gt; data.tab &amp;lt;- cbind(x=xs,data.tab)
&amp;gt; points(Median ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;)
&amp;gt; lines(lower ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;, lty = 2)
&amp;gt; lines(upper ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;, lty = 2)
&amp;gt; 
&amp;gt; axis(1)
&amp;gt; mtext(&amp;quot;X&amp;quot;, 1, cex = 1.5, line = 3)
&amp;gt; axis(2, las = 2)
&amp;gt; mtext(&amp;quot;Abundance of Y&amp;quot;, 2, cex = 1.5, line = 3)
&amp;gt; box(bty = &amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/model_code_v2_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;full-log-likelihood-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full log-likelihood function&lt;/h2&gt;
&lt;p&gt;Now lets try it by specifying log-likelihood and the zero trick. When applying this trick, we need to manually calculate the deviance as the inbuilt deviance will be based on the log-likelihood of estimating the zeros (as part of the zero trick) rather than the deviance of the intended model. The one advantage of the zero trick is that the Deviance and thus DIC, AIC provided by &lt;code&gt;R2jags&lt;/code&gt; will be incorrect. Hence, they too need to be manually defined within &lt;code&gt;JAGS&lt;/code&gt; I suspect that the AIC calculation I have used is incorrect.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~x, dat)
&amp;gt; nX &amp;lt;- ncol(Xmat)
&amp;gt; dat.list2 &amp;lt;- with(dat,list(Y=y, X=Xmat,N=nrow(dat), mu=rep(0,nX),
+                   Sigma=diag(1.0E-06,nX), zeros=rep(0,nrow(dat)), C=10000))
&amp;gt; modelString=&amp;quot;
+ model {
+   for (i in 1:N) {
+      zeros[i] ~ dpois(zeros.lambda[i])
+      zeros.lambda[i] &amp;lt;- -ll[i] + C     
+      ll[i] &amp;lt;- Y[i]*log(lambda[i]) - lambda[i] - loggam(Y[i]+1)
+      eta[i] &amp;lt;- inprod(beta[], X[i,])
+      log(lambda[i]) &amp;lt;- eta[i]
+     llm[i] &amp;lt;- Y[i]*log(meanlambda) - meanlambda - loggam(Y[i]+1)
+   }
+   meanlambda &amp;lt;- mean(lambda)
+   beta ~ dmnorm(mu[],Sigma[,])
+   dev &amp;lt;- sum(-2*ll)
+   pD &amp;lt;- mean(dev)-sum(-2*llm)
+   AIC &amp;lt;- min(dev+(2*pD))
+ } 
+ &amp;quot;
&amp;gt; 
&amp;gt; writeLines(modelString, con=&amp;#39;modelpois_ll.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta&amp;#39;,&amp;#39;dev&amp;#39;,&amp;#39;AIC&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.P.jags3 &amp;lt;- jags(data=dat.list2,model.file=&amp;#39;modelpois_ll.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 1
   Total graph size: 353

Initializing model
&amp;gt; 
&amp;gt; print(dat.P.jags3)
Inference for Bugs model at &amp;quot;modelpois_ll.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
            mu.vect sd.vect       2.5%        25%        50%        75%
AIC          13.728   4.725      9.624     10.548     11.952     15.158
beta[1]       0.481   0.259     -0.079      0.319      0.506      0.669
beta[2]       0.116   0.019      0.084      0.103      0.114      0.128
dev          88.382   2.009     86.361     86.883     87.731     89.265
deviance 400088.382   2.009 400086.361 400086.883 400087.731 400089.265
              97.5%  Rhat n.eff
AIC          26.878 1.016   180
beta[1]       0.922 1.037    49
beta[2]       0.155 1.029    60
dev          94.071 1.009   300
deviance 400094.071 1.000     1

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 2.0 and DIC = 400090.4
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;negative-binomial&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Negative binomial&lt;/h1&gt;
&lt;p&gt;The following equations are provided since in Bayesian modelling, it is occasionally necessary to directly define the log-likelihood calculations (particularly for zero-inflated models and other mixture models).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ f(y \mid r, p) = \frac{\Gamma(y+r)}{\Gamma(r)\Gamma(y+1)}p^r(1-p)^y,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the probability of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; successes until &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; failures. If, we make &lt;span class=&#34;math inline&#34;&gt;\(p=\frac{\text{size}}{\text{size}+\mu}\)&lt;/span&gt;, then we can define the function in terms of &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \mu = \frac{r(1-p)}{p},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(E[Y]=\mu\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(Var(Y)=\mu + \frac{\mu^2}{r}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;data-generation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Lets say we wanted to model the abundance of an item (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) against a continuous predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(37) #16 #35
&amp;gt; #The number of samples
&amp;gt; n.x &amp;lt;- 20
&amp;gt; #Create x values that at uniformly distributed throughout the rate of 1 to 20
&amp;gt; x &amp;lt;- sort(runif(n = n.x, min = 1, max =20))
&amp;gt; mm &amp;lt;- model.matrix(~x)
&amp;gt; intercept &amp;lt;- 0.6
&amp;gt; slope=0.1
&amp;gt; #The linear predictor
&amp;gt; linpred &amp;lt;- mm %*% c(intercept,slope)
&amp;gt; #Predicted y values
&amp;gt; lambda &amp;lt;- exp(linpred)
&amp;gt; #Add some noise and make binomial
&amp;gt; y &amp;lt;- rnbinom(n=n.x, mu=lambda, size=1)
&amp;gt; dat.nb &amp;lt;- data.frame(y,x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When counts are all very large (not close to &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;) and their ranges do not span orders of magnitude, they take on very Gaussian properties (symmetrical distribution and variance independent of the mean). Given that models based on the Gaussian distribution are more optimized and recognized than Generalized Linear Models, it can be prudent to adopt Gaussian models for such data. Hence it is a good idea to first explore whether a Poisson or Negative Binomial model is likely to be more appropriate than a standard Gaussian model. Recall from Poisson regression, there are five main potential models that we could consider fitting to these data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(dat$x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data1_negbin-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #now for the scatterplot
&amp;gt; plot(y~x, dat.nb, log=&amp;quot;y&amp;quot;)
&amp;gt; with(dat.nb, lines(lowess(y~x)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data1_negbin-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) does not display any skewness or other issues that might lead to non-linearity. The lowess smoother on the scatterplot does not display major deviations from a straight line and thus linearity is satisfied. Violations of linearity could be addressed by either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;define a non-linear linear predictor (such as a polynomial, spline or other non-linear function).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;transform the scale of the predictor variables.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although we have already established that there are few zeros in the data (and thus overdispersion is unlikely to be an issue), we can also explore this by comparing the number of zeros in the data to the number of zeros that would be expected from a Poisson distribution with a mean equal to the mean count of the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #proportion of 0&amp;#39;s in the data
&amp;gt; dat.nb.tab&amp;lt;-table(dat.nb$y==0)
&amp;gt; dat.nb.tab/sum(dat.nb.tab)

FALSE  TRUE 
 0.95  0.05 
&amp;gt; 
&amp;gt; #proportion of 0&amp;#39;s expected from a Poisson distribution
&amp;gt; mu &amp;lt;- mean(dat.nb$y)
&amp;gt; cnts &amp;lt;- rpois(1000, mu)
&amp;gt; dat.nb.tabE &amp;lt;- table(cnts == 0)
&amp;gt; dat.nb.tabE/sum(dat.nb.tabE)

FALSE 
    1 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above, the value under &lt;code&gt;FALSE&lt;/code&gt; is the proportion of non-zero values in the data and the value under &lt;code&gt;TRUE&lt;/code&gt; is the proportion of zeros in the data. In this example, the proportion of zeros observed is similar to the proportion expected. Indeed, there was only a single zero observed. Hence it is likely that if there is overdispersion it is unlikely to be due to excessive zeros.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{NegBin}(p_i,r),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(p_i=\frac{r}{r+\lambda_i}\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\log(\lambda_i)=\beta_0+\beta_1x_{i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_0,\beta_1 \sim N(0, 10000)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(r \sim \text{Unif}(0.001,1000)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dat.nb.list &amp;lt;- with(dat.nb,list(Y=y, X=x,N=nrow(dat.nb)))
&amp;gt; modelString=&amp;quot;
+ model {
+   for (i in 1:N) {
+      Y[i] ~ dnegbin(p[i],size)
+      p[i] &amp;lt;- size/(size+lambda[i])
+      log(lambda[i]) &amp;lt;- beta0 + beta1*X[i]
+   }
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+   size ~ dunif(0.001,1000)
+   theta &amp;lt;- pow(1/mean(p),2)
+   scaleparam &amp;lt;- mean((1-p)/p) 
+ } 
+ &amp;quot;
&amp;gt; writeLines(modelString, con=&amp;#39;modelnbin.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;, &amp;#39;size&amp;#39;,&amp;#39;theta&amp;#39;,&amp;#39;scaleparam&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.NB.jags &amp;lt;- jags(data=dat.nb.list,model.file=&amp;#39;modelnbin.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 3
   Total graph size: 157

Initializing model&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model evaluation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(dat.NB.jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;,&amp;quot;size&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/mcmc_diag_nbin-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(dat.NB.jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;,&amp;quot;size&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/mcmc_diag_nbin-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; raftery.diag(as.mcmc(dat.NB.jags))
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                  
            Burn-in  Total Lower bound  Dependence
            (M)      (N)   (Nmin)       factor (I)
 beta0      16       17518 3746         4.68      
 beta1      24       28713 3746         7.66      
 deviance   3        4198  3746         1.12      
 scaleparam 16       16290 3746         4.35      
 size       4        5038  3746         1.34      
 theta      16       16244 3746         4.34      


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                  
            Burn-in  Total Lower bound  Dependence
            (M)      (N)   (Nmin)       factor (I)
 beta0      18       20025 3746         5.35      
 beta1      24       21072 3746         5.63      
 deviance   3        4267  3746         1.14      
 scaleparam 18       19920 3746         5.32      
 size       3        4375  3746         1.17      
 theta      20       20682 3746         5.52      
&amp;gt; 
&amp;gt; autocorr.diag(as.mcmc(dat.NB.jags))
              beta0        beta1     deviance  scaleparam        size
Lag 0   1.000000000  1.000000000  1.000000000  1.00000000 1.000000000
Lag 1   0.855250119  0.856542892  0.566377262  0.33360033 0.684520361
Lag 5   0.519024321  0.521535488  0.163024546  0.07618281 0.220180993
Lag 10  0.276801196  0.280283232  0.025179110  0.02814049 0.039259726
Lag 50 -0.008060569 -0.004454124 -0.003876422 -0.01103395 0.006904325
             theta
Lag 0   1.00000000
Lag 1   0.26024619
Lag 5   0.05872969
Lag 10  0.02940084
Lag 50 -0.01349378&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now explore the goodness of fit of the models via the residuals and deviance. We could calculate the Pearsons’s residuals within the &lt;code&gt;JAGS&lt;/code&gt; model. Alternatively, we could use the parameters to generate the residuals outside of &lt;code&gt;JAGS&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #extract the samples for the two model parameters
&amp;gt; coefs &amp;lt;- dat.NB.jags$BUGSoutput$sims.matrix[,1:2]
&amp;gt; size &amp;lt;- dat.NB.jags$BUGSoutput$sims.matrix[,&amp;#39;size&amp;#39;]
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data=dat.nb)
&amp;gt; #expected values on a log scale
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; #expected value on response scale
&amp;gt; lambda &amp;lt;- exp(eta)
&amp;gt; varY &amp;lt;- lambda + (lambda^2)/size
&amp;gt; #sweep across rows and then divide by lambda
&amp;gt; Resid &amp;lt;- -1*sweep(lambda,2,dat.nb$y,&amp;#39;-&amp;#39;)/sqrt(varY)
&amp;gt; #plot residuals vs expected values
&amp;gt; plot(apply(Resid,2,mean)~apply(eta,2,mean))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/model2_mcmc_diag_nbin-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we will compare the sum of squared residuals to the sum of squares residuals that would be expected from a Negative binomial distribution matching that estimated by the model. Essentially this is estimating how well the Negative binomial distribution, the log-link function and the linear model approximates the observed data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; SSres&amp;lt;-apply(Resid^2,1,sum)
&amp;gt; 
&amp;gt; #generate a matrix of draws from a negative binomial distribution
&amp;gt; # the matrix is the same dimensions as pi and uses the probabilities of pi
&amp;gt; YNew &amp;lt;- matrix(rnbinom(length(lambda),mu=lambda, size=size),nrow=nrow(lambda))
&amp;gt; Resid1&amp;lt;-(lambda - YNew)/sqrt(varY)
&amp;gt; SSres.sim&amp;lt;-apply(Resid1^2,1,sum)
&amp;gt; mean(SSres.sim&amp;gt;SSres, na.rm = T)
[1] 0.4163&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the Bayesian p-value is approximately &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt;, suggesting that there is a good fit of the model to the data.&lt;/p&gt;
&lt;p&gt;Unfortunately, unlike with linear models (Gaussian family), the expected distribution of data (residuals) varies over the range of fitted values for numerous (often competing) ways that make diagnosing (and attributing causes thereof) miss-specified generalized linear models from standard residual plots very difficult. The use of standardized (Pearson) residuals or deviance residuals can partly address this issue, yet they still do not offer completely consistent diagnoses across all issues (miss-specified model, over-dispersion, zero-inflation). An alternative approach is to use simulated data from the model posteriors to calculate an empirical cumulative density function from which residuals are are generated as values corresponding to the observed data along the density function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #extract the samples for the two model parameters
&amp;gt; coefs &amp;lt;- dat.NB.jags$BUGSoutput$sims.matrix[,1:2]
&amp;gt; size &amp;lt;- dat.NB.jags$BUGSoutput$sims.matrix[,&amp;#39;size&amp;#39;]
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data=dat.nb)
&amp;gt; #expected values on a log scale
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; #expected value on response scale
&amp;gt; lambda &amp;lt;- exp(eta)
&amp;gt; 
&amp;gt; simRes &amp;lt;- function(lambda, data,n=250, plot=T, family=&amp;#39;negbin&amp;#39;, size=NULL) {
+  require(gap)
+  N = nrow(data)
+  sim = switch(family,
+     &amp;#39;poisson&amp;#39; = matrix(rpois(n*N,apply(lambda,2,mean)),ncol=N, byrow=TRUE),
+     &amp;#39;negbin&amp;#39; = matrix(MASS:::rnegbin(n*N,apply(lambda,2,mean),size),ncol=N, byrow=TRUE)
+  )
+  a = apply(sim + runif(n,-0.5,0.5),2,ecdf)
+  resid&amp;lt;-NULL
+  for (i in 1:nrow(data)) resid&amp;lt;-c(resid,a[[i]](data$y[i] + runif(1 ,-0.5,0.5)))
+  if (plot==T) {
+    par(mfrow=c(1,2))
+    gap::qqunif(resid,pch = 2, bty = &amp;quot;n&amp;quot;,
+    logscale = F, col = &amp;quot;black&amp;quot;, cex = 0.6, main = &amp;quot;QQ plot residuals&amp;quot;,
+    cex.main = 1, las=1)
+    plot(resid~apply(lambda,2,mean), xlab=&amp;#39;Predicted value&amp;#39;, ylab=&amp;#39;Standardized residual&amp;#39;, las=1)
+  }
+  resid
+ }
&amp;gt; 
&amp;gt; simRes(lambda,dat.nb, family=&amp;#39;negbin&amp;#39;, size=mean(size))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/model2_mcmc_res2_nbin-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; [1] 0.368 0.944 0.456 0.788 0.148 0.928 0.136 0.704 0.164 0.800 0.500 0.464
[13] 0.100 0.216 0.680 0.212 0.000 0.676 0.924 0.852&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The trend (black symbols) in the qq-plot does not appear to be overly non-linear (matching the ideal red line well), suggesting that the model is not overdispersed. The spread of standardized (simulated) residuals in the residual plot do not appear overly non-uniform. That is there is not trend in the residuals. Furthermore, there is not a concentration of points close to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; (which would imply overdispersion).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-the-model-parameters-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring the model parameters&lt;/h2&gt;
&lt;p&gt;If there was any evidence that the assumptions had been violated or the model was not an appropriate fit, then we would need to reconsider the model and start the process again. In this case, there is no evidence that the test will be unreliable so we can proceed to explore the test statistics. As with most Bayesian models, it is best to base conclusions on medians rather than means.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(dat.NB.jags)
Inference for Bugs model at &amp;quot;modelnbin.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
           mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta0        0.731   0.395  -0.023   0.470   0.717   0.984   1.534 1.001 10000
beta1        0.097   0.032   0.034   0.077   0.098   0.118   0.158 1.001 10000
scaleparam   2.787   1.756   0.704   1.670   2.412   3.444   7.089 1.001 10000
size         3.255   2.190   1.055   1.941   2.697   3.853   9.050 1.001 10000
theta       12.548  12.474   2.669   5.892   9.157  14.790  43.249 1.001 10000
deviance   113.053   2.691 110.093 111.115 112.352 114.190 120.305 1.002  2000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.6 and DIC = 116.7
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; adply(dat.NB.jags$BUGSoutput$sims.matrix, 2, function(x) {
+   data.frame(Median=median(x), Mean=mean(x), HPDinterval(as.mcmc(x)), HPDinterval(as.mcmc(x),p=0.5))
+ })
          X1       Median         Mean        lower       upper     lower.1
1      beta0   0.71693048   0.73121205  -0.05129743   1.5032427   0.4523583
2      beta1   0.09800852   0.09730699   0.03509028   0.1591976   0.0789372
3   deviance 112.35178835 113.05255254 109.86520971 118.4814291 110.0898498
4 scaleparam   2.41198253   2.78665197   0.33094006   5.9583607   1.2865037
5       size   2.69653197   3.25545915   0.68960555   7.2146030   1.4202953
6      theta   9.15704708  12.54776430   1.61632232  32.9116959   3.6489231
      upper.1
1   0.9610028
2   0.1201659
3 112.4668566
4   2.8677393
5   2.9988148
6  10.3646959
&amp;gt; 
&amp;gt; #on original scale
&amp;gt; adply(exp(dat.NB.jags$BUGSoutput$sims.matrix[,1:2]), 2, function(x) {
+   data.frame(Median=median(x), Mean=mean(x), HPDinterval(as.mcmc(x)), HPDinterval(as.mcmc(x),p=0.5))
+ })
     X1   Median     Mean     lower    upper  lower.1  upper.1
1 beta0 2.048137 2.249960 0.8335273 4.249614 1.340384 2.309801
2 beta1 1.102972 1.102753 1.0357132 1.172570 1.080463 1.125944&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: We would reject the null hypothesis of no effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. An increase in x is associated with a significant linear increase (positive slope) in the abundance of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. Every &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; results in a log &lt;span class=&#34;math inline&#34;&gt;\(0.09\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. We usually express this in terms of abundance rather than log abundance, so every &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; results in a ($e^{ 0.09} = 1.02 $) &lt;span class=&#34;math inline&#34;&gt;\(1.02\)&lt;/span&gt; unit increase in the abundance of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;explorations-of-the-trends-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Explorations of the trends&lt;/h2&gt;
&lt;p&gt;A measure of the strength of the relationship can be obtained according to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = 1 - \frac{\text{RSS}_{model}}{\text{RSS}_{null}}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~x, data=dat.nb)
&amp;gt; #expected values on a log scale
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; #expected value on response scale
&amp;gt; lambda &amp;lt;- exp(eta)
&amp;gt; #calculate the raw SS residuals
&amp;gt; SSres &amp;lt;- apply((-1*(sweep(lambda,2,dat.nb$y,&amp;#39;-&amp;#39;)))^2,1,sum)
&amp;gt; SSres.null &amp;lt;- sum((dat.nb$y - mean(dat.nb$y))^2)
&amp;gt; #OR 
&amp;gt; SSres.null &amp;lt;- crossprod(dat.nb$y - mean(dat.nb$y))
&amp;gt; #calculate the model r2
&amp;gt; 1-mean(SSres)/SSres.null
         [,1]
[1,] 0.270553&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(27\)&lt;/span&gt;% of the variation in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; abundance can be explained by its relationship with &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We can also do it directly into &lt;code&gt;JAGS&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Finally, we will create a summary plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; par(mar = c(4, 5, 0, 0))
&amp;gt; plot(y ~ x, data = dat.nb, type = &amp;quot;n&amp;quot;, ann = F, axes = F)
&amp;gt; points(y ~ x, data = dat.nb, pch = 16)
&amp;gt; xs &amp;lt;- seq(min(dat.nb$x,na.rm=TRUE),max(dat.nb$x,na.rm=TRUE), l = 1000)
&amp;gt; Xmat &amp;lt;- model.matrix(~xs)
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; ys &amp;lt;- exp(eta)
&amp;gt; library(plyr)
&amp;gt; library(coda)
&amp;gt; data.tab &amp;lt;- adply(ys,2,function(x) {
+   data.frame(Median=median(x), HPDinterval(as.mcmc(x)))
+ })
&amp;gt; data.tab &amp;lt;- cbind(x=xs,data.tab)
&amp;gt; points(Median ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;)
&amp;gt; lines(lower ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;, lty = 2)
&amp;gt; lines(upper ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;, lty = 2)
&amp;gt; 
&amp;gt; axis(1)
&amp;gt; mtext(&amp;quot;X&amp;quot;, 1, cex = 1.5, line = 3)
&amp;gt; axis(2, las = 2)
&amp;gt; mtext(&amp;quot;Abundance of Y&amp;quot;, 2, cex = 1.5, line = 3)
&amp;gt; box(bty = &amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/model_code_v2_plot_nbin-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;full-log-likelihood-function-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full log-likelihood function&lt;/h2&gt;
&lt;p&gt;Now lets try it by specifying log-likelihood and the zero trick. When applying this trick, we need to manually calculate the deviance as the inbuilt deviance will be based on the log-likelihood of estimating the zeros (as part of the zero trick) rather than the deviance of the intended model. The one advantage of the zero trick is that the Deviance and thus DIC, AIC provided by &lt;code&gt;R2jags&lt;/code&gt; will be incorrect. Hence, they too need to be manually defined within &lt;code&gt;JAGS&lt;/code&gt; I suspect that the AIC calculation I have used is incorrect.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~x, dat.nb)
&amp;gt; nX &amp;lt;- ncol(Xmat)
&amp;gt; dat.nb.list2 &amp;lt;- with(dat.nb,list(Y=y, X=Xmat,N=nrow(dat.nb), mu=rep(0,nX),
+                   Sigma=diag(1.0E-06,nX), zeros=rep(0,nrow(dat.nb)), C=10000))
&amp;gt; modelString=&amp;quot;
+ model {
+   for (i in 1:N) {
+      zeros[i] ~ dpois(zeros.lambda[i])
+      zeros.lambda[i] &amp;lt;- -ll[i] + C     
+      ll[i] &amp;lt;- loggam(Y[i]+size) - loggam(Y[i]+1) - loggam(size) + size*(log(p[i]) - log(p[i]+1)) - 
+               Y[i]*log(p[i]+1)
+      p[i] &amp;lt;- size/lambda[i]
+      eta[i] &amp;lt;- inprod(beta[], X[i,])
+      log(lambda[i]) &amp;lt;- eta[i]
+   }
+   beta ~ dmnorm(mu[],Sigma[,])
+   size ~ dunif(0.001,1000)
+   dev &amp;lt;- sum(-2*ll)
+ } 
+ &amp;quot;
&amp;gt; 
&amp;gt; writeLines(modelString, con=&amp;#39;modelnbin_ll.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta&amp;#39;,&amp;#39;dev&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.NB.jags3 &amp;lt;- jags(data=dat.nb.list2,model.file=&amp;#39;modelnbin_ll.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 2
   Total graph size: 453

Initializing model
&amp;gt; 
&amp;gt; print(dat.NB.jags3)
Inference for Bugs model at &amp;quot;modelnbin_ll.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
            mu.vect sd.vect       2.5%        25%        50%        75%
beta[1]       0.739   0.386      0.039      0.484      0.726      0.968
beta[2]       0.096   0.031      0.034      0.077      0.096      0.116
dev         112.830   2.548    110.074    111.037    112.105    113.842
deviance 400112.830   2.548 400110.074 400111.037 400112.105 400113.842
              97.5%  Rhat n.eff
beta[1]       1.536 1.015   160
beta[2]       0.153 1.010   230
dev         119.701 1.002  1200
deviance 400119.701 1.000     1

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.2 and DIC = 400116.1
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;zero-inflated-poisson&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Zero inflated Poisson&lt;/h1&gt;
&lt;p&gt;Zero-Inflation Poisson (ZIP) mixture model is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ p(y_i \mid \theta, \lambda) = \begin{cases}
  \theta + (1-\theta) \times \text{Pois}(0 \mid \lambda) &amp;amp; \text{if } y_i = 0\\    
  (1-\theta) \times \text{Pois}(y_i \mid \lambda) &amp;amp; \text{if } y_i &amp;gt; 0,    
\end{cases}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; is the probability of false values (zeros). Hence there is essentially two models coupled together (a mixture model) to yield an overall probability:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;when an observed response is zero (&lt;span class=&#34;math inline&#34;&gt;\(y_i=0\)&lt;/span&gt;), it is the probability of getting a false value (zero) plus the probability of a true value multiplied probability of drawing a value of zero from a Poisson distribution of lambda.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;when an observed response is greater than &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, it is the probability of a true value multiplied probability of drawing that value from a Poisson distribution of lambda&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above formulation indicates the same &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; for both the zeros and non-zeros components. In the model of zero values, we are essentially investigating whether the likelihood of false zeros is related to the linear predictor and then the greater than zero model investigates whether the counts are related to the linear predictor. However, we are typically less interested in modelling determinants of false zeros. Indeed, it is better that the likelihood of false zeros be unrelated to the linear predictor. For example, if excess (false zeros) are due to issues of detectability (individuals are present, just not detected), it is better that the detectability is not related to experimental treatments. Ideally, any detectability issues should be equal across all treatment levels. The expected value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; and the variance in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for a ZIP model are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ E[y_i] = \lambda \times (1-\theta),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \text{Var}(y_i) = \lambda \times (1-\theta) \times (1+\theta \times \lambda^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;div id=&#34;data-generation-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Lets say we wanted to model the abundance of an item (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) against a continuous predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(9) #34.5  #4 #10 #16 #17 #26
&amp;gt; #The number of samples
&amp;gt; n.x &amp;lt;- 20
&amp;gt; #Create x values that at uniformly distributed throughout the rate of 1 to 20
&amp;gt; x &amp;lt;- sort(runif(n = n.x, min = 1, max =20))
&amp;gt; mm &amp;lt;- model.matrix(~x)
&amp;gt; intercept &amp;lt;- 0.6
&amp;gt; slope=0.1
&amp;gt; #The linear predictor
&amp;gt; linpred &amp;lt;- mm %*% c(intercept,slope)
&amp;gt; #Predicted y values
&amp;gt; lambda &amp;lt;- exp(linpred)
&amp;gt; #Add some noise and make binomial
&amp;gt; library(gamlss.dist)
&amp;gt; #fixed latent binomial
&amp;gt; y&amp;lt;- rZIP(n.x,lambda, 0.4)
&amp;gt; #latent binomial influenced by the linear predictor 
&amp;gt; #y&amp;lt;- rZIP(n.x,lambda, 1-exp(linpred)/(1+exp(linpred)))
&amp;gt; dat.zip &amp;lt;- data.frame(y,x)
&amp;gt; 
&amp;gt; summary(glm(y~x, dat.zip, family=&amp;quot;poisson&amp;quot;))

Call:
glm(formula = y ~ x, family = &amp;quot;poisson&amp;quot;, data = dat.zip)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-4.6803  -2.0343   0.2895   1.2767   2.1153  

Coefficients:
            Estimate Std. Error z value Pr(&amp;gt;|z|)    
(Intercept)  0.30200    0.25247   1.196    0.232    
x            0.10691    0.01847   5.789 7.09e-09 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 111.495  on 19  degrees of freedom
Residual deviance:  79.118  on 18  degrees of freedom
AIC: 126.64

Number of Fisher Scoring iterations: 5
&amp;gt; 
&amp;gt; plot(glm(y~x, dat.zip, family=&amp;quot;poisson&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/generate_data_zip-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/generate_data_zip-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/generate_data_zip-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/generate_data_zip-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; library(pscl)
&amp;gt; summary(zeroinfl(y ~ x | 1, dist = &amp;quot;poisson&amp;quot;, data = dat.zip))

Call:
zeroinfl(formula = y ~ x | 1, data = dat.zip, dist = &amp;quot;poisson&amp;quot;)

Pearson residuals:
    Min      1Q  Median      3Q     Max 
-1.1625 -0.9549  0.1955  0.8125  1.4438 

Count model coefficients (poisson with log link):
            Estimate Std. Error z value Pr(&amp;gt;|z|)    
(Intercept)  0.88696    0.28825   3.077  0.00209 ** 
x            0.09374    0.02106   4.450 8.58e-06 ***

Zero-inflation model coefficients (binomial with logit link):
            Estimate Std. Error z value Pr(&amp;gt;|z|)
(Intercept)  -0.4581     0.4725   -0.97    0.332
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1 

Number of iterations in BFGS optimization: 8 
Log-likelihood: -38.58 on 3 Df
&amp;gt; 
&amp;gt; plot(resid(zeroinfl(y ~ x | 1, dist = &amp;quot;poisson&amp;quot;, data = dat.zip))~fitted(zeroinfl(y ~ x | 1, dist = &amp;quot;poisson&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/generate_data_zip-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; library(gamlss)
&amp;gt; summary(gamlss(y~x,data=dat.zip, family=ZIP))
GAMLSS-RS iteration 1: Global Deviance = 77.8434 
GAMLSS-RS iteration 2: Global Deviance = 77.1603 
GAMLSS-RS iteration 3: Global Deviance = 77.1598 
******************************************************************
Family:  c(&amp;quot;ZIP&amp;quot;, &amp;quot;Poisson Zero Inflated&amp;quot;) 

Call:  gamlss(formula = y ~ x, family = ZIP, data = dat.zip) 

Fitting method: RS() 

------------------------------------------------------------------
Mu link function:  log
Mu Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  0.88620    0.28819   3.075 0.006862 ** 
x            0.09387    0.02105   4.458 0.000345 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

------------------------------------------------------------------
Sigma link function:  logit
Sigma Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)
(Intercept)  -0.4582     0.4725   -0.97    0.346

------------------------------------------------------------------
No. of observations in the fit:  20 
Degrees of Freedom for the fit:  3
      Residual Deg. of Freedom:  17 
                      at cycle:  3 
 
Global Deviance:     77.15981 
            AIC:     83.15981 
            SBC:     86.14701 
******************************************************************
&amp;gt; 
&amp;gt; predict(gamlss(y~x,data=dat.zip, family=ZIP), se.fit=TRUE, what=&amp;quot;mu&amp;quot;)
GAMLSS-RS iteration 1: Global Deviance = 77.8434 
GAMLSS-RS iteration 2: Global Deviance = 77.1603 
GAMLSS-RS iteration 3: Global Deviance = 77.1598 
$fit
        1         2         3         4         5         6         7         8 
0.9952647 1.0233409 1.1897115 1.2189891 1.3490911 1.3644351 1.3748867 1.5164069 
        9        10        11        12        13        14        15        16 
1.6184170 1.6379917 1.6760055 1.6962694 1.7705249 1.8559090 1.8578379 1.8718850 
       17        18        19        20 
2.1712345 2.5536059 2.7205304 2.7472964 

$se.fit
        1         2         3         4         5         6         7         8 
0.3826655 0.3724115 0.3131865 0.3031078 0.2601025 0.2552658 0.2520053 0.2112310 
        9        10        11        12        13        14        15        16 
0.1872286 0.1833232 0.1765049 0.1733169 0.1646100 0.1610460 0.1610499 0.1611915 
       17        18        19        20 
0.2055555 0.3248709 0.3848647 0.3947072 &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;Check the distribution of the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; abundances.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(dat.zip$y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data1_zip-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; boxplot(dat.zip$y, horizontal=TRUE)
&amp;gt; rug(jitter(dat.zip$y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data1_zip-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is definitely signs of non-normality that would warrant Poisson models. Further to that, there appears to be a large number of zeros that are likely to be the cause of overdispersion A zero-inflated Poisson model is likely to be one of the most effective for modeling these data. Lets now explore linearity by creating a histogram of the predictor variable (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). Note, it is difficult to directly assess issues of linearity. Indeed, a scatterplot with lowess smoother will be largely influenced by the presence of zeros. One possible way of doing so is to explore the trend in the non-zero data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(dat.zip$x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data2_zip-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #now for the scatterplot
&amp;gt; plot(y~x, dat.zip)
&amp;gt; with(subset(dat.zip,y&amp;gt;0), lines(lowess(y~x)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data2_zip-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) does not display any skewness or other issues that might lead to non-linearity. The lowess smoother on the non-zero data cloud does not display major deviations from a straight line and thus linearity is likely to be satisfied. Violations of linearity (whilst difficult to be certain about due to the unknown influence of the zeros) could be addressed by either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;define a non-linear linear predictor (such as a polynomial, spline or other non-linear function).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;transform the scale of the predictor variables.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although we have already established that there are few zeros in the data (and thus overdispersion is unlikely to be an issue), we can also explore this by comparing the number of zeros in the data to the number of zeros that would be expected from a Poisson distribution with a mean equal to the mean count of the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #proportion of 0&amp;#39;s in the data
&amp;gt; dat.zip.tab&amp;lt;-table(dat.zip$y==0)
&amp;gt; dat.zip.tab/sum(dat.zip.tab)

FALSE  TRUE 
  0.6   0.4 
&amp;gt; 
&amp;gt; #proportion of 0&amp;#39;s expected from a Poisson distribution
&amp;gt; mu &amp;lt;- mean(dat.zip$y)
&amp;gt; cnts &amp;lt;- rpois(1000, mu)
&amp;gt; dat.zip.tabE &amp;lt;- table(cnts == 0)
&amp;gt; dat.zip.tabE/sum(dat.zip.tabE)

FALSE  TRUE 
0.982 0.018 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above, the value under &lt;code&gt;FALSE&lt;/code&gt; is the proportion of non-zero values in the data and the value under TRUE is the proportion of zeros in the data. In this example, the proportion of zeros observed (&lt;span class=&#34;math inline&#34;&gt;\(45\)&lt;/span&gt;%) far exceeds that that would have been expected (&lt;span class=&#34;math inline&#34;&gt;\(7.9\)&lt;/span&gt;%). Hence it is highly likely that any models will be zero-inflated.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{ZIP}(\lambda_i, \theta),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\text{logit}(\theta) = \gamma_0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\log(\lambda_i)=\eta_i\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\eta_i=\beta_0+\beta_1x_{i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_0,\beta_1,\gamma_0 \sim N(0, 10000)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dat.zip.list &amp;lt;- with(dat.zip,list(Y=y, X=x,N=nrow(dat.nb), z=ifelse(y==0,0,1)))
&amp;gt; modelString=&amp;quot;
+ model {
+   for (i in 1:N) {
+      z[i] ~ dbern(one.minus.theta)
+      Y[i] ~ dpois(lambda[i])
+      lambda[i] &amp;lt;- z[i]*eta[i]
+      log(eta[i]) &amp;lt;- beta0 + beta1*X[i]
+   }
+   one.minus.theta &amp;lt;- 1-theta
+   logit(theta) &amp;lt;- gamma0
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+   gamma0 ~ dnorm(0,1.0E-06)
+ } 
+ &amp;quot;
&amp;gt; writeLines(modelString, con=&amp;#39;modelzip.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;, &amp;#39;gamma0&amp;#39;,&amp;#39;theta&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.zip.jags &amp;lt;- jags(data=dat.zip.list,model.file=&amp;#39;modelzip.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 40
   Unobserved stochastic nodes: 3
   Total graph size: 149

Initializing model&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model evaluation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(dat.zip.jags, parms = c(&amp;#39;beta&amp;#39;, &amp;#39;gamma0&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/mcmc_diag_zip-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(dat.zip.jags, parms = c(&amp;#39;beta&amp;#39;, &amp;#39;gamma0&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/mcmc_diag_zip-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; raftery.diag(as.mcmc(dat.zip.jags))
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    20       20276 3746         5.41      
 beta1    22       24038 3746         6.42      
 deviance 4        4636  3746         1.24      
 gamma0   5        5908  3746         1.58      
 theta    5        5908  3746         1.58      


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    20       21336 3746         5.70      
 beta1    20       22636 3746         6.04      
 deviance 3        4267  3746         1.14      
 gamma0   5        6078  3746         1.62      
 theta    5        6078  3746         1.62      
&amp;gt; 
&amp;gt; autocorr.diag(as.mcmc(dat.zip.jags))
             beta0       beta1    deviance      gamma0       theta
Lag 0   1.00000000  1.00000000  1.00000000 1.000000000 1.000000000
Lag 1   0.88627108  0.88426590  0.51799594 0.232408997 0.227686735
Lag 5   0.58998005  0.59775827  0.19471855 0.002321179 0.001571686
Lag 10  0.35846288  0.35888205  0.06697926 0.017561785 0.015598223
Lag 50 -0.01753582 -0.01936659 -0.01212528 0.022040872 0.021016755&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;goodness-of-fit-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goodness of fit&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #extract the samples for the two model parameters
&amp;gt; coefs &amp;lt;- dat.zip.jags$BUGSoutput$sims.matrix[,1:2]
&amp;gt; theta &amp;lt;- dat.zip.jags$BUGSoutput$sims.matrix[,&amp;#39;theta&amp;#39;]
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data=dat.zip)
&amp;gt; #expected values on a log scale
&amp;gt; lambda&amp;lt;-coefs %*% t(Xmat)
&amp;gt; #expected value on response scale
&amp;gt; eta &amp;lt;- exp(lambda)
&amp;gt; expY &amp;lt;- sweep(eta,1,(1-theta),&amp;quot;*&amp;quot;)
&amp;gt; varY &amp;lt;- eta+sweep(eta^2,1,theta,&amp;quot;*&amp;quot;)
&amp;gt; varY &amp;lt;- sweep(varY,1,(1-theta),&amp;#39;*&amp;#39;)
&amp;gt; #sweep across rows and then divide by lambda
&amp;gt; Resid &amp;lt;- -1*sweep(expY,2,dat.zip$y,&amp;#39;-&amp;#39;)/sqrt(varY)
&amp;gt; #plot residuals vs expected values
&amp;gt; plot(apply(Resid,2,mean)~apply(eta,2,mean))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/model2_mcmc_gof_zip-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we will compare the sum of squared residuals to the sum of squares residuals that would be expected from a Poisson distribution matching that estimated by the model. Essentially this is estimating how well the Poisson distribution, the log-link function and the linear model approximates the observed data. When doing so, we need to consider the expected value and variance of the zero-inflated poisson.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; SSres&amp;lt;-apply(Resid^2,1,sum, na.rm=T)
&amp;gt; 
&amp;gt; #generate a matrix of draws from a zero-inflated poisson (ZIP) distribution
&amp;gt; # the matrix is the same dimensions as lambda
&amp;gt; library(gamlss.dist)
&amp;gt; #YNew &amp;lt;- matrix(rZIP(length(lambda),eta, theta),nrow=nrow(lambda))
&amp;gt; lambda &amp;lt;- sweep(eta,1,ifelse(dat.zip$y==0,0,1),&amp;#39;*&amp;#39;)
&amp;gt; YNew &amp;lt;- matrix(rpois(length(lambda),lambda),nrow=nrow(lambda))
&amp;gt; Resid1&amp;lt;-(expY - YNew)/sqrt(varY)
&amp;gt; SSres.sim&amp;lt;-apply(Resid1^2,1,sum)
&amp;gt; mean(SSres.sim&amp;gt;SSres, na.rm = T)
[1] 0.5619&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since it is difficult to diagnose many issues from the typical residuals we will now explore simulated residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #extract the samples for the two model parameters
&amp;gt; coefs &amp;lt;- dat.zip.jags$BUGSoutput$sims.matrix[,1:2]
&amp;gt; theta &amp;lt;- dat.zip.jags$BUGSoutput$sims.matrix[,&amp;#39;theta&amp;#39;]
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data=dat.zip)
&amp;gt; #expected values on a log scale
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; #expected value on response scale
&amp;gt; lambda &amp;lt;- exp(eta)
&amp;gt; 
&amp;gt; simRes &amp;lt;- function(lambda, data,n=250, plot=T, family=&amp;#39;negbin&amp;#39;, size=NULL,theta=NULL) {
+  require(gap)
+  N = nrow(data)
+  sim = switch(family,
+     &amp;#39;poisson&amp;#39; = matrix(rpois(n*N,apply(lambda,2,mean)),ncol=N, byrow=TRUE),
+     &amp;#39;negbin&amp;#39; = matrix(MASS:::rnegbin(n*N,apply(lambda,2,mean),size),ncol=N, byrow=TRUE),
+         &amp;#39;zip&amp;#39; = matrix(gamlss.dist:::rZIP(n*N,apply(lambda,2,mean),theta),ncol=N, byrow=TRUE)
+  )
+  a = apply(sim + runif(n,-0.5,0.5),2,ecdf)
+  resid&amp;lt;-NULL
+  for (i in 1:nrow(data)) resid&amp;lt;-c(resid,a[[i]](data$y[i] + runif(1 ,-0.5,0.5)))
+  if (plot==T) {
+    par(mfrow=c(1,2))
+    gap::qqunif(resid,pch = 2, bty = &amp;quot;n&amp;quot;,
+    logscale = F, col = &amp;quot;black&amp;quot;, cex = 0.6, main = &amp;quot;QQ plot residuals&amp;quot;,
+    cex.main = 1, las=1)
+    plot(resid~apply(lambda,2,mean), xlab=&amp;#39;Predicted value&amp;#39;, ylab=&amp;#39;Standardized residual&amp;#39;, las=1)
+  }
+  resid
+ }
&amp;gt; 
&amp;gt; simRes(lambda,dat.zip, family=&amp;#39;zip&amp;#39;,theta=theta)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/model2_mcmc_res3_zip-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; [1] 0.718 0.212 0.106 0.050 0.476 0.778 0.248 0.060 0.878 0.704 0.090 0.890
[13] 0.416 0.764 0.282 0.752 0.602 0.848 0.154 0.656&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The trend (black symbols) in the qq-plot does not appear to be overly non-linear (matching the ideal red line well), suggesting that the model is not overdispersed. The spread of standardized (simulated) residuals in the residual plot do not appear overly non-uniform. That is there is not trend in the residuals. Furthermore, there is not a concentration of points close to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; (which would imply overdispersion). Hence, once zero-inflation is accounted for, the model does not display overdispersion. Although there is a slight hint of non-linearity in that the residuals are high for low and high fitted values and lower in the middle, this might well be an artifact of the small data set size. By change, most of the observed values in the middle range of the predictor were zero.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-the-model-parameters-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring the model parameters&lt;/h2&gt;
&lt;p&gt;If there was any evidence that the assumptions had been violated or the model was not an appropriate fit, then we would need to reconsider the model and start the process again. In this case, there is no evidence that the test will be unreliable so we can proceed to explore the test statistics. As with most Bayesian models, it is best to base conclusions on medians rather than means.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(dat.zip.jags)
Inference for Bugs model at &amp;quot;modelzip.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
beta0      0.930   0.282  0.365  0.742  0.933  1.128  1.468 1.003   860
beta1      0.090   0.021  0.049  0.076  0.090  0.104  0.132 1.002  1400
gamma0    -0.420   0.458 -1.349 -0.722 -0.417 -0.110  0.459 1.001 10000
theta      0.401   0.105  0.206  0.327  0.397  0.472  0.613 1.001  7600
deviance  80.674   2.501 77.856 78.867 80.008 81.801 87.064 1.001 10000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.1 and DIC = 83.8
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; adply(dat.zip.jags$BUGSoutput$sims.matrix, 2, function(x) {
+   data.frame(Median=median(x), Mean=mean(x), HPDinterval(as.mcmc(x)), HPDinterval(as.mcmc(x),p=0.5))
+ })
        X1      Median        Mean       lower      upper    lower.1
1    beta0  0.93334635  0.92997411  0.37821529  1.4774189  0.7530788
2    beta1  0.09005537  0.09005981  0.04864163  0.1313802  0.0749821
3 deviance 80.00841187 80.67383245 77.63946567 85.5798539 77.8273778
4   gamma0 -0.41667356 -0.41996110 -1.34903991  0.4586909 -0.7013225
5    theta  0.39731301  0.40136809  0.19516803  0.6012233  0.3173026
      upper.1
1  1.13629442
2  0.10333030
3 80.10544007
4 -0.09258569
5  0.46170971
&amp;gt; 
&amp;gt; #on original scale
&amp;gt; adply(exp(dat.zip.jags$BUGSoutput$sims.matrix[,1:2]), 2, function(x) {
+   data.frame(Median=median(x), Mean=mean(x), HPDinterval(as.mcmc(x)), HPDinterval(as.mcmc(x),p=0.5))
+ })
     X1   Median     Mean    lower    upper  lower.1  upper.1
1 beta0 2.543005 2.636434 1.280362 4.056990 1.911083 2.853498
2 beta1 1.094235 1.094483 1.049844 1.140401 1.077865 1.108858&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: We would reject the null hypothesis of no effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. An increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is associated with a significant linear increase (positive slope) in the abundance of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. Every &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; results in a log &lt;span class=&#34;math inline&#34;&gt;\(0.09\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. We usually express this in terms of abundance rather than log abundance, so every &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; results in a (&lt;span class=&#34;math inline&#34;&gt;\(e^{0.09}=1.1\)&lt;/span&gt;) &lt;span class=&#34;math inline&#34;&gt;\(1.1\)&lt;/span&gt; unit increase in the abundance of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;explorations-of-the-trends-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Explorations of the trends&lt;/h2&gt;
&lt;p&gt;A measure of the strength of the relationship can be obtained according to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = 1 - \frac{\text{RSS}_{model}}{\text{RSS}_{null}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Alternatively, we could use McFadden’s psuedo&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = 1- \frac{LL(Model_{full})}{LL(Model_{reduced}}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~x, dat=dat.zip)
&amp;gt; #expected values on a log scale
&amp;gt; neta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; #expected value on response scale
&amp;gt; eta &amp;lt;- exp(neta)
&amp;gt; lambda &amp;lt;- sweep(eta,2,ifelse(dat.zip$y==0,0,1),&amp;#39;*&amp;#39;)
&amp;gt; theta &amp;lt;- dat.zip.jags$BUGSoutput$sims.matrix[,&amp;#39;theta&amp;#39;]
&amp;gt; expY &amp;lt;- sweep(lambda,2,1-theta,&amp;#39;*&amp;#39;)
&amp;gt; #calculate the raw SS residuals
&amp;gt; SSres &amp;lt;- apply((-1*(sweep(expY,2,dat.zip$y,&amp;#39;-&amp;#39;)))^2,1,sum)
&amp;gt; mean(SSres)
[1] 168.3814
&amp;gt; 
&amp;gt; SSres.null &amp;lt;- sum((dat.zip$y - mean(dat.zip$y))^2)
&amp;gt; #calculate the model r2
&amp;gt; 1-mean(SSres)/SSres.null
[1] 0.5977029&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(50\)&lt;/span&gt;% of the variation in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; abundance can be explained by its relationship with &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Finally, we will create a summary plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; par(mar = c(4, 5, 0, 0))
&amp;gt; plot(y ~ x, data = dat.zip, type = &amp;quot;n&amp;quot;, ann = F, axes = F)
&amp;gt; points(y ~ x, data = dat.zip, pch = 16)
&amp;gt; xs &amp;lt;- seq(min(dat.zip$x,na.rm=TRUE),max(dat.zip$x,na.rm=TRUE), l = 1000)
&amp;gt; Xmat &amp;lt;- model.matrix(~xs)
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; ys &amp;lt;- exp(eta)
&amp;gt; library(plyr)
&amp;gt; library(coda)
&amp;gt; data.tab &amp;lt;- adply(ys,2,function(x) {
+   data.frame(Median=median(x), HPDinterval(as.mcmc(x)))
+ })
&amp;gt; data.tab &amp;lt;- cbind(x=xs,data.tab)
&amp;gt; points(Median ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;)
&amp;gt; lines(lower ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;, lty = 2)
&amp;gt; lines(upper ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;, lty = 2)
&amp;gt; 
&amp;gt; axis(1)
&amp;gt; mtext(&amp;quot;X&amp;quot;, 1, cex = 1.5, line = 3)
&amp;gt; axis(2, las = 2)
&amp;gt; mtext(&amp;quot;Abundance of Y&amp;quot;, 2, cex = 1.5, line = 3)
&amp;gt; box(bty = &amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/model_code_v2_plot_zip-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;full-log-likelihood-function-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full log-likelihood function&lt;/h2&gt;
&lt;p&gt;Now lets try it by specifying log-likelihood and the zero trick. When applying this trick, we need to manually calculate the deviance as the inbuilt deviance will be based on the log-likelihood of estimating the zeros (as part of the zero trick) rather than the deviance of the intended model. The one advantage of the zero trick is that the Deviance and thus DIC, AIC provided by &lt;code&gt;R2jags&lt;/code&gt; will be incorrect. Hence, they too need to be manually defined within &lt;code&gt;JAGS&lt;/code&gt; I suspect that the AIC calculation I have used is incorrect.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~x, dat.zip)
&amp;gt; nX &amp;lt;- ncol(Xmat)
&amp;gt; dat.zip.list2 &amp;lt;- with(dat.zip,list(Y=y, X=Xmat,N=nrow(dat.zip), mu=rep(0,nX),
+                   Sigma=diag(1.0E-06,nX), zeros=rep(0,nrow(dat)), C=10000))
&amp;gt; modelString=&amp;quot;
+ model {
+   for (i in 1:N) {
+      zeros[i] ~ dpois(zeros.lambda[i])
+      zeros.lambda[i] &amp;lt;- -ll[i] + C     
+      ll[i] &amp;lt;- Y[i]*log(lambda[i]) - lambda[i] - loggam(Y[i]+1)
+      eta[i] &amp;lt;- inprod(beta[], X[i,])
+      log(lambda[i]) &amp;lt;- eta[i]
+     llm[i] &amp;lt;- Y[i]*log(meanlambda) - meanlambda - loggam(Y[i]+1)
+   }
+   meanlambda &amp;lt;- mean(lambda)
+   beta ~ dmnorm(mu[],Sigma[,])
+   dev &amp;lt;- sum(-2*ll)
+   pD &amp;lt;- mean(dev)-sum(-2*llm)
+   AIC &amp;lt;- min(dev+(2*pD))
+ } 
+ &amp;quot;
&amp;gt; 
&amp;gt; writeLines(modelString, con=&amp;#39;modelzip_ll.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta&amp;#39;,&amp;#39;dev&amp;#39;,&amp;#39;AIC&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.ZIP.jags3  &amp;lt;- jags(data=dat.zip.list2,model.file=&amp;#39;modelzip_ll.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 1
   Total graph size: 328

Initializing model
&amp;gt; 
&amp;gt; print(dat.ZIP.jags3 )
Inference for Bugs model at &amp;quot;modelzip_ll.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
            mu.vect sd.vect       2.5%        25%        50%        75%
AIC          61.488   3.844     57.991     58.846     60.144     62.785
beta[1]       0.329   0.225     -0.122      0.176      0.331      0.475
beta[2]       0.104   0.017      0.070      0.093      0.104      0.116
dev         124.472   1.801    122.700    123.170    123.871    125.221
deviance 400124.472   1.801 400122.700 400123.170 400123.871 400125.221
              97.5%  Rhat n.eff
AIC          72.257 1.089    35
beta[1]       0.785 1.071    67
beta[2]       0.137 1.051    69
dev         129.054 1.042    53
deviance 400129.054 1.000     1

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 1.6 and DIC = 400126.1
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;zero-inflated-negative-binomial&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Zero inflated Negative Binomial&lt;/h1&gt;
&lt;div id=&#34;data-generation-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Lets say we wanted to model the abundance of an item (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) against a continuous predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(37) #34.5  #4 #10 #16 #17 #26
&amp;gt; #The number of samples
&amp;gt; n.x &amp;lt;- 20
&amp;gt; #Create x values that at uniformly distributed throughout the rate of 1 to 20
&amp;gt; x &amp;lt;- sort(runif(n = n.x, min = 1, max =20))
&amp;gt; mm &amp;lt;- model.matrix(~x)
&amp;gt; intercept &amp;lt;- 0.6
&amp;gt; slope=0.1
&amp;gt; #The linear predictor
&amp;gt; linpred &amp;lt;- mm %*% c(intercept,slope)
&amp;gt; #Predicted y values
&amp;gt; lambda &amp;lt;- exp(linpred)
&amp;gt; #Add some noise and make binomial
&amp;gt; library(gamlss.dist)
&amp;gt; #fixed latent binomial
&amp;gt; y&amp;lt;- rZINBI(n.x,lambda, 0.4)
&amp;gt; #latent binomial influenced by the linear predictor 
&amp;gt; #y&amp;lt;- rZINB(n.x,lambda, 1-exp(linpred)/(1+exp(linpred)))
&amp;gt; dat.zinb &amp;lt;- data.frame(y,x)
&amp;gt; 
&amp;gt; summary(dat.glm.nb&amp;lt;-glm.nb(y~x, dat.zinb))

Call:
glm.nb(formula = y ~ x, data = dat.zinb, init.theta = 0.4646673144, 
    link = log)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.3578  -1.3455  -0.5069   0.3790   1.1809  

Coefficients:
            Estimate Std. Error z value Pr(&amp;gt;|z|)
(Intercept) 0.914191   0.796804   1.147    0.251
x           0.009149   0.067713   0.135    0.893

(Dispersion parameter for Negative Binomial(0.4647) family taken to be 1)

    Null deviance: 20.303  on 19  degrees of freedom
Residual deviance: 20.282  on 18  degrees of freedom
AIC: 90.365

Number of Fisher Scoring iterations: 1

              Theta:  0.465 
          Std. Err.:  0.218 

 2 x log-likelihood:  -84.365 
&amp;gt; 
&amp;gt; plot(glm.nb(y~x, dat.zinb))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/generate_data_zinb-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/generate_data_zinb-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/generate_data_zinb-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/generate_data_zinb-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; library(pscl)
&amp;gt; summary(dat.zeroinfl&amp;lt;-zeroinfl(y ~ x | 1, dist = &amp;quot;negbin&amp;quot;, data = dat.zinb))

Call:
zeroinfl(formula = y ~ x | 1, data = dat.zinb, dist = &amp;quot;negbin&amp;quot;)

Pearson residuals:
    Min      1Q  Median      3Q     Max 
-0.9609 -0.9268 -0.4446  1.0425  1.7556 

Count model coefficients (negbin with log link):
            Estimate Std. Error z value Pr(&amp;gt;|z|)   
(Intercept)  0.92733    0.32507   2.853  0.00433 **
x            0.06870    0.02755   2.494  0.01263 * 
Log(theta)   3.36066    3.59739   0.934  0.35020   

Zero-inflation model coefficients (binomial with logit link):
            Estimate Std. Error z value Pr(&amp;gt;|z|)
(Intercept)  -0.2250     0.4559  -0.494    0.622
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1 

Theta = 28.8082 
Number of iterations in BFGS optimization: 17 
Log-likelihood: -38.54 on 4 Df
&amp;gt; 
&amp;gt; plot(resid(zeroinfl(y ~ x | 1, dist = &amp;quot;negbin&amp;quot;, data = dat.zinb))~fitted(zeroinfl(y ~ x | 1, dist = &amp;quot;negbin&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/generate_data_zinb-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; vuong(dat.glm.nb, dat.zeroinfl)
Vuong Non-Nested Hypothesis Test-Statistic: 
(test-statistic is asymptotically distributed N(0,1) under the
 null that the models are indistinguishible)
-------------------------------------------------------------
              Vuong z-statistic             H_A p-value
Raw                  -1.2809521 model2 &amp;gt; model1 0.10011
AIC-corrected        -0.9296587 model2 &amp;gt; model1 0.17627
BIC-corrected        -0.7547616 model2 &amp;gt; model1 0.22520
&amp;gt; 
&amp;gt; library(gamlss)
&amp;gt; summary(gamlss(y~x, data=dat.zinb, family=&amp;#39;ZINBI&amp;#39;))
GAMLSS-RS iteration 1: Global Deviance = 81.436 
GAMLSS-RS iteration 2: Global Deviance = 78.1917 
GAMLSS-RS iteration 3: Global Deviance = 77.0798 
GAMLSS-RS iteration 4: Global Deviance = 77.0726 
GAMLSS-RS iteration 5: Global Deviance = 77.0725 
******************************************************************
Family:  c(&amp;quot;ZINBI&amp;quot;, &amp;quot;Zero inflated negative binomial type I&amp;quot;) 

Call:  gamlss(formula = y ~ x, family = &amp;quot;ZINBI&amp;quot;, data = dat.zinb) 

Fitting method: RS() 

------------------------------------------------------------------
Mu link function:  log
Mu Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)  
(Intercept)  0.92653    0.32502   2.851   0.0116 *
x            0.06880    0.02753   2.499   0.0237 *
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

------------------------------------------------------------------
Sigma link function:  log
Sigma Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)
(Intercept)   -3.363      3.603  -0.933    0.365

------------------------------------------------------------------
Nu link function:  logit 
Nu Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)
(Intercept)  -0.2250     0.4559  -0.494    0.628

------------------------------------------------------------------
No. of observations in the fit:  20 
Degrees of Freedom for the fit:  4
      Residual Deg. of Freedom:  16 
                      at cycle:  5 
 
Global Deviance:     77.0725 
            AIC:     85.0725 
            SBC:     89.05543 
******************************************************************
&amp;gt; 
&amp;gt; summary(gamlss(y~x, nu.fo=y~x,data=dat.zinb, family=&amp;#39;ZINBI&amp;#39;))
GAMLSS-RS iteration 1: Global Deviance = 78.2478 
GAMLSS-RS iteration 2: Global Deviance = 74.2622 
GAMLSS-RS iteration 3: Global Deviance = 73.8329 
GAMLSS-RS iteration 4: Global Deviance = 73.8305 
GAMLSS-RS iteration 5: Global Deviance = 73.8305 
******************************************************************
Family:  c(&amp;quot;ZINBI&amp;quot;, &amp;quot;Zero inflated negative binomial type I&amp;quot;) 

Call:  gamlss(formula = y ~ x, nu.formula = y ~ x, family = &amp;quot;ZINBI&amp;quot;,  
    data = dat.zinb) 

Fitting method: RS() 

------------------------------------------------------------------
Mu link function:  log
Mu Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)  
(Intercept)  0.84246    0.35267   2.389   0.0305 *
x            0.07481    0.02933   2.550   0.0222 *
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

------------------------------------------------------------------
Sigma link function:  log
Sigma Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)
(Intercept)   -2.982      2.844  -1.048    0.311

------------------------------------------------------------------
Nu link function:  logit 
Nu Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)
(Intercept)  -2.4988     1.8283  -1.367    0.192
x             0.1996     0.1417   1.408    0.179

------------------------------------------------------------------
No. of observations in the fit:  20 
Degrees of Freedom for the fit:  5
      Residual Deg. of Freedom:  15 
                      at cycle:  5 
 
Global Deviance:     73.83046 
            AIC:     83.83046 
            SBC:     88.80912 
******************************************************************&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;Check the distribution of the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; abundances.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(dat.zinb$y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data1_zinb-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; boxplot(dat.zinb$y, horizontal=TRUE)
&amp;gt; rug(jitter(dat.zinb$y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data1_zinb-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is definitely signs of non-normality that would warrant Poisson or negative binomial models. Further to that, there appears to be a large number of zeros and a possible clumpiness that are likely to be the cause of overdispersion A zero-inflated negative binomial model is likely to be one of the most effective for modeling these data. Lets now explore linearity by creating a histogram of the predictor variable (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). Note, it is difficult to directly assess issues of linearity. Indeed, a scatterplot with lowess smoother will be largely influenced by the presence of zeros. One possible way of doing so is to explore the trend in the non-zero data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(dat.zinb$x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data2_zinb-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #now for the scatterplot
&amp;gt; plot(y~x, dat.zinb, log=&amp;quot;y&amp;quot;)
&amp;gt; with(subset(dat.zinb,y&amp;gt;0), lines(lowess(y~x)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/expl_data2_zinb-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) does not display any skewness or other issues that might lead to non-linearity. The lowess smoother on the non-zero data cloud does not display major deviations from a straight line and thus linearity is likely to be satisfied. Violations of linearity (whilst difficult to be certain about due to the unknown influence of the zeros) could be addressed by either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;define a non-linear linear predictor (such as a polynomial, spline or other non-linear function).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;transform the scale of the predictor variables.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although we have already established that there are few zeros in the data (and thus overdispersion is unlikely to be an issue), we can also explore this by comparing the number of zeros in the data to the number of zeros that would be expected from a Poisson distribution with a mean equal to the mean count of the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #proportion of 0&amp;#39;s in the data
&amp;gt; dat.zinb.tab&amp;lt;-table(dat.zinb$y==0)
&amp;gt; dat.zinb.tab/sum(dat.zinb.tab)

FALSE  TRUE 
 0.55  0.45 
&amp;gt; 
&amp;gt; #proportion of 0&amp;#39;s expected from a Poisson distribution
&amp;gt; mu &amp;lt;- mean(dat.zinb$y)
&amp;gt; v &amp;lt;- var(dat.zinb$y)
&amp;gt; size &amp;lt;- mu + (mu^2)/v
&amp;gt; cnts &amp;lt;- rnbinom(1000, mu=mu, size=size)
&amp;gt; dat.zinb.tabE &amp;lt;- table(cnts == 0)
&amp;gt; dat.zinb.tabE/sum(dat.zinb.tabE)

FALSE  TRUE 
0.861 0.139 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above, the value under &lt;code&gt;FALSE&lt;/code&gt; is the proportion of non-zero values in the data and the value under TRUE is the proportion of zeros in the data. In this example, the proportion of zeros observed (&lt;span class=&#34;math inline&#34;&gt;\(45\)&lt;/span&gt;%) far exceeds that that would have been expected (&lt;span class=&#34;math inline&#34;&gt;\(14\)&lt;/span&gt;%). Hence it is highly likely that any models will be zero-inflated.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{ZINB}(\lambda_i, \theta),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\text{logit}(\theta) = \gamma_0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\log(\lambda_i)=\eta_i\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\eta_i=\beta_0+\beta_1x_{i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_0,\beta_1,\gamma_0 \sim N(0, 10000)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dat.zinb.list &amp;lt;- with(dat.zinb,list(Y=y, X=x,N=nrow(dat.zinb),z=ifelse(y==0,0,1)))
&amp;gt; modelString=&amp;quot;
+ model {
+   for (i in 1:N) {
+      z[i] ~ dbern(psi.min)
+      Y[i] ~ dnegbin(p[i],size)
+      p[i] &amp;lt;- size/(size+mu.eff[i])
+      mu.eff[i] &amp;lt;- z[i]*mu[i]
+      eta[i] &amp;lt;- beta0 + beta1*X[i]
+      log(mu[i]) &amp;lt;- eta[i]
+   }
+   gamma ~ dnorm(0,0.001)
+   psi.min &amp;lt;- min(0.9999, max(0.00001, (1-psi)))
+   logit(psi) &amp;lt;- max(-20, min(20, gamma))
+   size ~ dunif(0.001, 5)
+   theta &amp;lt;- pow(1/mean(p),2)
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+ } 
+ &amp;quot;
&amp;gt; writeLines(modelString, con=&amp;#39;modelzinb.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;, &amp;#39;size&amp;#39;, &amp;#39;theta&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.zinb.jags &amp;lt;- jags(data=dat.zinb.list,model.file=&amp;#39;modelzinb.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 40
   Unobserved stochastic nodes: 4
   Total graph size: 205

Initializing model
&amp;gt; 
&amp;gt; print(dat.zinb.jags)
Inference for Bugs model at &amp;quot;modelzinb.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
beta0      0.971   0.460  0.055  0.678  0.963  1.273  1.868 1.007   250
beta1      0.067   0.042 -0.016  0.039  0.066  0.094  0.151 1.008   200
size       3.501   1.015  1.389  2.763  3.644  4.351  4.935 1.001 10000
theta      2.200   0.367  1.721  1.937  2.115  2.371  3.145 1.001  3300
deviance  82.769   2.843 79.139 80.663 82.139 84.254 89.891 1.001 10000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.0 and DIC = 86.8
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model evaluation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(dat.zinb.jags, parms = c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;, &amp;#39;size&amp;#39;, &amp;#39;theta&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/mcmc_diag_zinb-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(dat.zinb.jags, parms = c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;, &amp;#39;size&amp;#39;, &amp;#39;theta&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/mcmc_diag_zinb-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; raftery.diag(as.mcmc(dat.zinb.jags))
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    15       16236 3746         4.33      
 beta1    14       15725 3746         4.20      
 deviance 3        4484  3746         1.20      
 size     5        5771  3746         1.54      
 theta    3        4338  3746         1.16      


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    27       27564 3746         7.36      
 beta1    18       21057 3746         5.62      
 deviance 3        4410  3746         1.18      
 size     5        5771  3746         1.54      
 theta    2        3995  3746         1.07      
&amp;gt; 
&amp;gt; autocorr.diag(as.mcmc(dat.zinb.jags))
             beta0       beta1    deviance        size       theta
Lag 0   1.00000000  1.00000000  1.00000000 1.000000000 1.000000000
Lag 1   0.82187294  0.82300377  0.55172222 0.391115803 0.387289605
Lag 5   0.44679310  0.44494849  0.13559995 0.045297725 0.067379632
Lag 10  0.19928140  0.20123773  0.05371302 0.008341721 0.013304093
Lag 50 -0.04037202 -0.04473554 -0.02496182 0.011474420 0.007333003&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;goodness-of-fit-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goodness of fit&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #extract the samples for the two model parameters
&amp;gt; coefs &amp;lt;- dat.zinb.jags$BUGSoutput$sims.matrix[,1:2]
&amp;gt; theta &amp;lt;- dat.zinb.jags$BUGSoutput$sims.matrix[,&amp;#39;theta&amp;#39;]
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data=dat.zinb)
&amp;gt; #expected values on a log scale
&amp;gt; lambda&amp;lt;-coefs %*% t(Xmat)
&amp;gt; #expected value on response scale
&amp;gt; eta &amp;lt;- exp(lambda)
&amp;gt; expY &amp;lt;- sweep(eta,1,(1-theta),&amp;quot;*&amp;quot;)
&amp;gt; varY &amp;lt;- eta+sweep(eta^2,1,theta,&amp;quot;*&amp;quot;)
&amp;gt; head(varY)
             1         2        3        4        5        6        7        8
[1,] 10.844323 13.189501 15.47499 15.73287 18.21519 26.87133 28.14742 29.27065
[2,] 71.832694 61.952112 54.97632 54.30484 48.72535 36.70113 35.49495 34.51074
[3,] 24.764991 24.273552 23.88302 23.84316 23.49392 22.60135 22.49799 22.41131
[4,]  6.397443  8.786249 11.40150 11.71375 14.89149 28.26188 30.51610 32.55772
[5,] 27.048585 28.561484 29.85015 29.98628 31.21706 34.70423 35.14294 35.51685
[6,] 32.911549 36.163316 39.03708 39.34619 42.18864 50.70280 51.82155 52.78337
            9       10       11       12        13        14        15
[1,] 32.48606 39.45733 45.43874 50.02645  59.31437  71.66019  73.00520
[2,] 32.02933 27.89750 25.25717 23.61192  20.97369  18.40930  18.17586
[3,] 22.18262 21.76433 21.46712 21.26761  20.92017  20.54281  20.50616
[4,] 38.69312 53.42044 67.53693 79.24793 105.19992 144.10581 148.63604
[5,] 36.53055 38.49254 39.97741 41.01961  42.92731  45.14296  45.36660
[6,] 55.42928 60.70818 64.84042 67.81058  73.39529  80.11924  80.81199
            16        17        18        19        20
[1,]  89.37583  90.29710  93.03697  99.45044 121.73297
[2,]  15.83105  15.72115  15.40547  14.72560  12.85289
[3,]  20.11263  20.09293  20.03565  19.90863  19.52937
[4,] 208.15726 211.74132 222.54395 248.66128 348.12988
[5,]  47.86864  47.99890  48.38049  49.24196  51.94528
[6,]  88.73695  89.15824  90.39740  93.22189 102.32692
&amp;gt; 
&amp;gt; #varY &amp;lt;- sweep(varY,1,(1-theta),&amp;#39;*&amp;#39;)
&amp;gt; #sweep across rows and then divide by lambda
&amp;gt; Resid &amp;lt;- -1*sweep(expY,2,dat.zinb$y,&amp;#39;-&amp;#39;)/sqrt(varY)
&amp;gt; #plot residuals vs expected values
&amp;gt; plot(apply(Resid,2,mean)~apply(eta,2,mean))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm2-jags/2020-02-01-glm2-jags_files/figure-html/model2_mcmc_gof_zinb-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we will compare the sum of squared residuals to the sum of squares residuals that would be expected from a Poisson distribution matching that estimated by the model. Essentially this is estimating how well the Poisson distribution, the log-link function and the linear model approximates the observed data. When doing so, we need to consider the expected value and variance of the zero-inflated poisson.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; SSres&amp;lt;-apply(Resid^2,1,sum, na.rm=T)
&amp;gt; 
&amp;gt; #generate a matrix of draws from a zero-inflated poisson (ZINB) distribution
&amp;gt; # the matrix is the same dimensions as lambda
&amp;gt; library(gamlss.dist)
&amp;gt; #YNew &amp;lt;- matrix(rZINB(length(lambda),eta, theta),nrow=nrow(lambda))
&amp;gt; lambda &amp;lt;- sweep(eta,1,ifelse(dat.zinb$y==0,0,1),&amp;#39;*&amp;#39;)
&amp;gt; YNew &amp;lt;- matrix(rpois(length(lambda),lambda),nrow=nrow(lambda))
&amp;gt; Resid1&amp;lt;-(expY - YNew)/sqrt(varY)
&amp;gt; SSres.sim&amp;lt;-apply(Resid1^2,1,sum)
&amp;gt; mean(SSres.sim&amp;gt;SSres, na.rm = T)
[1] 0.5212&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-the-model-parameters-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring the model parameters&lt;/h2&gt;
&lt;p&gt;If there was any evidence that the assumptions had been violated or the model was not an appropriate fit, then we would need to reconsider the model and start the process again. In this case, there is no evidence that the test will be unreliable so we can proceed to explore the test statistics. As with most Bayesian models, it is best to base conclusions on medians rather than means.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(dat.zinb.jags)
Inference for Bugs model at &amp;quot;modelzinb.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
beta0      0.971   0.460  0.055  0.678  0.963  1.273  1.868 1.007   250
beta1      0.067   0.042 -0.016  0.039  0.066  0.094  0.151 1.008   200
size       3.501   1.015  1.389  2.763  3.644  4.351  4.935 1.001 10000
theta      2.200   0.367  1.721  1.937  2.115  2.371  3.145 1.001  3300
deviance  82.769   2.843 79.139 80.663 82.139 84.254 89.891 1.001 10000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.0 and DIC = 86.8
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; adply(dat.zinb.jags$BUGSoutput$sims.matrix, 2, function(x) {
+   data.frame(Median=median(x), Mean=mean(x), HPDinterval(as.mcmc(x)), HPDinterval(as.mcmc(x),p=0.5))
+ })
        X1      Median        Mean       lower      upper     lower.1
1    beta0  0.96339931  0.97060322  0.05196655  1.8646388  0.68771701
2    beta1  0.06565837  0.06658472 -0.01850221  0.1478933  0.03570031
3 deviance 82.13938661 82.76912313 78.75619568 88.5891138 79.69050804
4     size  3.64385931  3.50054311  1.63847682  4.9995959  3.62583688
5    theta  2.11463918  2.19954948  1.65289052  2.9565781  1.83698278
      upper.1
1  1.28169341
2  0.09027889
3 82.76458253
4  4.98121591
5  2.20696839
&amp;gt; 
&amp;gt; #on original scale
&amp;gt; adply(exp(dat.zinb.jags$BUGSoutput$sims.matrix[,1:2]), 2, function(x) {
+   data.frame(Median=median(x), Mean=mean(x), HPDinterval(as.mcmc(x)), HPDinterval(as.mcmc(x),p=0.5))
+ })
     X1   Median     Mean     lower    upper  lower.1  upper.1
1 beta0 2.620590 2.935935 0.7910564 5.701997 1.628127 3.096623
2 beta1 1.067862 1.069796 0.9816679 1.159389 1.036345 1.094479&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: We would reject the null hypothesis of no effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. An increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is associated with a significant linear increase (positive slope) in the abundance of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. Every &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; results in a log &lt;span class=&#34;math inline&#34;&gt;\(0.06\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. We usually express this in terms of abundance rather than log abundance, so every &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; results in a (&lt;span class=&#34;math inline&#34;&gt;\(e^{0.06}=1.07\)&lt;/span&gt;) &lt;span class=&#34;math inline&#34;&gt;\(1.07\)&lt;/span&gt; unit increase in the abundance of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Generalised Linear Models - JAGS</title>
      <link>/jags/glm-jags/glm-jags/</link>
      <pubDate>Thu, 13 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/glm-jags/glm-jags/</guid>
      <description>


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Before discussing generalised linear models, we will first revise a couple of fundamental aspects of general linear models and in particular, how they restrict the usefulness of these models in clinical applications. General linear models provide a set of well adopted and recognised procedures for relating response variables to a linear combination of one or more continuous or categorical predictors (hence the “general”). Nevertheless, the reliability and applicability of such models are restricted by the degree to which the residuals conform to normality and the mean and variance are independent of one another. The general linear model essentially comprises three components.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ E[Y] = \beta_0 + \beta_1x_1 + \ldots + \beta_px_p + \epsilon.\]&lt;/span&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The Random (Stochastic) component&lt;/strong&gt; that specifies the conditional distribution (Normal or Gaussian distribution) of the response variable. Whilst the mean of the normal distribution is assumed to vary as a function of the linear predictors (Systematic component - the regression equation), the variance is assumed to remain constant. Denoted &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; in the above equation, the random component is more formally defined as &lt;span class=&#34;math inline&#34;&gt;\(Y_i \sim N(0, \sigma^2)\)&lt;/span&gt;. That is, each value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; (the response) is assumed to be drawn from a normal distribution with different means (&lt;span class=&#34;math inline&#34;&gt;\(\mu_i\)&lt;/span&gt;) yet fixed variance (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The Systematic component&lt;/strong&gt; that represents the linear combination of predictors (which can be categorical, continuous, polynomial or other contrasts) for a linear predictor. The linear predictor describes (predict) the “expected” mean and variability of the response(s) (which are assumed to follow normal distribution(s)).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The Link function&lt;/strong&gt; which links the expected values of the response (Random component) to the linear combination of predictors (systematic component). For the normal (Gaussian) distribution, the link function is a the “identity” link (&lt;span class=&#34;math inline&#34;&gt;\(\mu_i\)&lt;/span&gt;). That is:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \mu_i = \beta_0 + \beta_1x_{i1} + \ldots + \beta_px_{ip}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;There are many real situations for which the assumptions imposed by the normal distribution are unlikely to be satisfied. For example, if the measured response to a predictor treatment (such as nest parasite load) can only be binary (such as abandoned or not), then the differences between the observed and expected values (residuals) are unlikely to follow a normal distribution. Instead, in this case, they should follow a binomial distribution.&lt;/p&gt;
&lt;p&gt;Often response variables have a restricted range. For example a species may be either present or not present and thus the response is restricted to either &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (present) or absent (&lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;). Values less than &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; or greater than &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; are not logical. Similarly, the abundance of a species in a quadrat is bounded by a minimum value of zero - it is not possible to have fewer than zero individuals. Proportional abundances are also restricted to between &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (or &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;). The normal distribution however, is valid for the range between positive and negative infinity (ie not restricted) and thus expected values of the linear predictor can be outside of the restricted range that naturally operates on the response variable. Hence, the normal distribution might not always represent a sensible probability model as it can predict values outside the logical range of the data. Furthermore, the as a result of these range restrictions, variance can be tied to the mean in that expected probabilities towards the extremes of the restricted range tend to have lower variability (as the lower or upper bounds of the probabilities are trunctated).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-types&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data types&lt;/h2&gt;
&lt;p&gt;Response data can generally be classified into one of four levels&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Nominal&lt;/strong&gt; - responses are those that represent un-ordered categories For example, we could record the ‘preferred’ food choice of an animal as either “Fruit”, “Meat”, “Seeds” or “Leaves”. The spacing between categories is undetermined and responses are restricted to those options.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ordinal&lt;/strong&gt; - responses are those that represent categories with sensible orders, yet undetermined spacing between categories. Likert scale questionnaire responses to questions such as “Rate the quality of your experience… on a scale of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;” are a classic example. Categorized levels of a response (“High”, “Medium”,“Low”) would also be another example of an ordinal variable&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Interval&lt;/strong&gt; - responses are those for which both the order and scale (spacing) are meaningful, yet multiplication is meaningless due to the arbitrary scale of the data (where zero does not refer to nothing). Temperature in degrees C is a good example of such a response (consider whether &lt;span class=&#34;math inline&#34;&gt;\(-28\)&lt;/span&gt; degrees &lt;span class=&#34;math inline&#34;&gt;\(^\star-1 = 28\)&lt;/span&gt; degrees has a sensible interpretation).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ratio&lt;/strong&gt; - responses are those for which order, scale and zero are meaningful. For example a measurement scale such as length in millimeters or mass in grams.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;glms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;GLMs&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Generalized linear models&lt;/strong&gt; (GLM’s) extend the application range of linear modelling by accommodating non-stable variances as well as alternative exponential residual distributions (such as the binomial and Poisson distributions). GLMs have the same three components as general linear models (of which the systematic component is identical), yet a broader range of Random components are accommodated and thus alternative Link functions must also be possible.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Random component defines the exponential distribution (Gaussian, Poisson, binomial, gamma, and inverse Gaussian distributions) from which the responses are assumed to be drawn. These distributions are characterised by some function of the mean (canonical or location parameter) and a function of the variance (dispersion parameter). Note that for binomial and Poisson distributions, the dispersion parameter is &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;, whereas for the Guassian (normal) distribution the dispersion parameter is the error variance and is assumed to be independent of the mean. The negative binomial distribution can also be treated as an exponential distribution if the dispersion parameter is fixed as a constant.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Systematic component again defines the linear combination of predictors&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Link function, &lt;span class=&#34;math inline&#34;&gt;\(g(\mu)\)&lt;/span&gt; links the systematic and random components. Although there are many commonly employed link functions, typically the exact form of the link function depends on the nature of the random response distribution. Some of the canonical (natural choice) link functions and distribution pairings that are suitable for different forms of generalized linear models are listed in the following table. The only real restriction on a link function is that it must preserve the order of values such that larger values are always larger than smaller values (be monotonic) and must yield derivatives that are legal throughout the entire range of the data.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;link-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Link functions&lt;/h2&gt;
&lt;p&gt;In contrast to fitting linear models to transformations of the raw data, the link functions transform the curve predicted by the systematic component into a scale approximating that of the response.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Logit&lt;/strong&gt;. Log odds-ratio The slope parameter represents the rate of change in log odds-ratio per unit increase in a predictor.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Probit&lt;/strong&gt;. The probit transformation is the inverse cumulative distribution for the standard normal distribution and is useful when the response is likely to be a categorization of an otherwise continuous scale. So whilst measurements might be recorded on a categorical scale (either for convenience or because that is how they manifest), these measurements are a proxy for an underlying variable (latent variable) that is actually continuous. So if the purpose of the linear modeling is to predict the underlying latent variable, then probit regression is likely to be appropriate. The slope parameter represents the rate of change in response probability per unit increase in a predictor.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Complementary log-log&lt;/strong&gt;. The log-log transformation is useful for extremely asymmetrical distributions (notably survival analyses).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;estimation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Estimation&lt;/h2&gt;
&lt;p&gt;The generalized nature of GLM’s makes them incompatible with ordinary least squares model fitting procedures. Instead, parameter estimates and model fitting are typically achieved by maximum likelihood methods based on an iterative re-weighting algorithm (such as the Newton-Raphson algorithm). Essentially, the Newton-Raphson algorithm (also known as a scoring algorithm) fits a linear model to an adjusted response variable (transformed via the link function) using a set of weights and then iteratively re-fits the model with new sets of weights recalculated according to the fit of the previous iteration. For canonical link-distribution pairs (see the table above), the Newton-Raphson algorithm usually converges (arrives at a common outcome or equilibrium) very efficiently and reliably. The Newton-Raphson algorithm facilitates a unifying model fitting procedure across the family of exponential probability distributions thereby providing a means by which binary and count data can be incorporated into the suit of regular linear model designs. In fact, linear regression (including ANOVA, ANCOVA and other general linear models) can be considered a special form of GLM that features a normal distribution and identity link function and for which the maximum likelihood procedure has an exact solution. Notably, when variance is stable, both maximum likelihood and ordinary least squares yield very similar parameter estimates.&lt;/p&gt;
&lt;p&gt;Typical distributions used for GLMs include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Gaussian&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Binomial&lt;/strong&gt;. Represents the number of successes out of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; independent trials each with a set probability (typically &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Poisson&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Negative Binomial&lt;/strong&gt;. Represents the number of failures out of a sequence of n independent trials before a success is obtained each with a set probability. Alternatively, a negative binomial can be defined in terms of its mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and dispersion parameter. The dispersion parameter can be used to adjust the variances independent of the mean and is therefore useful as an alternative to the Poisson distribution when there is evidence of overdispersion (dispersion parameter &lt;span class=&#34;math inline&#34;&gt;\(&amp;gt;1\)&lt;/span&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;dispersion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dispersion&lt;/h2&gt;
&lt;p&gt;The variance of binomial or Poisson distributions is assumed to be related to the sample size and mean respectively, and thus, there is not a variance parameter in their definitions. In fact, the variance (or dispersion) parameter is fixed to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;. As a result, logistic/probit regression as well as Poisson regression and log-linear modelling assume that sample variances conform to the respective distribution definitions. However, it is common for individual sampling units (e.g. individuals) to co-vary such that other, unmeasured influences, increase (or less commonly, decrease) variability. For example, although a population sex ratio might be 1:1, male to female ratios within a clutch might be highly skewed towards one or other sex. Positive correlations cause greater variance (overdispersion) and result in deflated standard errors (and thus exaggerated levels of precision and higher Type I errors). Additionally, count data (for example number of fish per transect) can be overdispersed as a result of an unexpectedly high number of zero’s (zero inflated). In this case, the zeros arise for two reasons.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Genuine zero values - zero fish counted because there were non present.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;False zeros - there were fish present, yet not detected (and thus not recorded).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The dispersion parameter (degree of variance inflation or over-dispersion) can be estimated by dividing either the Pearsons &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; or the Deviance by the degrees of freedom, where &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the number of observations in p parameters). As a general rule, dispersion parameters approaching &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; (or &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt;) indicate possible violations of this assumption (although large overdispersion parameters can also be the result of a poorly specified model or outliers). Where over (or under) dispersion is suspected to be an issue, the following options are available:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;use &lt;strong&gt;quasibinomial&lt;/strong&gt; and &lt;strong&gt;quasipoisson&lt;/strong&gt; families can be used as alternatives to model the dispersion. These quasi-likelihood models derive the dispersion parameter (function of the variance) from the observed data and are useful when overdispersion is suspected to be caused by positive correlations or other unobserved sources of variance. Rather than assuming that the variance is fixed, quasi- models assume that variance is a linear (multiplicative) function of the mean. Test statistics from such models should be based on F-tests rather than chi-squared tests.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;for count data, use a &lt;strong&gt;negative binomial&lt;/strong&gt; as an alternative to a Poisson distribution. The negative binomial distribution also estimates the dispersion parameter and assumes that the variance is a quadratic function of the mean.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;use &lt;strong&gt;zero-inflated binomial&lt;/strong&gt; (ZIB) and &lt;strong&gt;zero-inflated poisson&lt;/strong&gt; (ZIP) when overdispersion is suspected to be caused by excessive numbers of zeros.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;binary-data---logistic-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Binary data - logistic regression&lt;/h2&gt;
&lt;p&gt;Logistic regression is a form of GLM that employs the logit-binomial link distribution canonical pairing to model the effects of one or more continuous or categorical (with dummy coding) predictor variables on a binary (dead/alive, presence/absence, etc) response variable. For example, we could investigate the relationship between salinity levels (salt concentration) and mortality of frogs. Similarly, we could model the presence of a species of bird as a function of habitat patch size, or nest predation (predated or not) as a function of the distance from vegetative cover. Consider the fictitious data presented in the following figure. Clearly, a regular simple linear model is inappropriate for modelling the probability of presence. Note that at very low and high levels of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, the predicted probabilities (probabilities or proportions of the population) are less than zero and greater than one respectively - logically impossible outcomes. Note also, that the residuals cannot be drawn from a normal distribution, since for any value of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, there are only two possible outcomes (&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;The logistic model (Figure c above) relating the probability (&lt;span class=&#34;math inline&#34;&gt;\(\pi(x)\)&lt;/span&gt;) that the response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) equals one (present) for a given level of &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; (patch size) is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \pi(x) = \frac{e^{\beta_0 + \beta_1x}}{1+e^{\beta_0+\beta_1x}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Appropriately, since &lt;span class=&#34;math inline&#34;&gt;\(e^{\beta_0+\beta_1x}\)&lt;/span&gt; (the “natural constant” raised to a simple linear model) must evaluate to between 0 and infinity, the logistic model must asymptote towards (and is thus bounded by) zero and one. Alternatively (as described briefly above), the logit link function can be used to transform &lt;span class=&#34;math inline&#34;&gt;\(\pi(x)\)&lt;/span&gt; such that the logistic model is expressed as the log odds (probability of one state relative to the alternative) against a familiar linear combination of the explanatory variables (as is linear regression).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ ln \left(  \frac{\pi(x)}{1-\pi(x)} \right) = \beta_0 + \beta_1x_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Although the &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept) parameter is interpreted similar to that of linear regression (albeit of little clinical interest), this is not the case for the slope parameter (&lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;). Rather than representing the rate of change in the response for a given change in the predictor, in logistic regression, &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; represents the rate of change in the odds ratio (ratio of odds of an event at two different levels of a predictor) for a given unit change in the predictor. The exponentiated slope represents the odds ratio (&lt;span class=&#34;math inline&#34;&gt;\(\theta=e^{\beta_1}\)&lt;/span&gt;), the proportional rate at which the predicted odds change for a given unit change of the predictor.&lt;/p&gt;
&lt;div id=&#34;null-hypotheses&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Null hypotheses&lt;/h3&gt;
&lt;p&gt;As with linear regression, a separate &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; is tested for each of the estimated model parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0:\beta_1=0\)&lt;/span&gt; (the population slope - proportional rate of change in odds ratio). This test examines whether the log odds of an occurrence are independent of the predictor variable and thus whether or not there is likely to be a relationship between the response and predictor.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0:\beta_0=0\)&lt;/span&gt; (the population intercept equals zero). As stated previously, this is typically of little clinical interest.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Similar to linear regression, there are two ways of testing the main null hypotheses:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Parameter estimation approach. Maximum likelihood estimates of the parameters and their asymptoticd standard errors (&lt;span class=&#34;math inline&#34;&gt;\(S_{b1}\)&lt;/span&gt;) are used to calculate the Wald &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; (or &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-ratio) statistic &lt;span class=&#34;math inline&#34;&gt;\(W=\frac{b_1}{S_{b1}}\)&lt;/span&gt;, which approximately follows a standard &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; distribution when the null hypothesis is true. The reliability of Wald tests diminishes substantially with small sample sizes. For such cases, the second option is therefore more appropriate.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;(log)-likelihood ratio tests approach. This approach essentially involves comparing the fit of models with (full) and without (reduced) the term of interest:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \text{logit}(\pi) = \beta_0 + \beta_1x_1 \;\;\; (\text{full model})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \text{logit}(\pi) = \beta_0 \;\;\; (\text{reduced model})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The fit of any given model is measured via log-likelihood and the differences between the fit of two models is described by a likelihood ratio statistic (G2 &lt;span class=&#34;math inline&#34;&gt;\(= 2\)&lt;/span&gt;(log-likelihood reduced model - log-likelihood full model)). The G2 quantity is also known as deviance and is analogous to the residual sums of squares in a linear model. When the null hypothesis is true, the G2 statistic approximately follows a &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution with one degree of freedom. An analogue of the linear model &lt;span class=&#34;math inline&#34;&gt;\(r^2\)&lt;/span&gt; measure can be calculated as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ r^2 = 1- \frac{G^2_0}{G^2_1},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(G^2_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(G^2_1\)&lt;/span&gt; are the deviances due to the intercept and slope terms respectively. Analogous to the ANOVA table that partitions the total variation into components explained by each of the model terms (and the unexplained error), it is possible to construct a analysis of deviance table that partitions the deviance into components explained by each of the model terms.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;count-data---poisson-and-log-linear-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Count data - Poisson and log-linear models&lt;/h2&gt;
&lt;p&gt;Another form of data for which scale transformations are often unsuitable or unsuccessful are count data. Count data tend to follow a Poisson distribution (see here) and consequently, the mean and variance are usually related. Generalized linear models provide appropriate means to model count data according to two design contexts:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;as an alternative to linear regression for modeling count data against a linear combination of continuous and/or categorical predictor variables (&lt;strong&gt;Poisson regression&lt;/strong&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;as an alternative to contingency tables in which the associations between categorical variables are explored (&lt;strong&gt;log-linear modelling&lt;/strong&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Poisson regression&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Poisson regression model is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \log(\mu)=\beta_0 + \beta_1x_1+ \ldots + \beta_px_p,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\log(\mu)\)&lt;/span&gt; is the link function used to link the mean of the Poisson response variable to the linear combination of predictor variables. Poisson regression otherwise shares null hypotheses, parameter estimation, model fitting and selection with logistic regression.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Log-linear modelling&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Contingency tables were introduced along with caveats regarding the reliability and interoperability of such analyses (particularly when expected proportions are small or for multi-way tables). In contrast to logistic and Poisson regression, all variables in a log-linear model do not empirically distinguish between response and predictor variables. Nevertheless, as in contingency tables, causality can be implied when logical and justified by interpretation. The saturated (or full) log-linear model resembles a multiway ANOVA model. The full and reduced log-linear models for a two factor design are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \log(f_{ij}) = \mu + \gamma^A_i + \gamma^B_j + \gamma^{AB}_{ij} \;\;\; (\text{full model}),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \log(f_{ij}) = \mu + \gamma^A_i + \gamma^B_j \;\;\; (\text{reduced model})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\log(f_{ij}\)&lt;/span&gt; is the log link function, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the mean of the (log) of expected frequencies (&lt;span class=&#34;math inline&#34;&gt;\(f_{ij}\)&lt;/span&gt;) and &lt;span class=&#34;math inline&#34;&gt;\(\gamma^A_i\)&lt;/span&gt; is the effect of the ith category of the variable (A), &lt;span class=&#34;math inline&#34;&gt;\(\gamma^B_j\)&lt;/span&gt; is the effect of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th category of B and &lt;span class=&#34;math inline&#34;&gt;\(\gamma^{AB}_{ij}\)&lt;/span&gt; is the interactive effect of each category combination on the (log) expected frequencies. Reduced models differ from full models in the absence of all higher order interaction terms. Comparing the fit of full and reduced models therefore provides a means of assessing the effect of the interaction. Whilst two-way tables contain only a single interaction term (and thus a single full and reduced model), multiway tables have multiple interactions. For example, a three-way table has a three way interaction (ABC) as well as three two-way interactions (AB, AC, BC). Consequently, there are numerous full and reduced models, each appropriate for different interaction terms. The following table indicates the association between null hypothesis and fitted models.&lt;/p&gt;
&lt;div id=&#34;null-hypothese&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Null hypothese&lt;/h3&gt;
&lt;p&gt;Consistent with contingency table analysis, log-linear models test the null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;) that the categorical variables are independent of (not associated with) one another. Such null hypotheses are tested by comparing the fit (deviance, G2) of full and reduced models. The G2 is compared to a &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution with degrees of freedom equal to the difference in degrees of freedom of the full and reduced models. Thereafter, odds ratios are useful for interpreting any lack of independence. For multi-way tables, there are multiple full and reduced models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Complete dependence&lt;/strong&gt;: &lt;span class=&#34;math inline&#34;&gt;\(H_0: ABC = 0\)&lt;/span&gt;. No three way interaction. Either no association (conditional independence) between each pair of variables, or else the patterns of associations (conditional dependencies) are the same for each level of the third. If this null hypothesis is rejected (&lt;span class=&#34;math inline&#34;&gt;\(ABC \neq 0\)&lt;/span&gt;), the causes of lack of independence can be explored by examining the residuals or odds ratios. Alternatively, main effects tests (testing the effects of two-way interactions separately at each level of the third) can be performed. If the three-way interaction is not rejected (no three-way association), lower order interactions can be explored.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Conditional independence/dependence&lt;/strong&gt;: if the three-way interaction is not rejected (no three-way association), lower order interactions can be explored.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: AB=0\)&lt;/span&gt; - A and B conditionally independent (not associated) within each level of C.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: AC=0\)&lt;/span&gt; - A and C conditionally independent (not associated) within each level of B.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: BC=0\)&lt;/span&gt; - B and C conditionally independent (not associated) within each level of A.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Marginal independence&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: AB=0\)&lt;/span&gt; - no association between A and B pooling over C.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: AC=0\)&lt;/span&gt; - no association between A and C pooling over B.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: BC=0\)&lt;/span&gt; - no association between B and C pooling over A.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Complete independence&lt;/strong&gt;: If none of the two-way interactions are rejected (no two-way associations), complete independence (all two-way interactions equal zero) can be explored.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: AB=AC=BC=0\)&lt;/span&gt; - Each of the variables are completely independent of all the other variables.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Analysis of designs with more than three factors proceed similarly, starting with tests of higher order interactions and progressing to lower order interactions only in the absence of higher order interactions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;Compared to general linear models, the requirements of generalised linear models are less stringent. In particular, neither normality nor homoscedasticity are assumed. Nevertheless, to maximize the reliability of null hypotheses tests, the following assumptions do apply:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;all observations should be &lt;strong&gt;independent&lt;/strong&gt; to ensure that the samples provide an unbiased estimate of the intended population.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;it is important to establish that no observations are overly influential. Most linear model &lt;strong&gt;influence&lt;/strong&gt; (and outlier) diagnostics extend to generalized linear models and are taken from the final iteration of the weighted least squares algorithm. Useful diagnoses include:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Residuals&lt;/em&gt; - there are numerous forms of residuals that have been defined for generalized linear models, each essentially being a variant on the difference between observed and predicted (influence in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-space) theme. Note that the residuals from logistic regression are difficult to interpret.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Leverage&lt;/em&gt; - a measure of outlyingness and influence in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;-space.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Dfbeta&lt;/em&gt; - an analogue of Cook’s D statistic which provides a standardized measure of the overall influence of observations on the parameter estimates and model fit.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;although &lt;strong&gt;linearity&lt;/strong&gt; between the response and predictors is not assumed, the relationship between each of the predictors and the link function is assumed to be linear. This linearity can be examined via the following:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;goodness-of-fit&lt;/em&gt;. For log-linear models, &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; contingency tables can be performed, however due to the low reliability of such tests with small sample sizes, this is not an option for logistic regression with continuous predictor(s) (since each combination is typically unique and thus the expected values are always &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Hosmer-Lemeshow&lt;/em&gt; (&lt;span class=&#34;math inline&#34;&gt;\(\hat{C}\)&lt;/span&gt;). Data are aggregated into &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; groups or bins (either by cutting the data according to the predictor range or equal frequencies in each group) such that goodness-of-fit test is more reliable. Nevertheless, the Hosmer-Lemeshow statistic has low power and relies on the somewhat arbitrary bin sizes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;le Cessie-van Houwelingen-Copas omnibus test&lt;/em&gt;. This is a goodness-of-fit test for binary data based on the smoothing of residuals.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;component + residual&lt;/em&gt; (partial residual) plots. Non-linearity is diagnosed as a substantial deviation from a linear trend.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Non-linearity can be dealt with either by transformation (of the predictor variable(s), fitting polynomial terms or via splines/generalised additive modelling (GAM) depending on the degree and nature of the non-linearity.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(over or under) &lt;strong&gt;dispersion&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Logistic regression is a type of generalised linear model (GLM) that models a binary response against a linear predictor via a specific link function. The linear predictor is the typically a linear combination of effects parameters (e.g. &lt;span class=&#34;math inline&#34;&gt;\(\beta_0+\beta_1x_1\)&lt;/span&gt;). The role of the link function is to transform the expected values of the response &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; (which is on the scale of (&lt;span class=&#34;math inline&#34;&gt;\(0,1\)&lt;/span&gt;), as is the binomial distribution from which expectations are drawn) into the scale of the linear predictor (which is &lt;span class=&#34;math inline&#34;&gt;\(-\infty;\infty\)&lt;/span&gt;). GLM’s transform the expected values (via a link) whereas LM’s transform the observed data. Thus while GLM’s operate on the scale of the original data and yet also on a scale appropriate of the residuals, LM’s do neither. There are many ways (transformations) that can map values on the (&lt;span class=&#34;math inline&#34;&gt;\(0,1\)&lt;/span&gt;) scale into values on the (&lt;span class=&#34;math inline&#34;&gt;\(-\infty;\infty\)&lt;/span&gt;) scale, however, the three most common are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;logit: &lt;span class=&#34;math inline&#34;&gt;\(\log\left(\frac{\pi}{1-\pi}\right)\)&lt;/span&gt; - log odds ratio.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;probit: &lt;span class=&#34;math inline&#34;&gt;\(\phi^{-1}(\pi)\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\phi^{-1}\)&lt;/span&gt; is an inverse normal cumulative density function.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;complimentary log-log: &lt;span class=&#34;math inline&#34;&gt;\(\log(−\log(1−\pi))\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lets say we wanted to model the presence/absence of an item (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) against a continuous predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(865)
&amp;gt; #The number of samples
&amp;gt; n.x &amp;lt;- 20
&amp;gt; #Create x values that at uniformly distributed throughout the rate of 1 to 20
&amp;gt; x &amp;lt;- sort(runif(n = n.x, min = 1, max =20))
&amp;gt; #The slope is the rate of change in log odds ratio for each unit change in x
&amp;gt; # the smaller the slope, the slower the change (more variability in data too)
&amp;gt; slope=0.5
&amp;gt; #Inflection point is where the slope of the line is greatest
&amp;gt; #this is also the LD50 point
&amp;gt; inflect &amp;lt;- 10
&amp;gt; #Intercept (no interpretation)
&amp;gt; intercept &amp;lt;- -1*(slope*inflect)
&amp;gt; #The linear predictor
&amp;gt; linpred &amp;lt;- intercept+slope*x
&amp;gt; #Predicted y values
&amp;gt; y.pred &amp;lt;- exp(linpred)/(1+exp(linpred))
&amp;gt; #Add some noise and make binomial
&amp;gt; n.y &amp;lt;-rbinom(n=n.x,20,p=0.9)
&amp;gt; y&amp;lt;- rbinom(n = n.x,size=1, prob = y.pred)
&amp;gt; dat &amp;lt;- data.frame(y,x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the binary response variable and the linear predictor (linear combination of one or more continuous or categorical predictors).&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;So lets explore linearity by creating a histogram of the predictor variable (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) and a scatterplot of the relationship between the response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) and the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(dat$x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/expl_data1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #now for the scatterplot
&amp;gt; plot(y~x, dat)
&amp;gt; with(dat, lines(lowess(y~x)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/expl_data1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) does not display any skewness or other issues that might lead to non-linearity. The lowess smoother on the scatterplot does not display major deviations from a standard sigmoidal curve and thus linearity is satisfied. Violations of linearity could be addressed by either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;define a non-linear linear predictor (such as a polynomial, spline or other non-linear function).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;transform the scale of the predictor variables.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Effects model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Note that in order to prevent arithmetic overflows (particularly with the clog-log model, I am going to constrain the estimated linear predictor to between &lt;span class=&#34;math inline&#34;&gt;\(-20\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(20\)&lt;/span&gt;. Values outside of this on a inverse-log scale are extremely small and huge respectively.
I will demonstrate logistic regression with a range of possible link functions (each of which yield different parameter interpretations). Consider first the logit function:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y \sim \text{Bern}(\pi),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\text{logit}(\pi)=\beta_0+\beta_1x_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_0,\beta_1 \sim N(0, 10000)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString=&amp;quot;
+ model{
+   for (i in 1:N) {
+     y[i] ~ dbern(p[i])
+     logit(p[i]) &amp;lt;- max(-20,min(20,beta0+beta1*x[i]))
+   }
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+ }
+ &amp;quot;
&amp;gt; writeLines(modelString, con=&amp;#39;modellogit.txt&amp;#39;)
&amp;gt; 
&amp;gt; dat.list &amp;lt;- with(dat, list(y=y, x=x, N=nrow(dat)))
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; library(R2jags)
&amp;gt; dat.logit.jags &amp;lt;- jags(data=dat.list,model.file=&amp;#39;modellogit.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 2
   Total graph size: 147

Initializing model&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, we consider the probit function:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y \sim \text{Bern}(\pi),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\text{probit}(\pi)=\beta_0+\beta_1x_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_0,\beta_1 \sim N(0, 10000)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2=&amp;quot;
+ model{
+   for (i in 1:N) {
+     y[i] ~ dbern(p[i])
+     probit(p[i]) &amp;lt;- max(-20,min(20,beta0+beta1*x[i]))
+   }
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+ }
+ &amp;quot;
&amp;gt; writeLines(modelString2, con=&amp;#39;modelprobit.txt&amp;#39;)
&amp;gt; 
&amp;gt; dat.list &amp;lt;- with(dat, list(y=y, x=x, N=nrow(dat)))
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.probit.jags &amp;lt;- jags(data=dat.list,model.file=&amp;#39;modelprobit.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 2
   Total graph size: 147

Initializing model&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, the complementary log-log&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y \sim \text{Bern}(\pi),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\text{probit}(\pi)=\beta_0+\beta_1x_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_0,\beta_1 \sim N(0, 10000)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString3=&amp;quot;
+ model{
+   for (i in 1:N) {
+     y[i] ~ dbern(p[i])
+     cloglog(p[i]) &amp;lt;- max(-20,min(20,beta0+beta1*x[i]))
+   }
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+ }
+ &amp;quot;
&amp;gt; writeLines(modelString3, con=&amp;#39;modelcloglog.txt&amp;#39;)
&amp;gt; 
&amp;gt; dat.list &amp;lt;- with(dat, list(y=y, x=x, N=nrow(dat)))
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.cloglog.jags &amp;lt;- jags(data=dat.list,model.file=&amp;#39;modelcloglog.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 2
   Total graph size: 147

Initializing model&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Prior to exploring the model parameters, it is prudent to confirm that the model did indeed fit the assumptions and was an appropriate fit to the data as well as that the MCMC sampling chain was adequately mixed and the retained samples independent. Whilst I will only demonstrate this for the logit model, the procedure would be identical for exploring the probit and clog-log models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model evaluation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(dat.logit.jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(dat.logit.jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; raftery.diag(as.mcmc(dat.logit.jags))
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    50       54338 3746         14.50     
 beta1    36       39555 3746         10.60     
 deviance 4        4955  3746          1.32     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    30       31743 3746          8.47     
 beta1    40       52860 3746         14.10     
 deviance 8        10336 3746          2.76     
&amp;gt; 
&amp;gt; autocorr.diag(as.mcmc(dat.logit.jags))
           beta0     beta1  deviance
Lag 0  1.0000000 1.0000000 1.0000000
Lag 1  0.9816715 0.9811729 0.5841946
Lag 5  0.9190319 0.9197111 0.4477029
Lag 10 0.8458674 0.8477906 0.3948904
Lag 50 0.4300407 0.4306464 0.2065881&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It seems that the level of auto-correlation at the nominated lag of &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; is extremely high. Ideally, the level of auto-correlation should be less than &lt;span class=&#34;math inline&#34;&gt;\(0.1\)&lt;/span&gt;. To achieve this, we need a lag of &lt;span class=&#34;math inline&#34;&gt;\(1000\)&lt;/span&gt;. Consequently, we will resample at a lag of &lt;span class=&#34;math inline&#34;&gt;\(1000\)&lt;/span&gt; and obviously we are going to need more iterations to ensure that we retain a large enough sample from which to derive estimates. In order to support a thinning rate of &lt;span class=&#34;math inline&#34;&gt;\(1000\)&lt;/span&gt;, the number of iterations is going to need to be very high. Hence, the following might take considerable time to run.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dat.logit.jags &amp;lt;- jags(data=dat.list,model.file=&amp;#39;modellogit.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=100)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 2
   Total graph size: 147

Initializing model
&amp;gt; 
&amp;gt; print(dat.logit.jags)
Inference for Bugs model at &amp;quot;modellogit.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded), n.thin = 100
 n.sims = 100 iterations saved
         mu.vect sd.vect    2.5%     25%     50%    75%  97.5%  Rhat n.eff
beta0     -16.51   9.652 -40.133 -20.118 -14.170 -9.587 -5.463 1.040    58
beta1       1.66   0.973   0.458   0.979   1.427  2.032  3.926 1.026   100
deviance    9.94   2.764   7.457   8.161   8.942 10.678 16.848 1.024   100

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.8 and DIC = 13.8
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; autocorr.diag(as.mcmc(dat.logit.jags))
              beta0      beta1   deviance
Lag 0     1.0000000  1.0000000  1.0000000
Lag 100   0.4435502  0.4390086  0.1529258
Lag 500   0.1102886  0.1246140  0.1950554
Lag 1000 -0.1091505 -0.1008427 -0.1582021&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the samples are now less auto-correlated and the chains are arguably mixed better. We now explore the goodness of fit of the models via the residuals and deviance. We could calculate the Pearsons’s residuals within the &lt;code&gt;JAGS&lt;/code&gt; model. Alternatively, we could use the parameters to generate the residuals outside of &lt;code&gt;JAGS&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(boot)
&amp;gt; coefs &amp;lt;- dat.logit.jags$BUGSoutput$sims.matrix[,1:2]
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data=dat)
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; pi &amp;lt;- inv.logit(eta)
&amp;gt; #sweep across rows and then divide by pi
&amp;gt; Resid &amp;lt;- -1*sweep(pi,2,dat$y,&amp;#39;-&amp;#39;)/sqrt(pi*(1-pi))
&amp;gt; plot(apply(Resid,2,mean)~apply(eta,2,mean))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/model2_mcmc_res-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we will compare the sum of squared residuals to the sum of squares residuals that would be expected from a Bernoulli distribution matching that estimated by the model. Essentially this is estimating how well the Bernoulli distribution and linear model approximates the observed data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; SSres&amp;lt;-apply(Resid^2,1,sum)
&amp;gt; 
&amp;gt; #generate a matrix of draws from a binomial distribution
&amp;gt; # the matrix is the same dimensions as pi and uses the probabilities of pi
&amp;gt; YNew &amp;lt;- matrix(rbinom(length(pi),prob=pi,size=1),nrow=nrow(pi))
&amp;gt; 
&amp;gt; Resid1&amp;lt;-(pi - YNew)/sqrt(pi*(1-pi))
&amp;gt; SSres.sim&amp;lt;-apply(Resid1^2,1,sum)
&amp;gt; mean(SSres.sim&amp;gt;SSres, na.rm = T)
[1] 0.21875&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, we could generate the new samples and calculate the sums squares of residuals etc all within &lt;code&gt;JAGS&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dat.list &amp;lt;- with(dat, list(y=y, x=x, N=nrow(dat)))
&amp;gt; modelString=&amp;quot;
+ model{
+   for (i in 1:N) {
+     y[i] ~ dbern(p[i])
+     logit(p[i]) &amp;lt;- max(-20,min(20,eta[i]))
+     eta[i] &amp;lt;- beta0+beta1*x[i]
+     YNew[i] ~dbern(p[i])
+     varY[i] &amp;lt;- p[i]*(1-p[i])
+     PRes[i] &amp;lt;- (y[i] - p[i]) / sqrt(varY[i])
+     PResNew[i] &amp;lt;- (YNew[i] - p[i]) / sqrt(varY[i])
+     D[i] &amp;lt;- pow(PRes[i],2)
+     DNew[i] &amp;lt;- pow(PResNew[i],2)
+   }
+   Fit &amp;lt;- sum(D[1:N])
+   FitNew &amp;lt;-sum(DNew[1:N]) 
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+   pvalue &amp;lt;- mean(FitNew&amp;gt;Fit)
+ }
+ &amp;quot;
&amp;gt; writeLines(modelString, con=&amp;#39;modellogit_v2.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;,&amp;#39;Fit&amp;#39;,&amp;#39;FitNew&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.logit.jags1 &amp;lt;- jags(data=dat.list,model.file=&amp;#39;modellogit_v2.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 20
   Unobserved stochastic nodes: 22
   Total graph size: 343

Initializing model
&amp;gt; 
&amp;gt; print(dat.logit.jags1)
Inference for Bugs model at &amp;quot;modellogit_v2.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
Fit       38.470 339.283   6.122   8.237  12.604  24.120 186.621 1.013   540
FitNew    15.837 230.080   0.395   2.025   3.780   8.372  63.411 1.001  3800
beta0    -15.507   7.665 -35.657 -19.433 -13.831 -10.040  -4.873 1.024   660
beta1      1.570   0.791   0.501   0.991   1.390   1.979   3.656 1.017 10000
deviance   9.678   2.175   7.482   8.070   9.018  10.581  15.412 1.013   220

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 2.4 and DIC = 12.0
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; out &amp;lt;- dat.logit.jags1$BUGSoutput
&amp;gt; mean(out$sims.list$FitNew &amp;gt; out$sims.list$Fit)
[1] 0.1947&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: although the Bayesian p-value is quite a bit lower than &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt;, suggesting that there is more variability in the data than should be expected from this simple logistic regression model, this value is not any closer to &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; (a value that would indicate that the model does not fit the data at all well. Thus we might conclude that whilst not ideal, the model is adequate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-the-model-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring the model parameters&lt;/h2&gt;
&lt;p&gt;If there was any evidence that the assumptions had been violated or the model was not an appropriate fit, then we would need to reconsider the model and start the process again. In this case, there is no evidence that the test will be unreliable so we can proceed to explore the test statistics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(coda)
&amp;gt; print(dat.logit.jags)
Inference for Bugs model at &amp;quot;modellogit.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded), n.thin = 100
 n.sims = 100 iterations saved
         mu.vect sd.vect    2.5%     25%     50%    75%  97.5%  Rhat n.eff
beta0     -16.51   9.652 -40.133 -20.118 -14.170 -9.587 -5.463 1.040    58
beta1       1.66   0.973   0.458   0.979   1.427  2.032  3.926 1.026   100
deviance    9.94   2.764   7.457   8.161   8.942 10.678 16.848 1.024   100

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.8 and DIC = 13.8
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; library(plyr)
&amp;gt; adply(dat.logit.jags$BUGSoutput$sims.matrix[,1:2], 2, function(x) {
+   data.frame(Median=median(x), Mean=mean(x), HPDinterval(as.mcmc(x)), HPDinterval(as.mcmc(x),p=0.5))
+ })
     X1     Median       Mean       lower     upper    lower.1   upper.1
1 beta0 -14.169526 -16.510277 -38.4322729 -2.190571 -15.809670 -6.767604
2 beta1   1.427161   1.660376   0.3019023  3.728819   0.866335  1.791501&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: We would reject the null hypothesis (p&lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;0.05\)&lt;/span&gt;). An increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is associated with a significant linear increase (positive slope) in log odds of y success. Every &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; results in a &lt;span class=&#34;math inline&#34;&gt;\(0.86\)&lt;/span&gt; unit increase in log odds-ratio. We usually express this in terms of odds-ratio rather than log odds-ratio, so every &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; results in a (&lt;span class=&#34;math inline&#34;&gt;\(e^{0.86}=2.36\)&lt;/span&gt;) &lt;span class=&#34;math inline&#34;&gt;\(2.36\)&lt;/span&gt; unit increase in odds-ratio.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;explorations-of-the-trends&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Explorations of the trends&lt;/h2&gt;
&lt;p&gt;We might also be interested in the LD50 - the value of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; where the probability switches from favoring &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; to favoring &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. LD50 is calculated as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ LD50 = - \frac{\text{intercept}}{\text{slope}}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; summary(as.mcmc(-coefs[,1]/coefs[,2]))

Iterations = 1:100
Thinning interval = 1 
Number of chains = 1 
Sample size per chain = 100 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

          Mean             SD       Naive SE Time-series SE 
       9.92488        0.84980        0.08498        0.06916 

2. Quantiles for each variable:

  2.5%    25%    50%    75%  97.5% 
 7.737  9.460  9.894 10.448 11.538 
&amp;gt; 
&amp;gt; #OR
&amp;gt; LD50 &amp;lt;- -coefs[,1]/coefs[,2]
&amp;gt; data.frame(Median=median(LD50), Mean=mean(LD50), HPDinterval(as.mcmc(LD50)), HPDinterval(as.mcmc(LD50),p=0.5))
       Median     Mean    lower    upper  lower.1  upper.1
var1 9.894002 9.924877 7.930942 11.59808 9.547373 10.50285&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the LD50 is &lt;span class=&#34;math inline&#34;&gt;\(10.5\)&lt;/span&gt;. Finally, we will create a summary plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; par(mar = c(4, 5, 0, 0))
&amp;gt; plot(y ~ x, data = dat, type = &amp;quot;n&amp;quot;, ann = F, axes = F)
&amp;gt; points(y ~ x, data = dat, pch = 16)
&amp;gt; xs &amp;lt;- seq(0, 20, l = 1000)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~xs)
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; ys &amp;lt;- inv.logit(eta)
&amp;gt; library(plyr)
&amp;gt; data.tab &amp;lt;- adply(ys,2,function(x) {
+   data.frame(Median=median(x), HPDinterval(as.mcmc(x)))
+ })
&amp;gt; data.tab &amp;lt;- cbind(x=xs,data.tab)
&amp;gt; 
&amp;gt; points(Median ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;)
&amp;gt; lines(lower ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;, lty = 2)
&amp;gt; lines(upper ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;, lty = 2)
&amp;gt; axis(1)
&amp;gt; mtext(&amp;quot;X&amp;quot;, 1, cex = 1.5, line = 3)
&amp;gt; axis(2, las = 2)
&amp;gt; mtext(&amp;quot;Y&amp;quot;, 2, cex = 1.5, line = 3)
&amp;gt; box(bty = &amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/model_code_v2_plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;grouped-binary-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Grouped binary data&lt;/h1&gt;
&lt;p&gt;In the previous demonstration, the response variable represented the state of a single item per level of the predictor variable (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). That single item could be observed having a value of either &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Another common situation is to observe the number of items in one of two states (typically dead or alive) for each level of a treatment. For example, you could tally up the number of germinated and non-germinated seeds out of a bank of &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; seeds at each of &lt;span class=&#34;math inline&#34;&gt;\(8\)&lt;/span&gt; temperature or nutrient levels. Recall that the binomial distribution represents the density (probability) of all possible successes (germinations) out of a total of &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; items (seeds). Hence the binomial distribution is also a suitable error distribution for such grouped binary data. For this demonstration, we will model the number of successes against a uniformly distributed predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). The number of trials in each group (level of the predictor) will vary slightly (yet randomly) so as to mimick complications that inevadably occur in real experiments.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(876)
&amp;gt; #The number of levels of x
&amp;gt; n.x &amp;lt;- 10
&amp;gt; #Create x values that at uniformly distributed throughout the rate of 10 to 20
&amp;gt; x &amp;lt;- sort(runif(n = n.x, min = 10, max =20))
&amp;gt; #The slope is the rate of change in log odds ratio for each unit change in x
&amp;gt; # the smaller the slope, the slower the change (more variability in data too)
&amp;gt; slope=-.25
&amp;gt; #Inflection point is where the slope of the line is greatest
&amp;gt; #this is also the LD50 point
&amp;gt; inflect &amp;lt;- 15
&amp;gt; #Intercept (no interpretation)
&amp;gt; intercept &amp;lt;- -1*(slope*inflect)
&amp;gt; #The linear predictor
&amp;gt; linpred &amp;lt;- intercept+slope*x
&amp;gt; #Predicted y values
&amp;gt; y.pred &amp;lt;- exp(linpred)/(1+exp(linpred))
&amp;gt; #Add some noise and make binary (0&amp;#39;s and 1&amp;#39;s)
&amp;gt; n.trial &amp;lt;- rbinom(n=n.x,20, prob=0.9)
&amp;gt; success &amp;lt;- rbinom(n = n.x, size = n.trial,prob = y.pred)
&amp;gt; failure &amp;lt;- n.trial - success
&amp;gt; dat &amp;lt;- data.frame(success,failure,x)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;So lets explore linearity by creating a histogram of the predictor variable (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) and a scatterplot of the relationship between the either the number of successes (success) or the number of (failures) and the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). Note, that this will not account for the differences in trial size per group and so a scatterplot of the relationship between the number of successes (success) or the number of (failures) divided by the total number of trials against the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) might be more appropriate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; hist(dat$x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/expl_data1_gbin-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #now for the scatterplot
&amp;gt; plot(success~x, dat)
&amp;gt; with(dat, lines(lowess(success~x)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/expl_data1_gbin-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #scatterplot standardised for trial size
&amp;gt; plot(success/(success+failure)~x, dat)
&amp;gt; with(dat, lines(lowess(success/(success+failure)~x)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/expl_data1_gbin-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) does not display any skewness (although it is not all that uniform - random data) or other issues that might lead to non-linearity. The lowess smoother on either scatterplot does not display major deviations from a standard sigmoidal curve and thus linearity is likely to be satisfied. Violations of linearity could be addressed by either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;define a non-linear linear predictor (such as a polynomial, spline or other non-linear function).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;transform the scale of the predictor variables.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;Clearly the number of successes is also dependent on the number of trials. Larger numbers of trials might be expected to yeild higher numbers of successes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dat.list &amp;lt;- with(dat, list(success=success, total=success+failure, x=x, N=nrow(dat)))
&amp;gt; modelString=&amp;quot;
+ model{
+   for (i in 1:N) {
+     success[i] ~ dbin(p[i],total[i])
+     logit(p[i]) &amp;lt;- max(-20,min(20,beta0+beta1*x[i]))
+   }
+   beta0 ~ dnorm(0,1.0E-06)
+   beta1 ~ dnorm(0,1.0E-06)
+ }
+ &amp;quot;
&amp;gt; writeLines(modelString, con=&amp;#39;modelgbin.txt&amp;#39;)
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta0&amp;#39;,&amp;#39;beta1&amp;#39;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 20000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; dat.logit.jags &amp;lt;- jags(data=dat.list,model.file=&amp;#39;modelgbin.txt&amp;#39;, param=params,
+                    n.chains=nChains, n.iter=nIter, n.burnin=burnInSteps, n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 10
   Unobserved stochastic nodes: 2
   Total graph size: 87

Initializing model&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As with the logistic regression presented earlier, we could alternatively use probit or clog-log link functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model evaluation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(dat.logit.jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/mcmc_diag_gbin-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(dat.logit.jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/mcmc_diag_gbin-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; raftery.diag(as.mcmc(dat.logit.jags))
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    46       50468 3746         13.50     
 beta1    90       98698 3746         26.30     
 deviance 6        8920  3746          2.38     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                 
          Burn-in  Total  Lower bound  Dependence
          (M)      (N)    (Nmin)       factor (I)
 beta0    84       103188 3746         27.50     
 beta1    52       58312  3746         15.60     
 deviance 8        9488   3746          2.53     
&amp;gt; 
&amp;gt; autocorr.diag(as.mcmc(dat.logit.jags))
           beta0     beta1   deviance
Lag 0  1.0000000 1.0000000 1.00000000
Lag 1  0.9830416 0.9831425 0.56062724
Lag 5  0.9248140 0.9256704 0.42678260
Lag 10 0.8543024 0.8555131 0.36633408
Lag 50 0.4631353 0.4636323 0.07250394&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lets explore the diagnostics - particularly the residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; inv.logit &amp;lt;- binomial()$linkinv
&amp;gt; #Calculate residuals
&amp;gt; coefs &amp;lt;- dat.logit.jags$BUGSoutput$sims.matrix[,1:2]
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data=dat)
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; pi &amp;lt;- inv.logit(eta)
&amp;gt; #sweep across rows and then divide by pi
&amp;gt; Resid &amp;lt;- -1*sweep(pi,2,dat$success/(dat$success+dat$failure),&amp;#39;-&amp;#39;)/sqrt(pi*(1-pi))
&amp;gt; plot(apply(Resid,2,mean)~apply(eta,2,mean))
&amp;gt; lines(lowess(apply(Resid,2,mean)~apply(eta,2,mean)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/model2_mcmc_res_gbin-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: there is no obvious patterns in the residuals, or at least there are no obvious trends remaining that would be indicative of non-linearity.&lt;/p&gt;
&lt;p&gt;Now we will compare the sum of squared residuals to the sum of squares residuals that would be expected from a Bernoulli distribution matching that estimated by the model. Essentially this is estimating how well the Bernoulli distribution and linear model approximates the observed data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; SSres&amp;lt;-apply(Resid^2,1,sum)
&amp;gt; 
&amp;gt; #generate a matrix of draws from a binomial distribution
&amp;gt; #the matrix is the same dimensions as pi and uses the probabilities of pi
&amp;gt; YNew &amp;lt;- matrix(rbinom(length(pi),prob=pi,size=(dat$success+dat$failure)),nrow=nrow(pi))
&amp;gt; Resid1 &amp;lt;- 1*(pi-YNew/(dat$success+dat$failure))/sqrt(pi*(1-pi))
&amp;gt; SSres.sim&amp;lt;-apply(Resid1^2,1,sum)
&amp;gt; mean(SSres.sim&amp;gt;SSres, na.rm=T)
[1] 0.4559&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: this Bayesian p-value is reasonably close to &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt;. Therefore we would conclude that there was no strong evidence for a lack of fit of the model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;explorations-of-the-trends-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Explorations of the trends&lt;/h2&gt;
&lt;p&gt;We might also be interested in the LD50 - the value of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; where the probability switches from favoring &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; to favoring &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. LD50 is calculated as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ LD50 = - \frac{\text{intercept}}{\text{slope}}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; summary(as.mcmc(-coefs[,1]/coefs[,2]))

Iterations = 1:10000
Thinning interval = 1 
Number of chains = 1 
Sample size per chain = 10000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

          Mean             SD       Naive SE Time-series SE 
      12.80838        6.30455        0.06305        0.05732 

2. Quantiles for each variable:

 2.5%   25%   50%   75% 97.5% 
10.09 12.45 13.08 13.58 14.41 
&amp;gt; 
&amp;gt; #OR
&amp;gt; LD50 &amp;lt;- -coefs[,1]/coefs[,2]
&amp;gt; data.frame(Median=median(LD50), Mean=mean(LD50), HPDinterval(as.mcmc(LD50)), HPDinterval(as.mcmc(LD50),p=0.5))
       Median     Mean    lower    upper  lower.1  upper.1
var1 13.08204 12.80838 10.76017 14.74202 12.71997 13.79013&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the LD50 is &lt;span class=&#34;math inline&#34;&gt;\(13.1\)&lt;/span&gt;. Finally, we will create a summary plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; par(mar = c(4, 5, 0, 0))
&amp;gt; plot(success/(success+failure) ~ x, data = dat, type = &amp;quot;n&amp;quot;, ann = F, axes = F)
&amp;gt; points(success/(success+failure) ~ x, data = dat, pch = 16)
&amp;gt; xs &amp;lt;- seq(min(dat$x, na.rm=TRUE),max(dat$x, na.rm=TRUE), l = 1000)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~xs)
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; ys &amp;lt;- inv.logit(eta)
&amp;gt; data.tab &amp;lt;- adply(ys,2,function(x) {
+   data.frame(Median=median(x), HPDinterval(as.mcmc(x)))
+ })
&amp;gt; data.tab &amp;lt;- cbind(x=xs,data.tab)
&amp;gt; 
&amp;gt; points(Median ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;)
&amp;gt; with(data.tab,polygon(c(x,rev(x)),c(lower,rev(upper)), col=&amp;quot;#0000ff60&amp;quot;, border=NA))
&amp;gt; #lines(lower ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;, lty = 2)
&amp;gt; #lines(upper ~ x, data=data.tab,col = &amp;quot;black&amp;quot;, type = &amp;quot;l&amp;quot;, lty = 2)
&amp;gt; axis(1)
&amp;gt; mtext(&amp;quot;X&amp;quot;, 1, cex = 1.5, line = 3)
&amp;gt; axis(2, las = 2)
&amp;gt; mtext(&amp;quot;Probability of success&amp;quot;, 2, cex = 1.5, line = 3)
&amp;gt; box(bty = &amp;quot;l&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/model_code_v2_plot_gbin-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #or via ggplot
&amp;gt; 
&amp;gt; xs &amp;lt;- seq(min(dat$x, na.rm=TRUE),max(dat$x, na.rm=TRUE), l = 1000)
&amp;gt; Xmat &amp;lt;- model.matrix(~xs)
&amp;gt; eta&amp;lt;-coefs %*% t(Xmat)
&amp;gt; library(boot)
&amp;gt; ys &amp;lt;- inv.logit(eta)
&amp;gt; library(plyr)
&amp;gt; data.tab &amp;lt;- adply(ys,2,function(x) {
+   data.frame(Median=median(x), HPDinterval(as.mcmc(x)))
+ })
&amp;gt; data.tab &amp;lt;- cbind(x=xs,data.tab)
&amp;gt; 
&amp;gt; library(ggplot2)
&amp;gt; library(grid)
&amp;gt; dat$p &amp;lt;- with(dat, success/(success+failure))
&amp;gt; p1 &amp;lt;- ggplot(data.tab,aes(y=Median, x=x)) + geom_point(data=dat,aes(y=p, x=x),color=&amp;quot;gray40&amp;quot;)+
+              geom_smooth(aes(ymin=lower, ymax=upper), stat=&amp;quot;identity&amp;quot;)+
+                          scale_x_continuous(&amp;quot;X&amp;quot;)+scale_y_continuous(&amp;quot;Probability of success&amp;quot;)
&amp;gt; p1+theme(panel.grid.major=element_blank(),
+          panel.grid.minor=element_blank(),
+          panel.border=element_blank(),
+          panel.background=element_blank(),
+                  axis.title.y=element_text(size=15,vjust=0,angle=90),
+                  axis.title.x=element_text(size=15,vjust=-1),
+                  axis.text.y=element_text(size=12),
+                  axis.text.x=element_text(size=12),
+                  axis.line=element_line(),
+                  plot.margin=unit(c(0.5,0.5,2,2), &amp;quot;lines&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/glm-jags/2020-02-01-glm-jags_files/figure-html/model_code_v2_plot_gbin-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Goodness of fit tests - JAGS</title>
      <link>/jags/gof-tests-jags/gof-tests-jags/</link>
      <pubDate>Wed, 12 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/gof-tests-jags/gof-tests-jags/</guid>
      <description>


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The analyses described in previous tutorials have all involved response variables that implicitly represent normally distributed and continuous population responses. In this context, continuous indicates that (at least in theory), any value of measurement down to an infinite number of decimal places is possible. Population responses can also be categorical such that the values could be logically or experimentally constrained to a set number of discrete possibilities. For example, individuals in a population can be categorized as either male or female, reaches in a stream could be classified as either riffles, runs or pools and salinity levels of sites might be categorized as either high, medium or low. Typically, categorical response variables are tallied up to generate the frequency of replicates in each of the possible categories. From above, we would tally up the frequency of males and females, the number of riffles, runs and pools and the high, medium and low salinity sites. Hence, rather than model data in which a response was measured from each replicate in the sample (as was the case for previous analyses in this series), frequency analyses model data on the frequency of replicates in each possible category. Furthermore, frequency data follow a Poisson distribution rather than a normal distribution. The Poisson distribution is a symmetrical distribution in which only discrete integer values are possible and whose variance is equal to its mean.&lt;/p&gt;
&lt;p&gt;Since the mean and variance of a Poisson distribution are equal, distributions with higher expected values are shorter and wider than those with smaller means. Note that a Poisson distribution with an expected less than less than &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; will be obviously asymmetrical as a Poisson distribution is bounded to the left by zero. This has important implications for the reliability of frequency analyses when sample sizes are low. The frequencies expected for each category are determined by the size of the sample and the nature of the (null) hypothesis. For example, if the null hypothesis is that there are three times as many females as males in a population (ratio of &lt;span class=&#34;math inline&#34;&gt;\(3:1\)&lt;/span&gt;), then a sample of &lt;span class=&#34;math inline&#34;&gt;\(110\)&lt;/span&gt; individuals would be expected to yield &lt;span class=&#34;math inline&#34;&gt;\(0.75\times110=82.5\)&lt;/span&gt; females and &lt;span class=&#34;math inline&#34;&gt;\(0.25\times110=27.5\)&lt;/span&gt; males.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-chi-square-statistic&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Chi-square statistic&lt;/h2&gt;
&lt;p&gt;The degree of difference between the observed (o) and expected (e) sample category frequencies is represented by the chi-square (&lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;) statistic.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \chi^2=\sum\frac{(o-e)^2}{e}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is a relative measure that is standardised by the magnitude of the expected frequencies. When the null hypothesis is true (typically this represents the situation when there are no effects or patterns of interest in the population response category frequencies), and we have sampled in an unbiased manner, we might expect the observed category frequencies in the sample to be very similar (if not equal) to the expected frequencies and thus, the chi-square value should be close to zero. Likewise, repeated sampling from such a population is likely to yield chi-square values close to zero and large chi-square values should be relatively rare. As such, the chi-square statistic approximately follows a &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution, a mathematical probability distribution representing the frequency (and thus probability) of all possible ranges of chi-square statistics that could result when the null hypothesis is true.&lt;br /&gt;
The &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ p(x) = \frac{1}{2^{\frac{n}{2}}\gamma(\frac{n}{2})}x^{\frac{n}{2-1}}e^{-\frac{x}{2}}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that the location AND shape are both determined by a single parameter (the sample size, n which is also equal to the degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\(+ 1\)&lt;/span&gt;). The &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution is an asymmetrical distribution bounded by zero and infinity and whose exact shape is determined by the degrees of freedom (calculated as the total number of categories minus &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). Note also that the peak of a chi-square distribution is not actually at zero (although it does approach it when the degrees of freedom is equal to zero). Initially, this might seem counter intuitive. We might expect that when a null hypothesis is true, the most common chi-square value will be zero. However, the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution takes into account the expected natural variability in a population as well as the nature of sampling (in which multiple samples should yield slightly different results). The more categories there are, the more likely that the observed and expected values will differ. It could be argued that when there are a large number of categories, samples in which all the observed frequencies are very close to the expected frequencies are a little suspicious and may represent dishonesty on the part of the researcher (Indeed the extraordinary conformity of Gregor Mendelâ€™s pea experiments have been subjected to such skepticism).&lt;/p&gt;
&lt;p&gt;By comparing any given sample chi-square statistic to its appropriate &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution, the probability that the observed category frequencies could have be collected from a population with a specific ratio of frequencies (for example &lt;span class=&#34;math inline&#34;&gt;\(3:1\)&lt;/span&gt;) can be estimated. As is the case for most hypothesis tests, probabilities lower than &lt;span class=&#34;math inline&#34;&gt;\(0.05\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;%) are considered unlikely and suggest that the sample is unlikely to have come from a population characterized by the null hypothesis. Chi-squared tests are typically one-tailed tests focusing on the right-hand tail as we are primarily interested in the probability of obtaining large chi-square values. Nevertheless, it is also possible to focus on the left-hand tail so as to investigate whether the observed values are “too good to be true”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;A chi-square statistic will follow a &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution approximately provided that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All observations are classified independently of one another. The classification of one replicate should not be influenced by or related to the classification of other replicates. Random sampling should address this.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;No more than &lt;span class=&#34;math inline&#34;&gt;\(20\)&lt;/span&gt;% of the expected frequencies are less than five. &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distributions do not reliably approximate the distribution of all possible chi-square values under those circumstances (Expected frequencies less than five result in asymmetrical sampling distributions (since they must be truncated at zero) and thus potentially unrepresentative χ2 distributions). Since the expected values are a function of sample sizes, meeting this assumption is a matter of ensuring sufficient replication. When sample sizes or other circumstances beyond control lead to a violation of this assumption, numerous options are available.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;goodness-of-fit-tests&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goodness of fit tests&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Homogeneous frequencies tests&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Homogeneous frequencies tests (often referred to as goodness of fit tests) are used to test null hypotheses that the category frequencies observed within a single variable could arise from a population displaying a specific ratio of frequencies. The null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;) is that the observed frequencies come from a population with a specific ratio of frequencies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Distributional conformity - Kolmogorov-Smirnov tests&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Strictly, goodness of fit tests are used to examine whether a frequency/sampling distribution is homogeneous with some declared distribution. For example, we might use a goodness of fit test to formally investigate whether the distribution of a response variable deviates substantially from a normal distribution. In this case, frequencies of responses in a set of pre-defined bin ranges are compared to those frequencies expected according to the mathematical model of a normal distribution. Since calculations of these expected frequencies also involve estimates of population mean and variance (both required to determine the mathematical formula), a two degree of freedom loss is incurred (hence &lt;span class=&#34;math inline&#34;&gt;\(df=n−2\)&lt;/span&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;contingency-tables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Contingency tables&lt;/h2&gt;
&lt;p&gt;Contingency tables are used to investigate the associations between two or more categorical variables. That is, they test whether the patterns of frequencies in one categorical variable differ between different levels of other categorical variable(s) or ould the variables be independent of another. In this way, they are analogous to interactions in factorial linear models (such as factorial ANOVA). Contingency tables test the null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;) that the categorical variables are independent of (not associated with) one another. Note that analyses of contingency tables do not empirically distinguish between response and predictor variables (analogous to correlation), yet causality can be implied when logical and justified by interpretation. As an example, contingency tables could be used to investigate whether incidences of hair and eye color in a population are associated with one another (is one hair color type more commonly observed with a certain eye color). In this case, neither hair color nor eye color influence one another, their incidences are both controlled by a separate set of unmeasured factors. By contrast, an association between the presence or absence of a species of frog and the level of salinity (high, medium or low) could imply that salinity effects the distribution of that species of frog - but not vice versa. Sample replicates are cross-classified according to the levels (categories) of multiple categorical variables. The data are conceptualized as a table (hence the name) with the rows representing the levels of one variable and the column the levels of the other variable(s) such that the cells represent the category combinations. The expected frequency of any given cell is calculated as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{\text{(row total)} \times \text{(column total)}}{\text{(grand total)}}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thereafter, the chi-square calculations are calculated as described above and the chi-square value is compared to a &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution with &lt;span class=&#34;math inline&#34;&gt;\((r−1)(c−1)\)&lt;/span&gt; degrees of freedom. Contingency tables involving more than two variables have multiple interaction levels and thus multiple potential sources of independence. For example, in a three-way contingency table between variables A, B and C, there are four interactions (A:B, A:C, B:C and A:B:C). Such designs are arguably more appropriately analysed using log-linear models.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Odds ratios&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The chi-square test provides an indication of whether or not the occurrences in one set of categories are likely to be associated with other sets of categories (an interaction between two or more categorical variables), yet does not provide any indication of how strongly the variables are associated (magnitude of the effect). Furthermore, for variables with more than two categories (e.g. high, medium, low), there is no indication of which category combinations contribute most to the associations. This role is provided by odds ratios which are essentially a measure of effect size. Odds refer the likelihood of a specific event or outcome occurring (such as the odds of a species being present) versus the odds of it not occurring (and thus the occurrence of an alternative outcome) and are calculated as &lt;span class=&#34;math inline&#34;&gt;\(\frac{\pi_j}{(1-\pi_j)}\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\pi_j\)&lt;/span&gt; refers to the probability of the event occurring. For example, we could calculate the odds of frogs being present in highly saline habitats as the probability of frogs being present divided by the probability of them being absent. Similarly, we could calculate the likelihood of frog presence (odds) within low salinity habitats. The ratio of two of these likelihoods (odds ratio) can then be used to compare whether the likelihood of one outcome (frog presence) is the same for both categories (salinity levels). For example, is the likelihood of frogs being present in highly saline habitats the same as the probability of them being present in habitats with low levels of salinity. In so doing, the odds ratio is a measure of effect size that describes the strength of an association between pairs of cross-classification levels. Although odds and thus odds ratios (&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;) are technically derived from probabilities, they can also be estimated using cell frequencies (&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \theta = \frac{n_{11}n_{22}}{n_{12}n_{21}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or alternatively&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \theta = \frac{(n_{11}+0.5)(n_{22}+0.5)}{(n_{12} + 0.5)(n_{21} + 0.5)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt; is a small constant added to prevent division by zero. An odds ratio of one indicates that the event or occurrence (presence of frogs) is equally likely in both categories (high and low salinity habitats). Odds ratios greater than one signify that the event or occurrence is more likely in the first than second category and vice verse for odds ratios less than one. For example, when comparing the presence/absence of frogs in low versus high salinity habitats, an odds ratio of &lt;span class=&#34;math inline&#34;&gt;\(5.8\)&lt;/span&gt; would suggest that frogs are &lt;span class=&#34;math inline&#34;&gt;\(5.8\)&lt;/span&gt; times more likely to be present in low salinity habitats than those that highly saline. The distribution of odds ratios (which range from &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(\infty\)&lt;/span&gt;) is not symmetrical around the null position (&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;) thereby precluding confidence interval and standard error calculations. Instead, these measures are calculated from log transformed (natural log) odds ratios (the distribution of which is a standard normal distribution centered around &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;) and then converted back into a linear scale by anti-logging. Odds ratios can only be calculated between category pairs from two variables and therefore &lt;span class=&#34;math inline&#34;&gt;\(2 \times 2\)&lt;/span&gt; contingency tables (tables with only two rows and two columns). However, tables with more rows and columns can be accommodate by splitting the table up into partial tables of specific category pair combinations. Odds ratios (and confidence intervals) are then calculated from each pairing, notwithstanding their lack of independence. For example, if there were three levels of salinity (high, medium and low), the odds ratios from three partial tables (high vs medium, high vs low, medium vs low) could be calculated.&lt;/p&gt;
&lt;p&gt;Since odds ratios only explore pairwise patterns within two-way interactions, odds ratios for multi-way (three or more variables) tables are considerably more complex to calculate and interpret. Partial tables between two of the variables (e.g frog presence/absence and high/low salinity) are constructed for each level of a third (season: summer/winter). This essentially removes the effect of the third variable by holding it constant. Associations in partial tables are therefore referred to as conditional associations - since the outcomes (associated or independent) from each partial table are explicitly conditional on the level of the third variable at which they were tested.&lt;/p&gt;
&lt;p&gt;Specific contributions to a lack of independence (significant associations) can also be investigated by exploring the residuals. Recall that residuals are the difference between the observed values (frequencies) and those predicted or expected when the null hypothesis is true (no association between variables). Hence the magnitude of each residual indicates how much each of the cross classification combinations differs from what is expected. The residuals are typically standardized (by dividing by the square of the expected frequencies) to enable individual residuals to be compared relative to one another. Large residuals (in magnitude) indicate large deviations from what is expected when the null hypothesis is true and thus also indicate large influences (contributions) to the overall association. The sign (&lt;span class=&#34;math inline&#34;&gt;\(+\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(-\)&lt;/span&gt;) of the residual indicates whether the frequencies were higher or lower than expected.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;g-tests&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;G tests&lt;/h2&gt;
&lt;p&gt;An alternative to the chi-square test for goodness of fit and contingency table analyses is the G-test. The G-test is based on a log likelihood-ratio test. A log likelihood ratio is a ratio of maximum likelihoods of the alternative and null hypotheses. More simply, a log likelihood ratio test essentially examines how likely (the probability) the alternative hypothesis (representing an effect) is compared to how likely the null hypothesis (no effect) is given the collected data. The G2 statistic is calculated as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ G^2 = 2 \sum o \; ln\frac{o}{e}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where o and e are the observed and expected sample category frequencies respectively and ln denotes the natural logarithm (base e). When the null hypothesis is true, the G2 statistic approximately follows a theoretical &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution with the same degrees of freedom as the corresponding chi-square statistic. The G2 statistic (which is twice the value of the log-likelihood ratio) is arguably more appropriate than the chi-square statistic as it is closely aligned with the theoretical basis of the χ2 distribution (for which the chi-squared statistic is a convenient approximation). For large sample sizes, G2 and &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; statistics are equivalent, however the former is a better approximation of the theoretical chi2 distribution when the difference between the observed and expected is less than the expected frequencies (ie &lt;span class=&#34;math inline&#34;&gt;\(|o−e|&amp;lt;e\)&lt;/span&gt;). Nevertheless, G-tests operate under the same assumptions are the chi-square statistic and thus very small sample sizes (expected values less than &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;) are still problematic. G-tests have the additional advantage that they can be used additively with more complex designs and a thus more extensible than the chi-squared statistic.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;small-sample-sizes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Small sample sizes&lt;/h2&gt;
&lt;p&gt;As discussed previously, both the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; and G2 statistics are poor approximations of theoretical &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distributions when sample sizes are very small. Under these circumstances a number of alternative options are available:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If the issue has arisen due to a large number of category levels in one or more of the variables, some categories could be combined together.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fishers exact test which essentially calculates the probability of obtaining the cell frequencies given the observed marginal totals in &lt;span class=&#34;math inline&#34;&gt;\(2 \times 2\)&lt;/span&gt; tables. The calculations involved in such tests are extremely tedious as they involve calculating probabilities from hypergeometric distributions (discrete distributions describing the number of successes from sequences of samples drawn with out replacement) for all combinations of cell values that result in the given marginal totals.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Yates’ continuity correction calculates the test statistic after adding and subtracting &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt; from observed values less than and greater than expected values respectively. Yates’ correction can only be applied to designs with a single degree of freedom (goodness-of-fit designs with two categories or &lt;span class=&#34;math inline&#34;&gt;\(2 \times 2\)&lt;/span&gt; tables) and for goodness-of-fit tests provide p-values that are closer to those of an exact binomial. However, they typically yield over inflated p-values in contingency tables and so have gone out of favour.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Williams’ correction is applied by dividing the test statistic by &lt;span class=&#34;math inline&#34;&gt;\(1+(p2−1)6nv\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the number of categories, &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the total sample size (total of observed frequencies) and &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; is the number of degrees of freedom &lt;span class=&#34;math inline&#34;&gt;\((p−1)\)&lt;/span&gt;. Williams’ corrections can be applied to designs with greater than one degree of freedom, and are considered marginally more appropriate than Yates’ corrections if corrections are insisted.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Randomisation tests in which the sample test statistic (either &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; or G2) is compared to a probability distribution generated by repeatedly calculating the test statistic from an equivalent number of observations drawn from a population (sampling with replacement) with the specific ratio of category frequencies defined by the null hypothesis. Significance is thereafter determined by the proportion of the randomised test statistic values that are greater than or equal to the value of the statistic that is based on observed data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Log-linear modelling (as a form of generalized linear model)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Goodness of fit tests are concerned with comparing the observed frequencies with those expected on the basis of a specific null hypothesis. So lets now fabricate a motivating scenario and some data. We will create a scenario that involves items classified into one of three groups (A, B and C). The number of items in each classification group are then tallied up. Out of a total of &lt;span class=&#34;math inline&#34;&gt;\(47\)&lt;/span&gt; items, &lt;span class=&#34;math inline&#34;&gt;\(15\)&lt;/span&gt; where of type A, &lt;span class=&#34;math inline&#34;&gt;\(9\)&lt;/span&gt; where of type B and &lt;span class=&#34;math inline&#34;&gt;\(23\)&lt;/span&gt; where of type C. We could evaluate a parity (a &lt;span class=&#34;math inline&#34;&gt;\(1:1:1\)&lt;/span&gt; ratio from these data. In a frequentist context, this might involve testing a null hypothesis that the observed data could have come from a population with a &lt;span class=&#34;math inline&#34;&gt;\(1:1\)&lt;/span&gt; item ratio. In this case the probability would be the probability of obtaining the observed ratio of frequencies when the null hypothesis is true. In a Bayesian context, there are numerous ways that we could tackle these data. We would be evaluating the evidence for the null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(1:1:1\)&lt;/span&gt; item ratio) given the observed by estimating the degree of freedom from a chi-square distribution. Alternatively, we could estimate the value of the three population fractions which are expected to be &lt;span class=&#34;math inline&#34;&gt;\(1/3, 1/3, 1/3\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(1:1:1\)&lt;/span&gt;. We will explore this option first and then explore the chi-square approach second. To extend the example, lets also explore a &lt;span class=&#34;math inline&#34;&gt;\(1:1:2\)&lt;/span&gt; ratio. We start by generating the observed data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #the observed frequences of A and B
&amp;gt; obs &amp;lt;- c(15,9,23)
&amp;gt; obs
[1] 15  9 23&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;estimating-population-fractions---binomial-distribution&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Estimating population fractions - binomial distribution&lt;/h1&gt;
&lt;p&gt;The binomial distribution represents the distribution of possible densities (probabilities) for the number of successes p out of a total of n independent trials. In this case, it can be used to model the number of items of each group (A, B and C) out of a total of &lt;span class=&#34;math inline&#34;&gt;\(47\)&lt;/span&gt; items. The prior distribution for &lt;span class=&#34;math inline&#34;&gt;\(p_i\)&lt;/span&gt; would be a beta distribution (values range from &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;) with shape parameters a and b the hyperpriors of which follow vague (flat, imprecise) gamma distributions.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ obs_i \sim \text{Bin}(p_i,n_i),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(p_i\sim \text{Beta}(a,b)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(a,b \sim \text{Gamma}(1,0.01)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;The data should logically follow a binomial distribution (since the observations are counts of positive events out of a total).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;We now translate the likelihood model into &lt;code&gt;JAGS&lt;/code&gt; code and store the code in an external file.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString=&amp;quot;
+ model {
+   #Likelihood
+  for (i in 1:nGroups) {
+    obs[i] ~ dbin(p[i],n[i])
+    p[i] ~ dbeta(a[i],b[i])
+    a[i] ~ dgamma(1,0.01)
+    b[i] ~ dgamma(1,0.01)
+  }
+  }
+ &amp;quot;
&amp;gt; ## write the model to a text file 
&amp;gt; writeLines(modelString,con=&amp;quot;chi2model.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The likelihood model indicates that the observed counts are modeled by a binomial distribution with a probability of p (fraction) from n trials (items).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The prior on each p is defined as a beta distribution with shape parameters a and b&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The hyperpriors for each a and b are drawn from imprecise (vague, flat) gamma distributions.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Define the data list. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # The observed item frequencies
&amp;gt; obs &amp;lt;- c(15, 9, 23)
&amp;gt; data.list &amp;lt;- list(obs = obs, n = c(47, 47, 47), nGroups = 3)
&amp;gt; data.list
$obs
[1] 15  9 23

$n
[1] 47 47 47

$nGroups
[1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the parameters to monitor and the chain details&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;p&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 1000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 5000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fit the model in &lt;code&gt;JAGS&lt;/code&gt; using the function &lt;code&gt;jags&lt;/code&gt; in the package &lt;code&gt;R2jags&lt;/code&gt; (which should be loaded first).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)
&amp;gt; # Fit the model for the 1:1:1 ratio
&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params, 
+                     model.file = &amp;quot;chi2model.txt&amp;quot;,n.chains = nChains, n.iter = nIter, 
+                     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 3
   Unobserved stochastic nodes: 9
   Total graph size: 18

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;chi2model.txt&amp;quot;, fit using jags,
 2 chains, each with 2500 iterations (first 1000 discarded)
 n.sims = 3000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
p[1]       0.323   0.064  0.205  0.276  0.321  0.365  0.449 1.003   570
p[2]       0.204   0.053  0.117  0.168  0.199  0.234  0.322 1.047    38
p[3]       0.496   0.073  0.350  0.448  0.497  0.545  0.636 1.001  3000
deviance  15.119   2.384 12.535 13.373 14.490 16.130 21.782 1.005   320

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 2.8 and DIC = 18.0
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: Initially, we should focus our attention on the Rhat and n.eff columns. These are the scale reduction and number of effective samples respectively and they provide an indication of the degree of mixing or coverage of the samples. Ideally, the n.eff values should be approximately equal to the number of saved samples (in this case &lt;span class=&#34;math inline&#34;&gt;\(4701\)&lt;/span&gt;), and the Rhat values should be approximately &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (complete convergence). Whilst the actual values are likely to differ substantially from run to run (due to the stochastic nature of the way the chains traverse the posterior distribution), on this occasion, the n.eff of the first two probability parameters (p[1] and p[2]) are substantially lower than &lt;span class=&#34;math inline&#34;&gt;\(4700\)&lt;/span&gt;. Hence, the samples of these parameters may not accurately reflect the posterior distribution. We might consider altering one or more of the chain behavioural paramters (such as the thinning rate), alter the model definition (or priors) itself.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model evaluation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;p&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/gof-tests-jags/2020-02-01-gof-tests-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;p&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/gof-tests-jags/2020-02-01-gof-tests-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; raftery.diag(as.mcmc(data.r2jags))
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s
&amp;gt; 
&amp;gt; autocorr.diag(as.mcmc(data.r2jags))
         deviance        p[1]        p[2]        p[3]
Lag 0  1.00000000  1.00000000  1.00000000  1.00000000
Lag 1  0.67862022  0.79329782  0.75266787  0.79501632
Lag 5  0.22316853  0.37163355  0.31066379  0.35879998
Lag 10 0.05470517  0.15225282  0.11155263  0.17106406
Lag 50 0.02781881 -0.00722609 -0.09133568 -0.03525663&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: Minimum required number of MCMC samples to ensure that sufficient samples had been collected to achieve good accuracy is &lt;span class=&#34;math inline&#34;&gt;\(3746\)&lt;/span&gt;. We had &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; per chain (&lt;span class=&#34;math inline&#34;&gt;\(5000\times3=15000\)&lt;/span&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;p&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 1000
&amp;gt; thinSteps = 50
&amp;gt; numSavedSteps = 5000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params, 
+                     model.file = &amp;quot;chi2model.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+                     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 3
   Unobserved stochastic nodes: 9
   Total graph size: 18

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;chi2model.txt&amp;quot;, fit using jags,
 2 chains, each with 125000 iterations (first 1000 discarded), n.thin = 50
 n.sims = 4960 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
p[1]       0.325   0.067  0.200  0.279  0.322  0.369  0.459 1.001  5000
p[2]       0.204   0.056  0.105  0.164  0.201  0.240  0.324 1.002  2100
p[3]       0.491   0.070  0.353  0.443  0.490  0.539  0.630 1.001  5000
deviance  15.223   2.356 12.524 13.457 14.647 16.360 21.253 1.002  1700

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 2.8 and DIC = 18.0
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: Rhat and n.eff are now much better for the probability parameters. The estimated fractions for A, B and C are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A: 0.327 (0.207, 0.466)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;B: 0.200 (0.104, 0.323)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;C: 0.491 (0.355, 0.625)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Collectively, the fractions of 1/3, 1/3 and 1/3 do not fall within these ranges. However, collectively the fractions 1/4, 1/4, 2/4 do fall comfortably within these ranges. This suggests that the population ratio is more likely to be 1:1:2 than 1:1:1.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;chi-square&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Chi-square&lt;/h1&gt;
&lt;p&gt;An appropriate test statistic for comparing an observed (o) frequency ratio to an expected (e) frequency ratio is the chi-square &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; statistic. In effect, the chi-square statistic (which incorporates the variability in the data in to measure of the difference between observed and expected) becomes the input for the likelihood model. Whilst we could simply pass &lt;code&gt;JAGS&lt;/code&gt; the chi-square statistic, by parsing the observed and expected values and having the chi-square value calculated within &lt;code&gt;JAGS&lt;/code&gt; data, the resulting &lt;code&gt;JAGS&lt;/code&gt; code is more complete and able to accommodate other scenarios. So if, chisq is the chi-square statistic and &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is the degrees of freedom (and thus expected value of the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution), then the likelihood model is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \text{chisq} \sim \chi^2(k),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(k \sim \text{Unif}(0.01,100)\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;So lets calculate the expected frequencies as a means to evaluate this assumption. The expected values are calculated as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ e=\text{total counts} \times \text{expected fraction}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It is clear that in neither case are any of the expected frequencies less than &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;. Therefore, we would conclude that probabilities derived from the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution are likely to be reliable.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;We now translate the likelihood model into &lt;code&gt;JAGS&lt;/code&gt; code and store the code in an external file.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2=&amp;quot;
+ data {
+ for (i in 1:n){
+      resid[i] &amp;lt;- pow(obs[i]-exp[i],2)/exp[i]
+    }
+    chisq &amp;lt;- sum(resid)
+ }
+ model {
+   #Likelihood
+   chisq  ~ dchisqr(k)
+   #Priors
+   k ~ dunif(0.01,100)
+  }
+ &amp;quot;
&amp;gt; ## write the model to a text file 
&amp;gt; writeLines(modelString2,con=&amp;quot;chi2model2.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;First of all, the standardized residuals and chi-square statistic are calculated according to the formula listed above.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The likelihood model indicates that the chi-squared statistic can be modeled by a &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution with a centrality parameter of &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The prior on &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is defined as a uniform (thus vague) flat prior whose values could range from &lt;span class=&#34;math inline&#34;&gt;\(0.01\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; (all with equal probability).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Define the data list. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # The observed item frequencies
&amp;gt; obs &amp;lt;- c(15, 9, 23)
&amp;gt; # The expected item frequencies (for a 1:1:1 ratio)
&amp;gt; exp &amp;lt;- rep(sum(obs) * 1/3, 3)
&amp;gt; data.list &amp;lt;- list(obs = obs, exp = exp, n = 3)
&amp;gt; data.list
$obs
[1] 15  9 23

$exp
[1] 15.66667 15.66667 15.66667

$n
[1] 3
&amp;gt; 
&amp;gt; # The expected item frequencies (for a 1:1:2 ratio)
&amp;gt; exp &amp;lt;- sum(obs) * c(1/4, 1/4, 2/4)
&amp;gt; data.list1 &amp;lt;- list(obs = obs, exp = exp, n = 3)
&amp;gt; data.list1
$obs
[1] 15  9 23

$exp
[1] 11.75 11.75 23.50

$n
[1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the parameters to monitor and the chain details&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;chisq&amp;quot;, &amp;quot;resid&amp;quot;, &amp;quot;k&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 1000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 5000
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fit the model in &lt;code&gt;JAGS&lt;/code&gt; using the function &lt;code&gt;jags&lt;/code&gt; in the package &lt;code&gt;R2jags&lt;/code&gt; (which should be loaded first).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # Fit the model for the 1:1:1 ratio
&amp;gt; data.r2jags2 &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params, 
+                     model.file = &amp;quot;chi2model2.txt&amp;quot;,n.chains = nChains, n.iter = nIter, 
+                     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling data graph
   Resolving undeclared variables
   Allocating nodes
   Initializing
   Reading data back into data table
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 1
   Unobserved stochastic nodes: 1
   Total graph size: 14

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags2)
Inference for Bugs model at &amp;quot;chi2model2.txt&amp;quot;, fit using jags,
 2 chains, each with 2500 iterations (first 1000 discarded)
 n.sims = 3000 iterations saved
         mu.vect sd.vect  2.5%   25%   50%    75%  97.5%  Rhat n.eff
chisq      6.298   0.000 6.298 6.298 6.298  6.298  6.298 1.000     1
k          8.293   3.611 2.306 5.686 7.915 10.559 16.165 1.001  3000
resid[1]   0.028   0.000 0.028 0.028 0.028  0.028  0.028 1.000     1
resid[2]   2.837   0.000 2.837 2.837 2.837  2.837  2.837 1.000     1
resid[3]   3.433   0.000 3.433 3.433 3.433  3.433  3.433 1.000     1
deviance   5.338   1.428 4.346 4.444 4.809  5.647  9.405 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 1.0 and DIC = 6.4
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # Fit the model for the 1:1:2 ratio
&amp;gt; data.r2jags2.1 &amp;lt;- jags(data = data.list1, inits = NULL, parameters.to.save = params, 
+                     model.file = &amp;quot;chi2model2.txt&amp;quot;,n.chains = nChains, n.iter = nIter, 
+                     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling data graph
   Resolving undeclared variables
   Allocating nodes
   Initializing
   Reading data back into data table
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 1
   Unobserved stochastic nodes: 1
   Total graph size: 14

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags2.1)
Inference for Bugs model at &amp;quot;chi2model2.txt&amp;quot;, fit using jags,
 2 chains, each with 2500 iterations (first 1000 discarded)
 n.sims = 3000 iterations saved
         mu.vect sd.vect  2.5%   25%   50%   75% 97.5%  Rhat n.eff
chisq      1.553   0.000 1.553 1.553 1.553 1.553 1.553 1.000     1
k          3.455   1.909 0.549 2.007 3.185 4.612 7.908 1.002  3000
resid[1]   0.899   0.000 0.899 0.899 0.899 0.899 0.899 1.000     1
resid[2]   0.644   0.000 0.644 0.644 0.644 0.644 0.644 1.000     1
resid[3]   0.011   0.000 0.011 0.011 0.011 0.011 0.011 1.000     1
deviance   3.883   1.426 2.870 2.976 3.334 4.230 8.006 1.003   920

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 1.0 and DIC = 4.9
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model evaluation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(data.r2jags2, parms = c(&amp;quot;k&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/gof-tests-jags/2020-02-01-gof-tests-jags_files/figure-html/mcmc_diag_v2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags2, parms = c(&amp;quot;k&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/gof-tests-jags/2020-02-01-gof-tests-jags_files/figure-html/mcmc_diag_v2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; raftery.diag(as.mcmc(data.r2jags2))
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s
&amp;gt; 
&amp;gt; autocorr.diag(as.mcmc(data.r2jags2))
       chisq    deviance           k resid[1] resid[2] resid[3]
Lag 0    NaN  1.00000000  1.00000000      NaN      NaN      NaN
Lag 1    NaN  0.42415918  0.27295298      NaN      NaN      NaN
Lag 5    NaN -0.01961156 -0.01627609      NaN      NaN      NaN
Lag 10   NaN -0.03086926 -0.01043329      NaN      NaN      NaN
Lag 50   NaN -0.01409259 -0.02172076      NaN      NaN      NaN&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: The trace plots show what appears to be “random noise” about the parameter value. There is no real suggestion of a step or dramatic change in the trend direction along the length of the sampling chain. The samples seem relatively stable. Thus it would seem that the chains are well mixed and have converged. The density plot (for &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;) is not symmetrical. This suggests that the mean is not a good point estimate for this parameter - the median would be better.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-model-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring model parameters&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags2)
Inference for Bugs model at &amp;quot;chi2model2.txt&amp;quot;, fit using jags,
 2 chains, each with 2500 iterations (first 1000 discarded)
 n.sims = 3000 iterations saved
         mu.vect sd.vect  2.5%   25%   50%    75%  97.5%  Rhat n.eff
chisq      6.298   0.000 6.298 6.298 6.298  6.298  6.298 1.000     1
k          8.293   3.611 2.306 5.686 7.915 10.559 16.165 1.001  3000
resid[1]   0.028   0.000 0.028 0.028 0.028  0.028  0.028 1.000     1
resid[2]   2.837   0.000 2.837 2.837 2.837  2.837  2.837 1.000     1
resid[3]   3.433   0.000 3.433 3.433 3.433  3.433  3.433 1.000     1
deviance   5.338   1.428 4.346 4.444 4.809  5.647  9.405 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 1.0 and DIC = 6.4
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: The median degrees of freedom (&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;) was &lt;span class=&#34;math inline&#34;&gt;\(8.00\)&lt;/span&gt; with a &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% spread of &lt;span class=&#34;math inline&#34;&gt;\(2.31-16.16\)&lt;/span&gt;. This interval does not include the value of &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; (expected value of the chi2 distribution for this hypothesis). Hence there is evidence that the population ratio deviates from a 1:1:1 ratio.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags2.1)
Inference for Bugs model at &amp;quot;chi2model2.txt&amp;quot;, fit using jags,
 2 chains, each with 2500 iterations (first 1000 discarded)
 n.sims = 3000 iterations saved
         mu.vect sd.vect  2.5%   25%   50%   75% 97.5%  Rhat n.eff
chisq      1.553   0.000 1.553 1.553 1.553 1.553 1.553 1.000     1
k          3.455   1.909 0.549 2.007 3.185 4.612 7.908 1.002  3000
resid[1]   0.899   0.000 0.899 0.899 0.899 0.899 0.899 1.000     1
resid[2]   0.644   0.000 0.644 0.644 0.644 0.644 0.644 1.000     1
resid[3]   0.011   0.000 0.011 0.011 0.011 0.011 0.011 1.000     1
deviance   3.883   1.426 2.870 2.976 3.334 4.230 8.006 1.003   920

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 1.0 and DIC = 4.9
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: The median degrees of freedom (&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;) was &lt;span class=&#34;math inline&#34;&gt;\(3.31\)&lt;/span&gt; with a &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% spread of &lt;span class=&#34;math inline&#34;&gt;\(0.57-7.61\)&lt;/span&gt;. This interval comfortably includes the value of &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; (expected value of the chi2 distribution for this hypothesis). Hence there is no evidence that the population ratio deviates from a 1:1:2 ratio.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploration-of-the-trends&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploration of the trends&lt;/h2&gt;
&lt;p&gt;There are a number of avenues we could take in order to explore the data and models further. One thing we could do is calculate the probability that &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is greater than $24 (the expected value) for each hypothesis. This can be done either by modifying the &lt;code&gt;JAGS&lt;/code&gt; code to include a derivative that uses the step function, or we can derive it within &lt;code&gt;R&lt;/code&gt; from the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; samples. Lets explore the latter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; k &amp;lt;- data.r2jags2$BUGSoutput$sims.matrix[, &amp;quot;k&amp;quot;]
&amp;gt; pr &amp;lt;- sum(k &amp;gt; 2)/length(k)
&amp;gt; pr
[1] 0.9813333
&amp;gt; 
&amp;gt; k &amp;lt;- data.r2jags2.1$BUGSoutput$sims.matrix[, &amp;quot;k&amp;quot;]
&amp;gt; pr1 &amp;lt;- sum(k &amp;gt; 2)/length(k)
&amp;gt; pr1
[1] 0.7513333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;: the probability that the expected value exceeds &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; for the 1:1:1 hypothesis is &lt;span class=&#34;math inline&#34;&gt;\(0.982\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(98.2\)&lt;/span&gt;%). There is an &lt;span class=&#34;math inline&#34;&gt;\(98.2\)&lt;/span&gt;% likelihood that the population is not 1:1:1.
We could also compare the two alternative hypotheses. The 1:1:2 hypothesis has lower DIC and is therefore considered a better fit (&lt;span class=&#34;math inline&#34;&gt;\(4.7\)&lt;/span&gt; vs &lt;span class=&#34;math inline&#34;&gt;\(6.4\)&lt;/span&gt;). This is a difference in DIC of around &lt;span class=&#34;math inline&#34;&gt;\(1.7\)&lt;/span&gt; units. So the data have higher support for a 1:1:2 population ratio than a 1:1:1 ratio.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Partly Nested Anova - JAGS</title>
      <link>/jags/partly-nested-anova-jags/block-anova-jags/</link>
      <pubDate>Tue, 11 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/partly-nested-anova-jags/block-anova-jags/</guid>
      <description>


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Split-plot designs&lt;/em&gt; (plots refer to agricultural field plots for which these designs were originally devised) extend unreplicated factorial (&lt;em&gt;randomised complete block&lt;/em&gt; and &lt;em&gt;simple repeated measures&lt;/em&gt;) designs by incorporating an additional factor whose levels are applied to entire blocks. Similarly, complex repeated measures designs are repeated measures designs in which there are different types of subjects. Consider the example of a randomised complete block. Blocks of four treatments (representing leaf packs subject to different aquatic taxa) were secured in numerous locations throughout a potentially heterogeneous stream. If some of those blocks had been placed in riffles, some in runs and some in pool habitats of the stream, the design becomes a split-plot design incorporating a between block factor (stream region: runs, riffles or pools) and a within block factor (leaf pack exposure type: microbial, macro invertebrate or vertebrate). Furthermore, the design would enable us to investigate whether the roles that different organism scales play on the breakdown of leaf material in stream are consistent across each of the major regions of a stream (interaction between region and exposure type). Alternatively (or in addition), shading could be artificially applied to half of the blocks, thereby introducing a between block effect (whether the block is shaded or not). Extending the repeated measures examples from Tutorial 9.3a, there might have been different populations (such as different species or histories) of rats or sharks. Any single subject (such as an individual shark or rat) can only be of one of the populations types and thus this additional factor represents a between subject effect.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models&lt;/h2&gt;
&lt;p&gt;The linear models for three and four factor partly nested designs are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_j + \gamma_k + (\alpha\gamma)_{ij} + (\beta\gamma)_{jk} + \epsilon_{ijkl},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijklm} = \mu + \alpha_i + \gamma_j + (\alpha\gamma)_{ij} + \beta_k + \delta_l + (\alpha\delta)_{il} + (\gamma\delta)_{jl} + (\alpha\gamma\delta)_{ijl} + \epsilon_{ijklm}, \;\;\; \text{(Model 2 additive - 2 between)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijklm} = \mu + \alpha_i + \beta_j + \gamma_k + \delta_l +  (\gamma\delta)_{kl} + (\alpha\gamma)_{ik} + (\alpha\delta)_{il} + (\alpha\gamma\delta)_{ikl} + \epsilon_{ijk}, \;\;\; \text{(Model 2 additive - 1 between)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of the Blocking Factor B and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;As partly nested designs share elements in common with each of nested, factorial and unreplicated factorial designs, they also share similar assumptions and implications to these other designs. Specifically, hypothesis tests assume that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the appropriate residuals are normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator (see Tables above) be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the appropriate residuals are equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the appropriate residuals are independent of one another. Critically, experimental units within blocks/subjects should be adequately spaced temporally and spatially to restrict contamination or carryover effects. Non-independence resulting from the hierarchical design should be accounted for.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;that the variance/covariance matrix displays &lt;strong&gt;sphericity&lt;/strong&gt; (strickly, the variance-covariance matrix must display a very specific pattern of sphericity in which both variances and covariances are equal (compound symmetry), however, an F-ratio will still reliably follow an F distribution provided basic sphericity holds). This assumption is likely to be met only if the treatment levels within each block can be randomly ordered. This assumption can be managed by either adjusting the sensitivity of the affected F-ratios or employing linear mixed effects modelling to the design.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there are no block by within block interactions. Such interactions render non-significant within block effects difficult to interpret unless we assume that there are no block by within block interactions, non-significant within block effects could be due to either an absence of a treatment effect, or as a result of opposing effects within different blocks. As these block by within block interactions are unreplicated, they can neither be formally tested nor is it possible to perform main effects tests to diagnose non-significant within block effects.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;split-plot-design&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Split-plot design&lt;/h1&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Imagine we has designed an experiment in which we intend to measure a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) to one of treatments (three levels; “a1”, “a2” and “a3”). Unfortunately, the system that we intend to sample is spatially heterogeneous and thus will add a great deal of noise to the data that will make it difficult to detect a signal (impact of treatment). Thus in an attempt to constrain this variability you decide to apply a design (RCB) in which each of the treatments within each of &lt;span class=&#34;math inline&#34;&gt;\(35\)&lt;/span&gt; blocks dispersed randomly throughout the landscape. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(plyr)
&amp;gt; set.seed(123)
&amp;gt; nA &amp;lt;- 3
&amp;gt; nC &amp;lt;- 3
&amp;gt; nBlock &amp;lt;- 36
&amp;gt; sigma &amp;lt;- 5
&amp;gt; sigma.block &amp;lt;- 12
&amp;gt; n &amp;lt;- nBlock*nC
&amp;gt; Block &amp;lt;- gl(nBlock, k=1)
&amp;gt; C &amp;lt;- gl(nC,k=1)
&amp;gt; 
&amp;gt; ## Specify the cell means
&amp;gt; AC.means&amp;lt;-(rbind(c(40,70,80),c(35,50,70),c(35,40,45)))
&amp;gt; ## Convert these to effects
&amp;gt; X &amp;lt;- model.matrix(~A*C,data=expand.grid(A=gl(3,k=1),C=gl(3,k=1)))
&amp;gt; AC &amp;lt;- as.vector(AC.means)
&amp;gt; AC.effects &amp;lt;- solve(X,AC)
&amp;gt; 
&amp;gt; A &amp;lt;- gl(nA,nBlock,n)
&amp;gt; dt &amp;lt;- expand.grid(C=C,Block=Block)
&amp;gt; dt &amp;lt;- data.frame(dt,A)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- cbind(model.matrix(~-1+Block, data=dt),model.matrix(~A*C, data=dt))
&amp;gt; block.effects &amp;lt;-  rnorm(n = nBlock, mean =0 , sd = sigma.block)
&amp;gt; all.effects &amp;lt;- c(block.effects, AC.effects)
&amp;gt; lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; ## the quadrat observations (within sites) are drawn from
&amp;gt; ## normal distributions with means according to the site means
&amp;gt; ## and standard deviations of 5
&amp;gt; y &amp;lt;- rnorm(n,lin.pred,sigma)
&amp;gt; data.splt &amp;lt;- data.frame(y=y, A=A,dt)
&amp;gt; head(data.splt)  #print out the first six rows of the data set
         y A C Block A.1
1 36.04388 1 1     1   1
2 62.96473 1 2     1   1
3 71.74448 1 3     1   1
4 35.33552 1 1     2   1
5 63.76434 1 2     2   1
6 76.19828 1 3     2   1
&amp;gt; 
&amp;gt; tapply(data.splt$y,data.splt$A,mean)
       1        2        3 
65.71431 49.43047 41.36212 
&amp;gt; 
&amp;gt; tapply(data.splt$y,data.splt$C,mean)
       1        2        3 
38.41079 53.56792 64.52819 
&amp;gt; 
&amp;gt; replications(y~A*C+Error(Block), data.splt)
  A   C A:C 
 36  36  12 
&amp;gt; 
&amp;gt; library(ggplot2)
&amp;gt; ggplot(data.splt, aes(y=y, x=C, linetype=A, group=A)) + geom_line(stat=&amp;#39;summary&amp;#39;, fun.y=mean)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/partly-nested-anova-jags/2020-02-01-partly-nested-anova-jags_files/figure-html/generate_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data.splt, aes(y=y, x=C,color=A)) + geom_point() + facet_wrap(~Block)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/partly-nested-anova-jags/2020-02-01-partly-nested-anova-jags_files/figure-html/generate_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # check between plot effects
&amp;gt; boxplot(y~A, ddply(data.splt,~A+Block, summarise,y=mean(y)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/partly-nested-anova-jags/2020-02-01-partly-nested-anova-jags_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #OR
&amp;gt; ggplot(ddply(data.splt,~A+Block, summarise,y=mean(y)), aes(y=y, x=A)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/partly-nested-anova-jags/2020-02-01-partly-nested-anova-jags_files/figure-html/exp1_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; # check within plot effects
&amp;gt; boxplot(y~A*C, data.splt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/partly-nested-anova-jags/2020-02-01-partly-nested-anova-jags_files/figure-html/exp1_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #OR 
&amp;gt; ggplot(data.splt, aes(y=y, x=C, fill=A)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/partly-nested-anova-jags/2020-02-01-partly-nested-anova-jags_files/figure-html/exp1_data-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the y-axis. Hence it there is no evidence of non-homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Block by within-Block interaction&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(car)
&amp;gt; with(data.splt, interaction.plot(C,Block,y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/partly-nested-anova-jags/2020-02-01-partly-nested-anova-jags_files/figure-html/exp2_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #OR with ggplot
&amp;gt; library(ggplot2)
&amp;gt; ggplot(data.splt, aes(y=y, x=C, group=Block,color=Block)) + geom_line() +
+   guides(color=guide_legend(ncol=3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/partly-nested-anova-jags/2020-02-01-partly-nested-anova-jags_files/figure-html/exp2_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; residualPlots(lm(y~Block+A*C, data.splt))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/partly-nested-anova-jags/2020-02-01-partly-nested-anova-jags_files/figure-html/exp2_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;           Test stat Pr(&amp;gt;|Test stat|)
Block                                
A                                    
C                                    
Tukey test    1.4518           0.1466
&amp;gt; 
&amp;gt; # the Tukey&amp;#39;s non-additivity test by itself can be obtained via an internal function
&amp;gt; # within the car package
&amp;gt; car:::tukeyNonaddTest(lm(y~Block+A*C, data.splt))
     Test    Pvalue 
1.4517644 0.1465671 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there is no visual or inferential evidence of any major interactions between Block and the within-Block effect (C). Any trends appear to be reasonably consistent between Blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example---split-plot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example - split-plot&lt;/h1&gt;
&lt;p&gt;In an attempt to understand the effects on marine animals of short-term exposure to toxic substances, such as might occur following a spill, or a major increase in storm water flows, a it was decided to examine the toxicant in question, Copper, as part of a field experiment in Honk Kong. The experiment consisted of small sources of Cu (small, hemispherical plaster blocks, impregnated with copper), which released the metal into sea water over &lt;span class=&#34;math inline&#34;&gt;\(4\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; days. The organism whose response to Cu was being measured was a small, polychaete worm, Hydroides, that attaches to hard surfaces in the sea, and is one of the first species to colonize any surface that is submerged. The biological questions focused on whether the timing of exposure to Cu affects the overall abundance of these worms. The time period of interest was the first or second week after a surface being available.&lt;/p&gt;
&lt;p&gt;The experimental setup consisted of sheets of black perspex (settlement plates), which provided good surfaces for these worms. Each plate had a plaster block bolted to its centre, and the dissolving block would create a gradient of [Cu] across the plate. Over the two weeks of the experiment, a given plate would have pl ain plaster blocks (Control) or a block containing copper in the first week, followed by a plain block, or a plain block in the first week, followed by a dose of copper in the second week. After two weeks in the water, plates were removed and counted back in the laboratory. Without a clear idea of how sensitive these worms are to copper, an effect of the treatments might show up as an overall difference in the density of worms across a plate, or it could show up as a gradient in abundance across the plate, with a different gradient in different treatments. Therefore, on each plate, the density of worms was recorded at each of four distances from the center of the plate. Let’s have a look at the dataset&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; copper &amp;lt;- read.table(&amp;#39;copper.csv&amp;#39;, header=T, sep=&amp;#39;,&amp;#39;, strip.white=T)
&amp;gt; head(copper)
   COPPER PLATE DIST WORMS
1 control   200    4 11.50
2 control   200    3 13.00
3 control   200    2 13.50
4 control   200    1 12.00
5 control    39    4 17.75
6 control    39    3 13.75&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Variables’ description:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Copper&lt;/strong&gt;. Categorical listing of the copper treatment (control = no copper applied, week 2 = copper treatment applied in second week and week 1= copper treatment applied in first week) applied to whole plates. Factor A (between plot factor).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Plate&lt;/strong&gt;. Substrate provided for polychaete worm colonization on which copper treatment applied. These are the plots (Factor B). Numbers in this column represent numerical labels given to each plate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dist&lt;/strong&gt;. Categorical listing for the four concentric distances from the center of the plate (source of copper treatment) with 1 being the closest and 4 the furthest. Factor C (within plot factor)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Worms&lt;/strong&gt;. Density of worms measured. Response variable.&lt;/p&gt;
&lt;p&gt;The Plates are the “random” groups. Within each Plate, all levels of the Distance factor occur (this is a within group factor). Each Plate can only be of one of the three levels of the Copper treatment. This is therefore a within group (nested) factor. Traditionally, this mixture of nested and randomised block design would be called a partly nested or split-plot design. In Bayesian (multilevel modeling) terms, this is a multi-level model with one hierarchical level the Plates means and another representing the Copper treatment means (based on the Plate means). Exploratory data analysis has indicated that the response variable could be normalised via a forth-root transformation.&lt;/p&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;We will only explore the matrix parameterisation (random intercepts) of the model, where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{number of lesions}_i = \beta \text{Site}_{j(i)} + \epsilon_{i},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_i∼ N(0,\sigma^2)\)&lt;/span&gt; and we treat Distance as a factor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau.res)
+       mu[i] &amp;lt;- inprod(beta[],X[i,]) + inprod(gamma[],Z[i,])
+       y.err[i] &amp;lt;- y[i] - mu[1]
+    }
+ 
+    #Priors and derivatives
+    for (i in 1:nZ) {
+       gamma[i] ~ dnorm(0,tau.plate)
+    }
+    for (i in 1:nX) {
+       beta[i] ~ dnorm(0,1.0E-06)
+    }
+ 
+    tau.res &amp;lt;- pow(sigma.res,-2)
+    sigma.res &amp;lt;- z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.plate &amp;lt;- pow(sigma.plate,-2)
+    sigma.plate &amp;lt;- z.plate/sqrt(chSq.plate)
+    z.plate ~ dnorm(0, .0016)I(0,)
+    chSq.plate ~ dgamma(0.5, 0.5)
+ 
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;matrixModel.txt&amp;quot;)
&amp;gt; 
&amp;gt; 
&amp;gt; #sort the data set so that the copper treatments are in a more logical order
&amp;gt; library(dplyr)
&amp;gt; copper$DIST &amp;lt;- factor(copper$DIST)
&amp;gt; copper$PLATE &amp;lt;- factor(copper$PLATE)
&amp;gt; copper.sort &amp;lt;- arrange(copper,COPPER,PLATE,DIST)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~COPPER*DIST, data=copper.sort)
&amp;gt; Zmat &amp;lt;- model.matrix(~-1+PLATE, data=copper.sort)
&amp;gt; copper.list &amp;lt;- list(y=copper.sort$WORMS,
+                X=Xmat, nX=ncol(Xmat),
+                            Z=Zmat, nZ=ncol(Zmat),
+                            n=nrow(copper.sort)
+                            )
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;gamma&amp;quot;,&amp;quot;sigma.res&amp;quot;,&amp;quot;sigma.plate&amp;quot;)
&amp;gt; burnInSteps = 1000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; library(R2jags)
&amp;gt; library(coda)
&amp;gt; 
&amp;gt; copper.r2jags.b &amp;lt;- jags(data = copper.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;matrixModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 60
   Unobserved stochastic nodes: 31
   Total graph size: 1971

Initializing model
&amp;gt; 
&amp;gt; print(copper.r2jags.b)
Inference for Bugs model at &amp;quot;matrixModel.txt&amp;quot;, fit using jags,
 2 chains, each with 1500 iterations (first 1000 discarded)
 n.sims = 1000 iterations saved
            mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]      10.814   0.685   9.401  10.369  10.795  11.258  12.157 1.001  1000
beta[2]      -3.544   0.984  -5.440  -4.199  -3.525  -2.869  -1.574 1.002   640
beta[3]     -10.560   0.966 -12.615 -11.177 -10.559  -9.923  -8.712 1.003   610
beta[4]       1.172   0.884  -0.556   0.586   1.199   1.778   2.892 1.002  1000
beta[5]       1.582   0.878  -0.167   0.999   1.577   2.158   3.184 1.003  1000
beta[6]       2.743   0.857   1.039   2.151   2.719   3.342   4.443 1.003  1000
beta[7]      -0.073   1.233  -2.504  -0.875  -0.120   0.748   2.508 1.000  1000
beta[8]       0.007   1.271  -2.447  -0.792  -0.068   0.868   2.556 1.003  1000
beta[9]      -0.365   1.257  -2.866  -1.165  -0.397   0.499   1.960 1.000  1000
beta[10]      2.184   1.237  -0.254   1.395   2.183   2.954   4.846 1.007  1000
beta[11]     -0.008   1.204  -2.424  -0.763  -0.013   0.781   2.378 1.008   530
beta[12]      4.830   1.235   2.390   4.051   4.840   5.632   7.290 1.018  1000
gamma[1]      0.182   0.496  -0.719  -0.102   0.117   0.461   1.300 1.023   650
gamma[2]     -0.115   0.515  -1.218  -0.384  -0.074   0.153   0.915 1.020   300
gamma[3]      0.301   0.541  -0.720  -0.032   0.210   0.593   1.540 1.028   130
gamma[4]     -0.450   0.567  -1.733  -0.791  -0.359  -0.043   0.455 1.032    61
gamma[5]     -0.404   0.520  -1.489  -0.705  -0.328  -0.034   0.455 1.028   130
gamma[6]      0.867   0.712  -0.169   0.295   0.793   1.306   2.470 1.084    25
gamma[7]     -0.186   0.549  -1.386  -0.497  -0.120   0.106   0.856 1.011   290
gamma[8]     -0.530   0.589  -1.808  -0.936  -0.432  -0.051   0.326 1.059    35
gamma[9]      0.153   0.523  -0.919  -0.130   0.100   0.444   1.301 1.008  1000
gamma[10]    -0.154   0.512  -1.206  -0.452  -0.101   0.136   0.848 1.026   290
gamma[11]    -0.113   0.517  -1.317  -0.384  -0.078   0.181   0.896 1.004   920
gamma[12]     0.221   0.546  -0.780  -0.087   0.146   0.541   1.373 1.034   200
gamma[13]     0.136   0.520  -0.822  -0.170   0.081   0.400   1.345 1.017  1000
gamma[14]     0.171   0.541  -0.896  -0.123   0.106   0.466   1.345 1.019   470
gamma[15]    -0.085   0.500  -1.090  -0.374  -0.051   0.202   0.886 1.012  1000
sigma.plate   0.633   0.346   0.050   0.381   0.622   0.842   1.352 1.094    23
sigma.res     1.385   0.166   1.085   1.274   1.377   1.488   1.750 1.038    44
deviance    207.885   8.472 192.227 202.168 207.696 213.399 225.038 1.060    31

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 34.7 and DIC = 242.6
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MCMC diagnostics&lt;/h2&gt;
&lt;p&gt;Before fully exploring the parameters, it is prudent to examine the convergence and mixing diagnostics. Chose either any of the parameterizations (they should yield much the same).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(copper.r2jags.b, parms = c(&amp;quot;gamma&amp;quot;,&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/partly-nested-anova-jags/2020-02-01-partly-nested-anova-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(copper.r2jags.b, parms = c(&amp;quot;gamma&amp;quot;,&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/partly-nested-anova-jags/2020-02-01-partly-nested-anova-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; raftery.diag(as.mcmc(copper.r2jags.b))
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s
&amp;gt; 
&amp;gt; autocorr.diag(as.mcmc(copper.r2jags.b))
            beta[1]     beta[2]      beta[3]      beta[4]      beta[5]
Lag 0   1.000000000  1.00000000  1.000000000  1.000000000  1.000000000
Lag 1   0.021272766  0.04648343  0.007883585 -0.031877909  0.005935939
Lag 5  -0.008158584 -0.04203414  0.003333370 -0.025041071 -0.049596493
Lag 10  0.031505586 -0.03660104  0.063264397  0.005126694  0.061062870
Lag 50 -0.027782043 -0.01419507 -0.063446191 -0.025966769  0.000139520
            beta[6]      beta[7]      beta[8]     beta[9]    beta[10]
Lag 0   1.000000000  1.000000000  1.000000000  1.00000000  1.00000000
Lag 1   0.003141284  0.006332145 -0.016090936  0.02230158 -0.01371002
Lag 5  -0.047609108 -0.015586534 -0.004392271 -0.04095146  0.03636817
Lag 10 -0.021534565  0.002483458  0.022938630  0.03931772  0.09976040
Lag 50  0.018649619  0.039287014 -0.026677246  0.02487322 -0.01257863
           beta[11]    beta[12]   deviance    gamma[1]    gamma[2]   gamma[3]
Lag 0   1.000000000  1.00000000 1.00000000  1.00000000  1.00000000 1.00000000
Lag 1   0.003598499  0.04451183 0.42158932  0.09957956  0.03142211 0.07683730
Lag 5  -0.048681325 -0.02569540 0.12353548  0.03983927 -0.00533499 0.02599357
Lag 10 -0.025741832 -0.01822980 0.08655390 -0.02625359  0.05903335 0.05050285
Lag 50  0.008573506 -0.02525275 0.02010397 -0.04670946 -0.04143951 0.01017881
          gamma[4]   gamma[5]   gamma[6]    gamma[7]    gamma[8]     gamma[9]
Lag 0   1.00000000 1.00000000  1.0000000  1.00000000  1.00000000  1.000000000
Lag 1   0.20659505 0.19599762  0.5113019  0.01034209  0.22908668  0.003942025
Lag 5   0.13726039 0.11488655  0.2890791 -0.07543631  0.15468366  0.039009815
Lag 10  0.08819534 0.06826430  0.1643047  0.03128544  0.03212642 -0.007477517
Lag 50 -0.03923514 0.01121642 -0.1002922 -0.01843480 -0.04706169 -0.012306197
          gamma[10]     gamma[11]    gamma[12]   gamma[13]   gamma[14]
Lag 0   1.000000000  1.0000000000  1.000000000  1.00000000 1.000000000
Lag 1   0.010206952  0.0028638893  0.009332531  0.03815594 0.007373479
Lag 5  -0.061360721  0.0008173756 -0.012857899 -0.02174086 0.022461865
Lag 10 -0.013288697 -0.0226321328  0.001324936  0.03479040 0.031318743
Lag 50  0.008887211 -0.0289618811 -0.026443165  0.01353287 0.037485638
          gamma[15] sigma.plate  sigma.res
Lag 0   1.000000000   1.0000000 1.00000000
Lag 1  -0.028327792   0.8371048 0.54229156
Lag 5  -0.010034686   0.5053673 0.03764157
Lag 10 -0.010388153   0.3404067 0.01350504
Lag 50  0.002533215  -0.1081944 0.07948304&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parameter estimates&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(copper.r2jags.b)
Inference for Bugs model at &amp;quot;matrixModel.txt&amp;quot;, fit using jags,
 2 chains, each with 1500 iterations (first 1000 discarded)
 n.sims = 1000 iterations saved
            mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]      10.814   0.685   9.401  10.369  10.795  11.258  12.157 1.001  1000
beta[2]      -3.544   0.984  -5.440  -4.199  -3.525  -2.869  -1.574 1.002   640
beta[3]     -10.560   0.966 -12.615 -11.177 -10.559  -9.923  -8.712 1.003   610
beta[4]       1.172   0.884  -0.556   0.586   1.199   1.778   2.892 1.002  1000
beta[5]       1.582   0.878  -0.167   0.999   1.577   2.158   3.184 1.003  1000
beta[6]       2.743   0.857   1.039   2.151   2.719   3.342   4.443 1.003  1000
beta[7]      -0.073   1.233  -2.504  -0.875  -0.120   0.748   2.508 1.000  1000
beta[8]       0.007   1.271  -2.447  -0.792  -0.068   0.868   2.556 1.003  1000
beta[9]      -0.365   1.257  -2.866  -1.165  -0.397   0.499   1.960 1.000  1000
beta[10]      2.184   1.237  -0.254   1.395   2.183   2.954   4.846 1.007  1000
beta[11]     -0.008   1.204  -2.424  -0.763  -0.013   0.781   2.378 1.008   530
beta[12]      4.830   1.235   2.390   4.051   4.840   5.632   7.290 1.018  1000
gamma[1]      0.182   0.496  -0.719  -0.102   0.117   0.461   1.300 1.023   650
gamma[2]     -0.115   0.515  -1.218  -0.384  -0.074   0.153   0.915 1.020   300
gamma[3]      0.301   0.541  -0.720  -0.032   0.210   0.593   1.540 1.028   130
gamma[4]     -0.450   0.567  -1.733  -0.791  -0.359  -0.043   0.455 1.032    61
gamma[5]     -0.404   0.520  -1.489  -0.705  -0.328  -0.034   0.455 1.028   130
gamma[6]      0.867   0.712  -0.169   0.295   0.793   1.306   2.470 1.084    25
gamma[7]     -0.186   0.549  -1.386  -0.497  -0.120   0.106   0.856 1.011   290
gamma[8]     -0.530   0.589  -1.808  -0.936  -0.432  -0.051   0.326 1.059    35
gamma[9]      0.153   0.523  -0.919  -0.130   0.100   0.444   1.301 1.008  1000
gamma[10]    -0.154   0.512  -1.206  -0.452  -0.101   0.136   0.848 1.026   290
gamma[11]    -0.113   0.517  -1.317  -0.384  -0.078   0.181   0.896 1.004   920
gamma[12]     0.221   0.546  -0.780  -0.087   0.146   0.541   1.373 1.034   200
gamma[13]     0.136   0.520  -0.822  -0.170   0.081   0.400   1.345 1.017  1000
gamma[14]     0.171   0.541  -0.896  -0.123   0.106   0.466   1.345 1.019   470
gamma[15]    -0.085   0.500  -1.090  -0.374  -0.051   0.202   0.886 1.012  1000
sigma.plate   0.633   0.346   0.050   0.381   0.622   0.842   1.352 1.094    23
sigma.res     1.385   0.166   1.085   1.274   1.377   1.488   1.750 1.038    44
deviance    207.885   8.472 192.227 202.168 207.696 213.399 225.038 1.060    31

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 34.7 and DIC = 242.6
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Randomised Complete Block Anova - JAGS</title>
      <link>/jags/block-anova-jags/block-anova-jags/</link>
      <pubDate>Mon, 10 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/block-anova-jags/block-anova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the previous tutorial (nested ANOVA), we introduced the concept of employing sub-replicates that are nested within the main treatment levels as a means of absorbing some of the unexplained variability that would otherwise arise from designs in which sampling units are selected from amongst highly heterogeneous conditions. Such (nested) designs are useful in circumstances where the levels of the main treatment (such as burnt and un-burnt sites) occur at a much larger temporal or spatial scale than the experimental/sampling units (e.g. vegetation monitoring quadrats). For circumstances in which the main treatments can be applied (or naturally occur) at the same scale as the sampling units (such as whether a stream rock is enclosed by a fish proof fence or not), an alternative design is available. In this design (&lt;strong&gt;randomised complete block design&lt;/strong&gt;), each of the levels of the main treatment factor are grouped (blocked) together (in space and/or time) and therefore, whilst the conditions between the groups (referred to as “blocks”) might vary substantially, the conditions under which each of the levels of the treatment are tested within any given block are far more homogeneous.&lt;/p&gt;
&lt;p&gt;If any differences between blocks (due to the heterogeneity) can account for some of the total variability between the sampling units (thereby reducing the amount of variability that the main treatment(s) failed to explain), then the main test of treatment effects will be more powerful/sensitive. As an simple example of a randomised complete block (RCB) design, consider an investigation into the roles of different organism scales (microbial, macro invertebrate and vertebrate) on the breakdown of leaf debris packs within streams. An experiment could consist of four treatment levels - leaf packs protected by fish-proof mesh, leaf packs protected by fine macro invertebrate exclusion mesh, leaf packs protected by dissolving antibacterial tablets, and leaf packs relatively unprotected as controls. As an acknowledgement that there are many other unmeasured factors that could influence leaf pack breakdown (such as flow velocity, light levels, etc) and that these are likely to vary substantially throughout a stream, the treatments are to be arranged into groups or “blocks” (each containing a single control, microbial, macro invertebrate and fish protected leaf pack). Blocks of treatment sets are then secured in locations haphazardly selected throughout a particular reach of stream. Importantly, the arrangement of treatments in each block must be randomized to prevent the introduction of some systematic bias - such as light angle, current direction etc.&lt;/p&gt;
&lt;p&gt;Blocking does however come at a cost. The blocks absorb both unexplained variability as well as degrees of freedom from the residuals. Consequently, if the amount of the total unexplained variation that is absorbed by the blocks is not sufficiently large enough to offset the reduction in degrees of freedom (which may result from either less than expected heterogeneity, or due to the scale at which the blocks are established being inappropriate to explain much of the variation), for a given number of sampling units (leaf packs), the tests of main treatment effects will suffer power reductions. Treatments can also be applied sequentially or repeatedly at the scale of the entire block, such that at any single time, only a single treatment level is being applied (see the lower two sub-figures above). Such designs are called repeated measures. A repeated measures ANOVA is to an single factor ANOVA as a paired t-test is to a independent samples t-test. One example of a repeated measures analysis might be an investigation into the effects of a five different diet drugs (four doses and a placebo) on the food intake of lab rats. Each of the rats (“subjects”) is subject to each of the four drugs (within subject effects) which are administered in a random order. In another example, temporal recovery responses of sharks to bi-catch entanglement stresses might be simulated by analyzing blood samples collected from captive sharks (subjects) every half hour for three hours following a stress inducing restraint. This repeated measures design allows the anticipated variability in stress tolerances between individual sharks to be accounted for in the analysis (so as to permit more powerful test of the main treatments). Furthermore, by performing repeated measures on the same subjects, repeated measures designs reduce the number of subjects required for the investigation. Essentially, this is a randomised complete block design except that the within subject (block) effect (e.g. time since stress exposure) cannot be randomised.&lt;/p&gt;
&lt;p&gt;To suppress contamination effects resulting from the proximity of treatment sampling units within a block, units should be adequately spaced in time and space. For example, the leaf packs should not be so close to one another that the control packs are effected by the antibacterial tablets and there should be sufficient recovery time between subsequent drug administrations. In addition, the order or arrangement of treatments within the blocks must be randomized so as to prevent both confounding as well as computational complications. Whilst this is relatively straight forward for the classic randomized complete block design (such as the leaf packs in streams), it is logically not possible for repeated measures designs. Blocking factors are typically random factors that represent all the possible blocks that could be selected. As such, no individual block can truly be replicated. Randomised complete block and repeated measures designs can therefore also be thought of as un-replicated factorial designs in which there are two or more factors but that the interactions between the blocks and all the within block factors are not replicated.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models&lt;/h2&gt;
&lt;p&gt;The linear models for two and three factor nested design are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \mu + \beta_i + \alpha_j + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \beta_i + \alpha_j + \gamma_k + (\beta\alpha)_{ij} + (\beta\gamma)_{ik} + (\alpha\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \epsilon_{ijk}, \;\;\; \text{(Model 1)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \beta_i + \alpha_j + \gamma_k + (\alpha\gamma)_{jk} + \epsilon_{ijk}, \;\;\; \text{(Model 2)},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of the Blocking Factor B (&lt;span class=&#34;math inline&#34;&gt;\(\sum \beta=0\)&lt;/span&gt;), &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; are the effects of withing block Factor A and Factor C, respectively, and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon \sim N(0,\sigma^2)\)&lt;/span&gt; is the random unexplained or residual component.&lt;/p&gt;
&lt;p&gt;Tests for the effects of blocks as well as effects within blocks assume that there are no interactions between blocks and the within block effects. That is, it is assumed that any effects are of similar nature within each of the blocks. Whilst this assumption may well hold for experiments that are able to consciously set the scale over which the blocking units are arranged, when designs utilize arbitrary or naturally occurring blocking units, the magnitude and even polarity of the main effects are likely to vary substantially between the blocks. The preferred (non-additive or “Model 1”) approach to un-replicated factorial analysis of some bio-statisticians is to include the block by within subject effect interactions (e.g. &lt;span class=&#34;math inline&#34;&gt;\(\beta\alpha\)&lt;/span&gt;). Whilst these interaction effects cannot be formally tested, they can be used as the denominators in F-ratio calculations of their respective main effects tests. Proponents argue that since these blocking interactions cannot be formally tested, there is no sound inferential basis for using these error terms separately. Alternatively, models can be fitted additively (“Model 2”) whereby all the block by within subject effect interactions are pooled into a single residual term (&lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;). Although the latter approach is simpler, each of the within subject effects tests do assume that there are no interactions involving the blocks and that perhaps even more restrictively, that sphericity holds across the entire design.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;As with other ANOVA designs, the reliability of hypothesis tests is dependent on the residuals being:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;independent of one another. Although the observations within a block may not strictly be independent, provided the treatments are applied or ordered randomly within each block or subject, within block proximity effects on the residuals should be random across all blocks and thus the residuals should still be independent of one another. Nevertheless, it is important that experimental units within blocks are adequately spaced in space and time so as to suppress contamination or carryover effects.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;simple-rcb&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simple RCB&lt;/h1&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Imagine we has designed an experiment in which we intend to measure a response (y) to one of treatments (three levels; “a1”, “a2” and “a3”). Unfortunately, the system that we intend to sample is spatially heterogeneous and thus will add a great deal of noise to the data that will make it difficult to detect a signal (impact of treatment). Thus in an attempt to constrain this variability you decide to apply a design (RCB) in which each of the treatments within each of 35 blocks dispersed randomly throughout the landscape. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(plyr)
&amp;gt; set.seed(123)
&amp;gt; nTreat &amp;lt;- 3
&amp;gt; nBlock &amp;lt;- 35
&amp;gt; sigma &amp;lt;- 5
&amp;gt; sigma.block &amp;lt;- 12
&amp;gt; n &amp;lt;- nBlock*nTreat
&amp;gt; Block &amp;lt;- gl(nBlock, k=1)
&amp;gt; A &amp;lt;- gl(nTreat,k=1)
&amp;gt; dt &amp;lt;- expand.grid(A=A,Block=Block)
&amp;gt; #Xmat &amp;lt;- model.matrix(~Block + A + Block:A, data=dt)
&amp;gt; Xmat &amp;lt;- model.matrix(~-1+Block + A, data=dt)
&amp;gt; block.effects &amp;lt;- rnorm(n = nBlock, mean = 40, sd = sigma.block)
&amp;gt; A.effects &amp;lt;- c(30,40)
&amp;gt; all.effects &amp;lt;- c(block.effects,A.effects)
&amp;gt; lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; # OR
&amp;gt; Xmat &amp;lt;- cbind(model.matrix(~-1+Block,data=dt),model.matrix(~-1+A,data=dt))
&amp;gt; ## Sum to zero block effects
&amp;gt; block.effects &amp;lt;- rnorm(n = nBlock, mean = 0, sd = sigma.block)
&amp;gt; A.effects &amp;lt;- c(40,70,80)
&amp;gt; all.effects &amp;lt;- c(block.effects,A.effects)
&amp;gt; lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; 
&amp;gt; 
&amp;gt; ## the quadrat observations (within sites) are drawn from
&amp;gt; ## normal distributions with means according to the site means
&amp;gt; ## and standard deviations of 5
&amp;gt; y &amp;lt;- rnorm(n,lin.pred,sigma)
&amp;gt; data.rcb &amp;lt;- data.frame(y=y, expand.grid(A=A, Block=Block))
&amp;gt; head(data.rcb)  #print out the first six rows of the data set
         y A Block
1 45.80853 1     1
2 66.71784 2     1
3 93.29238 3     1
4 43.10101 1     2
5 73.20697 2     2
6 91.77487 3     2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y~A, data.rcb)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. . More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Block by within-Block interaction&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(car)
&amp;gt; with(data.rcb, interaction.plot(A,Block,y))
&amp;gt; 
&amp;gt; #OR with ggplot
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data.rcb, aes(y=y, x=A, group=Block,color=Block)) + geom_line() +
+   guides(color=guide_legend(ncol=3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; residualPlots(lm(y~Block+A, data.rcb))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;           Test stat Pr(&amp;gt;|Test stat|)
Block                                
A                                    
Tukey test   -1.4163           0.1567
&amp;gt; 
&amp;gt; # the Tukey&amp;#39;s non-additivity test by itself can be obtained via an internal function
&amp;gt; # within the car package
&amp;gt; car:::tukeyNonaddTest(lm(y~Block+A, data.rcb))
      Test     Pvalue 
-1.4163343  0.1566776 
&amp;gt; 
&amp;gt; # alternatively, there is also a Tukey&amp;#39;s non-additivity test within the
&amp;gt; # asbio package
&amp;gt; library(asbio)
&amp;gt; with(data.rcb,tukey.add.test(y,A,Block))

Tukey&amp;#39;s one df test for additivity 
F = 2.0060029   Denom df = 67    p-value = 0.1613102&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there is no visual or inferential evidence of any major interactions between Block and the within-Block effect (A). Any trends appear to be reasonably consistent between Blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Full parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\beta_0 + \beta_i + \gamma_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{ij)} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0, \beta_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The &lt;em&gt;full parameterisation&lt;/em&gt;, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\beta_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Matrix parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\boldsymbol \beta \boldsymbol X + \gamma_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{ij} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta \sim MVN(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The full parameterisation, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\beta_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;). The &lt;em&gt;matrix parameterisation&lt;/em&gt; is a compressed notation, In this parameterisation, there are three alpha parameters (one representing the mean of treatment a1, and the other two representing the treatment effects (differences between a2 and a1 and a3 and a1). In generating priors for each of these three alpha parameters, we could loop through each and define a non-informative normal prior to each (as in the Full parameterisation version). However, it turns out that it is more efficient (in terms of mixing and thus the number of necessary iterations) to define the priors from a multivariate normal distribution. This has as many means as there are parameters to estimate (&lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt;) and a &lt;span class=&#34;math inline&#34;&gt;\(3\times3\)&lt;/span&gt; matrix of zeros and &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; in the diagonals.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol \mu =
  \begin{bmatrix} 0  \\ 0  \\ 0 \end{bmatrix}, \;\;\; \sigma^2 \sim   
  \begin{bmatrix}
   1000000 &amp;amp; 0 &amp;amp; 0 \\
   0 &amp;amp; 1000000 &amp;amp; 0 \\
   0 &amp;amp; 0 &amp;amp; 1000000
   \end{bmatrix}. \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}= \beta_0 + \beta_i + \gamma_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{ij} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0, \beta_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Rather than assume a specific variance-covariance structure, just like &lt;code&gt;lme&lt;/code&gt; we can incorporate an appropriate structure to account for different dependency/correlation structures in our data. In RCB designs, it is prudent to capture the residuals to allow checks that there are no outstanding dependency issues following model fitting.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;full-effect-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full effect parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- beta0 + beta[A[i]] + gamma[Block[i]]
+       res[i] &amp;lt;- y[i]-mu[i]
+    }
+    
+    #Priors
+    beta0 ~ dnorm(0, 1.0E-6)
+    beta[1] &amp;lt;- 0
+    for (i in 2:nA) {
+      beta[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    for (i in 1:nBlock) {
+      gamma[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;- z/sqrt(chSq) 
+    z ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;- z/sqrt(chSq.B) 
+    z.B ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.B ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;fullModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.list &amp;lt;- with(data.rcb,
+         list(y=y,
+                  Block=as.numeric(Block),
+          A=as.numeric(A),
+          n=nrow(data.rcb),
+          nBlock=length(levels(Block)),
+                  nA = length(levels(A))
+          )
+ )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;,&amp;#39;gamma&amp;#39;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;quot;res&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.r2jags.f &amp;lt;- jags(data = data.rcb.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;fullModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 105
   Unobserved stochastic nodes: 42
   Total graph size: 582

Initializing model
&amp;gt; 
&amp;gt; print(data.rcb.r2jags.f)
Inference for Bugs model at &amp;quot;fullModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
          mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]     0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000     1
beta[2]    27.923   1.236  25.587  27.086  27.918  28.736  30.363 1.001  3000
beta[3]    40.263   1.229  37.821  39.463  40.271  41.070  42.706 1.001  3000
beta0      41.834   2.154  37.519  40.406  41.833  43.338  46.002 1.001  3000
gamma[1]    3.731   3.394  -2.865   1.418   3.748   6.043  10.452 1.001  3000
gamma[2]    4.534   3.439  -2.033   2.182   4.508   6.865  11.317 1.003   690
gamma[3]   -3.951   3.464 -10.690  -6.324  -3.884  -1.600   2.829 1.001  3000
gamma[4]   -4.129   3.454 -10.758  -6.477  -4.200  -1.784   2.630 1.003   780
gamma[5]   -5.314   3.480 -12.143  -7.633  -5.325  -2.947   1.594 1.001  3000
gamma[6]   -6.050   3.377 -12.486  -8.331  -6.071  -3.700   0.524 1.001  3000
gamma[7]   -0.709   3.373  -7.083  -3.017  -0.728   1.585   6.032 1.001  3000
gamma[8]  -15.033   3.446 -21.689 -17.322 -15.065 -12.741  -7.939 1.001  3000
gamma[9]   27.856   3.444  20.996  25.498  27.927  30.226  34.525 1.001  3000
gamma[10]  12.830   3.591   5.798  10.453  12.809  15.249  20.065 1.001  3000
gamma[11] -14.936   3.427 -21.825 -17.228 -14.945 -12.635  -8.165 1.001  3000
gamma[12]  -7.878   3.427 -14.571 -10.161  -7.929  -5.551  -1.275 1.001  3000
gamma[13] -10.865   3.430 -17.569 -13.203 -10.852  -8.555  -4.076 1.001  2100
gamma[14]   9.153   3.466   2.557   6.679   9.161  11.473  15.941 1.002  1100
gamma[15]  -3.897   3.495 -10.811  -6.227  -3.882  -1.565   2.866 1.001  3000
gamma[16]   1.321   3.437  -5.486  -0.927   1.328   3.539   8.066 1.001  3000
gamma[17]  -4.137   3.445 -11.102  -6.451  -4.046  -1.802   2.384 1.001  2300
gamma[18]  -4.257   3.449 -10.970  -6.607  -4.280  -1.978   2.695 1.001  2900
gamma[19]  16.435   3.468   9.749  14.031  16.449  18.830  23.059 1.002  1600
gamma[20]  -5.108   3.439 -11.784  -7.392  -5.100  -2.851   1.708 1.001  3000
gamma[21]  18.935   3.517  12.023  16.632  18.857  21.210  25.944 1.001  3000
gamma[22] -20.654   3.459 -27.290 -23.041 -20.593 -18.341 -14.063 1.001  3000
gamma[23]   7.325   3.570   0.265   4.959   7.346   9.652  14.226 1.001  2500
gamma[24]  -1.300   3.500  -8.248  -3.680  -1.256   1.043   5.590 1.001  3000
gamma[25]  -6.114   3.419 -12.672  -8.442  -6.078  -3.725   0.554 1.001  2500
gamma[26]   1.038   3.451  -5.502  -1.351   1.018   3.415   7.820 1.001  3000
gamma[27]  -4.346   3.400 -10.942  -6.604  -4.351  -1.980   2.254 1.001  3000
gamma[28]  -4.721   3.368 -11.281  -6.939  -4.724  -2.572   2.057 1.001  3000
gamma[29] -12.328   3.513 -19.166 -14.660 -12.295 -10.096  -5.361 1.001  3000
gamma[30] -12.858   3.534 -19.927 -15.216 -12.782 -10.455  -5.999 1.001  3000
gamma[31]   0.272   3.457  -6.677  -2.020   0.279   2.562   7.061 1.002  1700
gamma[32]   8.682   3.389   1.905   6.358   8.769  10.986  15.304 1.002  1100
gamma[33]   0.315   3.433  -6.393  -2.013   0.292   2.624   7.101 1.001  3000
gamma[34]   9.586   3.491   2.775   7.232   9.621  11.954  16.438 1.002  1600
gamma[35]  23.906   3.429  17.230  21.620  23.976  26.208  30.709 1.004   660
res[1]      0.243   2.906  -5.276  -1.686   0.233   2.121   5.940 1.001  3000
res[2]     -6.771   2.869 -12.345  -8.647  -6.778  -4.904  -1.088 1.001  3000
res[3]      7.465   2.940   1.587   5.472   7.482   9.382  13.252 1.001  3000
res[4]     -3.267   2.927  -8.857  -5.249  -3.282  -1.245   2.325 1.003   710
res[5]     -1.085   2.946  -6.792  -3.130  -1.110   0.894   4.685 1.003   580
res[6]      5.144   2.913  -0.568   3.244   5.128   7.112  11.094 1.003   600
res[7]     -0.049   2.992  -5.806  -2.023  -0.081   1.917   5.915 1.002  1400
res[8]     -2.652   3.020  -8.617  -4.629  -2.690  -0.658   3.254 1.001  2100
res[9]      2.018   2.992  -3.965  -0.008   1.989   4.022   7.816 1.001  1900
res[10]    -2.071   2.894  -7.884  -4.016  -2.075  -0.143   3.626 1.003   790
res[11]     0.729   2.960  -5.122  -1.274   0.754   2.666   6.590 1.003   660
res[12]     0.287   2.974  -5.811  -1.700   0.396   2.232   5.977 1.003   700
res[13]    -2.939   2.956  -8.894  -4.938  -2.989  -0.959   2.831 1.001  3000
res[14]     4.213   2.943  -1.578   2.254   4.220   6.162  10.013 1.002  3000
res[15]    -2.451   2.949  -8.246  -4.449  -2.478  -0.503   3.535 1.001  3000
res[16]    -2.462   2.911  -8.169  -4.429  -2.422  -0.560   3.167 1.001  3000
res[17]     3.440   2.912  -2.164   1.559   3.394   5.390   9.051 1.001  3000
res[18]    -2.208   2.908  -7.897  -4.117  -2.183  -0.279   3.505 1.001  3000
res[19]    -5.249   2.902 -10.958  -7.149  -5.263  -3.289   0.456 1.001  2800
res[20]     4.201   2.886  -1.484   2.238   4.217   6.100   9.930 1.001  3000
res[21]     1.085   2.889  -4.579  -0.852   1.104   2.988   6.981 1.001  3000
res[22]     0.756   2.958  -5.385  -1.108   0.712   2.747   6.541 1.001  3000
res[23]     1.284   2.979  -4.882  -0.642   1.295   3.319   6.941 1.001  3000
res[24]    -5.388   2.941 -11.391  -7.320  -5.410  -3.425   0.336 1.001  3000
res[25]     3.141   2.979  -2.786   1.153   3.135   5.090   9.051 1.001  3000
res[26]    -4.587   2.978 -10.372  -6.597  -4.605  -2.589   1.268 1.001  3000
res[27]     7.011   2.963   1.359   4.983   6.994   8.965  12.803 1.001  3000
res[28]     7.495   3.018   1.549   5.443   7.508   9.538  13.331 1.002  1600
res[29]     0.730   3.013  -5.133  -1.311   0.723   2.759   6.603 1.001  2200
res[30]    -5.563   3.054 -11.597  -7.683  -5.577  -3.452   0.255 1.001  2100
res[31]    -3.927   2.962  -9.656  -5.903  -3.900  -1.965   1.925 1.001  3000
res[32]     2.986   2.928  -2.794   1.134   2.985   4.946   8.735 1.001  3000
res[33]    -1.871   2.951  -7.734  -3.824  -1.864   0.076   4.020 1.001  3000
res[34]    -0.528   2.951  -6.322  -2.505  -0.516   1.395   5.205 1.001  3000
res[35]    -1.472   2.949  -7.285  -3.350  -1.439   0.455   4.220 1.001  3000
res[36]     0.722   2.938  -4.922  -1.223   0.716   2.663   6.487 1.001  3000
res[37]    -0.493   2.928  -6.329  -2.503  -0.515   1.546   5.111 1.002   940
res[38]    -2.832   2.938  -8.610  -4.822  -2.827  -0.812   2.778 1.002  1300
res[39]     1.268   2.931  -4.339  -0.752   1.281   3.287   6.896 1.002  1200
res[40]     2.968   2.956  -2.952   0.972   2.987   4.925   8.768 1.003   540
res[41]    -2.427   2.942  -8.293  -4.383  -2.363  -0.534   3.629 1.003   660
res[42]     1.150   2.922  -4.453  -0.813   1.176   3.054   7.197 1.003   620
res[43]    -7.026   2.953 -12.859  -8.930  -7.097  -5.036  -1.170 1.001  3000
res[44]     2.862   2.915  -2.600   0.922   2.711   4.854   8.438 1.001  3000
res[45]     3.397   2.955  -2.273   1.404   3.364   5.361   9.127 1.001  3000
res[46]     1.390   2.972  -4.597  -0.607   1.321   3.366   7.167 1.001  2000
res[47]     2.490   2.991  -3.362   0.502   2.495   4.531   8.375 1.001  3000
res[48]    -3.582   2.963  -9.351  -5.573  -3.608  -1.606   2.286 1.001  2700
res[49]    -2.288   2.916  -7.729  -4.298  -2.366  -0.291   3.588 1.003  1000
res[50]    -1.083   2.906  -6.569  -3.067  -1.105   0.863   4.716 1.002  1300
res[51]     2.286   2.912  -3.216   0.331   2.244   4.222   8.075 1.002  1200
res[52]    -2.829   2.903  -8.540  -4.796  -2.804  -0.891   2.706 1.001  3000
res[53]     1.533   2.928  -4.178  -0.380   1.544   3.452   7.214 1.001  2700
res[54]     0.366   2.907  -5.326  -1.576   0.391   2.274   6.016 1.001  3000
res[55]     7.373   2.957   1.529   5.353   7.414   9.358  13.176 1.002  1300
res[56]    -3.029   2.984  -9.041  -4.985  -2.963  -1.047   2.888 1.002  1000
res[57]    -0.932   2.961  -6.889  -2.936  -0.824   0.995   4.741 1.002  1100
res[58]     0.955   2.941  -4.752  -1.089   0.981   2.907   6.650 1.001  3000
res[59]    -2.168   2.938  -8.052  -4.106  -2.164  -0.262   3.668 1.001  3000
res[60]    -0.054   2.957  -5.874  -2.011   0.024   1.879   5.755 1.001  3000
res[61]     4.652   3.013  -1.277   2.681   4.595   6.649  10.447 1.001  3000
res[62]     1.763   3.015  -4.198  -0.283   1.800   3.811   7.690 1.001  3000
res[63]    -2.627   2.975  -8.515  -4.603  -2.640  -0.650   3.124 1.001  3000
res[64]    -1.878   3.019  -7.923  -3.808  -1.879   0.207   3.832 1.001  3000
res[65]    -7.955   2.986 -14.124  -9.906  -7.908  -5.914  -2.185 1.001  3000
res[66]     5.629   3.022  -0.370   3.651   5.702   7.692  11.441 1.001  3000
res[67]    -9.447   2.997 -15.297 -11.427  -9.472  -7.515  -3.360 1.002  1100
res[68]     3.633   3.011  -2.241   1.639   3.558   5.638   9.647 1.002  1400
res[69]     7.139   3.005   1.189   5.081   7.118   9.082  13.136 1.002  1300
res[70]    -6.267   2.959 -11.956  -8.323  -6.249  -4.253  -0.493 1.001  3000
res[71]     6.538   2.978   0.563   4.494   6.525   8.512  12.391 1.001  3000
res[72]    -0.621   2.967  -6.432  -2.609  -0.683   1.364   5.125 1.001  3000
res[73]    -0.989   2.943  -6.875  -2.968  -0.975   0.949   4.951 1.001  3000
res[74]     1.375   2.946  -4.265  -0.614   1.336   3.269   7.187 1.001  2400
res[75]    -1.399   2.934  -7.135  -3.371  -1.401   0.618   4.478 1.001  2700
res[76]    -0.971   2.970  -6.912  -2.914  -1.004   1.027   4.841 1.001  3000
res[77]    -3.549   2.958  -9.315  -5.540  -3.567  -1.572   2.143 1.001  3000
res[78]     4.860   2.940  -0.988   2.887   4.805   6.835  10.606 1.001  3000
res[79]     6.984   2.964   1.461   4.967   6.920   9.004  12.824 1.001  3000
res[80]    -7.875   3.011 -13.687  -9.926  -7.936  -5.815  -1.954 1.001  3000
res[81]     0.160   2.947  -5.484  -1.824   0.127   2.155   6.047 1.001  3000
res[82]     2.734   2.915  -3.183   0.820   2.794   4.729   8.263 1.001  3000
res[83]     2.626   2.932  -3.161   0.748   2.624   4.515   8.266 1.001  3000
res[84]    -6.416   2.954 -12.297  -8.315  -6.382  -4.439  -0.826 1.001  3000
res[85]    -2.326   3.020  -8.242  -4.293  -2.308  -0.307   3.564 1.001  3000
res[86]    -1.054   3.030  -7.047  -3.116  -1.048   0.971   4.956 1.001  3000
res[87]     0.823   3.034  -5.036  -1.236   0.832   2.846   6.820 1.001  3000
res[88]    -3.700   3.021  -9.662  -5.732  -3.744  -1.656   2.141 1.001  3000
res[89]     5.124   3.000  -0.700   3.125   5.166   7.053  10.967 1.001  3000
res[90]    -3.973   3.026  -9.965  -5.967  -3.979  -1.965   2.004 1.001  3000
res[91]     6.800   2.936   1.114   4.888   6.726   8.792  12.683 1.001  2100
res[92]    -1.633   2.932  -7.382  -3.615  -1.645   0.303   4.342 1.002  1500
res[93]    -5.027   2.937 -10.801  -6.975  -5.090  -3.114   0.895 1.002  1600
res[94]    11.068   2.894   5.415   9.144  11.037  12.950  16.844 1.017   920
res[95]    -5.145   2.871 -10.758  -7.025  -5.209  -3.257   0.653 1.002   920
res[96]    -3.909   2.889  -9.670  -5.821  -3.975  -2.083   2.104 1.002  1000
res[97]     1.670   2.927  -4.070  -0.286   1.655   3.647   7.528 1.001  2600
res[98]    -1.855   2.902  -7.533  -3.814  -1.846   0.085   3.932 1.001  3000
res[99]     0.809   2.905  -4.984  -1.113   0.807   2.832   6.509 1.001  3000
res[100]    1.492   2.952  -4.294  -0.488   1.451   3.471   7.192 1.001  2000
res[101]    0.647   2.987  -5.287  -1.341   0.649   2.697   6.465 1.002  1500
res[102]   -0.289   2.974  -6.080  -2.262  -0.296   1.781   5.395 1.002  1600
res[103]   -1.309   2.976  -7.063  -3.273  -1.394   0.728   4.790 1.004   440
res[104]   11.580   2.959   5.725   9.638  11.567  13.515  17.434 1.003   770
res[105]   -5.108   2.939 -10.788  -7.110  -5.108  -3.165   0.707 1.006   490
sigma       5.090   0.453   4.294   4.775   5.059   5.360   6.091 1.002   980
sigma.B    11.494   1.491   8.926  10.487  11.365  12.348  14.912 1.002   920
deviance  637.702  11.556 618.449 629.190 636.668 645.140 663.417 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 66.8 and DIC = 704.5
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- inprod(beta[],X[i,]) + gamma[Block[i]]
+     res[i] &amp;lt;- y[i]-mu[i]
+    } 
+    
+    #Priors
+    beta ~ dmnorm(a0,A0)
+    for (i in 1:nBlock) {
+      gamma[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;- z/sqrt(chSq) 
+    z ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;- z/sqrt(chSq.B) 
+    z.B ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.B ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;matrixModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; A.Xmat &amp;lt;- model.matrix(~A,data.rcb)
&amp;gt; data.rcb.list &amp;lt;- with(data.rcb,
+         list(y=y,
+                  Block=as.numeric(Block),
+          X=A.Xmat,
+          n=nrow(data.rcb),
+          nBlock=length(levels(Block)),
+          a0=rep(0,3), A0=diag(3)
+          )
+ )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;#39;gamma&amp;#39;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;quot;res&amp;quot;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.r2jags.m &amp;lt;- jags(data = data.rcb.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;matrixModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 105
   Unobserved stochastic nodes: 40
   Total graph size: 910

Initializing model
&amp;gt; 
&amp;gt; print(data.rcb.r2jags.m)
Inference for Bugs model at &amp;quot;matrixModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
          mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]     0.550   1.010  -1.396  -0.163   0.543   1.212   2.618 1.001  3000
beta[2]     0.624   0.969  -1.267  -0.021   0.609   1.267   2.494 1.002   830
beta[3]     1.556   1.005  -0.458   0.886   1.564   2.248   3.495 1.001  3000
gamma[1]   64.957  12.115  41.593  56.722  64.856  72.937  89.019 1.001  3000
gamma[2]   65.491  12.061  40.343  57.573  65.450  73.443  89.230 1.001  3000
gamma[3]   57.107  11.937  34.004  49.204  56.969  65.191  79.840 1.001  3000
gamma[4]   56.660  11.705  32.676  48.922  56.796  64.418  79.244 1.002   980
gamma[5]   55.496  12.269  30.868  47.463  55.494  63.576  79.632 1.001  3000
gamma[6]   54.801  11.877  31.954  46.951  54.385  62.674  78.056 1.002  3000
gamma[7]   60.234  11.740  36.788  52.823  60.472  67.916  83.053 1.001  3000
gamma[8]   45.171  11.789  21.628  37.438  45.279  53.104  69.031 1.002  3000
gamma[9]   89.740  11.870  66.877  81.784  89.985  97.893 112.876 1.001  3000
gamma[10]  74.392  11.959  51.486  65.937  74.289  82.703  98.386 1.002  1500
gamma[11]  45.824  11.994  22.631  37.864  45.861  53.737  69.411 1.002  1100
gamma[12]  52.874  11.847  29.777  44.934  53.044  61.009  75.635 1.002  1800
gamma[13]  49.828  12.010  26.670  41.934  49.809  57.903  73.611 1.001  3000
gamma[14]  70.252  11.879  46.842  62.471  70.259  78.152  93.618 1.001  3000
gamma[15]  56.956  11.790  34.318  48.968  56.782  65.102  79.771 1.001  3000
gamma[16]  62.229  12.088  39.561  53.779  62.120  70.801  85.754 1.002  1500
gamma[17]  56.154  11.923  32.379  48.260  56.301  64.248  79.156 1.004   840
gamma[18]  56.302  11.789  32.839  48.585  56.477  64.399  79.221 1.001  3000
gamma[19]  78.011  12.127  53.246  69.932  78.041  86.393 100.917 1.001  3000
gamma[20]  55.445  11.822  32.414  47.480  55.477  63.566  78.456 1.002  3000
gamma[21]  79.975  11.935  56.573  72.184  80.069  87.728 103.091 1.001  3000
gamma[22]  39.667  11.800  16.288  31.836  39.723  47.341  62.882 1.001  3000
gamma[23]  68.605  11.860  45.831  60.540  68.721  76.702  91.376 1.001  3000
gamma[24]  59.858  12.057  36.038  51.799  59.900  67.940  83.312 1.001  2200
gamma[25]  54.974  11.970  31.161  47.135  55.153  62.882  78.327 1.002  1400
gamma[26]  62.397  11.915  38.745  54.113  62.260  70.437  86.239 1.002  3000
gamma[27]  56.526  11.968  32.943  48.610  56.627  64.491  80.067 1.003  1800
gamma[28]  56.062  12.002  33.315  48.254  56.158  64.016  79.264 1.001  3000
gamma[29]  47.976  11.787  24.940  39.984  47.840  55.752  71.140 1.001  3000
gamma[30]  47.866  11.894  24.408  40.161  47.877  55.955  70.787 1.001  3000
gamma[31]  61.528  12.021  37.815  53.617  61.620  69.800  84.596 1.001  3000
gamma[32]  70.047  11.805  46.872  62.230  70.224  78.030  93.180 1.001  3000
gamma[33]  61.830  11.934  38.654  53.718  61.828  69.563  85.450 1.002  1800
gamma[34]  70.909  12.075  47.408  62.788  70.805  78.794  95.338 1.002  3000
gamma[35]  85.532  12.138  61.716  77.422  85.479  93.434 109.336 1.001  3000
res[1]    -19.698  12.037 -43.684 -27.635 -19.684 -11.694   3.838 1.001  3000
res[2]      0.587  12.062 -23.374  -7.403   0.579   8.638  24.005 1.001  2500
res[3]     26.230  12.050   2.155  18.315  26.057  34.356  50.024 1.001  3000
res[4]    -22.940  11.997 -46.569 -30.787 -23.060 -15.111   2.226 1.001  3000
res[5]      6.542  11.989 -16.855  -1.311   6.542  14.381  31.699 1.001  3000
res[6]     24.179  11.977   0.862  16.176  24.040  31.902  49.149 1.001  3000
res[7]    -19.824  11.904 -42.484 -27.853 -19.648 -11.889   3.474 1.001  3000
res[8]      4.872  11.923 -17.801  -3.160   4.933  12.798  28.368 1.001  3000
res[9]     20.951  11.893  -1.904  12.827  21.045  28.785  44.008 1.001  3000
res[10]   -21.576  11.660 -44.079 -29.235 -21.708 -13.770   2.548 1.002   920
res[11]     8.523  11.658 -14.011   0.830   8.435  16.332  32.472 1.002  1100
res[12]    19.489  11.657  -2.829  11.774  19.266  27.343  43.385 1.002   910
res[13]   -22.465  12.167 -46.486 -30.516 -22.434 -14.565   2.114 1.001  3000
res[14]    11.986  12.183 -11.847   3.842  12.016  20.032  36.714 1.001  3000
res[15]    16.730  12.218  -7.281   8.522  16.737  24.706  41.406 1.001  3000
res[16]   -22.029  11.845 -45.221 -29.925 -21.621 -14.244   0.444 1.001  3000
res[17]    11.172  11.874 -12.338   3.326  11.433  18.964  33.977 1.001  3000
res[18]    16.933  11.886  -6.385   8.941  17.228  24.796  39.651 1.001  3000
res[19]   -24.908  11.723 -47.784 -32.552 -25.170 -17.491  -1.875 1.001  3000
res[20]    11.841  11.745 -11.265   4.268  11.662  19.369  35.065 1.001  3000
res[21]    20.133  11.744  -2.743  12.424  19.956  27.740  43.426 1.001  3000
res[22]   -18.164  11.729 -41.484 -26.023 -18.365 -10.358   5.425 1.001  3000
res[23]     9.664  11.740 -13.656   1.865   9.491  17.451  33.025 1.001  3000
res[24]    14.399  11.768  -8.920   6.550  14.224  22.160  38.381 1.001  3000
res[25]   -17.459  11.814 -40.240 -25.508 -17.731  -9.597   5.503 1.001  3000
res[26]     2.112  11.834 -20.695  -5.859   1.791   9.903  25.291 1.001  3000
res[27]    25.119  11.869   2.237  17.073  24.856  33.014  48.190 1.001  3000
res[28]   -12.783  11.927 -36.486 -21.081 -12.685  -4.484  10.101 1.002  1600
res[29]     7.751  11.951 -16.443  -0.606   7.820  16.063  30.397 1.001  2100
res[30]    12.866  11.971 -10.922   4.637  12.799  21.163  36.114 1.002  1600
res[31]   -23.404  11.959 -47.054 -31.381 -23.430 -15.471  -0.221 1.002  1200
res[32]    10.809  11.960 -12.765   2.757  10.883  18.657  33.990 1.002  1400
res[33]    17.359  11.972  -6.134   9.343  17.364  25.293  40.617 1.002  1100
res[34]   -19.997  11.800 -42.736 -28.106 -20.202 -12.124   3.343 1.002  2500
res[35]     6.359  11.812 -16.232  -1.893   6.081  14.115  29.804 1.002  1900
res[36]    19.960  11.807  -2.519  11.753  19.730  27.900  43.458 1.002  2600
res[37]   -19.902  11.980 -43.600 -27.871 -19.843 -12.058   3.587 1.001  3000
res[38]     5.059  12.005 -18.429  -3.025   5.164  12.756  28.837 1.001  3000
res[39]    20.566  11.996  -3.070  12.608  20.634  28.366  44.009 1.001  3000
res[40]   -16.847  11.831 -39.884 -24.766 -17.012  -9.239   6.596 1.001  3000
res[41]     5.057  11.855 -18.074  -2.883   4.927  12.687  28.394 1.001  3000
res[42]    20.042  11.830  -3.241  12.206  20.003  27.718  43.766 1.001  3000
res[43]   -26.596  11.746 -49.680 -34.580 -26.349 -18.627  -3.862 1.001  3000
res[44]    10.592  11.735 -12.047   2.531  10.659  18.547  33.288 1.001  3000
res[45]    22.535  11.759  -0.427  14.411  22.577  30.481  45.274 1.001  3000
res[46]   -18.234  12.031 -41.669 -26.696 -18.076  -9.978   4.443 1.002  1200
res[47]    10.165  12.061 -13.282   1.662  10.365  18.474  33.054 1.002  1500
res[48]    15.501  12.060  -7.938   7.051  15.690  23.578  38.325 1.002  1200
res[49]   -21.296  11.891 -44.247 -29.499 -21.509 -13.441   2.004 1.002  1000
res[50]     7.208  11.902 -15.618  -0.939   6.981  15.152  30.441 1.002   860
res[51]    21.986  11.895  -0.592  13.867  21.799  29.853  45.640 1.002  1000
res[52]   -22.104  11.729 -44.941 -29.987 -22.312 -14.241   1.133 1.001  3000
res[53]     9.556  11.751 -13.024   1.751   9.257  17.457  33.011 1.001  3000
res[54]    19.797  11.734  -2.966  11.838  19.629  27.542  43.295 1.001  3000
res[55]   -12.918  12.097 -35.949 -21.363 -12.982  -4.866  11.578 1.001  3000
res[56]     3.979  12.106 -19.166  -4.374   3.889  12.063  28.610 1.001  3000
res[57]    17.484  12.122  -5.688   8.981  17.300  25.557  42.114 1.001  3000
res[58]   -18.315  11.797 -41.135 -26.620 -18.209 -10.520   4.471 1.001  3000
res[59]     5.862  11.815 -16.900  -2.341   6.146  13.803  29.023 1.001  3000
res[60]    19.383  11.783  -3.464  11.144  19.447  27.072  42.559 1.001  3000
res[61]   -15.105  11.900 -38.125 -22.888 -15.284  -7.276   8.233 1.001  3000
res[62]     9.306  11.923 -13.585   1.507   9.128  17.140  32.775 1.001  3000
res[63]    16.323  11.956  -6.322   8.357  16.116  24.316  39.779 1.001  3000
res[64]   -20.915  11.793 -44.085 -28.598 -21.048 -13.147   2.444 1.001  3000
res[65]     0.307  11.820 -22.750  -7.598   0.334   7.975  23.864 1.001  3000
res[66]    25.298  11.813   2.156  17.551  25.247  33.151  48.893 1.001  3000
res[67]   -29.443  11.830 -52.213 -37.430 -29.692 -21.434  -6.575 1.001  3000
res[68]    10.936  11.848 -11.706   2.810  10.811  18.885  33.881 1.001  3000
res[69]    25.850  11.873   2.835  17.722  25.645  33.821  48.845 1.001  3000
res[70]   -26.142  11.991 -49.697 -34.072 -26.243 -18.049  -2.711 1.001  2300
res[71]    13.963  11.984  -9.101   6.160  13.990  22.029  37.049 1.001  3000
res[72]    18.211  12.015  -4.983  10.314  18.104  26.258  41.685 1.001  2300
res[73]   -20.794  11.932 -43.963 -28.725 -20.938 -12.958   3.106 1.002  1600
res[74]     8.870  11.937 -14.459   0.895   8.787  16.905  32.822 1.001  2000
res[75]    17.504  11.929  -5.274   9.402  17.317  25.457  41.765 1.002  1600
res[76]   -21.046  11.851 -44.910 -28.922 -21.131 -12.843   2.003 1.002  3000
res[77]     3.675  11.857 -19.985  -4.059   3.613  11.706  27.196 1.003  3000
res[78]    23.492  11.881  -0.028  15.552  23.399  31.576  46.776 1.003  3000
res[79]   -12.603  11.937 -35.961 -20.361 -12.719  -4.579  10.948 1.002  2900
res[80]    -0.163  11.955 -23.303  -8.120  -0.343   7.789  23.405 1.002  2200
res[81]    19.279  11.963  -4.001  11.319  19.160  27.293  42.755 1.002  3000
res[82]   -16.766  11.961 -39.955 -24.721 -16.887  -9.030   6.016 1.001  3000
res[83]    10.426  11.958 -13.000   2.504  10.510  18.221  32.859 1.001  3000
res[84]    12.792  11.939 -10.192   4.873  12.720  20.537  35.661 1.001  3000
res[85]   -21.347  11.725 -44.125 -28.923 -21.164 -13.609   1.848 1.001  3000
res[86]     7.224  11.690 -15.758  -0.362   7.382  15.079  30.544 1.001  3000
res[87]    20.510  11.739  -2.412  12.708  20.647  28.327  43.283 1.001  3000
res[88]   -23.140  11.838 -46.005 -31.274 -23.099 -15.502  -0.066 1.001  3000
res[89]    12.983  11.858  -9.972   4.729  13.009  20.680  36.860 1.001  3000
res[90]    15.293  11.892  -7.122   6.928  15.405  23.032  38.696 1.001  3000
res[91]   -13.173  11.935 -36.126 -21.376 -13.267  -5.416  10.293 1.001  3000
res[92]     5.694  11.935 -17.082  -2.485   5.640  13.450  29.247 1.001  3000
res[93]    13.708  11.936  -9.020   5.488  13.624  21.589  37.402 1.001  3000
res[94]    -9.013  11.766 -31.685 -16.863  -9.233  -1.091  14.418 1.001  3000
res[95]     2.073  11.780 -20.569  -5.756   1.871   9.830  25.639 1.001  3000
res[96]    14.717  11.782  -8.181   6.737  14.422  22.602  37.767 1.001  3000
res[97]   -18.561  11.906 -41.914 -26.360 -18.779 -10.492   4.073 1.002  1300
res[98]     5.213  11.908 -18.272  -2.559   5.068  13.190  28.414 1.002  1100
res[99]    19.285  11.939  -4.469  11.483  19.203  27.469  42.441 1.002  1300
res[100]  -18.547  12.018 -42.274 -26.484 -18.430 -10.631   5.083 1.001  3000
res[101]    7.907  12.020 -16.041  -0.084   8.072  15.733  31.471 1.001  3000
res[102]   18.379  12.034  -5.679  10.333  18.514  26.429  41.930 1.001  3000
res[103]  -21.652  12.104 -45.310 -29.603 -21.605 -13.692   1.709 1.001  2500
res[104]   18.537  12.095  -5.105  10.797  18.645  26.404  42.117 1.001  1900
res[105]   13.256  12.137 -10.949   5.489  13.253  21.341  36.897 1.001  2600
sigma      20.838   1.809  17.597  19.556  20.736  21.936  24.751 1.002  1000
sigma.B    63.500   7.812  50.201  58.005  62.978  68.138  80.806 1.001  3000
deviance  934.350  11.459 914.767 926.442 933.465 941.520 959.367 1.004   460

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 65.5 and DIC = 999.9
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For a simple model with only two hierarchical levels, the model is the same as above. If you want to include finite-population standard deviations in the model you can use the following code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString3=&amp;quot;
+ model {
+    #Likelihood (esimating site means (gamma.site)
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- gamma[Block[i]] + inprod(beta[], X[i,]) 
+       y.err[i]&amp;lt;- mu[i]-y[i]
+    }
+    for (i in 1:nBlock) {
+       gamma[i] ~ dnorm(0, tau.block)
+    }
+    #Priors
+    for (i in 1:nX) {
+      beta[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    sigma ~ dunif(0, 100)
+    tau &amp;lt;- 1 / (sigma * sigma)
+    sigma.block ~ dunif(0, 100)
+    tau.block &amp;lt;- 1 / (sigma.block * sigma.block)
+ 
+    sd.y &amp;lt;- sd(y.err)
+    sd.block &amp;lt;- sd(gamma)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString3, con = &amp;quot;SDModel.txt&amp;quot;)
&amp;gt; 
&amp;gt; #data list
&amp;gt; A.Xmat &amp;lt;- model.matrix(~A,ddply(data.rcb,~Block,catcolwise(unique)))
&amp;gt; data.rcb.list &amp;lt;- with(data.rcb,
+         list(y=y,
+                  Block=Block,
+          X= A.Xmat,
+          n=nrow(data.rcb),
+          nBlock=length(levels(Block)),
+                  nX = ncol(A.Xmat)
+          )
+ )
&amp;gt; 
&amp;gt; #parameters and chain details
&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sd.y&amp;quot;,&amp;#39;sd.block&amp;#39;,&amp;#39;sigma.block&amp;#39;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.rcb.r2jagsSD &amp;lt;- jags(data = data.rcb.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;SDModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 105
   Unobserved stochastic nodes: 40
   Total graph size: 899

Initializing model
&amp;gt; 
&amp;gt; print(data.rcb.r2jagsSD)
Inference for Bugs model at &amp;quot;SDModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
            mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]      41.715   2.196  37.449  40.231  41.710  43.183  45.995 1.001  3000
beta[2]      27.928   1.209  25.537  27.146  27.918  28.713  30.317 1.002   980
beta[3]      40.272   1.210  37.832  39.461  40.267  41.096  42.658 1.001  2300
sd.block     11.358   0.519  10.353  11.029  11.345  11.706  12.370 1.001  3000
sd.y          5.014   0.260   4.592   4.827   4.986   5.172   5.609 1.002  1300
sigma         5.074   0.443   4.322   4.752   5.045   5.350   6.036 1.001  3000
sigma.block  11.692   1.546   9.114  10.589  11.586  12.612  15.118 1.002  3000
deviance    637.262  10.949 618.392 629.413 636.321 644.252 660.930 1.001  2200

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 59.9 and DIC = 697.2
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calculate &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; from the posterior of the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.mcmc.listSD &amp;lt;- as.mcmc(data.rcb.r2jagsSD)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~A, data.rcb)
&amp;gt; coefs &amp;lt;- data.rcb.r2jagsSD$BUGSoutput$sims.list[[&amp;#39;beta&amp;#39;]]
&amp;gt; fitted &amp;lt;- coefs %*% t(Xmat)
&amp;gt; X.var &amp;lt;- aaply(fitted,1,function(x){var(x)})
&amp;gt; Z.var &amp;lt;- data.rcb.r2jagsSD$BUGSoutput$sims.list[[&amp;#39;sd.block&amp;#39;]]^2
&amp;gt; R.var &amp;lt;- data.rcb.r2jagsSD$BUGSoutput$sims.list[[&amp;#39;sd.y&amp;#39;]]^2
&amp;gt; R2.marginal &amp;lt;- (X.var)/(X.var+Z.var+R.var)
&amp;gt; R2.marginal &amp;lt;- data.frame(Mean=mean(R2.marginal), Median=median(R2.marginal), HPDinterval(as.mcmc(R2.marginal)))
&amp;gt; R2.conditional &amp;lt;- (X.var+Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.conditional &amp;lt;- data.frame(Mean=mean(R2.conditional),
+    Median=median(R2.conditional), HPDinterval(as.mcmc(R2.conditional)))
&amp;gt; R2.block &amp;lt;- (Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.block &amp;lt;- data.frame(Mean=mean(R2.block), Median=median(R2.block), HPDinterval(as.mcmc(R2.block)))
&amp;gt; R2.res&amp;lt;-(R.var)/(X.var+Z.var+R.var)
&amp;gt; R2.res &amp;lt;- data.frame(Mean=mean(R2.res), Median=median(R2.res), HPDinterval(as.mcmc(R2.res)))
&amp;gt; 
&amp;gt; rbind(R2.block=R2.block, R2.marginal=R2.marginal, R2.res=R2.res, R2.conditional=R2.conditional)
                    Mean     Median      lower      upper
R2.block       0.2927774 0.29248056 0.24902731 0.33605200
R2.marginal    0.6500204 0.65101312 0.60509352 0.68965593
R2.res         0.0572022 0.05628758 0.04596228 0.07055798
R2.conditional 0.9427978 0.94371242 0.92944202 0.95403772&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;planned-comparisonsand-pairwise-tests&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Planned comparisonsand pairwise tests&lt;/h2&gt;
&lt;p&gt;Since there are no restrictions on the type and number of comparisons derived from the posteriors, Bayesian analyses provide a natural framework for exploring additional contrasts and comparisons. For example, to compare all possible levels:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; coefs &amp;lt;- data.rcb.r2jags.m$BUGSoutput$sims.list[[c(&amp;#39;beta&amp;#39;)]]
&amp;gt; head(coefs)
           [,1]        [,2]       [,3]
[1,] -1.0697767 -0.46647636  0.4808020
[2,]  0.6186153  1.46210386  2.3592529
[3,] -1.5100302  0.09180824  1.1835869
[4,] -0.3127107  0.66392714 -0.5681012
[5,]  1.5552936  1.06785499  2.6443403
[6,]  0.7282182  0.59829747  2.8548669
&amp;gt; 
&amp;gt; newdata &amp;lt;- data.frame(A=levels(data.rcb$A))
&amp;gt; # A Tukeys contrast matrix
&amp;gt; library(multcomp)
&amp;gt; tuk.mat &amp;lt;- contrMat(n=table(newdata$A), type=&amp;quot;Tukey&amp;quot;)
&amp;gt; Xmat &amp;lt;- model.matrix(~A, data=newdata)
&amp;gt; pairwise.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; pairwise.mat
      (Intercept) A2 A3
2 - 1           0  1  0
3 - 1           0  0  1
3 - 2           0 -1  1
&amp;gt; 
&amp;gt; comps &amp;lt;- coefs %*% t(pairwise.mat)
&amp;gt; 
&amp;gt; MCMCsum &amp;lt;- function(x) {
+    data.frame(Median=median(x, na.rm=TRUE), t(quantile(x,na.rm=TRUE)),
+               HPDinterval(as.mcmc(x)),HPDinterval(as.mcmc(x),p=0.5))
+ }
&amp;gt; 
&amp;gt; (comps &amp;lt;-plyr:::adply(comps,2,MCMCsum))
     X1    Median       X0.         X25.      X50.     X75.    X100.      lower
1 2 - 1 0.6093838 -2.556240 -0.020575421 0.6093838 1.267051 4.786166 -1.2766747
2 3 - 1 1.5638199 -1.833977  0.886430287 1.5638199 2.248195 4.835948 -0.4024791
3 3 - 2 0.9310770 -4.672228 -0.003765539 0.9310770 1.864871 5.592247 -1.5970184
     upper     lower.1  upper.1
1 2.479999  0.03512204 1.316762
2 3.539364  0.92897200 2.273364
3 3.728297 -0.03345687 1.823124&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;rcb-repeated-measures---continuous-within&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;RCB (repeated measures) - continuous within&lt;/h1&gt;
&lt;div id=&#34;data-generation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Imagine now that we has designed an experiment to investigate the effects of a continuous predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, for example time) on a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;). Again, the system that we intend to sample is spatially heterogeneous and thus will add a great deal of noise to the data that will make it difficult to detect a signal (impact of treatment). Thus in an attempt to constrain this variability, we again decide to apply a design (RCB) in which each of the levels of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; (such as time) treatments within each of &lt;span class=&#34;math inline&#34;&gt;\(35\)&lt;/span&gt; blocks dispersed randomly throughout the landscape. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; slope &amp;lt;- 30
&amp;gt; intercept &amp;lt;- 200
&amp;gt; nBlock &amp;lt;- 35
&amp;gt; nTime &amp;lt;- 10
&amp;gt; sigma &amp;lt;- 50
&amp;gt; sigma.block &amp;lt;- 30
&amp;gt; n &amp;lt;- nBlock*nTime
&amp;gt; Block &amp;lt;- gl(nBlock, k=1)
&amp;gt; Time &amp;lt;- 1:10
&amp;gt; rho &amp;lt;- 0.8
&amp;gt; dt &amp;lt;- expand.grid(Time=Time,Block=Block)
&amp;gt; Xmat &amp;lt;- model.matrix(~-1+Block + Time, data=dt)
&amp;gt; block.effects &amp;lt;- rnorm(n = nBlock, mean = intercept, sd = sigma.block)
&amp;gt; #A.effects &amp;lt;- c(30,40)
&amp;gt; all.effects &amp;lt;- c(block.effects,slope)
&amp;gt; lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; # OR
&amp;gt; Xmat &amp;lt;- cbind(model.matrix(~-1+Block,data=dt),model.matrix(~Time,data=dt))
&amp;gt; ## Sum to zero block effects
&amp;gt; ##block.effects &amp;lt;- rnorm(n = nBlock, mean = 0, sd = sigma.block)
&amp;gt; ###A.effects &amp;lt;- c(40,70,80)
&amp;gt; ##all.effects &amp;lt;- c(block.effects,intercept,slope)
&amp;gt; ##lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; ## the quadrat observations (within sites) are drawn from
&amp;gt; ## normal distributions with means according to the site means
&amp;gt; ## and standard deviations of 5
&amp;gt; eps &amp;lt;- NULL
&amp;gt; eps[1] &amp;lt;- 0
&amp;gt; for (j in 2:n) {
+   eps[j] &amp;lt;- rho*eps[j-1] #residuals
+ }
&amp;gt; y &amp;lt;- rnorm(n,lin.pred,sigma)+eps
&amp;gt; 
&amp;gt; #OR
&amp;gt; eps &amp;lt;- NULL
&amp;gt; # first value cant be autocorrelated
&amp;gt; eps[1] &amp;lt;- rnorm(1,0,sigma)
&amp;gt; for (j in 2:n) {
+   eps[j] &amp;lt;- rho*eps[j-1] + rnorm(1, mean = 0, sd = sigma)  #residuals
+ }
&amp;gt; y &amp;lt;- lin.pred + eps
&amp;gt; data.rm &amp;lt;- data.frame(y=y, dt)
&amp;gt; head(data.rm)  #print out the first six rows of the data set
         y Time Block
1 282.1142    1     1
2 321.1404    2     1
3 278.7700    3     1
4 285.8709    4     1
5 336.6390    5     1
6 333.5961    6     1
&amp;gt; 
&amp;gt; ggplot(data.rm, aes(y=y, x=Time)) + geom_smooth(method=&amp;#39;lm&amp;#39;) + geom_point() + facet_wrap(~Block)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/generate_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y~Time, data.rm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp1_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data.rm, aes(y=y, x=factor(Time))) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp1_data_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Block by within-Block interaction&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; with(data.rm, interaction.plot(Time,Block,y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data.rm, aes(y=y, x=Time, color=Block, group=Block)) + geom_line() +
+   guides(color=guide_legend(ncol=3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; residualPlots(lm(y~Block+Time, data.rm))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data_ex2-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;           Test stat Pr(&amp;gt;|Test stat|)
Block                                
Time         -0.7274           0.4675
Tukey test   -0.9809           0.3267
&amp;gt; 
&amp;gt; # the Tukey&amp;#39;s non-additivity test by itself can be obtained via an internal function
&amp;gt; # within the car package
&amp;gt; car:::tukeyNonaddTest(lm(y~Block+Time, data.rm))
      Test     Pvalue 
-0.9808606  0.3266615 
&amp;gt; 
&amp;gt; # alternatively, there is also a Tukey&amp;#39;s non-additivity test within the
&amp;gt; # asbio package
&amp;gt; with(data.rm,tukey.add.test(y,Time,Block))

Tukey&amp;#39;s one df test for additivity 
F = 0.3997341   Denom df = 305    p-value = 0.5277003&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there is no visual or inferential evidence of any major interactions between Block and the within-Block effect (Time). Any trends appear to be reasonably consistent between Blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Sphericity&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Since the levels of Time cannot be randomly assigned, it is likely that sphericity is not met. We can explore whether there is an auto-correlation patterns in the residuals. Note, as there was only ten time periods, it does not make logical sense to explore lags above &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(nlme)
&amp;gt; data.rm.lme &amp;lt;- lme(y~Time, random=~1|Block, data=data.rm)
&amp;gt; acf(resid(data.rm.lme), lag=10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp3_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;The autocorrelation factor (ACF) at a range of lags up to &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;, indicate that there is a cyclical pattern of residual auto-correlation. We really should explore incorporating some form of correlation structure into our model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;full-effect-parameterisation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full effect parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- beta0 + beta*Time[i] + gamma[Block[i]]
+       res[i] &amp;lt;- y[i]-mu[i]
+    }
+    
+    #Priors
+    beta0 ~ dnorm(0, 1.0E-6)
+    beta ~ dnorm(0, 1.0E-6) #prior
+    
+    for (i in 1:nBlock) {
+      gamma[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;- z/sqrt(chSq) 
+    z ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;- z/sqrt(chSq.B) 
+    z.B ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.B ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;fullModel2.txt&amp;quot;)
&amp;gt; 
&amp;gt; data.rm.list &amp;lt;- with(data.rm,
+         list(y=y,
+                  Block=as.numeric(Block),
+          Time=Time,
+          n=nrow(data.rm),
+          nBlock=length(levels(Block))
+              )
+ )
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;,&amp;#39;gamma&amp;#39;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;quot;res&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.rm.r2jags.f &amp;lt;- jags(data = data.rm.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;fullModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 350
   Unobserved stochastic nodes: 41
   Total graph size: 1815

Initializing model
&amp;gt; 
&amp;gt; print(data.rm.r2jags.f)
Inference for Bugs model at &amp;quot;fullModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
           mu.vect sd.vect     2.5%      25%      50%      75%    97.5%  Rhat
beta        30.689   1.047   28.609   30.017   30.687   31.401   32.705 1.001
beta0      189.009  12.648  164.589  180.318  189.054  197.523  213.976 1.001
gamma[1]   -35.015  20.219  -74.991  -47.706  -35.021  -21.382    3.826 1.002
gamma[2]   -52.026  20.114  -91.663  -65.012  -52.008  -38.575  -12.685 1.001
gamma[3]    20.417  19.878  -19.313    7.462   20.587   33.579   60.228 1.001
gamma[4]     0.671  20.295  -38.799  -12.839    0.882   14.490   39.807 1.001
gamma[5]    67.812  19.967   29.683   54.189   67.514   81.150  109.392 1.001
gamma[6]    36.338  19.760   -2.575   22.780   36.203   49.381   76.772 1.001
gamma[7]    24.072  20.155  -14.701   10.740   24.009   36.728   63.397 1.001
gamma[8]   -31.199  20.016  -70.564  -44.687  -31.149  -17.691    7.011 1.001
gamma[9]    73.971  20.034   35.053   60.309   73.846   87.726  113.132 1.003
gamma[10]   58.034  19.900   19.397   44.730   58.085   71.380   97.283 1.001
gamma[11]  141.644  20.387  101.956  127.950  141.240  154.897  181.751 1.001
gamma[12]    5.655  20.094  -32.833   -7.787    5.349   19.065   47.017 1.001
gamma[13]  -44.187  20.168  -84.778  -57.576  -44.641  -30.571   -5.599 1.001
gamma[14]  -23.866  19.908  -63.673  -37.311  -23.653  -10.578   14.435 1.001
gamma[15]   30.407  20.239   -8.109   16.928   30.379   43.830   70.587 1.001
gamma[16]  103.433  20.123   64.608   90.052  103.087  116.736  143.495 1.002
gamma[17]   91.556  20.060   53.115   77.561   91.725  104.473  131.814 1.002
gamma[18]  -63.563  20.127 -102.913  -77.195  -63.210  -50.190  -24.916 1.002
gamma[19]   16.404  19.820  -21.892    2.880   16.232   29.420   55.497 1.001
gamma[20]  -26.858  19.837  -66.283  -39.890  -26.676  -13.651   12.760 1.002
gamma[21] -104.771  19.743 -143.174 -117.701 -105.347  -92.448  -64.620 1.001
gamma[22]  -14.307  19.903  -54.617  -27.704  -14.041   -0.901   23.918 1.001
gamma[23]  -81.493  19.863 -121.932  -94.860  -81.367  -67.618  -43.350 1.001
gamma[24]  -86.520  20.067 -125.826 -100.133  -86.297  -73.003  -47.481 1.001
gamma[25]  -47.166  20.417  -86.549  -61.568  -47.155  -33.479   -6.020 1.001
gamma[26]  -92.375  19.497 -130.380 -105.540  -92.310  -79.043  -54.017 1.002
gamma[27]   20.875  20.031  -18.328    6.625   20.873   34.275   60.661 1.002
gamma[28]   74.464  19.909   36.179   61.091   74.369   87.433  114.480 1.001
gamma[29]   -0.792  19.771  -39.202  -14.402   -0.589   12.677   36.999 1.001
gamma[30]  -75.855  20.350 -116.077  -89.286  -76.179  -62.465  -35.911 1.001
gamma[31]  -58.457  20.104  -97.479  -72.394  -58.390  -44.695  -19.492 1.001
gamma[32]  -53.274  20.080  -91.482  -66.984  -53.201  -40.309  -13.057 1.001
gamma[33]   15.405  20.131  -22.770    1.695   15.048   28.831   55.869 1.001
gamma[34]   59.338  20.334   19.750   45.810   59.517   72.790   99.194 1.001
gamma[35]   56.933  20.301   15.197   43.906   57.388   70.588   94.583 1.001
res[1]      97.432  17.921   62.629   85.359   97.337  109.111  134.580 1.002
res[2]     105.769  17.698   71.182   93.805  105.826  117.408  142.144 1.002
res[3]      32.710  17.534   -1.148   20.909   32.522   44.178   68.460 1.002
res[4]       9.121  17.431  -23.865   -2.637    8.871   20.532   44.239 1.002
res[5]      29.201  17.391   -4.021   17.641   28.835   40.540   64.071 1.002
res[6]      -4.531  17.414  -38.094  -16.092   -4.863    6.832   30.205 1.002
res[7]    -107.185  17.500 -140.651 -118.950 -107.516  -95.741  -72.125 1.002
res[8]     -37.350  17.647  -71.015  -49.217  -37.556  -25.708   -1.746 1.002
res[9]     -67.307  17.855 -101.635  -79.246  -67.326  -55.699  -31.035 1.002
res[10]    -78.614  18.121 -113.985  -90.735  -78.654  -66.764  -42.063 1.002
res[11]     49.884  18.193   13.728   37.834   50.102   61.789   84.845 1.001
res[12]     11.595  17.930  -23.183   -0.446   11.692   23.269   46.321 1.001
res[13]     61.820  17.726   27.566   49.860   61.924   73.375   96.299 1.001
res[14]     -3.458  17.582  -37.401  -15.192   -3.465    8.046   30.969 1.001
res[15]    -10.511  17.499  -44.587  -21.767  -10.459    1.089   24.112 1.001
res[16]     -2.243  17.479  -36.572  -13.604   -2.049    9.337   32.255 1.001
res[17]    -50.520  17.522  -85.179  -61.867  -50.373  -38.782  -16.278 1.001
res[18]    -62.585  17.627  -97.953  -73.969  -62.501  -50.564  -28.305 1.001
res[19]    -42.079  17.792  -77.762  -53.482  -42.166  -30.142   -7.621 1.001
res[20]      9.165  18.018  -26.988   -2.455    9.147   21.271   43.778 1.001
res[21]    -77.926  17.501 -113.047  -89.469  -78.006  -66.052  -43.688 1.002
res[22]    -73.189  17.257 -108.057  -84.536  -73.411  -61.442  -39.850 1.002
res[23]    -14.228  17.075  -48.379  -25.553  -14.413   -2.773   18.665 1.002
res[24]    -31.958  16.955  -66.594  -43.263  -32.141  -20.655    0.554 1.002
res[25]     -7.975  16.900  -42.439  -19.028   -8.192    3.408   24.762 1.002
res[26]     24.320  16.909   -9.262   13.308   24.202   35.576   57.313 1.002
res[27]     38.799  16.983    5.216   27.563   38.571   50.247   72.421 1.002
res[28]     69.516  17.120   35.582   58.330   69.291   80.872  103.259 1.002
res[29]     55.153  17.321   20.895   43.887   54.848   66.615   89.335 1.002
res[30]     28.976  17.581   -5.726   17.342   28.565   40.577   63.635 1.002
res[31]   -121.587  17.872 -156.152 -133.567 -121.526 -109.634  -87.382 1.001
res[32]   -100.256  17.618 -133.884 -111.966 -100.063  -88.659  -66.409 1.001
res[33]    -57.168  17.423  -90.542  -68.902  -57.110  -45.627  -22.964 1.001
res[34]    -17.580  17.290  -51.232  -29.462  -17.603   -6.075   16.449 1.001
res[35]    -40.581  17.219  -74.430  -52.498  -40.599  -29.045   -6.738 1.001
res[36]     57.619  17.212   23.794   45.812   57.457   69.114   91.210 1.001
res[37]     61.388  17.269   27.008   49.782   61.277   72.884   95.367 1.004
res[38]     56.259  17.389   21.473   44.753   56.294   67.702   90.416 1.001
res[39]    109.316  17.570   73.992   97.577  109.390  120.643  143.528 1.001
res[40]     52.088  17.811   16.206   39.944   52.135   63.655   86.709 1.001
res[41]    -38.914  17.643  -73.656  -50.658  -38.634  -26.860   -5.046 1.001
res[42]     77.326  17.420   42.616   65.720   77.575   89.215  111.120 1.001
res[43]     50.865  17.258   16.915   39.497   51.222   62.617   84.564 1.001
res[44]    110.679  17.159   76.469   99.239  111.186  122.203  144.204 1.001
res[45]      4.790  17.122  -29.711   -6.616    5.343   16.301   38.330 1.001
res[46]    -17.661  17.150  -52.491  -29.227  -17.113   -5.957   16.017 1.001
res[47]     -7.311  17.242  -42.494  -18.933   -6.757    4.462   26.166 1.001
res[48]     -3.089  17.396  -38.865  -14.616   -2.473    8.846   31.113 1.001
res[49]    -65.133  17.611 -101.697  -76.777  -64.519  -53.174  -30.398 1.001
res[50]    -63.661  17.886 -100.707  -75.693  -63.048  -51.501  -28.264 1.001
res[51]    -31.518  17.144  -65.465  -43.209  -31.355  -19.712    1.672 1.001
res[52]     14.815  16.893  -18.897    3.470   14.776   26.305   47.890 1.001
res[53]     70.347  16.704   36.921   58.939   70.092   81.766  102.877 1.001
res[54]    -50.853  16.579  -83.834  -62.055  -51.073  -39.619  -18.942 1.001
res[55]     25.083  16.520   -8.057   14.027   24.935   36.357   56.754 1.001
res[56]    -38.143  16.527  -71.222  -49.423  -38.357  -26.836   -6.450 1.001
res[57]     -4.070  16.600  -36.763  -15.317   -4.236    7.197   27.724 1.001
res[58]     33.306  16.738    0.513   22.191   33.191   44.522   65.598 1.001
res[59]     20.080  16.940  -12.937    8.828   19.836   31.550   52.764 1.001
res[60]    -12.900  17.204  -46.161  -24.276  -13.088   -1.463   20.472 1.001
res[61]    -17.368  17.885  -51.348  -29.241  -17.425   -5.291   18.072 1.001
res[62]      7.369  17.652  -26.193   -4.253    7.234   19.236   42.448 1.001
res[63]     49.245  17.479   15.639   37.647   49.046   60.880   83.698 1.001
res[64]    -64.174  17.368  -97.742  -75.711  -64.357  -52.534  -30.120 1.001
res[65]   -134.249  17.320 -167.266 -146.107 -134.437 -122.586 -100.604 1.001
res[66]    -37.107  17.334  -70.680  -48.991  -37.270  -25.543   -3.298 1.001
res[67]     21.279  17.412  -12.492    9.532   21.267   33.096   55.105 1.001
res[68]     37.284  17.552    3.245   25.564   37.265   49.184   71.420 1.001
res[69]     63.944  17.753   29.095   52.068   63.864   75.938   98.781 1.001
res[70]     95.234  18.013   60.203   83.123   95.270  107.455  130.632 1.001
res[71]    -48.396  17.620  -83.102  -60.471  -48.230  -36.426  -13.894 1.001
res[72]     16.818  17.403  -17.131    4.932   16.936   28.621   50.566 1.001
res[73]    -10.912  17.247  -44.871  -22.609  -10.795    0.606   22.307 1.001
res[74]      2.547  17.154  -31.372   -8.982    2.664   14.012   35.509 1.001
res[75]    -13.113  17.125  -47.212  -24.603  -12.951   -1.578   20.054 1.001
res[76]     32.577  17.159   -1.807   20.989   32.596   44.219   65.805 1.001
res[77]      7.970  17.257  -27.008   -3.791    7.911   19.682   41.186 1.001
res[78]     31.495  17.418   -3.602   19.914   31.400   43.395   65.506 1.001
res[79]      4.718  17.639  -30.550   -6.860    4.806   16.702   39.109 1.001
res[80]    -51.946  17.919  -87.119  -63.726  -51.922  -39.897  -17.025 1.001
res[81]    -63.210  17.647  -97.791  -75.690  -63.212  -51.190  -29.440 1.002
res[82]    -31.067  17.390  -65.386  -43.236  -31.079  -19.273    2.374 1.002
res[83]     43.678  17.193    9.558   31.772   43.540   55.495   76.981 1.002
res[84]     20.380  17.058  -13.497    8.805   20.360   32.176   53.934 1.002
res[85]     54.597  16.986   21.096   43.276   54.749   66.249   87.971 1.002
res[86]    124.353  16.979   90.938  113.063  124.583  135.902  157.927 1.002
res[87]     67.176  17.037   33.903   55.809   67.439   78.691  101.104 1.002
res[88]    -30.778  17.158  -64.046  -42.370  -30.407  -19.292    2.913 1.002
res[89]    -55.098  17.342  -88.751  -66.851  -54.716  -43.392  -21.208 1.002
res[90]    -73.427  17.586 -107.590  -85.203  -73.116  -61.615  -38.693 1.002
res[91]    -39.879  17.759  -75.389  -51.772  -39.985  -28.068   -4.896 1.001
res[92]     40.803  17.486    5.829   29.249   40.623   52.320   75.462 1.001
res[93]      3.288  17.272  -30.880   -8.346    3.017   14.813   37.091 1.001
res[94]      8.096  17.120  -26.071   -3.487    7.840   19.496   41.421 1.001
res[95]    -18.230  17.031  -51.683  -29.609  -18.372   -6.678   14.819 1.001
res[96]    -27.022  17.006  -60.187  -38.426  -27.134  -15.863    6.296 1.001
res[97]    -19.513  17.045  -52.825  -30.880  -19.632   -8.423   13.668 1.001
res[98]     37.064  17.149    3.831   25.570   37.124   48.265   70.659 1.001
res[99]     21.843  17.315  -12.203   10.180   21.878   33.093   55.675 1.001
res[100]    39.105  17.542    5.025   27.487   38.948   50.788   73.056 1.001
res[101]    29.449  17.991   -5.205   17.155   29.781   41.807   63.442 1.001
res[102]    49.685  17.766   15.218   37.673   50.072   61.814   82.819 1.001
res[103]    -8.723  17.601  -43.029  -20.739   -8.303    3.244   24.590 1.001
res[104]    54.477  17.498   20.833   42.653   54.759   66.407   87.773 1.001
res[105]     4.508  17.456  -29.390   -7.159    4.817   16.421   37.676 1.001
res[106]   -21.847  17.477  -55.720  -33.395  -21.535   -9.860   11.772 1.001
res[107]    32.423  17.561   -2.084   20.791   32.811   44.448   66.578 1.001
res[108]    70.203  17.706   35.619   58.406   70.311   82.156  104.571 1.001
res[109]   -18.915  17.912  -54.616  -30.740  -18.911   -6.868   15.481 1.001
res[110]   -79.501  18.176 -115.834  -91.501  -79.578  -67.080  -44.590 1.001
res[111]   -35.407  17.785  -70.692  -46.976  -35.584  -23.160   -0.930 1.001
res[112]   -16.834  17.533  -51.394  -28.356  -17.011   -4.647   17.012 1.001
res[113]    -2.964  17.342  -37.311  -14.283   -3.253    9.068   30.829 1.001
res[114]    17.958  17.211  -16.244    6.888   17.697   29.740   51.566 1.001
res[115]    43.960  17.144    9.743   32.909   43.779   55.749   77.773 1.002
res[116]     6.922  17.141  -27.302   -4.089    6.746   18.522   41.245 1.002
res[117]   -42.437  17.202  -76.634  -53.389  -42.592  -31.097   -7.471 1.002
res[118]    18.962  17.325  -15.305    7.723   18.882   30.432   53.655 1.003
res[119]    54.157  17.511   19.505   42.669   54.007   65.841   88.924 1.003
res[120]   -30.836  17.757  -66.091  -42.472  -31.031  -18.943    4.597 1.003
res[121]    29.694  17.913   -5.583   17.603   29.789   41.163   65.302 1.001
res[122]    -8.428  17.668  -42.894  -20.446   -8.260    2.790   26.838 1.001
res[123]   -97.805  17.483 -132.040 -109.658  -97.722  -86.688  -63.003 1.001
res[124]   -58.400  17.360  -92.551  -70.268  -58.013  -47.184  -24.118 1.001
res[125]   -38.480  17.298  -72.858  -50.159  -38.072  -27.272   -4.162 1.001
res[126]   -23.590  17.301  -58.378  -35.298  -23.103  -12.266   10.906 1.001
res[127]     3.860  17.366  -31.068   -7.655    4.299   15.220   38.206 1.001
res[128]    58.998  17.494   23.758   47.395   59.472   70.391   93.062 1.001
res[129]    69.127  17.683   33.354   57.321   69.673   80.505  103.147 1.001
res[130]    35.991  17.931   -0.747   24.279   36.423   47.825   70.397 1.001
res[131]   -18.707  17.753  -53.599  -30.549  -18.607   -6.714   16.819 1.003
res[132]   -14.747  17.516  -48.954  -26.537  -14.555   -2.845   20.061 1.003
res[133]    10.374  17.340  -23.749   -1.370   10.597   22.133   44.664 1.003
res[134]   -37.152  17.225  -70.611  -48.839  -37.026  -25.712   -3.136 1.002
res[135]   -32.541  17.174  -65.860  -44.108  -32.536  -21.077    1.265 1.002
res[136]    28.588  17.186   -4.848   17.066   28.625   39.992   62.044 1.002
res[137]    23.576  17.262  -10.078   11.987   23.698   35.092   57.117 1.002
res[138]   -10.078  17.401  -43.670  -21.709   -9.920    1.610   23.933 1.001
res[139]   -16.016  17.601  -49.961  -27.799  -15.770   -4.358   18.774 1.001
res[140]    48.626  17.861   14.303   36.410   48.905   60.610   83.764 1.001
res[141]     4.593  17.780  -29.625   -7.191    4.424   16.505   38.788 1.001
res[142]    57.463  17.544   23.749   45.968   57.368   69.300   91.358 1.001
res[143]    44.743  17.368   11.543   33.225   44.780   56.414   78.495 1.001
res[144]    47.987  17.253   14.659   36.564   48.140   59.625   81.776 1.001
res[145]     2.009  17.202  -31.053   -9.596    2.094   13.679   35.963 1.001
res[146]    23.279  17.214   -9.893   11.605   23.253   34.820   57.175 1.001
res[147]   -15.427  17.290  -49.433  -27.118  -15.449   -4.007   19.070 1.001
res[148]   -92.242  17.428 -126.419 -104.123  -92.223  -80.822  -57.405 1.001
res[149]   -76.403  17.628 -110.319  -88.293  -76.440  -64.957  -41.280 1.001
res[150]    27.022  17.887   -7.788   14.991   26.934   38.901   62.553 1.001
res[151]    56.524  17.435   23.497   44.650   56.376   68.008   91.937 1.002
res[152]    94.888  17.193   62.473   83.265   94.748  106.107  129.551 1.001
res[153]    85.122  17.012   53.069   73.707   84.983   96.084  119.032 1.001
res[154]    28.800  16.893   -3.079   17.754   28.668   39.844   62.380 1.001
res[155]     3.921  16.839  -28.102   -7.248    3.904   15.053   37.301 1.001
res[156]   -19.671  16.850  -51.711  -30.814  -19.649   -8.511   13.270 1.001
res[157]   -48.454  16.926  -81.115  -59.563  -48.405  -37.301  -15.678 1.001
res[158]   -12.976  17.067  -46.088  -24.257  -12.925   -1.706   20.012 1.001
res[159]   -79.807  17.269 -113.216  -91.035  -79.682  -68.569  -46.865 1.001
res[160]   -30.224  17.532  -64.395  -41.789  -29.847  -18.816    2.893 1.001
res[161]   -10.710  17.984  -46.042  -22.979  -10.276    1.572   24.298 1.002
res[162]   -82.452  17.740 -118.119  -94.601  -82.059  -70.317  -47.916 1.002
res[163]   -48.077  17.555  -83.627  -59.974  -47.795  -35.994  -13.951 1.002
res[164]    68.821  17.431   33.752   56.976   68.995   80.691  102.233 1.005
res[165]    12.830  17.369  -22.123    1.019   12.897   24.719   45.628 1.002
res[166]    38.006  17.370    3.280   26.085   37.983   49.937   71.003 1.002
res[167]   -23.347  17.435  -58.240  -35.377  -23.237  -11.414    9.865 1.002
res[168]    22.078  17.561  -13.256    9.887   22.185   34.157   55.218 1.001
res[169]    15.237  17.749  -20.525    3.105   15.325   27.296   48.552 1.001
res[170]    79.730  17.996   43.542   67.295   79.674   91.820  113.635 1.002
res[171]    63.717  17.877   28.767   51.218   63.625   75.992   98.346 1.002
res[172]    50.693  17.611   16.356   38.398   50.624   62.696   84.475 1.001
res[173]    16.355  17.405  -17.386    4.388   16.412   28.087   49.899 1.001
res[174]     5.229  17.259  -28.246   -6.690    5.281   16.848   38.937 1.001
res[175]   -25.424  17.176  -58.537  -37.419  -25.426  -13.955    7.970 1.001
res[176]   -60.299  17.157  -93.240  -72.218  -60.299  -48.754  -26.651 1.001
res[177]   -17.707  17.202  -50.497  -29.605  -17.777   -6.222   15.477 1.001
res[178]   -67.087  17.310  -99.859  -79.145  -67.067  -55.435  -33.398 1.001
res[179]    21.851  17.480  -10.981    9.770   21.871   33.713   56.070 1.001
res[180]   -40.647  17.711  -73.957  -52.771  -40.513  -28.613   -5.841 1.001
res[181]   -19.458  17.542  -54.333  -31.085  -19.422   -7.722   15.640 1.001
res[182]    13.382  17.297  -20.657    2.031   13.446   24.888   47.985 1.001
res[183]    42.203  17.113    8.488   30.978   42.207   53.606   75.709 1.001
res[184]    20.699  16.991  -12.648    9.734   20.572   32.070   53.897 1.001
res[185]    22.419  16.933  -10.796   11.505   22.206   33.885   55.335 1.001
res[186]    67.746  16.941   34.410   57.004   67.445   79.392  100.423 1.001
res[187]   -17.017  17.012  -50.239  -27.920  -17.298   -5.427   15.763 1.001
res[188]   -51.228  17.148  -84.441  -62.328  -51.548  -39.688  -18.069 1.001
res[189]   -23.628  17.345  -57.805  -34.767  -23.760  -11.997   10.684 1.001
res[190]   -39.945  17.603  -74.634  -51.215  -40.154  -28.208   -5.214 1.001
res[191]    52.530  17.512   18.626   41.139   52.206   64.088   87.150 1.006
res[192]    79.593  17.246   46.248   68.448   79.388   91.100  113.049 1.017
res[193]    71.051  17.040   37.868   59.980   70.793   82.571  104.153 1.021
res[194]   -14.917  16.897  -48.034  -25.902  -15.296   -3.462   18.041 1.005
res[195]    -7.135  16.817  -39.943  -18.047   -7.544    4.215   25.897 1.005
res[196]   -18.174  16.803  -51.133  -29.182  -18.623   -6.895   14.827 1.005
res[197]   -16.439  16.854  -48.969  -27.463  -16.762   -5.147   16.557 1.004
res[198]   -69.150  16.970 -102.173  -80.328  -69.361  -57.572  -35.980 1.004
res[199]   -27.445  17.149  -60.854  -38.683  -27.690  -15.800    6.299 1.003
res[200]   -71.100  17.389 -104.684  -82.727  -71.394  -59.189  -37.691 1.003
res[201]     1.426  17.309  -34.407   -9.571    1.332   12.962   35.011 1.001
res[202]    36.131  17.046    0.771   25.266   36.227   47.347   69.464 1.001
res[203]     5.510  16.844  -28.967   -5.374    5.685   16.535   38.753 1.001
res[204]    49.200  16.705   15.453   38.505   49.435   60.187   82.079 1.001
res[205]   -10.960  16.631  -44.546  -21.713  -10.492   -0.147   21.703 1.001
res[206]  -133.889  16.623 -167.539 -144.693 -133.301 -123.036 -101.431 1.001
res[207]   -68.634  16.681 -102.616  -79.683  -67.975  -57.769  -36.182 1.001
res[208]     2.212  16.804  -31.897   -8.838    2.830   13.283   34.752 1.001
res[209]     2.431  16.991  -31.627   -8.767    3.000   13.550   35.269 1.001
res[210]    41.968  17.240    6.811   30.539   42.440   53.467   75.061 1.001
res[211]   -67.622  17.508 -102.075  -79.236  -67.541  -56.136  -32.937 1.001
res[212]   -57.530  17.266  -91.092  -68.962  -57.500  -46.025  -22.873 1.001
res[213]  -140.313  17.084 -173.718 -151.700 -140.155 -128.926 -105.859 1.002
res[214]   -50.542  16.964  -83.840  -61.841  -50.386  -39.139  -16.241 1.002
res[215]    55.074  16.909   22.122   43.726   55.352   66.374   89.195 1.002
res[216]   100.133  16.919   67.118   88.860  100.592  111.422  133.899 1.002
res[217]    80.975  16.993   48.141   69.704   81.338   92.108  115.080 1.002
res[218]    65.212  17.132   32.285   53.430   65.470   76.536  100.152 1.001
res[219]   -21.674  17.332  -55.118  -33.640  -21.456  -10.022   13.856 1.002
res[220]    24.003  17.593   -9.530   11.811   24.101   35.907   59.852 1.002
res[221]    60.185  17.783   25.820   48.457   59.813   72.436   96.171 1.001
res[222]    26.825  17.539   -6.907   15.267   26.510   38.780   62.320 1.001
res[223]   -37.765  17.355  -71.270  -49.250  -38.173  -25.946   -2.142 1.001
res[224]   -33.962  17.232  -67.496  -45.390  -34.499  -22.046    1.130 1.001
res[225]   -58.522  17.173  -91.829  -70.044  -59.083  -46.732  -23.657 1.001
res[226]   -55.706  17.177  -88.390  -67.397  -56.263  -44.042  -21.182 1.001
res[227]   -94.620  17.245 -127.457 -106.411  -95.119  -82.969  -60.749 1.001
res[228]    19.371  17.375  -13.948    7.607   19.044   31.010   53.459 1.001
res[229]    25.246  17.568   -8.529   13.626   24.828   37.075   59.410 1.001
res[230]    84.355  17.820   50.467   72.405   83.982   96.570  118.968 1.001
res[231]   -31.497  18.030  -66.696  -43.447  -31.785  -19.738    3.853 1.001
res[232]   -33.555  17.750  -68.255  -45.064  -33.695  -22.067    1.221 1.001
res[233]   -46.454  17.529  -80.525  -58.085  -46.585  -35.121  -11.905 1.001
res[234]   -84.283  17.368 -118.128  -95.729  -84.398  -73.094  -50.480 1.001
res[235]    23.792  17.270   -9.429   12.004   23.713   34.911   57.625 1.001
res[236]   -37.979  17.234  -71.525  -49.693  -38.039  -26.826   -3.726 1.001
res[237]    -0.851  17.262  -34.217  -12.666   -0.823   10.179   33.380 1.001
res[238]    55.116  17.354   21.132   43.276   55.278   66.313   89.932 1.001
res[239]    66.340  17.507   31.871   54.397   66.435   77.816  102.154 1.001
res[240]    22.509  17.721  -12.331   10.444   22.467   34.188   58.690 1.001
res[241]    48.779  17.985   13.144   36.603   49.101   61.358   82.744 1.001
res[242]    54.607  17.728   19.723   42.634   54.853   67.014   88.097 1.001
res[243]    -2.573  17.531  -36.920  -14.310   -2.250    9.522   31.153 1.001
res[244]   -64.682  17.394  -98.704  -76.398  -64.353  -52.693  -31.136 1.001
res[245]    59.232  17.320   25.143   47.518   59.597   70.983   92.873 1.001
res[246]    19.963  17.309  -14.316    8.145   20.310   31.886   53.371 1.001
res[247]   -70.443  17.361 -105.373  -82.320  -70.049  -58.397  -36.717 1.001
res[248]   -23.463  17.476  -58.679  -35.360  -23.248  -11.587   10.598 1.001
res[249]     2.831  17.652  -32.482   -8.951    3.087   14.786   37.287 1.001
res[250]   -59.475  17.888  -95.014  -71.176  -59.315  -47.543  -24.802 1.001
res[251]  -118.664  17.326 -151.645 -130.208 -118.894 -107.309  -83.446 1.002
res[252]   -91.020  17.066 -123.512 -102.427  -91.199  -79.836  -57.008 1.001
res[253]    -6.258  16.868  -38.555  -17.830   -6.464    4.709   27.751 1.001
res[254]    36.251  16.734    4.248   24.639   35.981   47.226   70.217 1.001
res[255]    13.667  16.664  -18.023    2.118   13.400   24.523   47.428 1.001
res[256]   -21.601  16.659  -53.042  -33.062  -21.878  -10.646   12.267 1.001
res[257]     5.310  16.721  -26.340   -6.021    5.033   16.411   39.015 1.001
res[258]    21.015  16.847  -10.852    9.662   20.790   32.193   55.145 1.001
res[259]    57.059  17.037   24.518   45.611   56.831   68.241   92.442 1.002
res[260]    34.481  17.288    1.254   23.094   34.411   45.908   70.086 1.001
res[261]    50.413  17.715   15.780   38.279   50.907   62.488   84.294 1.002
res[262]     1.013  17.462  -32.559  -11.003    1.463   13.068   33.840 1.002
res[263]   -13.632  17.268  -46.927  -25.466  -13.251   -1.826   18.917 1.002
res[264]    28.083  17.137   -5.178   16.694   28.340   39.623   60.566 1.003
res[265]    73.774  17.069   40.522   62.477   73.840   85.174  106.109 1.003
res[266]   -36.234  17.065  -69.304  -47.505  -35.963  -24.747   -3.793 1.003
res[267]   -22.093  17.125  -55.763  -33.330  -21.828  -10.616   10.070 1.003
res[268]    14.160  17.249  -19.827    3.041   14.507   25.776   46.182 1.003
res[269]   -59.954  17.435  -93.778  -71.235  -59.514  -48.101  -27.315 1.003
res[270]   -22.812  17.681  -57.121  -34.293  -22.324  -10.851   10.918 1.003
res[271]  -125.907  17.458 -160.933 -137.188 -125.802 -114.461  -92.053 1.001
res[272]   -62.314  17.229  -97.496  -73.416  -62.473  -50.835  -29.085 1.001
res[273]   -35.666  17.061  -70.145  -46.545  -35.800  -24.427   -3.232 1.001
res[274]    -2.957  16.956  -37.392  -13.883   -2.813    8.075   29.213 1.001
res[275]    -9.344  16.916  -43.467  -20.207   -9.343    1.681   22.885 1.001
res[276]    22.554  16.940  -11.628   11.868   22.593   33.645   54.629 1.001
res[277]    73.779  17.029   39.473   63.039   73.780   84.850  106.184 1.001
res[278]   143.908  17.181  109.484  132.820  143.915  155.171  176.723 1.001
res[279]   100.141  17.395   65.573   88.965  100.141  111.576  133.506 1.001
res[280]   -46.044  17.669  -80.667  -57.400  -45.955  -34.590  -12.407 1.001
res[281]    -5.699  17.595  -39.468  -17.381   -5.770    5.983   28.301 1.001
res[282]     0.419  17.343  -33.174  -10.923    0.288   11.974   34.262 1.001
res[283]   -12.869  17.152  -46.211  -24.317  -13.049   -1.401   20.398 1.001
res[284]    12.545  17.023  -20.331    1.056   12.458   24.113   45.686 1.001
res[285]    54.857  16.958   22.320   43.310   54.741   66.049   88.406 1.001
res[286]    12.136  16.958  -20.207    0.644   11.947   23.530   45.348 1.001
res[287]   -10.984  17.022  -43.192  -22.616  -10.977    0.294   22.275 1.001
res[288]     4.979  17.150  -27.724   -6.762    5.048   16.454   38.007 1.001
res[289]   -29.791  17.340  -62.952  -41.651  -29.779  -18.299    3.958 1.001
res[290]   -25.671  17.591  -59.797  -37.708  -25.457  -14.066    8.558 1.001
res[291]    28.550  17.963   -7.697   16.728   28.845   40.812   62.212 1.001
res[292]    -9.089  17.712  -45.024  -20.553   -8.933    2.924   24.333 1.001
res[293]   -49.732  17.521  -85.124  -61.052  -49.636  -38.060  -16.508 1.001
res[294]   -58.677  17.390  -93.259  -69.572  -58.567  -47.134  -25.799 1.001
res[295]   -57.955  17.322  -92.707  -68.933  -57.842  -46.344  -25.049 1.001
res[296]    -3.734  17.317  -38.668  -14.858   -3.653    7.873   29.033 1.001
res[297]    69.494  17.375   34.053   58.293   69.643   81.139  102.719 1.001
res[298]    42.465  17.496    6.356   31.206   42.578   54.056   75.774 1.001
res[299]     7.231  17.678  -29.387   -4.288    7.395   19.167   40.819 1.001
res[300]   -23.337  17.919  -60.558  -34.994  -23.228  -11.302   10.882 1.001
res[301]   -51.903  17.982  -88.248  -63.876  -52.309  -39.714  -17.303 1.001
res[302]   -37.852  17.747  -73.574  -49.599  -38.337  -25.637   -3.466 1.001
res[303]     9.383  17.571  -25.880   -2.168    9.060   21.337   43.272 1.001
res[304]     6.786  17.457  -27.982   -4.692    6.466   18.794   40.534 1.001
res[305]   -83.287  17.404 -117.576  -94.688  -83.511  -71.384  -50.132 1.001
res[306]   -56.131  17.415  -90.605  -67.604  -56.382  -44.092  -22.768 1.001
res[307]    29.387  17.488   -5.255   17.630   29.168   41.485   62.770 1.001
res[308]    97.884  17.624   63.110   86.054   97.739  110.020  131.499 1.001
res[309]    53.516  17.820   18.505   41.582   53.468   65.807   87.676 1.001
res[310]   -20.057  18.074  -55.492  -32.169  -20.032   -7.574   14.442 1.001
res[311]   101.300  17.549   67.220   89.168  101.137  113.302  135.233 1.001
res[312]    83.175  17.312   49.506   71.360   82.808   95.098  116.774 1.001
res[313]    71.785  17.135   37.980   60.064   71.677   83.600  105.227 1.001
res[314]    88.437  17.022   55.339   76.901   88.506  100.014  122.116 1.001
res[315]    -0.110  16.972  -33.336  -11.341    0.071   11.200   33.192 1.001
res[316]   -26.794  16.987  -60.411  -38.159  -26.771  -15.599    6.418 1.001
res[317]   -88.891  17.067 -122.585 -100.389  -88.824  -77.593  -55.404 1.001
res[318]   -96.339  17.209 -130.866 -107.673  -96.328  -84.910  -62.716 1.001
res[319]   -61.837  17.414  -96.679  -73.288  -61.840  -50.019  -28.051 1.001
res[320]  -108.552  17.679 -143.474 -120.010 -108.694  -96.508  -74.344 1.001
res[321]   -74.410  17.625 -109.575  -85.816  -74.485  -62.663  -39.753 1.001
res[322]   -41.400  17.380  -75.871  -52.760  -41.519  -29.797   -7.178 1.001
res[323]   -74.807  17.196 -108.901  -86.261  -74.760  -63.308  -41.163 1.001
res[324]   -45.144  17.074  -79.209  -56.502  -45.026  -33.729  -12.103 1.001
res[325]     4.537  17.016  -29.468   -6.710    4.542   15.856   37.618 1.001
res[326]    59.794  17.022   26.116   48.375   59.758   71.282   93.240 1.001
res[327]    40.165  17.092    6.814   28.767   40.355   51.655   73.479 1.001
res[328]    30.285  17.226   -3.464   18.692   30.679   41.872   63.673 1.001
res[329]    22.589  17.422  -10.860   10.756   23.053   34.110   56.454 1.001
res[330]    92.703  17.678   58.616   80.766   93.284  104.245  126.965 1.001
res[331]    95.283  17.977   59.650   83.167   95.192  107.412  130.221 1.001
res[332]   112.719  17.720   77.424  100.669  112.724  124.693  147.222 1.001
res[333]    70.443  17.522   35.436   58.422   70.438   82.385  104.268 1.001
res[334]    69.514  17.384   34.563   57.587   69.353   81.410  102.556 1.001
res[335]    70.134  17.309   35.643   58.219   69.855   81.817  103.521 1.001
res[336]    -1.755  17.297  -35.726  -13.635   -1.976   10.018   31.941 1.001
res[337]   -93.736  17.349 -127.604 -105.548  -93.768  -81.835  -60.000 1.001
res[338]   -48.951  17.463  -82.779  -60.869  -49.029  -36.839  -14.994 1.001
res[339]  -121.819  17.638 -156.071 -133.910 -122.015 -109.591  -87.286 1.001
res[340]  -103.701  17.874 -138.279 -115.672 -103.713  -91.305  -68.978 1.001
res[341]   -69.317  18.059 -103.485  -81.639  -69.415  -57.406  -33.457 1.001
res[342]   -32.346  17.788  -65.785  -44.511  -32.362  -20.467    2.839 1.001
res[343]   -21.629  17.575  -54.850  -33.597  -21.808   -9.882   13.449 1.001
res[344]   -59.307  17.422  -92.307  -71.080  -59.415  -47.483  -24.425 1.001
res[345]    -3.627  17.331  -36.621  -15.370   -3.984    8.092   31.060 1.001
res[346]    78.394  17.304   46.202   66.537   78.021   90.261  112.620 1.001
res[347]   100.999  17.339   68.667   89.254  100.770  113.032  135.290 1.001
res[348]   -22.296  17.438  -55.281  -34.095  -22.507  -10.328   12.264 1.001
res[349]    46.092  17.598   12.847   34.241   46.001   58.157   80.422 1.001
res[350]    27.883  17.819   -5.915   15.648   27.735   40.121   63.077 1.001
sigma       55.917   2.244   51.705   54.351   55.829   57.468   60.369 1.003
sigma.B     64.474   8.406   50.251   58.466   63.695   69.675   83.144 1.006
deviance  3809.753   9.145 3794.047 3803.114 3809.077 3815.608 3829.461 1.003
          n.eff
beta       3000
beta0      3000
gamma[1]   1800
gamma[2]   3000
gamma[3]   2100
gamma[4]   3000
gamma[5]   3000
gamma[6]   3000
gamma[7]   3000
gamma[8]   3000
gamma[9]   2800
gamma[10]  3000
gamma[11]  2100
gamma[12]  3000
gamma[13]  3000
gamma[14]  3000
gamma[15]  2500
gamma[16]  1700
gamma[17]  1700
gamma[18]  1800
gamma[19]  3000
gamma[20]  1500
gamma[21]  3000
gamma[22]  3000
gamma[23]  3000
gamma[24]  3000
gamma[25]  3000
gamma[26]  1700
gamma[27]  1500
gamma[28]  3000
gamma[29]  2300
gamma[30]  3000
gamma[31]  3000
gamma[32]  3000
gamma[33]  2500
gamma[34]  3000
gamma[35]  3000
res[1]     1100
res[2]     1000
res[3]      990
res[4]      940
res[5]      910
res[6]      880
res[7]      860
res[8]      850
res[9]      840
res[10]     840
res[11]    3000
res[12]    3000
res[13]    3000
res[14]    3000
res[15]    3000
res[16]    3000
res[17]    3000
res[18]    3000
res[19]    3000
res[20]    3000
res[21]    1200
res[22]    1200
res[23]    1100
res[24]    1000
res[25]    1000
res[26]     970
res[27]     950
res[28]    1200
res[29]     920
res[30]     920
res[31]    3000
res[32]    3000
res[33]    3000
res[34]    3000
res[35]    3000
res[36]    3000
res[37]    3000
res[38]    3000
res[39]    3000
res[40]    3000
res[41]    3000
res[42]    3000
res[43]    3000
res[44]    3000
res[45]    3000
res[46]    3000
res[47]    3000
res[48]    3000
res[49]    3000
res[50]    3000
res[51]    3000
res[52]    3000
res[53]    3000
res[54]    3000
res[55]    3000
res[56]    3000
res[57]    3000
res[58]    3000
res[59]    3000
res[60]    3000
res[61]    3000
res[62]    3000
res[63]    3000
res[64]    3000
res[65]    3000
res[66]    3000
res[67]    3000
res[68]    3000
res[69]    3000
res[70]    3000
res[71]    3000
res[72]    3000
res[73]    3000
res[74]    3000
res[75]    3000
res[76]    3000
res[77]    3000
res[78]    3000
res[79]    3000
res[80]    3000
res[81]    1100
res[82]    1100
res[83]    1000
res[84]     970
res[85]     930
res[86]     930
res[87]    1100
res[88]     860
res[89]     850
res[90]     850
res[91]    3000
res[92]    3000
res[93]    3000
res[94]    3000
res[95]    3000
res[96]    3000
res[97]    3000
res[98]    3000
res[99]    3000
res[100]   3000
res[101]   2700
res[102]   2700
res[103]   2800
res[104]   3000
res[105]   3000
res[106]   3000
res[107]   3000
res[108]   3000
res[109]   3000
res[110]   3000
res[111]   3000
res[112]   3000
res[113]   3000
res[114]   3000
res[115]   3000
res[116]   3000
res[117]   3000
res[118]   3000
res[119]   3000
res[120]   3000
res[121]   3000
res[122]   3000
res[123]   3000
res[124]   3000
res[125]   3000
res[126]   3000
res[127]   3000
res[128]   3000
res[129]   3000
res[130]   3000
res[131]   3000
res[132]   3000
res[133]   3000
res[134]   3000
res[135]   3000
res[136]   3000
res[137]   3000
res[138]   3000
res[139]   3000
res[140]   3000
res[141]   2700
res[142]   2700
res[143]   2800
res[144]   3000
res[145]   3000
res[146]   3000
res[147]   3000
res[148]   3000
res[149]   3000
res[150]   3000
res[151]   1700
res[152]   2200
res[153]   2300
res[154]   1900
res[155]   1900
res[156]   2000
res[157]   2200
res[158]   2300
res[159]   2500
res[160]   2700
res[161]   1500
res[162]   1500
res[163]   1500
res[164]   1000
res[165]   1600
res[166]   1700
res[167]   1800
res[168]   1900
res[169]   2000
res[170]   1600
res[171]   3000
res[172]   1900
res[173]   1900
res[174]   2000
res[175]   2000
res[176]   2100
res[177]   2300
res[178]   2400
res[179]   2600
res[180]   2800
res[181]   3000
res[182]   3000
res[183]   3000
res[184]   3000
res[185]   3000
res[186]   3000
res[187]   3000
res[188]   3000
res[189]   3000
res[190]   3000
res[191]   1500
res[192]    630
res[193]    570
res[194]   1600
res[195]   1700
res[196]   1800
res[197]   1900
res[198]   2000
res[199]   2100
res[200]   2300
res[201]   3000
res[202]   3000
res[203]   3000
res[204]   3000
res[205]   3000
res[206]   3000
res[207]   3000
res[208]   3000
res[209]   3000
res[210]   3000
res[211]   2000
res[212]   1900
res[213]   1700
res[214]   1600
res[215]   1600
res[216]   1700
res[217]   1700
res[218]   1900
res[219]   1400
res[220]   1400
res[221]   3000
res[222]   3000
res[223]   3000
res[224]   3000
res[225]   3000
res[226]   3000
res[227]   3000
res[228]   3000
res[229]   3000
res[230]   3000
res[231]   3000
res[232]   3000
res[233]   3000
res[234]   3000
res[235]   3000
res[236]   3000
res[237]   3000
res[238]   3000
res[239]   3000
res[240]   3000
res[241]   3000
res[242]   3000
res[243]   3000
res[244]   3000
res[245]   3000
res[246]   3000
res[247]   3000
res[248]   3000
res[249]   3000
res[250]   3000
res[251]   1800
res[252]   1800
res[253]   1900
res[254]   1900
res[255]   2000
res[256]   2100
res[257]   2200
res[258]   2400
res[259]   3000
res[260]   2800
res[261]    930
res[262]    880
res[263]    830
res[264]    790
res[265]    750
res[266]    740
res[267]    720
res[268]    710
res[269]    710
res[270]    710
res[271]   3000
res[272]   3000
res[273]   3000
res[274]   3000
res[275]   3000
res[276]   3000
res[277]   3000
res[278]   3000
res[279]   3000
res[280]   3000
res[281]   2600
res[282]   2600
res[283]   2700
res[284]   2800
res[285]   3000
res[286]   3000
res[287]   3000
res[288]   3000
res[289]   3000
res[290]   3000
res[291]   3000
res[292]   3000
res[293]   3000
res[294]   3000
res[295]   3000
res[296]   3000
res[297]   3000
res[298]   3000
res[299]   3000
res[300]   3000
res[301]   3000
res[302]   3000
res[303]   3000
res[304]   3000
res[305]   3000
res[306]   3000
res[307]   3000
res[308]   3000
res[309]   3000
res[310]   3000
res[311]   3000
res[312]   3000
res[313]   3000
res[314]   3000
res[315]   3000
res[316]   3000
res[317]   3000
res[318]   3000
res[319]   3000
res[320]   3000
res[321]   2700
res[322]   2800
res[323]   2900
res[324]   3000
res[325]   3000
res[326]   3000
res[327]   3000
res[328]   3000
res[329]   3000
res[330]   3000
res[331]   3000
res[332]   3000
res[333]   3000
res[334]   3000
res[335]   3000
res[336]   3000
res[337]   3000
res[338]   3000
res[339]   3000
res[340]   3000
res[341]   3000
res[342]   3000
res[343]   3000
res[344]   3000
res[345]   3000
res[346]   3000
res[347]   3000
res[348]   3000
res[349]   3000
res[350]   3000
sigma       700
sigma.B    1000
deviance    720

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 41.8 and DIC = 3851.5
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- inprod(beta[],X[i,]) + gamma[Block[i]]
+     res[i] &amp;lt;- y[i]-mu[i]
+    } 
+    
+    #Priors
+    beta ~ dmnorm(a0,A0)
+    for (i in 1:nBlock) {
+      gamma[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;- z/sqrt(chSq) 
+    z ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;- z/sqrt(chSq.B) 
+    z.B ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.B ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;matrixModel2.txt&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~Time,data.rm)
&amp;gt; data.rm.list &amp;lt;- with(data.rm,
+         list(y=y,
+                  Block=as.numeric(Block),
+          X=Xmat,
+          n=nrow(data.rm),
+          nBlock=length(levels(Block)),
+          a0=rep(0,ncol(Xmat)), A0=diag(ncol(Xmat))
+          )
+ )
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;#39;gamma&amp;#39;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;quot;res&amp;quot;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.rm.r2jags.m &amp;lt;- jags(data = data.rm.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;matrixModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 350
   Unobserved stochastic nodes: 40
   Total graph size: 2521

Initializing model
&amp;gt; 
&amp;gt; print(data.rm.r2jags.m)
Inference for Bugs model at &amp;quot;matrixModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
           mu.vect sd.vect     2.5%      25%      50%      75%    97.5%  Rhat
beta[1]      0.118   0.993   -1.825   -0.560    0.127    0.772    2.136 1.002
beta[2]      9.067   1.041    6.989    8.384    9.085    9.754   11.096 1.009
gamma[1]   268.496  28.003  214.165  249.963  268.515  287.365  322.199 1.002
gamma[2]   249.357  27.207  196.523  230.541  249.374  268.093  303.009 1.001
gamma[3]   326.337  28.472  271.718  306.769  325.694  345.668  383.423 1.002
gamma[4]   305.015  28.782  249.411  285.199  305.040  324.243  361.356 1.001
gamma[5]   377.709  27.831  324.335  358.940  377.037  396.616  432.150 1.001
gamma[6]   343.430  27.578  288.864  325.843  342.939  361.444  396.819 1.001
gamma[7]   332.166  27.783  278.248  313.377  331.664  351.388  385.777 1.002
gamma[8]   271.616  27.163  217.184  253.588  271.956  289.628  322.963 1.001
gamma[9]   384.589  27.386  332.007  366.136  384.502  402.093  440.209 1.001
gamma[10]  367.756  27.587  314.137  349.123  368.026  386.501  421.707 1.001
gamma[11]  457.715  27.438  405.652  439.504  457.268  476.098  513.423 1.001
gamma[12]  312.867  27.216  262.216  293.798  313.154  331.284  366.377 1.001
gamma[13]  258.804  27.818  201.324  240.475  259.644  276.264  313.330 1.002
gamma[14]  279.449  28.042  224.175  260.014  279.067  298.411  335.404 1.001
gamma[15]  337.363  28.099  284.866  317.715  336.998  356.109  394.348 1.001
gamma[16]  416.383  27.354  363.925  397.826  416.595  434.011  473.215 1.002
gamma[17]  403.080  27.501  349.003  384.921  403.079  421.627  456.974 1.002
gamma[18]  237.418  27.946  183.713  218.161  237.435  256.648  290.420 1.001
gamma[19]  323.886  27.728  270.777  305.233  323.114  342.641  377.533 1.001
gamma[20]  275.462  28.013  220.684  255.987  275.838  294.317  330.957 1.001
gamma[21]  194.059  27.398  141.539  175.756  194.167  211.807  248.181 1.002
gamma[22]  289.821  27.693  236.092  271.210  289.707  307.332  344.403 1.001
gamma[23]  217.663  28.050  164.441  197.887  217.932  235.812  274.184 1.002
gamma[24]  212.748  27.923  159.816  193.937  211.567  231.708  268.892 1.001
gamma[25]  255.843  26.839  204.539  237.181  255.916  274.542  309.265 1.003
gamma[26]  206.396  28.055  152.547  187.160  206.227  225.611  261.170 1.001
gamma[27]  327.559  27.486  273.350  309.633  327.509  345.364  380.375 1.002
gamma[28]  384.714  27.705  330.300  365.884  384.552  403.155  437.847 1.003
gamma[29]  304.783  28.077  251.111  284.961  304.255  323.437  360.045 1.001
gamma[30]  225.251  28.017  168.742  206.532  226.000  243.944  279.897 1.001
gamma[31]  242.036  28.513  184.632  223.534  242.114  260.552  297.438 1.001
gamma[32]  250.059  27.603  197.965  231.432  249.373  268.506  305.275 1.003
gamma[33]  321.386  27.863  266.714  302.647  321.462  340.165  377.552 1.003
gamma[34]  368.704  27.907  314.047  350.229  368.434  387.452  423.293 1.001
gamma[35]  365.968  27.738  311.338  347.444  365.930  385.018  420.415 1.005
res[1]       4.433  27.784  -48.877  -14.717    4.562   22.705   58.869 1.002
res[2]      34.393  27.628  -18.119   15.474   34.478   52.583   88.788 1.002
res[3]     -17.044  27.510  -69.264  -35.707  -16.883    0.972   37.088 1.002
res[4]     -19.010  27.431  -70.907  -37.537  -18.756   -0.634   35.109 1.002
res[5]      22.692  27.391  -29.376    4.107   22.942   41.160   77.308 1.001
res[6]      10.582  27.391  -41.038   -7.968   10.837   28.907   65.778 1.001
res[7]     -70.449  27.431 -121.778  -88.991  -69.960  -52.214  -14.834 1.001
res[8]      21.008  27.509  -30.615    2.408   21.241   39.197   76.881 1.001
res[9]      12.673  27.627  -39.023   -6.003   12.972   31.145   68.777 1.001
res[10]     22.988  27.783  -29.250    4.168   22.937   41.683   79.296 1.001
res[11]    -40.986  26.942  -94.515  -59.717  -41.262  -22.608   11.356 1.001
res[12]    -57.652  26.765 -110.392  -76.201  -57.806  -39.438   -5.452 1.001
res[13]     14.195  26.627  -37.606   -4.203   14.145   32.218   66.504 1.001
res[14]    -29.460  26.529  -81.001  -47.601  -29.683  -11.482   22.755 1.001
res[15]    -14.892  26.472  -66.711  -32.886  -15.051    3.149   37.784 1.001
res[16]     15.000  26.456  -36.965   -3.255   14.703   33.011   68.048 1.001
res[17]    -11.656  26.481  -63.530  -29.872  -12.202    6.352   41.041 1.001
res[18]     -2.098  26.546  -53.836  -20.736   -2.884   15.886   51.209 1.001
res[19]     40.030  26.652  -11.158   21.366   39.102   58.171   93.729 1.001
res[20]    112.896  26.799   61.236   94.306  112.162  131.227  167.261 1.001
res[21]   -173.333  28.266 -230.343 -192.502 -172.496 -153.934 -119.008 1.002
res[22]   -146.973  28.095 -203.369 -166.084 -146.394 -127.937  -93.044 1.002
res[23]    -66.390  27.961 -122.215  -85.409  -65.713  -47.492  -12.298 1.002
res[24]    -62.498  27.865 -117.833  -81.428  -61.625  -43.630   -7.786 1.001
res[25]    -16.892  27.808  -71.818  -35.704  -16.206    2.104   37.863 1.001
res[26]     37.026  27.790  -17.773   18.140   37.505   55.996   91.643 1.001
res[27]     73.127  27.811   18.616   54.532   73.671   91.725  127.823 1.001
res[28]    125.466  27.871   71.518  106.855  125.737  144.036  180.266 1.001
res[29]    132.725  27.969   78.584  113.924  133.004  151.381  187.753 1.001
res[30]    128.171  28.106   73.520  109.247  128.243  147.168  184.155 1.001
res[31]   -215.417  28.519 -271.907 -234.515 -215.477 -196.031 -160.014 1.001
res[32]   -172.464  28.331 -228.398 -191.559 -172.626 -153.223 -117.470 1.001
res[33]   -107.754  28.180 -163.519 -126.542 -107.988  -88.710  -53.225 1.001
res[34]    -46.543  28.067 -102.122  -65.407  -46.791  -27.844    8.278 1.001
res[35]    -47.922  27.992 -103.460  -66.793  -48.157  -29.112    7.029 1.001
res[36]     71.901  27.955   16.630   52.816   71.633   90.451  126.471 1.001
res[37]     97.292  27.958   42.344   78.098   97.282  115.785  151.917 1.001
res[38]    113.786  27.999   59.110   94.749  113.857  132.397  169.334 1.001
res[39]    188.465  28.078  134.278  169.268  188.455  207.026  244.767 1.001
res[40]    152.859  28.196   98.827  133.783  152.725  171.438  209.588 1.001
res[41]   -138.298  27.589 -192.214 -157.018 -137.668 -119.884  -85.511 1.001
res[42]     -0.435  27.414  -54.092  -19.066    0.070   17.947   51.755 1.001
res[43]     -5.275  27.278  -58.296  -23.835   -4.661   12.955   46.693 1.001
res[44]     76.163  27.182   23.390   57.931   76.757   94.384  128.160 1.001
res[45]     -8.105  27.124  -60.470  -26.335   -7.526   10.317   43.968 1.001
res[46]     -8.933  27.107  -61.592  -27.005   -8.421    9.419   43.130 1.001
res[47]     23.039  27.130  -29.532    5.000   23.698   41.485   75.548 1.001
res[48]     48.884  27.192   -3.759   30.945   49.511   67.086  101.297 1.001
res[49]      8.462  27.295  -44.134   -9.630    8.812   26.700   61.215 1.001
res[50]     31.557  27.436  -20.973   13.381   31.746   50.020   84.424 1.001
res[51]   -128.097  27.415 -180.770 -146.327 -127.910 -110.576  -73.568 1.001
res[52]    -60.141  27.254 -112.252  -78.239  -59.732  -42.653   -5.561 1.001
res[53]     17.013  27.132  -35.210   -1.266   17.578   34.265   71.525 1.001
res[54]    -82.564  27.049 -134.784 -100.658  -82.293  -65.282  -27.984 1.002
res[55]     14.994  27.006  -36.578   -3.173   15.282   32.302   69.851 1.002
res[56]    -26.609  27.004  -78.326  -44.704  -26.580   -9.314   28.128 1.002
res[57]     29.085  27.041  -22.987   10.998   29.221   46.243   83.856 1.002
res[58]     88.084  27.118   35.657   69.858   88.230  105.263  142.463 1.004
res[59]     96.481  27.235   43.718   78.058   96.354  113.557  150.554 1.004
res[60]     85.123  27.391   32.058   66.554   85.013  102.661  139.651 1.005
res[61]   -114.949  27.627 -168.618 -134.296 -114.394  -96.450  -60.949 1.001
res[62]    -68.590  27.512 -121.492  -87.723  -68.056  -50.063  -14.649 1.001
res[63]     -5.091  27.435  -57.658  -24.187   -4.767   13.171   48.423 1.001
res[64]    -96.888  27.399 -149.185 -115.932  -96.721  -78.893  -43.557 1.001
res[65]   -145.340  27.401 -197.553 -164.388 -145.424 -127.432  -91.411 1.001
res[66]    -26.577  27.444  -78.399  -45.694  -26.594   -8.455   27.555 1.001
res[67]     53.432  27.525    1.678   34.253   53.095   71.854  107.546 1.001
res[68]     91.059  27.646   39.251   71.830   90.780  109.558  145.538 1.003
res[69]    139.341  27.805   87.022  120.095  138.966  157.961  193.921 1.001
res[70]    192.254  28.001  139.613  173.011  191.889  211.174  247.685 1.001
res[71]   -140.697  26.945 -192.131 -158.462 -140.921 -122.682  -86.498 1.001
res[72]    -53.861  26.803 -104.692  -71.382  -53.867  -36.045   -0.026 1.001
res[73]    -59.969  26.701 -110.888  -77.531  -60.116  -42.419   -5.779 1.001
res[74]    -24.888  26.639  -75.800  -42.339  -25.220   -7.759   28.792 1.001
res[75]    -18.925  26.617  -70.569  -36.419  -19.228   -1.820   34.501 1.001
res[76]     48.388  26.637   -3.281   30.722   48.168   65.796  102.013 1.001
res[77]     45.403  26.697   -6.795   27.656   45.293   62.830   99.324 1.001
res[78]     90.550  26.797   38.062   72.851   90.464  108.076  144.636 1.001
res[79]     85.396  26.937   32.309   67.374   84.992  103.181  139.994 1.001
res[80]     50.353  27.116   -2.874   32.360   50.071   68.275  105.635 1.001
res[81]   -163.315  27.183 -218.512 -180.651 -163.268 -145.149 -111.213 1.001
res[82]   -109.549  27.050 -164.522 -126.836 -109.407  -91.446  -57.185 1.001
res[83]    -13.182  26.957  -68.058  -30.309  -13.185    4.672   38.759 1.001
res[84]    -14.857  26.904  -69.375  -32.207  -15.130    2.965   37.149 1.001
res[85]     40.982  26.891  -12.987   23.736   40.580   58.715   93.178 1.001
res[86]    132.360  26.918   78.198  115.020  131.926  150.358  184.466 1.001
res[87]     96.805  26.986   42.362   79.456   96.215  114.807  149.347 1.001
res[88]     20.474  27.093  -33.942    3.067   19.924   38.470   72.341 1.001
res[89]     17.776  27.240  -36.170    0.154   17.205   35.757   69.869 1.001
res[90]     21.069  27.426  -33.512    3.375   20.566   38.921   73.507 1.001
res[91]   -139.087  27.401 -192.251 -157.857 -139.429 -120.731  -85.751 1.001
res[92]    -36.783  27.249  -89.549  -55.363  -37.012  -18.606   16.371 1.001
res[93]    -52.676  27.136 -105.357  -71.142  -52.862  -34.505    0.149 1.001
res[94]    -26.246  27.062  -78.812  -44.487  -26.694   -8.200   27.216 1.001
res[95]    -30.949  27.028  -83.569  -49.064  -31.432  -12.883   22.822 1.001
res[96]    -18.119  27.035  -70.366  -36.181  -18.630   -0.071   35.799 1.001
res[97]     11.013  27.081  -42.062   -7.308   10.371   29.090   64.960 1.001
res[98]     89.212  27.167   36.723   70.825   88.487  107.474  143.357 1.001
res[99]     95.614  27.293   43.369   77.242   94.962  114.096  150.199 1.001
res[100]   134.498  27.457   80.966  116.052  134.051  153.002  189.417 1.001
res[101]   -76.108  27.204 -130.082  -94.332  -75.847  -57.878  -24.353 1.001
res[102]   -34.250  27.032  -87.681  -52.048  -34.152  -16.151   17.341 1.001
res[103]   -71.035  26.900 -124.029  -88.589  -71.012  -53.026  -19.557 1.001
res[104]    13.787  26.807  -38.887   -3.638   13.685   31.994   65.003 1.001
res[105]   -14.560  26.754  -67.146  -32.253  -14.734    3.512   36.383 1.001
res[106]   -19.293  26.742  -72.025  -36.855  -19.308   -1.263   32.398 1.001
res[107]    56.600  26.770    3.888   38.981   56.413   74.590  108.690 1.001
res[108]   116.002  26.839   62.639   98.370  115.911  133.987  168.211 1.001
res[109]    48.507  26.948   -4.467   30.803   48.406   66.425  100.281 1.001
res[110]     9.543  27.096  -43.482   -8.442    9.395   27.710   61.257 1.001
res[111]  -132.106  27.068 -185.510 -150.360 -132.361 -113.290  -81.768 1.002
res[112]   -91.911  26.941 -144.896 -110.112  -92.368  -73.497  -41.675 1.002
res[113]   -56.418  26.853 -110.121  -74.546  -56.821  -38.144   -6.066 1.002
res[114]   -13.873  26.805  -66.754  -32.098  -14.064    4.250   36.754 1.002
res[115]    33.751  26.798  -19.527   15.438   33.439   51.710   84.504 1.002
res[116]    18.335  26.831  -34.945   -0.042   17.997   36.508   69.231 1.003
res[117]    -9.402  26.904  -62.947  -27.827   -9.801    8.739   41.996 1.003
res[118]    73.620  27.018   20.102   55.043   73.349   91.735  125.589 1.003
res[119]   130.437  27.170   77.165  111.769  130.243  148.448  183.288 1.003
res[120]    67.067  27.362   14.395   48.375   66.985   85.315  120.963 1.004
res[121]   -62.784  27.602 -117.124  -80.547  -63.554  -44.541   -5.745 1.002
res[122]   -79.284  27.432 -132.901  -96.959  -80.152  -61.213  -23.216 1.002
res[123]  -147.038  27.300 -200.594 -164.755 -147.987 -129.337  -91.122 1.002
res[124]   -86.011  27.208 -139.363 -103.583  -87.079  -68.166  -30.561 1.001
res[125]   -44.469  27.155  -96.901  -61.934  -45.519  -26.882   10.835 1.001
res[126]    -7.957  27.143  -60.233  -25.501   -9.007    9.627   47.109 1.001
res[127]    41.116  27.170  -10.769   23.449   40.140   58.470   96.951 1.001
res[128]   117.876  27.237   66.278   99.824  117.103  135.377  173.458 1.003
res[129]   149.628  27.343   98.060  131.402  148.903  167.283  205.474 1.002
res[130]   138.114  27.489   85.817  119.560  137.512  155.791  194.856 1.002
res[131]  -111.510  27.838 -167.229 -130.194 -111.277  -92.014  -56.583 1.002
res[132]   -85.928  27.671 -141.664 -104.693  -85.568  -66.741  -30.867 1.002
res[133]   -39.184  27.543  -95.068  -57.826  -39.100  -20.158   15.452 1.002
res[134]   -65.087  27.454 -120.528  -83.757  -65.031  -46.398  -10.806 1.002
res[135]   -38.854  27.404  -94.235  -57.313  -38.905  -20.233   15.932 1.002
res[136]    43.897  27.394  -11.085   25.502   43.662   62.725   99.335 1.002
res[137]    60.508  27.423    5.661   42.259   60.002   79.149  116.033 1.002
res[138]    48.476  27.491   -6.511   30.204   47.961   67.171  103.838 1.002
res[139]    64.161  27.599    9.521   45.658   63.389   82.927  119.918 1.002
res[140]   150.425  27.745   95.799  131.748  149.642  169.252  206.380 1.003
res[141]   -91.850  27.881 -148.268 -110.602  -91.492  -72.233  -39.029 1.001
res[142]   -17.357  27.708  -73.303  -36.036  -17.162    1.868   35.260 1.001
res[143]    -8.456  27.572  -63.972  -27.298   -8.090   10.649   43.948 1.001
res[144]    16.411  27.476  -38.675   -2.242   16.566   35.463   68.828 1.001
res[145]    -7.945  27.418  -62.620  -26.453   -7.775   11.028   44.009 1.001
res[146]    34.948  27.400  -19.537   16.194   35.119   53.767   87.148 1.001
res[147]    17.864  27.422  -36.519   -0.769   17.959   36.562   70.397 1.001
res[148]   -37.328  27.483  -92.124  -55.967  -37.389  -18.410   15.393 1.001
res[149]     0.133  27.583  -54.930  -18.289    0.029   18.855   53.369 1.001
res[150]   125.181  27.722   69.744  106.772  124.931  144.185  179.294 1.001
res[151]   -45.913  27.112 -101.600  -63.384  -46.504  -27.406    6.233 1.002
res[152]    14.074  26.949  -41.422   -3.190   13.364   32.310   66.645 1.001
res[153]    25.930  26.825  -28.692    8.617   25.258   43.842   78.335 1.001
res[154]    -8.769  26.741  -62.803  -25.915   -9.134    8.810   43.512 1.001
res[155]   -12.026  26.698  -66.536  -29.146  -12.358    5.538   40.695 1.001
res[156]   -13.996  26.695  -68.442  -31.190  -14.374    3.511   39.057 1.001
res[157]   -21.157  26.732  -75.444  -38.415  -21.645   -3.442   32.176 1.001
res[158]    35.944  26.810  -17.938   18.462   35.409   53.573   89.820 1.001
res[159]    -9.265  26.928  -63.044  -26.958   -9.879    8.560   44.932 1.001
res[160]    61.941  27.086    8.272   44.148   61.146   79.841  116.112 1.001
res[161]  -111.720  27.299 -164.219 -130.281 -111.941  -93.352  -57.961 1.002
res[162]  -161.840  27.142 -214.803 -180.270 -162.077 -143.321 -108.335 1.002
res[163]  -105.843  27.025 -158.096 -124.374 -106.136  -87.584  -52.496 1.002
res[164]    32.678  26.947  -18.932   14.279   32.115   50.832   85.368 1.002
res[165]    -1.691  26.909  -53.352  -20.188   -2.310   16.517   51.266 1.002
res[166]    45.107  26.912   -6.211   26.808   44.518   63.279   97.999 1.002
res[167]     5.376  26.954  -46.126  -12.677    4.882   23.392   58.513 1.002
res[168]    72.424  27.037   20.741   54.308   72.204   90.456  125.956 1.002
res[169]    87.205  27.159   35.982   68.965   87.205  105.288  141.275 1.002
res[170]   173.321  27.321  121.880  155.039  173.059  191.695  228.030 1.003
res[171]   -26.750  27.741  -79.583  -45.635  -26.886   -7.432   26.470 1.001
res[172]   -18.152  27.612  -70.442  -37.010  -18.270    0.993   35.150 1.001
res[173]   -30.868  27.522  -82.411  -49.842  -30.897  -11.752   22.359 1.001
res[174]   -20.371  27.471  -72.112  -39.216  -20.399   -1.090   32.975 1.001
res[175]   -29.402  27.460  -81.284  -48.575  -29.553   -9.855   23.536 1.001
res[176]   -42.654  27.488  -94.488  -61.958  -42.932  -23.151   10.118 1.001
res[177]    21.559  27.555  -30.491    2.158   21.213   40.881   74.590 1.001
res[178]    -6.198  27.662  -58.988  -25.815   -6.244   13.036   47.593 1.001
res[179]   104.363  27.807   51.627   84.332  104.497  123.625  158.553 1.001
res[180]    63.487  27.989   10.897   43.415   63.657   82.927  118.256 1.002
res[181]  -116.426  27.477 -170.058 -135.254 -115.973  -98.040  -63.859 1.001
res[182]   -61.964  27.315 -115.028  -80.596  -61.367  -43.741   -8.748 1.001
res[183]   -11.520  27.191  -65.196  -29.915  -10.904    6.736   41.954 1.001
res[184]   -11.403  27.107  -64.157  -29.928  -10.938    7.033   42.438 1.001
res[185]    11.940  27.063  -40.738   -6.618   12.599   30.143   65.828 1.001
res[186]    78.890  27.059   26.180   60.481   79.578   97.004  132.471 1.001
res[187]    15.749  27.094  -36.961   -2.786   16.169   33.923   68.912 1.001
res[188]     3.160  27.170  -49.311  -15.573    3.325   21.357   56.992 1.001
res[189]    52.382  27.285   -0.331   33.687   52.699   70.616  106.503 1.001
res[190]    57.688  27.439    4.937   38.848   57.982   75.882  112.335 1.001
res[191]   -39.277  27.823  -93.946  -58.037  -39.479  -19.984   14.965 1.001
res[192]     9.409  27.662  -44.962   -9.063    9.312   28.464   63.569 1.001
res[193]    22.489  27.540  -32.351    3.890   22.479   41.387   76.748 1.001
res[194]   -41.856  27.457  -96.305  -60.387  -41.784  -23.180   12.866 1.001
res[195]   -12.452  27.413  -66.510  -31.155  -12.405    6.113   42.359 1.001
res[196]    -1.869  27.408  -55.985  -20.561   -1.913   16.685   53.271 1.001
res[197]    21.489  27.443  -32.127    2.711   21.389   39.871   76.814 1.001
res[198]    -9.600  27.518  -62.931  -28.632   -9.617    8.338   45.590 1.002
res[199]    53.727  27.631   -0.059   34.427   53.676   71.736  108.974 1.002
res[200]    31.695  27.783  -22.231   12.143   31.743   49.979   87.523 1.002
res[201]   -86.890  27.181 -140.177 -104.770  -87.118  -68.603  -35.106 1.001
res[202]   -30.563  27.031  -83.642  -48.350  -31.011  -12.345   20.910 1.002
res[203]   -39.562  26.920  -92.523  -57.243  -39.987  -21.390   11.887 1.002
res[204]    25.751  26.850  -27.313    8.074   25.467   43.881   77.877 1.002
res[205]   -12.787  26.819  -65.884  -30.405  -13.246    5.237   39.562 1.002
res[206]  -114.094  26.829 -166.864 -131.854 -114.195  -96.423  -61.166 1.002
res[207]   -27.215  26.880  -80.040  -44.971  -27.431   -9.544   26.079 1.002
res[208]    65.253  26.970   12.034   47.409   65.333   82.874  119.333 1.002
res[209]    87.094  27.100   33.577   69.194   87.081  104.945  141.467 1.003
res[210]   148.253  27.269   94.421  130.305  148.113  166.284  203.466 1.002
res[211]  -161.236  27.503 -215.889 -178.736 -161.122 -142.886 -108.375 1.001
res[212]  -129.522  27.348 -183.477 -146.819 -129.294 -111.282  -76.871 1.001
res[213]  -190.682  27.231 -243.930 -208.062 -190.524 -172.562 -138.450 1.001
res[214]   -79.289  27.154 -132.322  -96.647  -79.209  -61.143  -27.250 1.001
res[215]    47.949  27.116   -4.985   30.474   48.166   66.107  100.695 1.001
res[216]   114.631  27.119   61.912   96.825  114.839  132.864  167.496 1.001
res[217]   117.095  27.161   63.624   99.215  117.216  135.276  169.783 1.001
res[218]   122.954  27.243   68.976  105.183  123.040  140.999  175.833 1.001
res[219]    57.691  27.364    2.985   40.012   57.620   75.929  110.855 1.001
res[220]   124.990  27.525   70.453  107.235  124.767  143.105  178.606 1.001
res[221]   -28.457  27.809  -85.147  -46.709  -28.877   -8.749   24.203 1.001
res[222]   -40.195  27.642  -96.634  -58.154  -40.465  -20.895   12.714 1.001
res[223]   -83.163  27.513 -139.662 -101.235  -83.213  -63.910  -30.005 1.001
res[224]   -57.737  27.424 -113.878  -75.793  -57.651  -38.683   -5.179 1.001
res[225]   -60.675  27.373 -116.422  -78.560  -60.376  -41.718   -8.273 1.001
res[226]   -36.237  27.363  -91.706  -54.143  -35.975  -17.495   16.397 1.001
res[227]   -53.528  27.391 -108.591  -71.787  -53.313  -34.530   -0.302 1.001
res[228]    82.085  27.460   27.176   63.546   82.505  100.972  135.212 1.001
res[229]   109.582  27.567   54.642   90.994  110.106  128.598  162.713 1.001
res[230]   190.314  27.713  135.634  171.529  190.765  209.465  244.223 1.001
res[231]  -120.252  27.694 -175.928 -138.875 -119.474 -101.313  -68.003 1.001
res[232]  -100.688  27.530 -155.801 -119.226  -99.978  -81.979  -48.238 1.001
res[233]   -91.964  27.405 -146.450 -110.666  -91.280  -73.148  -39.619 1.001
res[234]  -108.171  27.319 -162.489 -126.710 -107.330  -89.436  -55.884 1.001
res[235]    21.527  27.273  -32.755    3.074   22.292   40.459   73.543 1.001
res[236]   -18.622  27.266  -73.068  -36.988  -18.139    0.348   33.406 1.001
res[237]    40.129  27.299  -14.569   21.865   40.523   59.257   92.027 1.001
res[238]   117.718  27.372   62.996   99.591  118.175  136.830  169.568 1.001
res[239]   150.564  27.484   95.949  132.308  150.955  169.833  203.577 1.001
res[240]   128.355  27.634   73.287  109.633  128.714  147.821  181.492 1.001
res[241]   -43.717  26.592  -96.442  -61.945  -43.778  -25.366    7.706 1.002
res[242]   -16.266  26.421  -68.915  -34.345  -16.394    1.657   34.738 1.002
res[243]   -51.824  26.290 -104.250  -69.666  -51.904  -34.191   -0.773 1.002
res[244]   -92.310  26.200 -144.512 -109.770  -92.356  -74.742  -41.007 1.002
res[245]    53.225  26.151    1.165   35.773   53.155   70.545  104.484 1.002
res[246]    35.579  26.143  -16.717   18.099   35.633   52.862   86.869 1.001
res[247]   -33.204  26.177  -85.575  -50.833  -33.098  -15.939   18.146 1.001
res[248]    35.397  26.252  -16.792   17.809   35.174   52.691   87.176 1.001
res[249]    83.314  26.368   30.491   65.761   83.032  100.631  135.542 1.001
res[250]    42.630  26.524   -9.672   24.976   42.309   59.916   95.055 1.001
res[251]  -206.923  27.800 -260.529 -225.880 -206.782 -187.968 -153.986 1.001
res[252]  -157.656  27.629 -211.249 -176.383 -157.567 -138.906 -104.887 1.001
res[253]   -51.271  27.496 -104.867  -70.030  -51.271  -32.412    1.659 1.001
res[254]    12.860  27.402  -40.341   -5.856   13.103   31.625   65.496 1.001
res[255]    11.898  27.348  -41.371   -7.218   11.887   30.504   64.701 1.001
res[256]    -1.747  27.333  -54.813  -20.847   -1.807   16.587   50.997 1.001
res[257]    46.786  27.357   -6.081   27.648   46.704   65.069  100.383 1.001
res[258]    84.114  27.422   31.253   65.110   83.938  102.405  137.813 1.001
res[259]   141.780  27.525   88.996  122.717  141.448  159.933  195.838 1.001
res[260]   140.825  27.667   88.214  121.349  140.766  158.831  195.301 1.001
res[261]   -45.758  27.262  -98.677  -63.456  -45.803  -28.120    8.017 1.002
res[262]   -73.536  27.103 -126.119  -91.086  -73.677  -55.880  -19.998 1.001
res[263]   -66.558  26.984 -118.944  -84.155  -66.732  -49.089  -12.830 1.001
res[264]    -3.221  26.904  -55.491  -20.926   -3.268   14.217   50.110 1.001
res[265]    64.093  26.864   12.275   46.220   64.035   81.487  117.920 1.001
res[266]   -24.292  26.865  -75.837  -42.281  -24.457   -6.832   29.548 1.001
res[267]    11.470  26.906  -40.398   -6.459   11.267   29.011   65.223 1.001
res[268]    69.347  26.987   17.413   51.396   68.896   87.025  123.112 1.001
res[269]    16.854  27.108  -35.179   -1.244   16.533   34.478   70.967 1.001
res[270]    75.619  27.268   23.067   57.629   75.329   93.227  129.655 1.001
res[271]  -225.643  27.480 -278.886 -243.823 -225.694 -207.386 -171.764 1.003
res[272]  -140.428  27.320 -193.206 -158.567 -140.609 -122.309  -86.874 1.003
res[273]   -92.158  27.198 -145.009 -110.346  -92.252  -74.095  -38.573 1.003
res[274]   -37.826  27.116  -90.730  -55.873  -38.139  -19.735   15.494 1.002
res[275]   -22.591  27.074  -75.243  -40.456  -22.982   -4.368   30.621 1.002
res[276]    30.930  27.072  -22.094   13.172   30.419   49.127   84.548 1.002
res[277]   103.777  27.109   50.599   85.820  102.988  121.948  157.742 1.002
res[278]   195.528  27.187  142.165  177.513  194.832  213.701  249.967 1.002
res[279]   173.383  27.304  119.414  155.128  172.627  191.796  228.591 1.001
res[280]    48.822  27.460   -5.443   30.590   47.952   67.271  104.943 1.001
res[281]  -100.761  27.924 -155.664 -119.211 -100.098  -81.104  -47.734 1.001
res[282]   -73.020  27.777 -127.369  -91.266  -72.520  -53.694  -20.563 1.001
res[283]   -64.686  27.669 -119.132  -82.823  -64.075  -45.417  -12.494 1.001
res[284]   -17.650  27.599  -72.206  -35.666  -17.169    1.377   35.020 1.001
res[285]    46.285  27.569   -7.652   28.252   46.815   65.328   99.260 1.001
res[286]    25.187  27.577  -28.572    7.101   25.553   44.083   78.569 1.001
res[287]    23.689  27.625  -29.512    5.427   23.865   42.895   77.192 1.001
res[288]    61.274  27.713    8.220   42.691   61.404   80.495  114.966 1.001
res[289]    48.126  27.838   -5.127   29.210   48.155   67.369  102.003 1.001
res[290]    73.868  28.002   20.444   54.993   73.670   93.109  128.079 1.001
res[291]   -62.043  27.792 -115.822  -80.494  -62.779  -43.673   -4.435 1.001
res[292]   -78.060  27.657 -131.681  -96.527  -78.957  -60.027  -21.083 1.001
res[293]   -97.080  27.560 -150.130 -115.697  -97.882  -79.080  -40.450 1.001
res[294]   -84.403  27.502 -137.305 -103.193  -85.127  -66.419  -27.873 1.001
res[295]   -62.058  27.484 -115.409  -80.974  -62.634  -43.885   -5.395 1.001
res[296]    13.785  27.505  -39.891   -5.375   13.338   32.209   69.885 1.001
res[297]   108.636  27.565   55.243   89.343  108.404  127.130  164.689 1.001
res[298]   103.229  27.665   49.562   83.789  102.942  122.033  159.137 1.001
res[299]    89.617  27.803   35.620   70.171   89.485  108.312  146.507 1.001
res[300]    80.672  27.979   26.414   60.959   80.808   99.562  137.744 1.001
res[301]  -141.883  28.305 -196.509 -160.420 -141.920 -123.442  -84.721 1.001
res[302]  -106.210  28.157 -160.120 -124.453 -106.309  -87.823  -49.394 1.001
res[303]   -37.352  28.047  -91.475  -55.335  -37.285  -19.229   19.895 1.001
res[304]   -18.327  27.975  -72.662  -36.286  -18.237   -0.397   38.713 1.001
res[305]   -86.778  27.942 -140.890 -105.114  -86.791  -68.788  -29.209 1.001
res[306]   -37.999  27.947  -91.849  -56.327  -37.867  -20.131   19.461 1.001
res[307]    69.141  27.991   14.641   50.665   69.178   86.859  126.516 1.001
res[308]   159.261  28.074  104.599  140.704  159.387  177.180  216.359 1.001
res[309]   136.516  28.195   80.873  118.244  136.554  154.819  193.892 1.001
res[310]    84.565  28.354   28.496   66.131   84.693  102.951  142.719 1.002
res[311]     8.480  27.336  -47.030   -9.792    8.978   27.073   59.498 1.003
res[312]    11.977  27.128  -43.062   -5.921   12.427   30.119   62.594 1.003
res[313]    22.210  26.959  -32.858    4.243   22.751   40.219   72.580 1.003
res[314]    60.484  26.829    5.199   42.716   60.942   78.598  110.330 1.002
res[315]    -6.440  26.739  -61.507  -24.246   -6.091   11.508   43.556 1.002
res[316]   -11.502  26.689  -66.443  -29.364  -11.033    6.418   38.397 1.002
res[317]   -51.977  26.680 -107.165  -69.981  -51.390  -33.782   -1.318 1.002
res[318]   -37.802  26.711  -93.392  -55.747  -37.309  -19.574   12.624 1.002
res[319]    18.322  26.783  -37.480    0.309   19.012   36.680   68.620 1.001
res[320]    -6.770  26.895  -62.754  -24.603   -5.931   11.437   44.809 1.001
res[321]  -169.878  27.641 -225.412 -188.557 -170.087 -150.812 -115.846 1.003
res[322]  -115.245  27.475 -170.155 -133.481 -115.610  -96.509  -61.338 1.002
res[323]  -127.030  27.348 -181.991 -145.028 -127.405 -108.460  -73.235 1.002
res[324]   -75.745  27.260 -130.493  -94.150  -76.056  -57.347  -21.877 1.002
res[325]    -4.442  27.211  -59.066  -22.893   -4.731   14.091   49.373 1.002
res[326]    72.438  27.202   17.923   54.115   72.083   90.962  125.624 1.002
res[327]    74.431  27.233   20.320   56.096   74.054   93.130  128.264 1.001
res[328]    86.173  27.303   32.254   68.056   86.103  104.893  140.473 1.001
res[329]   100.100  27.413   46.110   82.027  100.161  118.754  154.311 1.001
res[330]   191.836  27.562  137.087  173.612  191.900  210.527  246.650 1.001
res[331]    -3.568  27.677  -58.111  -22.218   -3.240   14.872   51.330 1.001
res[332]    35.490  27.505  -18.504   16.700   35.467   53.896   89.971 1.001
res[333]    14.836  27.372  -38.705   -3.945   14.883   33.326   69.479 1.001
res[334]    35.529  27.278  -17.795   16.742   35.624   53.845   89.880 1.001
res[335]    57.772  27.224    4.745   39.406   57.712   76.032  112.258 1.001
res[336]     7.505  27.209  -45.201  -11.277    7.241   25.550   61.787 1.001
res[337]   -62.853  27.234 -115.231  -81.656  -63.102  -44.830   -8.470 1.001
res[338]     3.554  27.299  -48.771  -15.196    3.261   21.590   57.887 1.001
res[339]   -47.691  27.403 -100.181  -66.462  -48.175  -29.624    6.870 1.001
res[340]    -7.951  27.546  -60.486  -26.990   -8.417   10.133   47.240 1.001
res[341]  -167.838  27.534 -221.260 -186.767 -167.997 -149.518 -113.530 1.005
res[342]  -109.245  27.409 -162.241 -128.030 -109.426  -91.138  -55.319 1.005
res[343]   -76.905  27.323 -129.335  -95.553  -76.780  -58.727  -23.086 1.004
res[344]   -92.961  27.276 -144.845 -111.585  -92.688  -74.742  -39.601 1.004
res[345]   -15.658  27.269  -67.414  -34.298  -15.410    2.716   37.316 1.004
res[346]    87.984  27.302   36.319   69.290   88.171  106.278  140.902 1.003
res[347]   132.212  27.374   80.204  113.503  132.167  150.380  185.832 1.003
res[348]    30.540  27.486  -21.770   11.869   30.461   48.883   84.590 1.003
res[349]   120.550  27.636   67.565  101.960  120.450  138.866  174.815 1.002
res[350]   123.963  27.825   70.604  105.055  123.691  142.633  178.437 1.002
sigma       86.053   4.095   78.239   83.300   85.994   88.737   94.268 1.013
sigma.B    317.817  38.958  252.469  291.832  313.873  339.888  405.125 1.002
deviance  4111.820  21.476 4069.687 4097.266 4111.765 4126.251 4152.352 1.008
          n.eff
beta[1]    1400
beta[2]     230
gamma[1]   1000
gamma[2]   3000
gamma[3]   1300
gamma[4]   2800
gamma[5]   3000
gamma[6]   3000
gamma[7]   1800
gamma[8]   3000
gamma[9]   1800
gamma[10]  2900
gamma[11]  3000
gamma[12]  1800
gamma[13]  1900
gamma[14]  3000
gamma[15]  3000
gamma[16]  1300
gamma[17]  1100
gamma[18]  3000
gamma[19]  3000
gamma[20]  3000
gamma[21]  3000
gamma[22]  3000
gamma[23]  1800
gamma[24]  3000
gamma[25]   810
gamma[26]  3000
gamma[27]  1500
gamma[28]   570
gamma[29]  3000
gamma[30]  3000
gamma[31]  3000
gamma[32]   660
gamma[33]   730
gamma[34]  3000
gamma[35]   340
res[1]     1100
res[2]     1200
res[3]     1400
res[4]     1700
res[5]     2100
res[6]     2700
res[7]     3000
res[8]     3000
res[9]     3000
res[10]    3000
res[11]    3000
res[12]    3000
res[13]    3000
res[14]    3000
res[15]    3000
res[16]    3000
res[17]    3000
res[18]    3000
res[19]    3000
res[20]    3000
res[21]    1200
res[22]    1400
res[23]    1700
res[24]    2000
res[25]    2500
res[26]    3000
res[27]    3000
res[28]    3000
res[29]    3000
res[30]    3000
res[31]    3000
res[32]    3000
res[33]    3000
res[34]    3000
res[35]    3000
res[36]    3000
res[37]    3000
res[38]    3000
res[39]    3000
res[40]    3000
res[41]    3000
res[42]    3000
res[43]    3000
res[44]    3000
res[45]    3000
res[46]    3000
res[47]    3000
res[48]    3000
res[49]    3000
res[50]    3000
res[51]    3000
res[52]    2800
res[53]    2200
res[54]    1700
res[55]    1400
res[56]    1200
res[57]    1000
res[58]     710
res[59]     630
res[60]     550
res[61]    2000
res[62]    2400
res[63]    3000
res[64]    3000
res[65]    3000
res[66]    3000
res[67]    3000
res[68]    3000
res[69]    3000
res[70]    3000
res[71]    3000
res[72]    3000
res[73]    3000
res[74]    3000
res[75]    3000
res[76]    3000
res[77]    3000
res[78]    3000
res[79]    3000
res[80]    3000
res[81]    2100
res[82]    2600
res[83]    3000
res[84]    3000
res[85]    3000
res[86]    3000
res[87]    3000
res[88]    3000
res[89]    3000
res[90]    3000
res[91]    3000
res[92]    3000
res[93]    3000
res[94]    3000
res[95]    3000
res[96]    3000
res[97]    3000
res[98]    3000
res[99]    3000
res[100]   3000
res[101]   3000
res[102]   3000
res[103]   3000
res[104]   3000
res[105]   3000
res[106]   3000
res[107]   3000
res[108]   3000
res[109]   3000
res[110]   3000
res[111]   1700
res[112]   1400
res[113]   1100
res[114]    980
res[115]    840
res[116]    740
res[117]    650
res[118]    580
res[119]    600
res[120]    480
res[121]   1600
res[122]   2000
res[123]   2400
res[124]   3000
res[125]   3000
res[126]   3000
res[127]   3000
res[128]   3000
res[129]   3000
res[130]   3000
res[131]   3000
res[132]   3000
res[133]   3000
res[134]   3000
res[135]   3000
res[136]   3000
res[137]   3000
res[138]   3000
res[139]   2700
res[140]   3000
res[141]   3000
res[142]   3000
res[143]   3000
res[144]   3000
res[145]   3000
res[146]   3000
res[147]   3000
res[148]   3000
res[149]   3000
res[150]   3000
res[151]   1600
res[152]   1900
res[153]   2300
res[154]   3000
res[155]   3000
res[156]   3000
res[157]   3000
res[158]   3000
res[159]   3000
res[160]   3000
res[161]   1000
res[162]   1200
res[163]   1400
res[164]   1700
res[165]   2100
res[166]   2600
res[167]   3000
res[168]   3000
res[169]   3000
res[170]   3000
res[171]   3000
res[172]   3000
res[173]   3000
res[174]   3000
res[175]   3000
res[176]   3000
res[177]   2700
res[178]   2200
res[179]   2000
res[180]   1500
res[181]   3000
res[182]   3000
res[183]   3000
res[184]   3000
res[185]   3000
res[186]   3000
res[187]   3000
res[188]   3000
res[189]   3000
res[190]   3000
res[191]   3000
res[192]   3000
res[193]   3000
res[194]   3000
res[195]   3000
res[196]   2500
res[197]   2000
res[198]   1700
res[199]   1400
res[200]   1200
res[201]   3000
res[202]   3000
res[203]   2700
res[204]   2100
res[205]   1700
res[206]   1400
res[207]   1200
res[208]   1000
res[209]    890
res[210]   1100
res[211]   3000
res[212]   3000
res[213]   3000
res[214]   3000
res[215]   3000
res[216]   3000
res[217]   3000
res[218]   3000
res[219]   3000
res[220]   3000
res[221]   1800
res[222]   2200
res[223]   2800
res[224]   3000
res[225]   3000
res[226]   3000
res[227]   3000
res[228]   3000
res[229]   3000
res[230]   3000
res[231]   3000
res[232]   3000
res[233]   3000
res[234]   3000
res[235]   3000
res[236]   3000
res[237]   3000
res[238]   3000
res[239]   3000
res[240]   3000
res[241]    900
res[242]   1000
res[243]   1200
res[244]   1400
res[245]   1800
res[246]   2200
res[247]   2800
res[248]   3000
res[249]   3000
res[250]   3000
res[251]   3000
res[252]   3000
res[253]   3000
res[254]   3000
res[255]   3000
res[256]   3000
res[257]   3000
res[258]   3000
res[259]   2600
res[260]   2100
res[261]   1600
res[262]   1900
res[263]   2400
res[264]   3000
res[265]   3000
res[266]   3000
res[267]   3000
res[268]   3000
res[269]   3000
res[270]   3000
res[271]    590
res[272]    650
res[273]    730
res[274]    830
res[275]    960
res[276]   1100
res[277]   1200
res[278]   1500
res[279]   1800
res[280]   2500
res[281]   3000
res[282]   3000
res[283]   3000
res[284]   3000
res[285]   3000
res[286]   3000
res[287]   3000
res[288]   3000
res[289]   3000
res[290]   2800
res[291]   3000
res[292]   3000
res[293]   3000
res[294]   3000
res[295]   3000
res[296]   3000
res[297]   3000
res[298]   3000
res[299]   3000
res[300]   3000
res[301]   3000
res[302]   3000
res[303]   3000
res[304]   3000
res[305]   3000
res[306]   3000
res[307]   3000
res[308]   2700
res[309]   2300
res[310]   1700
res[311]    610
res[312]    670
res[313]    760
res[314]    860
res[315]    990
res[316]   1200
res[317]   1400
res[318]   1700
res[319]   2100
res[320]   2600
res[321]    770
res[322]    870
res[323]   1000
res[324]   1200
res[325]   1400
res[326]   1600
res[327]   2000
res[328]   2600
res[329]   2700
res[330]   3000
res[331]   3000
res[332]   3000
res[333]   3000
res[334]   3000
res[335]   3000
res[336]   3000
res[337]   3000
res[338]   3000
res[339]   3000
res[340]   3000
res[341]    350
res[342]    380
res[343]    420
res[344]    460
res[345]    510
res[346]    570
res[347]    810
res[348]    740
res[349]   1200
res[350]   1500
sigma       130
sigma.B    3000
deviance    200

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 229.5 and DIC = 4341.4
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Given that Time cannot be randomized, there is likely to be a temporal dependency structure to the data. The above analyses assume no temporal dependency - actually, they assume that the variance-covariance matrix demonstrates a structure known as sphericity. Lets specifically model in a first order autoregressive correlation structure in an attempt to accommodate the expected temporal autocorrelation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString3=&amp;quot;
+ model {
+    #Likelihood
+    y[1]~dnorm(mu[1],tau)
+    mu[1] &amp;lt;- eta1[1]
+    eta1[1] ~ dnorm(eta[1], taueps)
+    eta[1] &amp;lt;- inprod(beta[],X[1,]) + gamma[Block[1]]
+    res[1] &amp;lt;- y[1]-mu[1]
+    for (i in 2:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- eta1[i]
+       eta1[i] ~ dnorm(temp[i], taueps)
+       temp[i] &amp;lt;- eta[i] + -rho*(mu[i-1]-y[i-1])
+       eta[i] &amp;lt;- inprod(beta[],X[i,]) + gamma[Block[i]]
+     res[i] &amp;lt;- y[i]-mu[i]
+    } 
+    beta ~ dmnorm(a0,A0)
+    for (i in 1:nBlock) {
+      gamma[i] ~ dnorm(0, tau.B) #prior
+    }
+    rho ~ dunif(-1,1)
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;- z/sqrt(chSq) 
+    z ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq ~ dgamma(0.5, 0.5)
+    taueps &amp;lt;- pow(sigma.eps,-2)
+    sigma.eps &amp;lt;- z/sqrt(chSq.eps) 
+    z.eps ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.eps ~ dgamma(0.5, 0.5)
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;- z/sqrt(chSq.B) 
+    z.B ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.B ~ dgamma(0.5, 0.5)
+    sd.y &amp;lt;- sd(res)
+    sd.block &amp;lt;- sd(gamma)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString3, con = &amp;quot;matrixModel3.txt&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~Time,data.rm)
&amp;gt; data.rm.list &amp;lt;- with(data.rm,
+         list(y=y,
+                  Block=as.numeric(Block),
+          X=Xmat,
+          n=nrow(data.rm),
+          nBlock=length(levels(Block)),
+          a0=rep(0,ncol(Xmat)), A0=diag(ncol(Xmat))
+          )
+ )
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;#39;gamma&amp;#39;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;quot;res&amp;quot;,&amp;#39;sigma.eps&amp;#39;,&amp;#39;rho&amp;#39;,&amp;#39;sd.y&amp;#39;,&amp;#39;sd.block&amp;#39;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.rm.r2jags.mt &amp;lt;- jags(data = data.rm.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;matrixModel3.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 350
   Unobserved stochastic nodes: 393
   Total graph size: 3931

Initializing model
&amp;gt; 
&amp;gt; data.rm.mt.mcmc &amp;lt;- data.rm.r2jags.mt$BUGSoutput$sims.matrix
&amp;gt; summary(as.mcmc(data.rm.mt.mcmc[,grep(&amp;#39;beta|sigma|rho&amp;#39;,colnames(data.rm.mt.mcmc))]))

Iterations = 1:3000
Thinning interval = 1 
Number of chains = 1 
Sample size per chain = 3000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

              Mean      SD Naive SE Time-series SE
beta[1]     0.1093  1.0090 0.018422       0.018422
beta[2]     9.1917  1.0421 0.019026       0.019026
rho         0.6991  0.1635 0.002985       0.002985
sigma      63.1901  7.6813 0.140241       0.140241
sigma.B   314.5779 38.4731 0.702419       0.702419
sigma.eps  32.8263  9.4551 0.172625       0.172625

2. Quantiles for each variable:

              2.5%      25%       50%      75%    97.5%
beta[1]    -1.8402  -0.5698   0.09792   0.7920   2.0576
beta[2]     7.2315   8.4966   9.19938   9.8961  11.2232
rho         0.4549   0.5508   0.68313   0.8453   0.9746
sigma      49.8811  56.9814  62.70134  69.5262  77.4328
sigma.B   251.2601 286.7395 310.40901 338.2187 398.3167
sigma.eps  14.8598  25.5907  35.65555  40.2488  46.3558
&amp;gt; 
&amp;gt; #head(data.rm.r2jags.mt$BUGSoutput$sims.list[[c(&amp;#39;beta&amp;#39;,&amp;#39;rho&amp;#39;,&amp;#39;sigma&amp;#39;)]]) 
&amp;gt; #print(data.rm.r2jags.mt)
&amp;gt; data.rm.mcmc.list.mt &amp;lt;- as.mcmc(data.rm.r2jags.mt)
&amp;gt; Data.Rm.mcmc.list.mt &amp;lt;- data.rm.mcmc.list.mt
&amp;gt; 
&amp;gt; # R2 calculations
&amp;gt; Xmat &amp;lt;- model.matrix(~Time, data.rm)
&amp;gt; coefs &amp;lt;- data.rm.r2jags.mt$BUGSoutput$sims.list[[&amp;#39;beta&amp;#39;]]
&amp;gt; fitted &amp;lt;- coefs %*% t(Xmat)
&amp;gt; X.var &amp;lt;- aaply(fitted,1,function(x){var(x)})
&amp;gt; X.var[1:10]
       1        2        3        4        5        6        7        8 
814.3418 591.0181 634.1438 685.5362 900.1883 740.2397 864.5962 435.7952 
       9       10 
672.4743 584.2064 
&amp;gt; 
&amp;gt; Z.var &amp;lt;- data.rm.r2jags.mt$BUGSoutput$sims.list[[&amp;#39;sd.block&amp;#39;]]^2
&amp;gt; R.var &amp;lt;- data.rm.r2jags.mt$BUGSoutput$sims.list[[&amp;#39;sd.y&amp;#39;]]^2
&amp;gt; R2.marginal &amp;lt;- (X.var)/(X.var+Z.var+R.var)
&amp;gt; R2.marginal &amp;lt;- data.frame(Mean=mean(R2.marginal), Median=median(R2.marginal), HPDinterval(as.mcmc(R2.marginal)))
&amp;gt; R2.conditional &amp;lt;- (X.var+Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.conditional &amp;lt;- data.frame(Mean=mean(R2.conditional),
+    Median=median(R2.conditional), HPDinterval(as.mcmc(R2.conditional)))
&amp;gt; R2.block &amp;lt;- (Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.block &amp;lt;- data.frame(Mean=mean(R2.block), Median=median(R2.block), HPDinterval(as.mcmc(R2.block)))
&amp;gt; R2.res&amp;lt;-(R.var)/(X.var+Z.var+R.var)
&amp;gt; R2.res &amp;lt;- data.frame(Mean=mean(R2.res), Median=median(R2.res), HPDinterval(as.mcmc(R2.res)))
&amp;gt; 
&amp;gt; (r2 &amp;lt;- rbind(R2.block=R2.block, R2.marginal=R2.marginal, R2.res=R2.res, R2.conditional=R2.conditional))
                     Mean     Median      lower     upper
R2.block       0.52595295 0.52197768 0.40289527 0.6376026
R2.marginal    0.07190426 0.06983026 0.03887103 0.1087763
R2.res         0.40214279 0.40351594 0.28261806 0.5200679
R2.conditional 0.59785721 0.59648406 0.47993214 0.7173819&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It would appear that the incorporation of a first order autocorrelation structure is indeed appropriate. The degree of correlation between successive points is &lt;span class=&#34;math inline&#34;&gt;\(0.733\)&lt;/span&gt;. Let’s have a look at a summary figure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; coefs &amp;lt;- data.rm.r2jags.mt$BUGSoutput$sims.list[[&amp;#39;beta&amp;#39;]]
&amp;gt; newdata &amp;lt;- with(data.rm, data.frame(Time=seq(min(Time, na.rm=TRUE), max(Time, na.rm=TRUE), len=100)))
&amp;gt; Xmat &amp;lt;- model.matrix(~Time, newdata)
&amp;gt; pred &amp;lt;- (coefs %*% t(Xmat))
&amp;gt; pred &amp;lt;- adply(pred, 2, function(x) {
+    data.frame(Mean=mean(x), Median=median(x, na.rm=TRUE), t(quantile(x,na.rm=TRUE)),
+               HPDinterval(as.mcmc(x)),HPDinterval(as.mcmc(x),p=0.5))
+ })
&amp;gt; newdata &amp;lt;- cbind(newdata, pred)
&amp;gt; #Also calculate the partial observations
&amp;gt; Xmat &amp;lt;- model.matrix(~Time, data.rm)
&amp;gt; pred &amp;lt;- colMeans(as.vector(coefs %*% t(Xmat))+data.rm.r2jags.mt$BUGSoutput$sims.list[[&amp;#39;res&amp;#39;]])
&amp;gt; part.obs &amp;lt;- cbind(data.rm,Median=pred)
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y=Median, x=Time)) +
+   geom_point(data=part.obs, aes(y=Median))+
+   geom_ribbon(aes(ymin=lower, ymax=upper), fill=&amp;#39;blue&amp;#39;,alpha=0.2) +
+   geom_line()+
+   scale_x_continuous(&amp;#39;Time&amp;#39;) +
+   scale_y_continuous(&amp;#39;Y&amp;#39;) +
+   theme_classic() +
+   theme(axis.title.y = element_text(vjust=2, size=rel(1.2)),
+         axis.title.x = element_text(vjust=-2, size=rel(1.2)),
+         plot.margin=unit(c(0.5,0.5,2,2), &amp;#39;lines&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/R2sd_model_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nested Anova - JAGS</title>
      <link>/jags/nested-anova-jags/netsed-anova-jags/</link>
      <pubDate>Sun, 09 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/nested-anova-jags/netsed-anova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When single sampling units are selected amongst highly heterogeneous conditions, it is unlikely that these single units will adequately represent the populations and repeated sampling is likely to yield very different outcomes. For example, if we were investigating the impacts of fuel reduction burning across a highly heterogeneous landscape, our ability to replicate adequately might be limited by the number of burn sites available.&lt;/p&gt;
&lt;p&gt;Alternatively, sub-replicates within each of the sampling units (e.g. sites) can be collected (and averaged) so as to provided better representatives for each of the units and ultimately reduce the unexplained variability of the test of treatments. In essence, the sub-replicates are the replicates of an additional nested factor whose levels are nested within the main treatment factor. A nested factor refers to a factor whose levels are unique within each level of the factor it is nested within and each level is only represented once. For example, the fuel reduction burn study design could consist of three burnt sites and three un-burnt (control) sites each containing four quadrats (replicates of site and sub-replicates of the burn treatment). Each site represents a unique level of a random factor (any given site cannot be both burnt and un-burnt) that is nested within the fire treatment (burned or not).&lt;/p&gt;
&lt;p&gt;A nested design can be thought of as a hierarchical arrangement of factors (hence the alternative name hierarchical designs) whereby a treatment is progressively sub-replicated. As an additional example, imagine an experiment designed to comparing the leaf toughness of a number of tree species. Working down the hierarchy, five individual trees were randomly selected within (nested within) each species, three branches were randomly selected within each tree, two leaves were randomly selected within each branch and the force required to shear the leaf material in half (transversely) was measured in four random locations along the leaf. Clearly any given leaf can only be from a single branch, tree and species. Each level of sub-replication is introduced to further reduce the amount of unexplained variation and thereby increasing the power of the test for the main treatment effect. Additionally, it is possible to investigate which scale has the greatest (or least, etc) degree of variability - the level of the species, individual tree, branch, leaf, leaf region etc.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nested factors are typically random factors, of which the levels are randomly selected to represent all possible levels (e.g. sites). When the main treatment effect (often referred to as Factor A) is a fixed factor, such designs are referred to as a &lt;em&gt;mixed model nested ANOVA&lt;/em&gt;, whereas when Factor A is random, the design is referred to as a &lt;em&gt;Model II nested ANOVA&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fixed nested factors are also possible. For example, specific dates (corresponding to particular times during a season) could be nested within season. When all factors are fixed, the design is referred to as a &lt;em&gt;Model I mixed model&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fully nested designs (the topic of this chapter) differ from other multi-factor designs in that all factors within (below) the main treatment factor are nested and thus interactions are un-replicated and cannot be tested. Indeed, interaction effects (interaction between Factor A and site) are assumed to be zero.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models-frequentist&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models (frequentist)&lt;/h2&gt;
&lt;p&gt;The linear models for two and three factor nested design are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \alpha_i + \beta_{j(i)} + \epsilon_{ijk},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_{j(i)} + gamma_{k(j(i))}  + \epsilon_{ijkl},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the effect of Factor A, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of Factor B, &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the effect of Factor C and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models-bayesian&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models (Bayesian)&lt;/h2&gt;
&lt;p&gt;So called “random effects” are modelled differently from “fixed effects” in that rather than estimate their individual effects, we instead estimate the variability due to these “random effects”. Since technically all variables in a Bayesian framework are random, some prefer to use the terms ‘fixed effects’ and ‘varying effects’. As random factors typically represent “random” selections of levels (such as a set of randomly selected sites), incorporated in order to account for the dependency structure (observations within sites are more likely to be correlated to one another - not strickly independent) to the data, we are not overly interested in the individual differences between levels of the ‘varying’ (random) factor. Instead (in addition to imposing a separate correlation structure within each nest), we want to know how much variability is attributed to this level of the design. The linear models for two and three factor nested design are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \alpha_i + \beta_{j(i)} + \epsilon_{ijk}, \;\;\; \epsilon_{ijk} \sim N(0, \sigma^2), \;\;\; \beta_{j(i)} \sim N(0, \sigma^2_{B}) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_{j(i)} + \gamma_{k(j(i))} + \epsilon_{ijkl}, \;\;\; \epsilon_{ijkl} \sim N(0, \sigma^2), \;\;\; \beta_{j(i)} \sim N(0, \sigma^2_{B}) \;\;\; \gamma_{k(j(i))} \sim N(0, \sigma^2_C) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the effect of Factor A, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the variability of Factor B (nested within Factor A), &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the variability of Factor C (nested within Factor B) and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component that is assumed to be normally distributed with a mean of zero and a constant amount of standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;). The subscripts are iterators. For example, the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; represents the number of effects to be estimated for Factor A. Thus the first formula can be read as the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;-th observation of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is drawn from a normal distribution (with a specific level of variability) and mean proposed to be determined by a base mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; - mean of the first treatment across all nests) plus the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th treatment effect plus the variabilitythe model proposes that, given a base mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and knowing the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th treatment (factor A) and which of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th nests within the treatment the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;-th observation from Block &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; (factor B) within treatment effect.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypotheses&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypotheses&lt;/h2&gt;
&lt;p&gt;Separate null hypotheses are associated with each of the factors, however, nested factors are typically only added to absorb some of the unexplained variability and thus, specific hypotheses tests associated with nested factors are of lesser biological importance. Hence, rather than estimate the effects of random effects, we instead estimate how much variability they contribute.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor A: the main treatment effect (fixed)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A): \mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt; (the population group means are all equal). That is, that the mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to one another - no effect of the factor on the response. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the mean of the first group (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu_1\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A) : \alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt; (the effect of each group equals zero). If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), there is evidence that the null hypothesis is not true indicating that the factor does affect the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Factor A: the main treatment effect (random)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A) : \sigma^2_{\alpha}=0\)&lt;/span&gt; (population variance equals zero). There is no added variance due to all possible levels of A.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Factor B: the nested effect (random)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B) : \sigma^2_{\beta}=0\)&lt;/span&gt; (population variance equals zero). There is no added variance due to all possible levels of B within the (set or all possible) levels of A.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Factor B: the nested effect (fixed)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B): \mu_{1(1)}=\mu_{2(1)}=\ldots=\mu_{j(i)}=\mu\)&lt;/span&gt; (the population group means of B (within A) are all equal).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B): \beta_{1(1)}=\beta_{2(1)}=\ldots=\beta_{j(i)}=0\)&lt;/span&gt; (the effect of each chosen B group equals zero).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;Analysis of variance sequentially partitions the total variability in the response variable into components explained by each of the factors (starting with the factors lowest down in the hierarchy - the most deeply nested) and the components unexplained by each factor. Explained variability is calculated by subtracting the amount unexplained by the factor from the amount unexplained by a reduced model that does not contain the factor. When the null hypothesis for a factor is true (no effect or added variability), the ratio of explained and unexplained components for that factor (F-ratio) should follow a theoretical F-distribution with an expected value less than 1. The appropriate unexplained residuals and therefore the appropriate F-ratios for each factor differ according to the different null hypotheses associated with different combinations of fixed and random factors in a nested linear model (see Table below).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; fact_anova_table
      df        MS         F-ratio (B random)    Var comp (B random)        
A     &amp;quot;a-1&amp;quot;     &amp;quot;MS A&amp;quot;     &amp;quot;(MS A)/(MS B&amp;#39;(A))&amp;quot;   &amp;quot;((MS A) - (MS B&amp;#39;(A)))/nb&amp;quot; 
B&amp;#39;(A) &amp;quot;(b-1)a&amp;quot;  &amp;quot;MS B&amp;#39;(A)&amp;quot; &amp;quot;(MS B&amp;#39;(A))/(MS res)&amp;quot; &amp;quot;((MS B&amp;#39;(A)) - (MS res))/n&amp;quot;
Res   &amp;quot;(n-1)ba&amp;quot; &amp;quot;MS res&amp;quot;   &amp;quot;&amp;quot;                    &amp;quot;&amp;quot;                         
      F-ratio (B fixed)     Var comp (B fixed)         
A     &amp;quot;(MS A)/(MS res)&amp;quot;     &amp;quot;((MS A) - (MS res))/nb&amp;quot;   
B&amp;#39;(A) &amp;quot;(MS B&amp;#39;(A))/(MS res)&amp;quot; &amp;quot;((MS B&amp;#39;(A)) - (MS res))/n&amp;quot;
Res   &amp;quot;&amp;quot;                    &amp;quot;&amp;quot;                         &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The corresponding &lt;code&gt;R&lt;/code&gt; syntax is given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #A fixed/random, B random (balanced)
&amp;gt; summary(aov(y~A+Error(B), data))
&amp;gt; VarCorr(lme(y~A,random=1|B, data))
&amp;gt; 
&amp;gt; #A fixed/random, B random (unbalanced)
&amp;gt; anova(lme(y~A,random=1|B, data), type=&amp;#39;marginal&amp;#39;)
&amp;gt; 
&amp;gt; #A fixed/random, B fixed(balanced)
&amp;gt; summary(aov(y~A+B, data))
&amp;gt; 
&amp;gt; #A fixed/random, B fixed (unbalanced)
&amp;gt; contrasts(data$B) &amp;lt;- contr.sum
&amp;gt; Anova(aov(y~A/B, data), type=&amp;#39;III&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;variance-components&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Variance components&lt;/h2&gt;
&lt;p&gt;As previously alluded to, it can often be useful to determine the relative contribution (to explaining the unexplained variability) of each of the factors as this provides insights into the variability at each different scales. These contributions are known as &lt;strong&gt;Variance components&lt;/strong&gt; and are estimates of the added variances due to each of the factors. For consistency with leading texts on this topic, I have included estimated variance components for various balanced nested ANOVA designs in the above table. However, variance components based on a modified version of the maximum likelihood iterative model fitting procedure (&lt;em&gt;REML&lt;/em&gt;) is generally recommended as this accommodates both balanced and unbalanced designs. While there are no numerical differences in the calculations of variance components for fixed and random factors, fixed factors are interpreted very differently and arguably have little clinical meaning (other to infer relative contribution). For fixed factors, variance components estimate the variance between the means of the specific populations that are represented by the selected levels of the factor and therefore represent somewhat arbitrary and artificial populations. For random factors, variance components estimate the variance between means of all possible populations that could have been selected and thus represents the true population variance.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;An F-distribution represents the relative frequencies of all the possible F-ratio’s when a given null hypothesis is true and certain assumptions about the residuals (denominator in the F-ratio calculation) hold. Consequently, it is also important that diagnostics associated with a particular hypothesis test reflect the denominator for the appropriate F-ratio. For example, when testing the null hypothesis that there is no effect of Factor A (&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_i=0\)&lt;/span&gt;) in a mixed nested ANOVA, the means of each level of Factor B are used as the replicates of Factor A. As with single factor anova, hypothesis testing for nested ANOVA assumes the residuals are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;normally distributed. Factors higher up in the hierarchy of a nested model are based on means (or means of means) of lower factors and thus the &lt;em&gt;Central Limit Theory&lt;/em&gt; would predict that normality will usually be satisfied for the higher level factors. Nevertheless, boxplots using the appropriate scale of replication should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;independent of one another - this requires special consideration so as to ensure that the scale at which sub-replicates are measured is still great enough to enable observations to be independent.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;unbalanced-nested-designs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Unbalanced nested designs&lt;/h2&gt;
&lt;p&gt;Designs that incorporate fixed and random factors (either nested or factorial), involve F-ratio calculations in which the denominators are themselves random factors other than the overall residuals. Many statisticians argue that when such denominators are themselves not statistically significant (at the &lt;span class=&#34;math inline&#34;&gt;\(0.25\)&lt;/span&gt; level), there are substantial power benefits from pooling together successive non-significant denominator terms. Thus an F-ratio for a particular factor might be recalculated after pooling together its original denominator with its denominators denominator and so on. The conservative &lt;span class=&#34;math inline&#34;&gt;\(0.25\)&lt;/span&gt; is used instead of the usual 0.05 to reduce further the likelihood of Type II errors (falsely concluding an effect is non-significant - that might result from insufficient power).&lt;/p&gt;
&lt;p&gt;For a simple completely balanced nested ANOVA, it is possible to pool together (calculate their mean) each of the sub-replicates within each nest (site) and then perform single factor ANOVA on those aggregates. Indeed, for a &lt;em&gt;balanced design&lt;/em&gt;, the estimates and hypothesis for Factor A will be identical to that produced via nested ANOVA. However, if there are an unequal number of sub-replicates within each nest, then the single factor ANOVA will be less powerful that a proper nested ANOVA. &lt;em&gt;Unbalanced designs&lt;/em&gt; are those designs in which sample (subsample) sizes for each level of one or more factors differ. These situations are relatively common in biological research, however such imbalance has some important implications for nested designs.&lt;/p&gt;
&lt;p&gt;Firstly, hypothesis tests are more robust to the assumptions of normality and equal variance when the design is balanced. Secondly (and arguably, more importantly), the model contrasts are not orthogonal (independent) and the sums of squares component attributed to each of the model terms cannot be calculated by simple additive partitioning of the total sums of squares. In such situations, exact F-ratios cannot be constructed (at least in theory), variance components calculations are more complicated and significance tests cannot be computed. The denominator MS in an &lt;em&gt;F-ratio&lt;/em&gt; is determined by examining the expected value of the mean squares of each term in a model. Unequal sample sizes result in expected means squares for which there are no obvious logical comparators that enable the impact of an individual model term to be isolated. The severity of this issue depends on which scale of the sub-sampling hierarchy the unbalance(s) occurs as well whether the unbalance occurs in the replication of a fixed or random factor. For example, whilst unequal levels of the first nesting factor (e.g. unequal number of burn vs un-burnt sites) has no effect on F-ratio construction or hypothesis testing for the top level factor (irrespective of whether either of the factors are fixed or random), unequal sub-sampling (replication) at the level of a random (but not fixed) nesting factor will impact on the ability to construct F-ratios and variance components of all terms above it in the hierarchy. There are a number of alternative ways of dealing with unbalanced nested designs. All alternatives assume that the imbalance is not a direct result of the treatments themselves. Such outcomes are more appropriately analysed by modelling the counts of surviving observations via frequency analysis.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Split the analysis up into separate smaller simple ANOVA’s each using the means of the nesting factor to reflect the appropriate scale of replication. As the resulting sums of squares components are thereby based on an aggregated dataset the analyses then inherit the procedures and requirements of single ANOVA.&lt;/li&gt;
&lt;li&gt;Adopt mixed-modelling techniques.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We note that, in a Bayesian framework, issues of design balance essentially evaporate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-mixed-effects-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear mixed effects models&lt;/h2&gt;
&lt;p&gt;Although the term “mixed-effects” can be used to refer to any design that incorporates both fixed and random predictors, its use is more commonly restricted to designs in which factors are nested or grouped within other factors. Typical examples include nested, longitudinal (measurements repeated over time) data, repeated measures and blocking designs. Furthermore, rather than basing parameter estimations on observed and expected mean squares or error strata (as outline above), mixed-effects models estimate parameters via &lt;strong&gt;maximum likelihood&lt;/strong&gt; (ML) or &lt;strong&gt;residual maximum likelihood&lt;/strong&gt; (REML). In so doing, mixed-effects models more appropriately handle estimation of parameters, effects and variance components of unbalanced designs (particularly for random effects). Resulting fitted (or expected) values of each level of a factor (for example, the expected population site means) are referred to as &lt;em&gt;Best Linear Unbiased Predictors&lt;/em&gt; (BLUP’s). As an acknowledgement that most estimated site means will be more extreme than the underlying true population means they estimate (based on the principle that smaller sample sizes result in greater chances of more extreme observations and that nested sub-replicates are also likely to be highly intercorrelated), BLUP’s are less spread from the overall mean than are simple site means. In addition, mixed-effects models naturally model the “within-block” correlation structure that complicates many longitudinal designs.&lt;/p&gt;
&lt;p&gt;Whilst the basic concepts of mixed-effects models have been around for a long time, recent computing advances and adoptions have greatly boosted the popularity of these procedures. Linear mixed effects models are currently at the forefront of statistical development, and as such, are very much a work in progress - both in theory and in practice. Recent developments have seen a further shift away from the traditional practices associated with degrees of freedom, probability distribution and p-value calculations. The traditional approach to inference testing is to compare the fit of an alternative (full) model to a null (reduced) model (via an F-ratio). When assumptions of normality and homogeneity of variance apply, the degrees of freedom are easily computed and the F-ratio has an exact F-distribution to which it can be compared. However, this approach introduces two additional problematic assumptions when estimating fixed effects in a mixed effects model. Firstly, when estimating the effects of one factor, the parameter estimates associated with other factor(s) are assumed to be the true values of those parameters (not estimates). Whilst this assumption is reasonable when all factors are fixed, as random factors are selected such that they represent one possible set of levels drawn from an entire population of possible levels for the random factor, it is unlikely that the associated parameter estimates accurately reflect the true values. Consequently, there is not necessarily an appropriate F-distribution. Furthermore, determining the appropriate degrees of freedom (nominally, the number of independent observations on which estimates are based) for models that incorporate a hierarchical structure is only possible under very specific circumstances (such as completely balanced designs). Degrees of freedom is a somewhat arbitrary defined concept used primarily to select a theoretical probability distribution on which a statistic can be compared. Arguably, however, it is a concept that is overly simplistic for complex hierarchical designs. Most statistical applications continue to provide the “approximate” solutions (as did earlier versions within &lt;code&gt;R&lt;/code&gt;). However, &lt;code&gt;R&lt;/code&gt; linear mixed effects development leaders argue strenuously that given the above shortcomings, such approximations are variably inappropriate and are thus omitted.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Markov chain Monte Carlo&lt;/strong&gt; (MCMC) sampling methods provide a Bayesian-like alternative for inference testing. Markov chains use the mixed model parameter estimates to generate posterior probability distributions of each parameter from which Monte Carlo sampling methods draw a large set of parameter samples. These parameter samples can then be used to calculate &lt;em&gt;highest posterior density&lt;/em&gt; (HPD) intervals (also known as Bayesian credible intervals). Such intervals indicate the interval in which there is a specified probability (typically &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;%) that the true population parameter lies. Furthermore, whilst technically against the spirit of the Bayesian philosophy, it is also possible to generate P values on which to base inferences.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Imagine we has designed an experiment in which we intend to measure a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) to one of treatments (three levels; “a1”, “a2” and “a3”). The treatments occur at a spatial scale (over an area) that far exceeds the logistical scale of sampling units (it would take too long to sample at the scale at which the treatments were applied). The treatments occurred at the scale of hectares whereas it was only feasible to sample y using 1m quadrats. Given that the treatments were naturally occurring (such as soil type), it was not possible to have more than five sites of each treatment type, yet prior experience suggested that the sites in which you intended to sample were very uneven and patchy with respect to &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. In an attempt to account for this inter-site variability (and thus maximize the power of the test for the effect of treatment, you decided to employ a nested design in which 10 quadrats were randomly located within each of the five replicate sites per three treatments. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(plyr)
&amp;gt; set.seed(123)
&amp;gt; nTreat &amp;lt;- 3
&amp;gt; nSites &amp;lt;- 15
&amp;gt; nSitesPerTreat &amp;lt;- nSites/nTreat
&amp;gt; nQuads &amp;lt;- 10
&amp;gt; site.sigma &amp;lt;- 12
&amp;gt; sigma &amp;lt;- 5
&amp;gt; n &amp;lt;- nSites * nQuads
&amp;gt; sites &amp;lt;- gl(n=nSites,k=nQuads, lab=paste0(&amp;#39;S&amp;#39;,1:nSites))
&amp;gt; A &amp;lt;- gl(nTreat, nSitesPerTreat*nQuads, n, labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a.means &amp;lt;- c(40,70,80)
&amp;gt; ## the site means (treatment effects) are drawn from normal distributions
&amp;gt; ## with means of 40, 70 and 80 and standard deviations of 12
&amp;gt; A.effects &amp;lt;- rnorm(nSites, rep(a.means,each=nSitesPerTreat),site.sigma)
&amp;gt; #A.effects &amp;lt;- a.means %*% t(model.matrix(~A, data.frame(A=gl(nTreat,nSitesPerTreat,nSites))))+rnorm(nSites,0,site.sigma)
&amp;gt; Xmat &amp;lt;- model.matrix(~sites -1)
&amp;gt; lin.pred &amp;lt;- Xmat %*% c(A.effects)
&amp;gt; ## the quadrat observations (within sites) are drawn from
&amp;gt; ## normal distributions with means according to the site means
&amp;gt; ## and standard deviations of 5
&amp;gt; y &amp;lt;- rnorm(n,lin.pred,sigma)
&amp;gt; data.nest &amp;lt;- data.frame(y=y, A=A, Sites=sites,Quads=1:length(y))
&amp;gt; head(data.nest)  #print out the first six rows of the data set
         y  A Sites Quads
1 42.20886 a1    S1     1
2 35.76354 a1    S1     2
3 23.44121 a1    S1     3
4 36.78107 a1    S1     4
5 30.91034 a1    S1     5
6 27.93517 a1    S1     6
&amp;gt; 
&amp;gt; library(ggplot2)
&amp;gt; ggplot(data.nest, aes(y=y, x=1)) + geom_boxplot() + facet_grid(.~Sites)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/generate_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Effects of treatment
&amp;gt; boxplot(y~A, ddply(data.nest, ~A+Sites,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #Site effects
&amp;gt; boxplot(y~Sites, ddply(data.nest, ~A+Sites+Quads,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ## with ggplot2
&amp;gt; ggplot(ddply(data.nest, ~A+Sites,numcolwise(mean, na.rm=T)), aes(y=y, x=A)) +
+   geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the y-axis. Hence it there is no evidence of non-homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;For non-hierarchical linear models, uniform priors on variance (standard deviation) parameters seem to work reasonably well. &lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt; warns that the use of the inverse-gamma family of non-informative priors are very sensitive to ϵ particularly when variance is close to zero and this may lead to unintentionally informative priors. When the number of groups (treatments or varying/random effects) is large (more than &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;), &lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt; advocated the use of either uniform or half-cauchy priors. Yet when the number of groups is low, &lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt; indicates that uniform priors have a tendency to result in inflated variance estimates. Consequently, half-cauchy priors are generally recommended for variances.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Full parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\alpha_0 + \alpha_i + \beta_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_{ij)} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\alpha_0, \alpha_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The &lt;em&gt;full parameterisation&lt;/em&gt;, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Matrix parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\boldsymbol \alpha \boldsymbol X + \beta_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_{ij} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \alpha \sim MVN(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The full parameterisation, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;). The &lt;em&gt;matrix parameterisation&lt;/em&gt; is a compressed notation, In this parameterisation, there are three alpha parameters (one representing the mean of treatment a1, and the other two representing the treatment effects (differences between a2 and a1 and a3 and a1). In generating priors for each of these three alpha parameters, we could loop through each and define a non-informative normal prior to each (as in the Full parameterisation version). However, it turns out that it is more efficient (in terms of mixing and thus the number of necessary iterations) to define the priors from a multivariate normal distribution. This has as many means as there are parameters to estimate (&lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt;) and a &lt;span class=&#34;math inline&#34;&gt;\(3\times3\)&lt;/span&gt; matrix of zeros and &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; in the diagonals.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol \mu =
  \begin{bmatrix} 0  \\ 0  \\ 0 \end{bmatrix}, \;\;\; \sigma^2 \sim   
  \begin{bmatrix}
   1000000 &amp;amp; 0 &amp;amp; 0 \\
   0 &amp;amp; 1000000 &amp;amp; 0 \\
   0 &amp;amp; 0 &amp;amp; 1000000
   \end{bmatrix}. \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\beta_{i(j)}, \sigma^2), \;\;\; \beta_{i(j)}\sim N(\mu_i, \sigma^2_B), \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i = \boldsymbol \alpha \boldsymbol X\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. In the &lt;em&gt;heirarchical parameterisation&lt;/em&gt;, we are indicating two residual layers - one representing the variability in the observed data between individual observations (within sites) and the second representing the variability between site means (within the three treatments).&lt;/p&gt;
&lt;div id=&#34;full-effect-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full effect parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- alpha0 + alpha[A[i]] + beta[site[i]]
+    }
+    
+    #Priors
+    alpha0 ~ dnorm(0, 1.0E-6)
+    alpha[1] &amp;lt;- 0
+    for (i in 2:nA) {
+      alpha[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    for (i in 1:nSite) {
+      beta[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;-z/sqrt(chSq.B)
+    z.B ~ dnorm(0, .0016)I(0,)
+    chSq.B ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;fullModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.list &amp;lt;- with(data.nest,
+         list(y=y,
+                  site=as.numeric(Sites),
+          A=as.numeric(A),
+          n=nrow(data.nest),
+          nSite=length(levels(Sites)),
+                  nA = length(levels(A))
+          )
+ )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha0&amp;quot;,&amp;quot;alpha&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.r2jags.f &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;fullModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 22
   Total graph size: 502

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.f)
Inference for Bugs model at &amp;quot;fullModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
alpha[1]   0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000     1
alpha[2]  27.388   7.149  13.085  22.881  27.312  31.980  41.230 1.001  3000
alpha[3]  40.839   7.083  26.936  36.251  40.800  45.412  55.107 1.002  3000
alpha0    42.325   4.978  32.452  39.136  42.215  45.422  52.310 1.002  3000
sigma      5.069   0.307   4.530   4.851   5.051   5.265   5.722 1.002  3000
sigma.B   10.990   2.527   7.168   9.260  10.656  12.306  17.136 1.009   190
deviance 909.635   5.937 899.898 905.400 908.952 913.145 923.175 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 17.6 and DIC = 927.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- inprod(alpha[],X[i,]) + inprod(beta[], Z[i,])
+    } 
+    
+    #Priors
+    alpha ~ dmnorm(a0,A0)
+    for (i in 1:nZ) {
+      beta[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;-z/sqrt(chSq.B)
+    z.B ~ dnorm(0, .0016)I(0,)
+    chSq.B ~ dgamma(0.5, 0.5)
+ 
+ }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;matrixModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; A.Xmat &amp;lt;- model.matrix(~A,data.nest)
&amp;gt; Zmat &amp;lt;- model.matrix(~-1+Sites, data.nest)
&amp;gt; data.nest.list &amp;lt;- with(data.nest,
+         list(y=y,
+          X=A.Xmat,
+          n=nrow(data.nest),
+          Z=Zmat, nZ=ncol(Zmat),
+          a0=rep(0,3), A0=diag(3)
+          )
+ )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;#39;beta&amp;#39;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.r2jags.m &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;matrixModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 20
   Total graph size: 3231

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.m)
Inference for Bugs model at &amp;quot;matrixModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
alpha[1]   0.201   1.016  -1.750  -0.474   0.215   0.872   2.161 1.001  3000
alpha[2]   0.082   0.972  -1.835  -0.585   0.092   0.730   1.954 1.003  2000
alpha[3]   0.077   1.005  -1.867  -0.608   0.075   0.771   2.055 1.001  3000
beta[1]   31.532   1.871  27.942  30.237  31.536  32.794  35.248 1.001  3000
beta[2]   38.069   1.911  34.289  36.788  38.125  39.343  41.817 1.001  3000
beta[3]   59.346   1.872  55.692  58.089  59.346  60.579  63.088 1.001  3000
beta[4]   40.644   1.936  36.885  39.378  40.659  41.960  44.321 1.002  1400
beta[5]   40.506   1.855  36.802  39.248  40.492  41.750  44.199 1.001  3000
beta[6]   90.495   2.131  86.451  89.013  90.489  91.970  94.602 1.001  3000
beta[7]   75.252   2.114  71.007  73.850  75.238  76.681  79.322 1.002  1200
beta[8]   57.061   2.180  52.888  55.574  57.032  58.568  61.289 1.001  2400
beta[9]   61.336   2.171  57.214  59.855  61.372  62.822  65.415 1.001  3000
beta[10]  62.816   2.159  58.580  61.353  62.774  64.268  67.144 1.001  3000
beta[11]  93.379   2.134  89.192  91.945  93.374  94.750  97.533 1.001  3000
beta[12]  83.011   2.161  78.822  81.508  83.024  84.486  87.245 1.001  3000
beta[13]  82.765   2.202  78.398  81.292  82.774  84.252  87.054 1.001  3000
beta[14]  81.140   2.165  76.775  79.675  81.185  82.598  85.236 1.001  3000
beta[15]  74.041   2.119  70.008  72.616  74.027  75.493  78.245 1.001  3000
sigma      5.058   0.306   4.499   4.844   5.049   5.255   5.710 1.002  1200
sigma.B   68.791  13.133  48.825  59.338  66.869  75.995  98.963 1.002  3000
deviance 909.431   6.235 899.560 905.043 908.621 913.008 923.865 1.003   810

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 19.4 and DIC = 928.8
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;hierarchical-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hierarchical parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString3=&amp;quot;
+ model {
+    #Likelihood (esimating site means (gamma.site)
+    for (i in 1:n) {
+       y[i]~dnorm(quad.means[i],tau)
+       quad.means[i] &amp;lt;- gamma.site[site[i]]
+    }
+    for (i in 1:s) {
+       gamma.site[i] ~ dnorm(site.means[i], tau.site)
+       site.means[i] &amp;lt;- inprod(beta[],A.Xmat[i,])
+    }
+    #Priors
+    for (i in 1:a) {
+      beta[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;-z/sqrt(chSq.B)
+    z.B ~ dnorm(0, .0016)I(0,)
+    chSq.B ~ dgamma(0.5, 0.5)
+ 
+    tau.site &amp;lt;- pow(sigma.site,-2)
+    sigma.site &amp;lt;-z/sqrt(chSq.site)
+    z.site ~ dnorm(0, .0016)I(0,)
+    chSq.site ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString3, con = &amp;quot;hierarchicalModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; A.Xmat &amp;lt;- model.matrix(~A,ddply(data.nest,~Sites,catcolwise(unique)))
&amp;gt; data.nest.list &amp;lt;- with(data.nest,
+         list(y=y,
+                  site=Sites,
+          A.Xmat= A.Xmat,
+          n=nrow(data.nest),
+          s=length(levels(Sites)),
+                  a = ncol(A.Xmat)
+          )
+ )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.site&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.r2jags.h &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;hierarchicalModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 24
   Total graph size: 406

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.h)
Inference for Bugs model at &amp;quot;hierarchicalModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
           mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]     42.139   4.991  32.186  38.913  42.226  45.346  51.751 1.001  3000
beta[2]     27.611   6.859  13.692  23.437  27.617  31.993  41.118 1.001  3000
beta[3]     41.048   7.032  26.813  36.805  41.067  45.316  55.566 1.002  1200
sigma        5.058   0.315   4.483   4.841   5.036   5.257   5.763 1.001  3000
sigma.site  10.889   2.386   7.235   9.269  10.578  12.125  16.695 1.005  3000
deviance   909.557   6.168 899.915 905.154 908.708 913.153 923.686 1.001  1900

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 19.0 and DIC = 928.6
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to include finite-population standard deviations in the model you can use the following code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString4=&amp;quot;
+ model {
+    #Likelihood (esimating site means (gamma.site)
+    for (i in 1:n) {
+       y[i]~dnorm(quad.means[i],tau)
+       quad.means[i] &amp;lt;- gamma.site[site[i]]
+       y.err[i]&amp;lt;- quad.means[i]-y[i]
+    }
+    for (i in 1:s) {
+       gamma.site[i] ~ dnorm(site.means[i], tau.site)
+       site.means[i] &amp;lt;- inprod(beta[],A.Xmat[i,])
+       site.err[i] &amp;lt;- site.means[i] - gamma.site[i]
+    }
+    #Priors
+    for (i in 1:a) {
+      beta[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.site &amp;lt;- pow(sigma.site,-2)
+    sigma.site &amp;lt;-z/sqrt(chSq.site)
+    z.site ~ dnorm(0, .0016)I(0,)
+    chSq.site ~ dgamma(0.5, 0.5)
+    
+    sd.y &amp;lt;- sd(y.err)
+    sd.site &amp;lt;- sd(site.err)
+    sd.A &amp;lt;- sd(beta)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString4, con = &amp;quot;SDModel.txt&amp;quot;)
&amp;gt; 
&amp;gt; #data list
&amp;gt; A.Xmat &amp;lt;- model.matrix(~A,ddply(data.nest,~Sites,catcolwise(unique)))
&amp;gt; data.nest.list &amp;lt;- with(data.nest,
+         list(y=y,
+                  site=Sites,
+          A.Xmat= A.Xmat,
+          n=nrow(data.nest),
+          s=length(levels(Sites)),
+                  a = ncol(A.Xmat)
+          )
+ )
&amp;gt; 
&amp;gt; #parameters and chain details
&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sd.y&amp;quot;,&amp;#39;sd.site&amp;#39;,&amp;#39;sd.A&amp;#39;,&amp;#39;sigma.site&amp;#39;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.nest.r2jags.SD &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;SDModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 22
   Total graph size: 571

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.SD)
Inference for Bugs model at &amp;quot;SDModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
           mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]     42.336   5.027  32.564  39.187  42.338  45.373  52.570 1.004   420
beta[2]     27.417   7.290  12.457  22.904  27.308  31.955  42.039 1.001  2100
beta[3]     40.862   7.164  26.163  36.386  40.920  45.444  55.173 1.007   770
sd.A        10.042   4.276   2.657   7.162   9.646  12.369  19.900 1.001  2200
sd.site     10.592   1.057   9.214   9.909  10.354  11.029  13.276 1.010   280
sd.y         4.999   0.095   4.852   4.929   4.987   5.058   5.219 1.003   770
sigma        5.047   0.309   4.489   4.830   5.029   5.257   5.705 1.005   310
sigma.site  11.003   2.465   7.419   9.295  10.610  12.282  16.704 1.004   480
deviance   909.411   6.011 899.576 904.938 908.750 913.034 922.925 1.003   630

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 18.0 and DIC = 927.5
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calculate &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; from the posterior of the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.mcmc.listSD &amp;lt;- as.mcmc(data.nest.r2jags.SD)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~A, data.nest)
&amp;gt; coefs &amp;lt;- data.nest.r2jags.SD$BUGSoutput$sims.list[[&amp;#39;beta&amp;#39;]]
&amp;gt; fitted &amp;lt;- coefs %*% t(Xmat)
&amp;gt; X.var &amp;lt;- aaply(fitted,1,function(x){var(x)})
&amp;gt; Z.var &amp;lt;- data.nest.r2jags.SD$BUGSoutput$sims.list[[&amp;#39;sd.site&amp;#39;]]^2
&amp;gt; R.var &amp;lt;- data.nest.r2jags.SD$BUGSoutput$sims.list[[&amp;#39;sd.y&amp;#39;]]^2
&amp;gt; R2.marginal &amp;lt;- (X.var)/(X.var+Z.var+R.var)
&amp;gt; R2.marginal &amp;lt;- data.frame(Mean=mean(R2.marginal), Median=median(R2.marginal), HPDinterval(as.mcmc(R2.marginal)))
&amp;gt; R2.conditional &amp;lt;- (X.var+Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.conditional &amp;lt;- data.frame(Mean=mean(R2.conditional),
+    Median=median(R2.conditional), HPDinterval(as.mcmc(R2.conditional)))
&amp;gt; R2.site &amp;lt;- (Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.site &amp;lt;- data.frame(Mean=mean(R2.site), Median=median(R2.site), HPDinterval(as.mcmc(R2.site)))
&amp;gt; R2.res&amp;lt;-(R.var)/(X.var+Z.var+R.var)
&amp;gt; R2.res &amp;lt;- data.frame(Mean=mean(R2.res), Median=median(R2.res), HPDinterval(as.mcmc(R2.res)))
&amp;gt; 
&amp;gt; rbind(R2.site=R2.site, R2.marginal=R2.marginal, R2.res=R2.res, R2.conditional=R2.conditional)
                     Mean    Median      lower      upper
R2.site        0.26437322 0.2428822 0.16881028 0.41958555
R2.marginal    0.67674004 0.6992418 0.49930501 0.78437310
R2.res         0.05888674 0.0584191 0.03459529 0.08514432
R2.conditional 0.94111326 0.9415809 0.91485568 0.96540471&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graphical summaries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; newdata &amp;lt;- with(data.nest, data.frame(A=levels(A)))
&amp;gt; Xmat &amp;lt;- model.matrix(~A, newdata)
&amp;gt; coefs &amp;lt;- data.nest.r2jags.m$BUGSoutput$sims.list[[&amp;#39;alpha&amp;#39;]]
&amp;gt; fit &amp;lt;- coefs %*% t(Xmat)
&amp;gt; newdata &amp;lt;- cbind(newdata,
+    adply(fit, 2, function(x) {
+           data.frame(Mean=mean(x), Median=median(x), HPDinterval(as.mcmc(x)),
+              HPDinterval(as.mcmc(x), p=0.68))
+    })
+ )
&amp;gt; 
&amp;gt; 
&amp;gt; library(ggplot2)
&amp;gt; library(gridExtra)
&amp;gt; library(grid)
&amp;gt; p1 &amp;lt;- ggplot(newdata, aes(y=Median, x=A)) +
+   geom_errorbar(aes(ymin=lower, ymax=upper), width=0.01, size=1) +
+   geom_errorbar(aes(ymin=lower.1, ymax=upper.1), width=0, size=2) +
+   geom_point(size=4, shape=21, fill=&amp;#39;white&amp;#39;)+
+   scale_y_continuous(&amp;#39;Y&amp;#39;)+
+   scale_x_discrete(&amp;#39;X&amp;#39;)+
+   theme_classic()+
+   theme(axis.title.y=element_text(vjust=2, size=rel(1.25)),
+         axis.title.x=element_text(vjust=-2, size=rel(1.25)),
+         plot.margin=unit(c(0.5,0.5,2,2), &amp;#39;lines&amp;#39;)
+   )
&amp;gt; 
&amp;gt; p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/summaries_graph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation---second-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation - second example&lt;/h1&gt;
&lt;p&gt;Now imagine a similar experiment in which we intend to measure a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) to one of treatments (three levels; “a1”, “a2” and “a3”). As with the previous design, we decided to establish a nested design in which there are sub-replicate (&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;m Quadrats) within each Site. In the current design, we have decided to further sub-replicate. Within each of the &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; Quadrats, we are going to randomly place &lt;span class=&#34;math inline&#34;&gt;\(2\times10\)&lt;/span&gt;cm pit traps. Now we have Sites nested within Treatments, Quadrats nested within Sites AND, Pits nested within Sites. The latter of these (Pits nested within Sites) are the observations (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; nTreat &amp;lt;- 3
&amp;gt; nSites &amp;lt;- 15
&amp;gt; nSitesPerTreat &amp;lt;- nSites/nTreat
&amp;gt; nQuads &amp;lt;- 5
&amp;gt; nPits &amp;lt;- 2
&amp;gt; site.sigma &amp;lt;- 10 # sd within between sites within treatment
&amp;gt; quad.sigma &amp;lt;- 10
&amp;gt; sigma &amp;lt;- 7.5
&amp;gt; n &amp;lt;- nSites * nQuads * nPits
&amp;gt; sites &amp;lt;- gl(n=nSites,n/nSites,n, lab=paste(&amp;quot;site&amp;quot;,1:nSites))
&amp;gt; A &amp;lt;- gl(nTreat, n/nTreat, n, labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a.means &amp;lt;- c(40,70,80)
&amp;gt; 
&amp;gt; #A&amp;lt;-gl(nTreat,nSites/nTreat,nSites,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a&amp;lt;-gl(nTreat,1,nTreat,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a.X &amp;lt;- model.matrix(~a, expand.grid(a))
&amp;gt; a.eff &amp;lt;- as.vector(solve(a.X,a.means))
&amp;gt; site.means &amp;lt;- rnorm(nSites,a.X %*% a.eff,site.sigma)
&amp;gt; 
&amp;gt; A &amp;lt;- gl(nTreat,nSites/nTreat,nSites,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; A.X &amp;lt;- model.matrix(~A, expand.grid(A))
&amp;gt; #a.X &amp;lt;- model.matrix(~A, expand.grid(A=gl(nTreat,nSites/nTreat,nSites,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))))
&amp;gt; site.means &amp;lt;- rnorm(nSites,A.X %*% a.eff,site.sigma)
&amp;gt; 
&amp;gt; SITES &amp;lt;- gl(nSites,(nSites*nQuads)/nSites,nSites*nQuads,labels=paste(&amp;#39;site&amp;#39;,1:nSites))
&amp;gt; sites.X &amp;lt;- model.matrix(~SITES-1)
&amp;gt; quad.means &amp;lt;- rnorm(nSites*nQuads,sites.X %*% site.means,quad.sigma)
&amp;gt; 
&amp;gt; #SITES &amp;lt;- gl(nSites,1,nSites,labels=paste(&amp;#39;site&amp;#39;,1:nSites))
&amp;gt; #sites.X &amp;lt;- model.matrix(~SITES-1)
&amp;gt; #quad.means &amp;lt;- rnorm(nSites*nQuads,sites.X %*% site.means,quad.sigma)
&amp;gt; 
&amp;gt; QUADS &amp;lt;- gl(nSites*nQuads,n/(nSites*nQuads),n,labels=paste(&amp;#39;quad&amp;#39;,1:(nSites*nQuads)))
&amp;gt; quads.X &amp;lt;- model.matrix(~QUADS-1)
&amp;gt; #quads.eff &amp;lt;- as.vector(solve(quads.X,quad.means))
&amp;gt; #pit.means &amp;lt;- rnorm(n,quads.eff %*% t(quads.X),sigma)
&amp;gt; pit.means &amp;lt;- rnorm(n,quads.X %*% quad.means,sigma)
&amp;gt; 
&amp;gt; PITS &amp;lt;- gl(nPits*nSites*nQuads,1, n, labels=paste(&amp;#39;pit&amp;#39;,1:(nPits*nSites*nQuads)))
&amp;gt; data.nest1&amp;lt;-data.frame(Pits=PITS,Quads=QUADS,Sites=rep(SITES,each=2), A=rep(A,each=nQuads*nPits),y=pit.means)
&amp;gt; #data.nest1&amp;lt;-data.nest1[order(data.nest1$A,data.nest1$Sites,data.nest1$Quads),]
&amp;gt; head(data.nest1)  #print out the first six rows of the data set
   Pits  Quads  Sites  A        y
1 pit 1 quad 1 site 1 a1 61.79607
2 pit 2 quad 1 site 1 a1 56.24699
3 pit 3 quad 2 site 1 a1 42.40885
4 pit 4 quad 2 site 1 a1 52.06672
5 pit 5 quad 3 site 1 a1 73.71286
6 pit 6 quad 3 site 1 a1 62.50529
&amp;gt; 
&amp;gt; ggplot(data.nest1, aes(y=y, x=1)) + geom_boxplot() + facet_grid(.~Quads)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/generate_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Effects of treatment
&amp;gt; boxplot(y~A, ddply(data.nest1, ~A+Sites,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #Site effects
&amp;gt; boxplot(y~Sites, ddply(data.nest1, ~A+Sites+Quads,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #Quadrat effects
&amp;gt; boxplot(y~Quads, ddply(data.nest1, ~A+Sites+Quads+Pits,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data_ex2-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;it is a little difficult to assess normality/homogeneity of variance of quadrats since there are only two pits per quadrat. Nevertheless, there is no suggestion that variance increases with increasing mean.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;div id=&#34;frequentist-for-comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Frequentist for comparison&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(nlme)
&amp;gt; d.lme &amp;lt;- lme(y ~ A, random=~1|Sites/Quads,data=data.nest1)
&amp;gt; summary(d.lme)
Linear mixed-effects model fit by REML
 Data: data.nest1 
       AIC      BIC   logLik
  1137.994 1155.937 -562.997

Random effects:
 Formula: ~1 | Sites
        (Intercept)
StdDev:    10.38248

 Formula: ~1 | Quads %in% Sites
        (Intercept) Residual
StdDev:    8.441615 7.161178

Fixed effects: y ~ A 
               Value Std.Error DF  t-value p-value
(Intercept) 41.38646   5.04334 75 8.206160  0.0000
Aa2         21.36271   7.13236 12 2.995181  0.0112
Aa3         39.14584   7.13236 12 5.488483  0.0001
 Correlation: 
    (Intr) Aa2   
Aa2 -0.707       
Aa3 -0.707  0.500

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-2.11852493 -0.54600763 -0.03428569  0.53382444  2.26256381 

Number of Observations: 150
Number of Groups: 
           Sites Quads %in% Sites 
              15               75 
&amp;gt; 
&amp;gt; anova(d.lme)
            numDF denDF  F-value p-value
(Intercept)     1    75 446.9152  &amp;lt;.0001
A               2    12  15.1037   5e-04&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;full-effect-parameterisation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full effect parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- alpha0 + alpha[A[i]] + beta.site[site[i]] + beta.quad[quad[i]]
+    }
+    
+    #Priors
+    alpha0 ~ dnorm(0, 1.0E-6)
+    alpha[1] &amp;lt;- 0
+    for (i in 2:nA) {
+      alpha[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    for (i in 1:nSite) {
+      beta.site[i] ~ dnorm(0, tau.Bs) #prior
+    }
+    for (i in 1:nQuad) {
+      beta.quad[i] ~ dnorm(0, tau.Bq) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.Bs &amp;lt;- pow(sigma.Bs,-2)
+    sigma.Bs &amp;lt;-z/sqrt(chSq.Bs)
+    z.Bs ~ dnorm(0, .0016)I(0,)
+    chSq.Bs ~ dgamma(0.5, 0.5)
+ 
+    tau.Bq &amp;lt;- pow(sigma.Bq,-2)
+    sigma.Bq &amp;lt;-z/sqrt(chSq.Bq)
+    z.Bq ~ dnorm(0, .0016)I(0,)
+    chSq.Bq ~ dgamma(0.5, 0.5)
+ 
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;fullModel2.txt&amp;quot;)
&amp;gt; 
&amp;gt; data.nest.list &amp;lt;- with(data.nest1,
+         list(y=y,
+                  site=as.numeric(Sites),
+          A=as.numeric(A),
+          n=nrow(data.nest1),
+          nSite=length(levels(Sites)),
+                  nA = length(levels(A)),
+          nQuad=length(levels(Quads)),
+                  quad = as.numeric(Quads)
+          )
+ )
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;quot;alpha0&amp;quot;,&amp;quot;alpha&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.Bs&amp;quot;,&amp;quot;sigma.Bq&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.nest.r2jags.f2 &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;fullModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 99
   Total graph size: 793

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.f2)
Inference for Bugs model at &amp;quot;fullModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
          mu.vect sd.vect    2.5%      25%      50%      75%    97.5%  Rhat
alpha[1]    0.000   0.000   0.000    0.000    0.000    0.000    0.000 1.000
alpha[2]   21.147   7.532   6.252   16.137   21.140   25.968   35.890 1.001
alpha[3]   38.985   7.635  23.341   34.130   39.120   43.879   53.757 1.001
alpha0     41.541   5.460  30.677   37.967   41.659   45.032   52.383 1.001
sigma       7.294   0.604   6.238    6.870    7.264    7.664    8.580 1.003
sigma.Bq    8.433   1.132   6.355    7.650    8.378    9.175   10.757 1.005
sigma.Bs   10.779   2.673   6.704    8.951   10.409   12.219   17.127 1.017
deviance 1020.495  17.724 988.898 1007.948 1019.500 1032.389 1056.708 1.005
         n.eff
alpha[1]     1
alpha[2]  3000
alpha[3]  3000
alpha0    3000
sigma      970
sigma.Bq   420
sigma.Bs   100
deviance   510

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 156.8 and DIC = 1177.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- inprod(alpha[], X[i,]) + inprod(beta.site[],Z.site[i,]) + inprod(beta.quad[],Z.quad[i,])
+       y.err[i] &amp;lt;- y[i]-mu[i]
+    }
+    
+    #Priors
+    for (i in 1:nX) {
+      alpha[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    for (i in 1:nSite) {
+      beta.site[i] ~ dnorm(0, tau.Bs) #prior
+    }
+    for (i in 1:nQuad) {
+      beta.quad[i] ~ dnorm(0, tau.Bq) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.Bs &amp;lt;- pow(sigma.Bs,-2)
+    sigma.Bs &amp;lt;-z/sqrt(chSq.Bs)
+    z.Bs ~ dnorm(0, .0016)I(0,)
+    chSq.Bs ~ dgamma(0.5, 0.5)
+ 
+    tau.Bq &amp;lt;- pow(sigma.Bq,-2)
+    sigma.Bq &amp;lt;-z/sqrt(chSq.Bq)
+    z.Bq ~ dnorm(0, .0016)I(0,)
+    chSq.Bq ~ dgamma(0.5, 0.5)
+ 
+    sd.res &amp;lt;- sd(y.err[])
+    sd.site &amp;lt;- sd(beta.site[])
+    sd.quad &amp;lt;- sd(beta.quad[])   
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;matrixModel2.txt&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~A, data=data.nest1)
&amp;gt; Zsite &amp;lt;- model.matrix(~-1+Sites, data=data.nest1)
&amp;gt; Zquad &amp;lt;- model.matrix(~-1+Quads, data=data.nest1)
&amp;gt; 
&amp;gt; data.nest.list &amp;lt;- with(data.nest1,
+         list(y=y,
+          n=nrow(data.nest1),
+                  X=Xmat, nX=ncol(Xmat),
+          Z.site=Zsite, nSite=ncol(Zsite),
+                  Z.quad=Zquad, nQuad=ncol(Zquad)
+          )
+ )
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;quot;alpha&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.Bs&amp;quot;,&amp;quot;sigma.Bq&amp;quot;,&amp;#39;sd.res&amp;#39;,&amp;#39;sd.site&amp;#39;,&amp;#39;sd.quad&amp;#39;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.nest.r2jags.m2 &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;matrixModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 99
   Total graph size: 14993

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.m2)
Inference for Bugs model at &amp;quot;matrixModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
          mu.vect sd.vect    2.5%      25%      50%      75%    97.5%  Rhat
alpha[1]   41.247   5.438  30.494   37.721   41.227   44.692   52.262 1.002
alpha[2]   21.535   7.824   6.537   16.541   21.439   26.473   37.416 1.003
alpha[3]   39.276   7.723  24.165   34.357   39.319   44.191   54.637 1.001
sd.quad     8.427   0.828   6.866    7.889    8.420    8.956   10.131 1.001
sd.res      7.221   0.420   6.500    6.924    7.186    7.486    8.137 1.010
sd.site    10.263   1.703   7.202    9.180   10.187   11.240   13.917 1.002
sigma       7.261   0.598   6.189    6.845    7.209    7.631    8.540 1.010
sigma.Bq    8.514   1.064   6.557    7.776    8.454    9.189   10.801 1.001
sigma.Bs   10.703   2.802   6.379    8.805   10.283   12.108   17.304 1.001
deviance 1019.366  17.429 987.783 1007.166 1018.196 1030.618 1056.340 1.010
         n.eff
alpha[1]  3000
alpha[2]  3000
alpha[3]  2500
sd.quad   3000
sd.res     150
sd.site   3000
sigma      160
sigma.Bq  3000
sigma.Bs  3000
deviance   160

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 151.0 and DIC = 1170.4
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we use the &lt;code&gt;JAGS&lt;/code&gt; matrix parameterisation model from above, the &lt;code&gt;JAGS&lt;/code&gt; model is already complete (as we defined the sd components in that model already).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest1.mcmc.listSD &amp;lt;- as.mcmc(data.nest.r2jags.m2)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~A, data.nest1)
&amp;gt; coefs &amp;lt;- data.nest.r2jags.m2$BUGSoutput$sims.list[[&amp;#39;alpha&amp;#39;]]
&amp;gt; fitted &amp;lt;- coefs %*% t(Xmat)
&amp;gt; X.var &amp;lt;- aaply(fitted,1,function(x){var(x)})
&amp;gt; Z.var &amp;lt;- data.nest.r2jags.m2$BUGSoutput$sims.list[[&amp;#39;sd.site&amp;#39;]]^2
&amp;gt; R.var &amp;lt;- data.nest.r2jags.m2$BUGSoutput$sims.list[[&amp;#39;sd.res&amp;#39;]]^2
&amp;gt; R2.marginal &amp;lt;- (X.var)/(X.var+Z.var+R.var)
&amp;gt; R2.marginal &amp;lt;- data.frame(Mean=mean(R2.marginal), Median=median(R2.marginal), HPDinterval(as.mcmc(R2.marginal)))
&amp;gt; R2.conditional &amp;lt;- (X.var+Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.conditional &amp;lt;- data.frame(Mean=mean(R2.conditional),
+    Median=median(R2.conditional), HPDinterval(as.mcmc(R2.conditional)))
&amp;gt; R2.site &amp;lt;- (Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.site &amp;lt;- data.frame(Mean=mean(R2.site), Median=median(R2.site), HPDinterval(as.mcmc(R2.site)))
&amp;gt; R2.res&amp;lt;-(R.var)/(X.var+Z.var+R.var)
&amp;gt; R2.res &amp;lt;- data.frame(Mean=mean(R2.res), Median=median(R2.res), HPDinterval(as.mcmc(R2.res)))
&amp;gt; 
&amp;gt; rbind(R2.site=R2.site, R2.marginal=R2.marginal, R2.res=R2.res, R2.conditional=R2.conditional)
                    Mean    Median     lower     upper
R2.site        0.2537842 0.2373232 0.1145934 0.4450797
R2.marginal    0.6199972 0.6408875 0.4077973 0.7873383
R2.res         0.1262186 0.1233096 0.0646023 0.1907540
R2.conditional 0.8737814 0.8766904 0.8092460 0.9353977&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2006prior&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2006. “Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by Browne and Draper).” &lt;em&gt;Bayesian Analysis&lt;/em&gt; 1 (3): 515–34.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Temporal Autocorrelation - JAGS</title>
      <link>/jags/autocorrelation-jags/autocorrelation-jags/</link>
      <pubDate>Sat, 08 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/autocorrelation-jags/autocorrelation-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Up until now (in the proceeding tutorials), the focus has been on models that adhere to specific assumptions about the underlying populations (and data). Indeed, both before and immediately after fitting these models, I have stressed the importance of evaluating and validating the proposed and fitted models to ensure reliability of the models. It is now worth us revisiting those fundamental assumptions as well as exploring the options that are available when the populations (data) do not conform. Let’s explore a simple linear regression model to see how each of the assumptions relate to the model.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_i + \epsilon_i \;\;\; \text{with} \;\;\; \epsilon_i \sim \text{Normal}(0, \sigma^2).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above simple statistical model models the &lt;strong&gt;linear relationship&lt;/strong&gt; of &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; against &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;. The residuals (&lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;) are assumed to be &lt;strong&gt;normally distributed&lt;/strong&gt; with a mean of zero and a constant (yet unknown) variance (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, &lt;strong&gt;homogeneity of variance&lt;/strong&gt;). The residuals (and thus observations) are also assumed to all be &lt;strong&gt;independent&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Homogeneity of variance and independence are encapsulated within the single symbol for variance (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;). In assuming equal variances and independence, we are actually making an assumption about the variance-covariance structure of the populations (and thus residuals). Specifically, we assume that all populations are equally varied and thus can be represented well by a single variance term (all diagonal values in a &lt;span class=&#34;math inline&#34;&gt;\(N\times N\)&lt;/span&gt; covariance matrix are the same, &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;) and the covariances between each population are zero (off diagonals). In simple regression, each observation (data point) represents a single observation drawn (sampled) from an entire population of possible observations. The above covariance structure thus assumes that the covariance between each population (observation) is zero - that is, each observation is completely independent of each other observation. Whilst it is mathematically convenient when data conform to these conditions (normality, homogeneity of variance, independence and linearity), data often violate one or more of these assumptions. In the following, I want to discuss and explore the causes and options for dealing with non-compliance to each of these conditions. By gaining a better understanding of how the various model fitting engines perform their task, we are better equipped to accommodate aspects of the data that don’t otherwise conform to the simple regression assumptions. In this tutorial we specifically focus on the topic of heterogeneity of the variance.&lt;/p&gt;
&lt;p&gt;In order that the estimated parameters represent the underlying populations in an unbiased manner, the residuals (and thus each each observation) must be independent. However, what if we were sampling a population over time and we were interested in investigating how changes in a response relate to changes in a predictor (such as rainfall). For any response that does not “reset” itself on a regular basis, the state of the population (the value of its response) at a given time is likely to be at least partly dependent on the state of the population at the sampling time before. We can further generalise the above into:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim Dist(\mu_i),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\boldsymbol X \boldsymbol \beta + \boldsymbol Z \boldsymbol \gamma\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; representing the &lt;em&gt;fixed data structure&lt;/em&gt; and &lt;em&gt;fixed effects&lt;/em&gt;, respectively, while with &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol Z\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \gamma\)&lt;/span&gt; represent the &lt;em&gt;varying data structure&lt;/em&gt; and &lt;em&gt;varying effects&lt;/em&gt;, respectively. In simple regression, there are no “varying” effects, and thus:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol \gamma \sim MVN(\boldsymbol 0, \boldsymbol \Sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \Sigma\)&lt;/span&gt; is a variance-covariance matrix of the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol \Sigma =  \frac{\sigma^2}{1-\rho^2}
  \begin{bmatrix}
   1 &amp;amp; \rho^{\phi_{1,2}} &amp;amp; \ldots &amp;amp; \rho^{\phi_{1,n}} \\
   \rho^{\phi_{2,1}} &amp;amp; 1 &amp;amp; \ldots &amp;amp; \vdots\\
   \vdots &amp;amp; \ldots &amp;amp; 1 &amp;amp; \vdots\\
   \rho^{\phi_{n,1}} &amp;amp; \ldots &amp;amp; \ldots &amp;amp; 1
   \end{bmatrix}. \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Notice that this introduces a very large number of additional parameters that require estimating: &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; (error variance), &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; (base autocorrelation) and each of the individual covariances (&lt;span class=&#34;math inline&#34;&gt;\(\rho^{\phi_{n,n}}\)&lt;/span&gt;). Hence, there are always going to be more parameters to estimate than there are date avaiable to use to estimate these paramters. We typically make one of a number of alternative assumptions so as to make this task more manageable.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When we assume that all residuals are independent (regular regression), i.e. &lt;span class=&#34;math inline&#34;&gt;\(\rho=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \Sigma\)&lt;/span&gt; is essentially equal to &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2 \boldsymbol I\)&lt;/span&gt; and we simply use:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol \gamma \sim N( 0,\sigma^2).\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We could assume there is a reasonably simple pattern of correlation that declines over time. The simplest of these is a &lt;em&gt;first order autoregressive&lt;/em&gt; (AR1) structure in which exponent on the correlation declines linearly according to the time lag (&lt;span class=&#34;math inline&#34;&gt;\(\mid t - s\mid\)&lt;/span&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol \Sigma =  \frac{\sigma^2}{1-\rho^2}
  \begin{bmatrix}
   1 &amp;amp; \rho &amp;amp; \ldots &amp;amp; \rho^{\mid t-s \mid} \\
   \rho &amp;amp; 1 &amp;amp; \ldots &amp;amp; \vdots\\
   \vdots &amp;amp; \ldots &amp;amp; 1 &amp;amp; \vdots\\
   \rho^{\mid t-s \mid } &amp;amp; \ldots &amp;amp; \ldots &amp;amp; 1
   \end{bmatrix}. \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note, in making this assumption, we are also assuming that the degree of correlation is dependent only on the lag and not on when the lag occurs (stationarity). That is all lag 1 residual pairs will have the same degree of correlation, all the lag &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; pairs will have the same correlation and so on.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;first-order-autocorrelation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;First order autocorrelation&lt;/h1&gt;
&lt;p&gt;Consider an example, in which the number of individuals at time &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; will be partly dependent on the number of individuals present at time &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;. Clearly then, the observations (and thus residuals) are not fully independent - there is an auto-regressive correlation dependency structure. We could accommodate this lack of independence by fitting a model that incorporates a AR1 variance-covariance structure. Alternatively, we fit the following model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{it} \sim Dist(\mu_{it}),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu_{it}=\boldsymbol X \boldsymbol \beta + \rho \epsilon_{i,t-1} + \gamma_{it},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and where &lt;span class=&#34;math inline&#34;&gt;\(\gamma \sim N(0, \sigma^2)\)&lt;/span&gt;. In this version of the model, we are stating that the expected value of an observation is equal to the regular linear predictor plus the autocorrelation parameter (&lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;) multipled by the residual associated with the previous observation plus the regular independently distributed noise (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;). Such a model is substantially faster to fit, although along with stationarity assumes in estimating the autocorrelation parameter, only the smallest lags are used. To see this in action, we will first generate some temporally auto-correlated data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(126)
&amp;gt; n = 50
&amp;gt; a &amp;lt;- 20  #intercept
&amp;gt; b &amp;lt;- 0.2  #slope
&amp;gt; x &amp;lt;- round(runif(n, 1, n), 1)  #values of the year covariate
&amp;gt; year &amp;lt;- 1:n
&amp;gt; sigma &amp;lt;- 20
&amp;gt; rho &amp;lt;- 0.8
&amp;gt; 
&amp;gt; library(nlme)
&amp;gt; ## define a constructor for a first-order
&amp;gt; ## correlation structure
&amp;gt; ar1 &amp;lt;- corAR1(form = ~year, value = rho)
&amp;gt; ## initialize this constructor against our data
&amp;gt; AR1 &amp;lt;- Initialize(ar1, data = data.frame(year))
&amp;gt; ## generate a correlation matrix
&amp;gt; V &amp;lt;- corMatrix(AR1)
&amp;gt; ## Cholesky factorization of V
&amp;gt; Cv &amp;lt;- chol(V)
&amp;gt; ## simulate AR1 errors
&amp;gt; e &amp;lt;- t(Cv) %*% rnorm(n, 0, sigma)  # cov(e) = V * sig^2
&amp;gt; ## generate response
&amp;gt; y &amp;lt;- a + b * x + e
&amp;gt; data.temporalCor = data.frame(y = y, x = x, year = year)
&amp;gt; write.table(data.temporalCor, file = &amp;quot;data.temporalCor.csv&amp;quot;,
+     sep = &amp;quot;,&amp;quot;, quote = F, row.names = FALSE)
&amp;gt; 
&amp;gt; pairs(data.temporalCor)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/generate_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We will now proceed to analyse these data via both of the above techniques for &lt;code&gt;JAGS&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;incorporating AR1 residual autocorrelation structure&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;incorporating lagged residuals into the model&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;incorporating-lagged-residuals&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Incorporating lagged residuals&lt;/h1&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Define the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot; 
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   fit[i] &amp;lt;- inprod(beta[],X[i,])
+   y[i] ~ dnorm(mu[i],tau.cor)
+   }
+   e[1] &amp;lt;- (y[1] - fit[1])
+   mu[1] &amp;lt;- fit[1]
+   for (i in 2:n) {
+   e[i] &amp;lt;- (y[i] - fit[i]) #- phi*e[i-1]
+   mu[i] &amp;lt;- fit[i] + phi * e[i-1]
+   }
+   #Priors
+   phi ~ dunif(-1,1)
+   for (i in 1:nX) {
+   beta[i] ~ dnorm(0,1.0E-6)
+   }
+   sigma &amp;lt;- z/sqrt(chSq)    # prior for sigma; cauchy = normal/sqrt(chi^2)
+   z ~ dnorm(0, 0.04)I(0,)
+   chSq ~ dgamma(0.5, 0.5)  # chi^2 with 1 d.f.
+   tau &amp;lt;- pow(sigma, -2)
+   tau.cor &amp;lt;- tau #* (1- phi*phi)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;tempModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat = model.matrix(~x, data.temporalCor)
&amp;gt; data.temporalCor.list &amp;lt;- with(data.temporalCor, list(y = y, X = Xmat,
+     n = nrow(data.temporalCor), nX = ncol(Xmat)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;phi&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 10000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.temporalCor.r2jags &amp;lt;- jags(data = data.temporalCor.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;tempModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 50
   Unobserved stochastic nodes: 5
   Total graph size: 413

Initializing model
&amp;gt; 
&amp;gt; print(data.temporalCor.r2jags)
Inference for Bugs model at &amp;quot;tempModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   30.841  11.858   8.852  22.556  30.505  38.559  55.177 1.001 10000
beta[2]    0.225   0.100   0.028   0.159   0.225   0.292   0.422 1.001  3800
phi        0.913   0.054   0.793   0.879   0.919   0.954   0.994 1.001  3400
sigma     12.133   1.253   9.967  11.253  12.034  12.902  14.828 1.001  7300
deviance 391.602   2.641 388.354 389.656 390.985 392.927 398.180 1.001  9200

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.5 and DIC = 395.1
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MCMC diagnostics&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.temporalCor.r2jags, parms = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;phi&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.temporalCor.r2jags, parms = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;phi&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.temporalCor.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3930  3746         1.05      
 beta[2]  2        3866  3746         1.03      
 deviance 2        3866  3746         1.03      
 phi      7        7397  3746         1.97      
 sigma    4        4636  3746         1.24      


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  3        4062  3746         1.080     
 beta[2]  2        3620  3746         0.966     
 deviance 2        3803  3746         1.020     
 phi      6        6878  3746         1.840     
 sigma    4        4713  3746         1.260     &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
           beta[1]      beta[2]     deviance          phi        sigma
Lag 0  1.000000000  1.000000000  1.000000000  1.000000000  1.000000000
Lag 1  0.174857318 -0.006205038  0.164212015  0.398270011  0.166634323
Lag 5  0.017823932  0.002140092 -0.016470982  0.017851360  0.011892997
Lag 10 0.004107514  0.010910488  0.020001216 -0.005693854  0.007020861
Lag 50 0.002176470  0.016102607  0.008360988  0.002061169 -0.007663541&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All diagnostics seem fine.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model validation&lt;/h2&gt;
&lt;p&gt;Whenever we fit a model that incorporates changes to the variance-covariance structures, we need to explore modified standardized residuals. In this case, the raw residuals should be updated to reflect the autocorrelation (subtract residual from previous time weighted by the autocorrelation parameter) before standardising by &lt;code&gt;sigma&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Res_i = Y_i - \mu_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Res_{i+1} = Res_{i+1} - \rho Res_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Res_i = \frac{Res_i}{\sigma} \]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.temporalCor.r2jags$BUGSoutput$sims.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.temporalCor
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = -1 * sweep(fit, 2, data.temporalCor$y, &amp;quot;-&amp;quot;)
&amp;gt; n = ncol(resid)
&amp;gt; resid[, -1] = resid[, -1] - (resid[, -n] * mcmc[, &amp;quot;phi&amp;quot;])
&amp;gt; resid = apply(resid, 2, median)/median(mcmc[, &amp;quot;sigma&amp;quot;])
&amp;gt; fit = apply(fit, 2, median)
&amp;gt; 
&amp;gt; library(ggplot2)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = data.temporalCor$x)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_residuals-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data = NULL, aes(y = resid, x = data.temporalCor$year)) +
+     geom_point() + geom_line() + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_residuals-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; plot(acf(resid, lag = 40))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_residuals-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;No obvious autocorrelation or other issues with residuals remaining.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parameter estimates&lt;/h2&gt;
&lt;p&gt;Explore parameter estimates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.temporalCor.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 5 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    30.8     11.9      7.36      53.5  
2 beta[2]     0.225    0.100    0.0321     0.425
3 deviance  392.       2.64   388.       397.   
4 phi         0.913    0.0537   0.813      1.000
5 sigma      12.1      1.25     9.91      14.7  &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;incorporating-ar1-residual-autocorrelation-structure&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Incorporating AR1 residual autocorrelation structure&lt;/h1&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Define the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2 = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   mu[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   y[1:n] ~ dmnorm(mu[1:n],Omega)
+   for (i in 1:n) {
+   for (j in 1:n) {
+   Sigma[i,j] &amp;lt;- sigma2*(equals(i,j) + (1-equals(i,j))*pow(phi,abs(i-j))) 
+   }
+   }
+   Omega &amp;lt;- inverse(Sigma)
+   
+   #Priors
+   phi ~ dunif(-1,1)
+   for (i in 1:nX) {
+   beta[i] ~ dnorm(0,1.0E-6)
+   }
+   sigma &amp;lt;- z/sqrt(chSq)    # prior for sigma; cauchy = normal/sqrt(chi^2)
+   z ~ dnorm(0, 0.04)I(0,)
+   chSq ~ dgamma(0.5, 0.5)  # chi^2 with 1 d.f.
+   sigma2 = pow(sigma,2)
+   #tau.cor &amp;lt;- tau #* (1- phi*phi)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;tempModel2.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat = model.matrix(~x, data.temporalCor)
&amp;gt; data.temporalCor.list &amp;lt;- with(data.temporalCor, list(y = y, X = Xmat,
+     n = nrow(data.temporalCor), nX = ncol(Xmat)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;phi&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 5000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 10000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.temporalCor2.r2jags &amp;lt;- jags(data = data.temporalCor.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;tempModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 1
   Unobserved stochastic nodes: 5
   Total graph size: 5566

Initializing model
&amp;gt; 
&amp;gt; print(data.temporalCor2.r2jags)
Inference for Bugs model at &amp;quot;tempModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10000 iterations (first 5000 discarded)
 n.sims = 10000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   19.926  24.597 -19.141   9.722  18.990  29.365  64.348 1.014 10000
beta[2]    0.225   0.100   0.028   0.159   0.227   0.291   0.421 1.001 10000
phi        0.890   0.055   0.773   0.854   0.895   0.930   0.980 1.011   160
sigma     30.352  15.780  18.171  22.799  26.810  32.951  61.419 1.010   410
deviance 392.642   2.706 389.232 390.628 392.029 394.019 399.490 1.001  2900

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.7 and DIC = 396.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MCMC diagnostics&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(data.temporalCor2.r2jags, parms = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;phi&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_diag_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.temporalCor2.r2jags, parms = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;phi&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_diag_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.temporalCor2.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  15       14982 3746         4.00      
 beta[2]  2        3866  3746         1.03      
 deviance 2        3995  3746         1.07      
 phi      9        9308  3746         2.48      
 sigma    8        10294 3746         2.75      


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  4        4955  3746         1.320     
 beta[2]  2        3620  3746         0.966     
 deviance 2        3930  3746         1.050     
 phi      12       12162 3746         3.250     
 sigma    8        10644 3746         2.840     &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
            beta[1]      beta[2]   deviance       phi      sigma
Lag 0   1.000000000  1.000000000 1.00000000 1.0000000 1.00000000
Lag 1   0.023745389 -0.007088969 0.19477040 0.8775299 0.95206712
Lag 5   0.019171996  0.008569178 0.08589717 0.5774327 0.80961727
Lag 10 -0.009155805  0.008682983 0.06468974 0.3677587 0.64495814
Lag 50  0.012167974  0.014954099 0.01686647 0.0317406 0.04466731&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All diagnostics seem fine.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model validation&lt;/h2&gt;
&lt;p&gt;Whenever we fit a model that incorporates changes to the variance-covariance structures, we need to explore modified standardized residuals. In this case, the raw residuals should be updated to reflect the autocorrelation (subtract residual from previous time weighted by the autocorrelation parameter) before standardising by &lt;code&gt;sigma&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Res_i = Y_i - \mu_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Res_{i+1} = Res_{i+1} - \rho Res_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Res_i = \frac{Res_i}{\sigma} \]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.temporalCor2.r2jags$BUGSoutput$sims.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.temporalCor
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = -1 * sweep(fit, 2, data.temporalCor$y, &amp;quot;-&amp;quot;)
&amp;gt; n = ncol(resid)
&amp;gt; resid[, -1] = resid[, -1] - (resid[, -n] * mcmc[, &amp;quot;phi&amp;quot;])
&amp;gt; resid = apply(resid, 2, median)/median(mcmc[, &amp;quot;sigma&amp;quot;])
&amp;gt; fit = apply(fit, 2, median)
&amp;gt; 
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_residuals_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = data.temporalCor$x)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_residuals_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data = NULL, aes(y = resid, x = data.temporalCor$year)) +
+     geom_point() + geom_line() + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_residuals_ex2-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; plot(acf(resid, lag = 40))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/autocorrelation-jags/2020-02-01-autocorrelation-jags_files/figure-html/mcmc_residuals_ex2-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;No obvious autocorrelation or other issues with residuals remaining&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parameter estimates&lt;/h2&gt;
&lt;p&gt;Explore parameter estimates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; tidyMCMC(as.mcmc(data.temporalCor2.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 5 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    19.9     24.6    -16.6       66.3  
2 beta[2]     0.225    0.0997   0.0313     0.423
3 deviance  393.       2.71   389.       398.   
4 phi         0.890    0.0546   0.780      0.984
5 sigma      30.4     15.8     16.2       51.2  &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Variance Heterogeneity - JAGS</title>
      <link>/jags/heterogeneity-jags/heterogeneity-jags/</link>
      <pubDate>Fri, 07 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/heterogeneity-jags/heterogeneity-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Up until now (in the proceeding tutorials), the focus has been on models that adhere to specific assumptions about the underlying populations (and data). Indeed, both before and immediately after fitting these models, I have stressed the importance of evaluating and validating the proposed and fitted models to ensure reliability of the models. It is now worth us revisiting those fundamental assumptions as well as exploring the options that are available when the populations (data) do not conform. Let’s explore a simple linear regression model to see how each of the assumptions relate to the model.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_i + \epsilon_i \;\;\; \text{with} \;\;\; \epsilon_i \sim \text{Normal}(0, \sigma^2).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above simple statistical model models the &lt;strong&gt;linear relationship&lt;/strong&gt; of &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; against &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;. The residuals (&lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;) are assumed to be &lt;strong&gt;normally distributed&lt;/strong&gt; with a mean of zero and a constant (yet unknown) variance (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, &lt;strong&gt;homogeneity of variance&lt;/strong&gt;). The residuals (and thus observations) are also assumed to all be &lt;strong&gt;independent&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Homogeneity of variance and independence are encapsulated within the single symbol for variance (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;). In assuming equal variances and independence, we are actually making an assumption about the variance-covariance structure of the populations (and thus residuals). Specifically, we assume that all populations are equally varied and thus can be represented well by a single variance term (all diagonal values in a &lt;span class=&#34;math inline&#34;&gt;\(N\times N\)&lt;/span&gt; covariance matrix are the same, &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;) and the covariances between each population are zero (off diagonals). In simple regression, each observation (data point) represents a single observation drawn (sampled) from an entire population of possible observations. The above covariance structure thus assumes that the covariance between each population (observation) is zero - that is, each observation is completely independent of each other observation. Whilst it is mathematically convenient when data conform to these conditions (normality, homogeneity of variance, independence and linearity), data often violate one or more of these assumptions. In the following, I want to discuss and explore the causes and options for dealing with non-compliance to each of these conditions. By gaining a better understanding of how the various model fitting engines perform their task, we are better equipped to accommodate aspects of the data that don’t otherwise conform to the simple regression assumptions. In this tutorial we specifically focus on the topic of heterogeneity of the variance.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;dealing-with-heterogeneity&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dealing with heterogeneity&lt;/h1&gt;
&lt;p&gt;The validity and reliability of the above linear models are very much dependent on variance homogeneity. In particular, variances that increase (or decrease) with a change in expected values are substantial violations. Whilst non-normality can also be a source of heterogeneity and therefore normalising can address both issues, heterogeneity can also be independent of normality. Similarly, generalised linear models (that accommodate alternative residual distributions - such as Poisson, Binomial, Gamma, etc) can be useful for more appropriate modelling of both the distribution and variance of a model. However, for Gaussian (normal) models in which there is evidence of heterogeneity of variance, yet no evidence of non-normality, it is also possible to specifically model in an alternative variance structure. For example, we can elect to allow variance to increase proportionally to a covariate. To assist us in the following demonstration, we will generate another data set - one that has heteroskedasticity (unequal variance) by design. Rather than draw each residual (and thus observation) from a normal distribution with a constant standard deviation), we will draw the residuals from normal distributions whose variance is proportional to the &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; predictor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(126)
&amp;gt; n &amp;lt;- 16
&amp;gt; a &amp;lt;- 40  #intercept
&amp;gt; b &amp;lt;- 1.5  #slope
&amp;gt; x &amp;lt;- 1:n  #values of the year covariate
&amp;gt; sigma &amp;lt;- 1.5 * x
&amp;gt; sigma
 [1]  1.5  3.0  4.5  6.0  7.5  9.0 10.5 12.0 13.5 15.0 16.5 18.0 19.5 21.0 22.5
[16] 24.0
&amp;gt; 
&amp;gt; eps &amp;lt;- rnorm(n, mean = 0, sd = sigma)  #residuals
&amp;gt; y &amp;lt;- a + b * x + eps  #response variable
&amp;gt; # OR
&amp;gt; y &amp;lt;- (model.matrix(~x) %*% c(a, b)) + eps
&amp;gt; data.het &amp;lt;- data.frame(y = round(y, 1), x)  #dataset
&amp;gt; head(data.het)  #print out the first six rows of the data set
     y x
1 42.1 1
2 44.2 2
3 41.2 3
4 51.7 4
5 43.5 5
6 48.3 6
&amp;gt; 
&amp;gt; # scatterplot of y against x
&amp;gt; library(car)
&amp;gt; scatterplot(y ~ x, data.het)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/generate_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; # regular simple linear regression
&amp;gt; data.het.lm &amp;lt;- lm(y ~ x, data.het)
&amp;gt; 
&amp;gt; # plot of standardised residuals
&amp;gt; plot(rstandard(data.het.lm) ~ fitted(data.het.lm))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/generate_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; # plot of standardized residuals against the predictor
&amp;gt; plot(rstandard(data.het.lm) ~ x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/generate_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above scatterplot suggests that variance may increase with increasing &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The residual plot (using standardised residuals) suggests that mean and variance could be related - there is a hint of a wedge-shaped pattern. Importantly, the plot of standardised residuals against the predictor shows the same pattern as the residual plot implying that heterogeneity is likely to be due a relationship between variance &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. That is, an increase in &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is associated with an increase in variance. In response to this, we could incorporate an alternative variance structure. The simple model we fit earlier assumed that the expected values were all drawn from normal distributions with the same level of precision &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; and therefore variance. This assumption is often summarised as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol V = \sigma^2 \times \boldsymbol I,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol I\)&lt;/span&gt; is the &lt;span class=&#34;math inline&#34;&gt;\(N \times N\)&lt;/span&gt; identity matrix (elements on the main diagonal are one and zero outside) which multipled by the constant value &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; produces the homoskedastic covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol V\)&lt;/span&gt; (elements on the main diagonal are &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; and zero outside). If, instead, we consider an heteroskedastic covariance matrix then, for example, we could assume that the variance is proportional to the level of the covariate. This assumption can be summarised as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol V = \sigma^2 \times X \times \boldsymbol I,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the product of the identity matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol I\)&lt;/span&gt; and the covariate-specific values &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2 \times X\)&lt;/span&gt; produces the heteroskedastic covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol V\)&lt;/span&gt; (elements on the main diagonal are &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2 \times X\)&lt;/span&gt; and zero outside). With a couple of small adjustments, we can modify the &lt;code&gt;JAGS&lt;/code&gt; code in order to accommodate a variance structure in which variance is proportional to the predictor variable. Note that since &lt;code&gt;JAGS&lt;/code&gt; works with precision (&lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;), I have elected to express the predictor as &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{x}\)&lt;/span&gt;. This way the weightings are compatible with precision rather than variance. In previous tutorials, we have used a flat, uniform distribution &lt;span class=&#34;math inline&#34;&gt;\([0,100]\)&lt;/span&gt; for variance priors. Whilst this is a reasonable choice for a non-informative prior, &lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt; suggest that half-cauchy priors are more appropriate when the number of groups is low.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation weighted by &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; on the value of the covariate (&lt;span class=&#34;math inline&#34;&gt;\(\sigma \times \omega\)&lt;/span&gt;). The expected values (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0 + \beta_1x\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the mean of the first group and the set of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;’s represent the differences between each other group and the first group. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma \times \omega),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. We note that we can also indirectly specify the prior on &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; by expressing the standard deviation as the ratio between two variable: &lt;span class=&#34;math inline&#34;&gt;\(\sigma=\frac{z}{\sqrt{\chi}}\)&lt;/span&gt;. The numerator is a zero-truncated normally distributed variable &lt;span class=&#34;math inline&#34;&gt;\(z \sim N(0, 0.04) I(0,)\)&lt;/span&gt;, while the denominator is the square root of a variable distributed according to a Gamma distribution &lt;span class=&#34;math inline&#34;&gt;\(\chi \sim \text{Gamma}(0.5,0.5)\)&lt;/span&gt; (equivalent to a &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution with &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; degrees of freedom).&lt;/p&gt;
&lt;p&gt;We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Note the following example as group means calculated as derived posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mu[i],tau*(1/x[i]))
+   mu[i] &amp;lt;- beta0+beta1*x[i]
+   }
+ 
+   #Priors and derivatives
+   beta0 ~ dnorm(0,1.0E-6)
+   beta1 ~ dnorm(0,1.0E-6)
+ 
+   sigma &amp;lt;- z/sqrt(chSq)    # prior for sigma; cauchy = normal/sqrt(chi^2)
+   z ~ dnorm(0, 0.04)I(0,)
+   chSq ~ dgamma(0.5, 0.5)  # chi^2 with 1 d.f.
+   tau &amp;lt;- pow(sigma, -2)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;heteroskModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.het.list &amp;lt;- with(data.het, list(y = y, x = x, n = nrow(data.het)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.het.r2jags &amp;lt;- jags(data = data.het.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;heteroskModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 16
   Unobserved stochastic nodes: 4
   Total graph size: 111

Initializing model
&amp;gt; 
&amp;gt; print(data.het.r2jags)
Inference for Bugs model at &amp;quot;heteroskModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta0     41.492   2.571  36.510  39.844  41.466  43.160  46.599 1.001 15000
beta1      1.114   0.401   0.313   0.857   1.112   1.371   1.913 1.001 15000
sigma      3.070   0.629   2.119   2.627   2.969   3.410   4.592 1.002  1300
deviance 110.901   2.744 107.742 108.871 110.200 112.216 117.874 1.002  2800

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.8 and DIC = 114.7
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.het.r2jags, parms = c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.het.r2jags, parms = c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trace plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters (such as &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;s).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.het.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    2        3938  3746         1.050     
 beta1    2        3729  3746         0.995     
 deviance 2        3770  3746         1.010     
 sigma    4        4643  3746         1.240     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    2        3853  3746         1.030     
 beta1    2        3895  3746         1.040     
 deviance 2        3729  3746         0.995     
 sigma    3        4346  3746         1.160     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
              beta0         beta1     deviance        sigma
Lag 0   1.000000000  1.0000000000  1.000000000  1.000000000
Lag 1   0.011777589  0.0071404620  0.229687388  0.247278554
Lag 5   0.006349593  0.0032513419 -0.000699578  0.011972761
Lag 10 -0.001248639 -0.0002634626 -0.010327446 -0.001271626
Lag 50  0.018019858 -0.0055775204 -0.013066989  0.010275604&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.&lt;/p&gt;
&lt;p&gt;There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Standardised residuals&lt;/strong&gt;. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Studentised residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the residuals. Note that &lt;strong&gt;externally studentised residuals&lt;/strong&gt; are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pearson residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%) back thereby allowing us to train the model on &lt;span class=&#34;math inline&#34;&gt;\(75\)&lt;/span&gt;% of the data and then see how well the model can predict the withheld &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.&lt;/p&gt;
&lt;p&gt;Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within &lt;code&gt;JAGS&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.het.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data.het$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data.het$y - fit
&amp;gt; 
&amp;gt; library(ggplot2)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above residual plot would make us believe that we had a homogeneity of variance issue (which we thought we were addressing by defining a model that allowed the variance to be proportional to the predictor). This is because we have plotted the raw residuals rather than residuals that have been standardized by the variances. The above plot is also what the residual plot would look like if we had not made any attempt to define a model in which the variance was related to the predictor. Whenever we fit a model that incorporates changes to the variance-covariance structures, we should explore standardised residuals. In this case, we should divide the residuals by sigma and then divide by the square-root of the weights.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Res_i = \frac{Y_i - \mu_i}{\sigma \times \sqrt{\omega}}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; library(tidyr)
&amp;gt; mcmc = data.het.r2jags$BUGSoutput$sims.matrix
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; Xmat = model.matrix(~x, data.het)
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = -1 * sweep(fit, 2, data.het$y, &amp;quot;-&amp;quot;)
&amp;gt; resid = apply(resid, 2, median)/(median(mcmc[, &amp;quot;sigma&amp;quot;]) * sqrt(data.het$x))
&amp;gt; fit = apply(fit, 2, median)
&amp;gt; 
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is certainly an improvement. Nevertheless, there is still an indication of a relationship between mean and variance. We could attempt to further address this by refining &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt; in the Bayesian model. That is, rather than indicate that variance is proportional to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, we could indicate that variance is proportional to &lt;span class=&#34;math inline&#34;&gt;\(x^2\)&lt;/span&gt; (as an example) - we will leave this as an exercise for the reader. Residuals against predictors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = data.het$x)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.het.r2jags$BUGSoutput$sims.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~x, data.het)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data.het), fit[i, ],
+     mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; ggplot() + geom_density(data = NULL, aes(x = as.vector(yRep), fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_density(data = data.het, aes(x = y, fill = &amp;quot;Obs&amp;quot;),
+     alpha = 0.5) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;First, we look at the results from the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.het.r2jags)
Inference for Bugs model at &amp;quot;heteroskModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta0     41.492   2.571  36.510  39.844  41.466  43.160  46.599 1.001 15000
beta1      1.114   0.401   0.313   0.857   1.112   1.371   1.913 1.001 15000
sigma      3.070   0.629   2.119   2.627   2.969   3.410   4.592 1.002  1300
deviance 110.901   2.744 107.742 108.871 110.200 112.216 117.874 1.002  2800

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.8 and DIC = 114.7
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.het.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta0       41.5      2.57    36.5       46.6 
2 beta1        1.11     0.401    0.338      1.94
3 deviance   111.       2.74   108.       116.  
4 sigma        3.07     0.629    2.00       4.35&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A one unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(1.11\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; declines at a rate of &lt;span class=&#34;math inline&#34;&gt;\(1.11\)&lt;/span&gt; per unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the slope does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }
&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.het.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta1&amp;quot;)])
[1] 0.0092&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of essentially &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, we would conclude that there is almost no evidence that the slope was likely to be equal to zero, suggesting there is a relationship.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.het.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = data.frame(x = seq(min(data.het$x, na.rm = TRUE), max(data.het$x,
+     na.rm = TRUE), len = 1000))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you wanted to represent sample data on the figure in such a simple example (single predictor) we could simply over- (or under-) lay the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = data.het,
+     aes(y = y, x = x), color = &amp;quot;gray&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A more general solution would be to add the partial residuals to the figure. Partial residuals are the fitted values plus the residuals. In this simple case, that equates to exactly the same as the raw observations since &lt;span class=&#34;math inline&#34;&gt;\(\text{resid}=\text{obs}−\text{fitted}\)&lt;/span&gt; and the fitted values depend only on the single predictor we are interested in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data.het
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data.het$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = rdata, aes(y = partial.resid),
+     color = &amp;quot;gray&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low, ymax = conf.high),
+     fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_continuous(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_post3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.het.r2jags$BUGSoutput$sims.matrix
&amp;gt; Xmat = model.matrix(~x, data.het)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data.het$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.244     0.108   0.0309     0.440
&amp;gt; 
&amp;gt; # for comparison with frequentist summary(lm(y ~ x, data.het))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;heteroskedasticity-with-categorical-predictors&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Heteroskedasticity with categorical predictors&lt;/h1&gt;
&lt;p&gt;For regression models that include a categorical variable (e.g. ANOVA), heterogeneity manifests as vastly different variances for different levels (treatment groups) of the categorical variable. Recall, that this is diagnosed from the relative size of boxplots. Whilst, the degree of group variability may not be related to the means of the groups, having wildly different variances does lead to an increase in standard errors and thus a lowering of power. In such cases, we would like to be able to indicate that the variances should be estimated separately for each group. That is the variance term is multiplied by a different number for each group. The appropriate matrix is referred to as an &lt;em&gt;Identity matrix&lt;/em&gt;. Again, to assist in the explanation some fabricated ANOVA data - data that has heteroscadasticity by design - will be useful.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(126)
&amp;gt; ngroups &amp;lt;- 5  #number of populations
&amp;gt; nsample &amp;lt;- 10  #number of reps in each
&amp;gt; pop.means &amp;lt;- c(40, 45, 55, 40, 30)  #population mean length
&amp;gt; sigma &amp;lt;- rep(c(6, 4, 2, 0.5, 1), each = nsample)  #residual standard deviation
&amp;gt; n &amp;lt;- ngroups * nsample  #total sample size
&amp;gt; eps &amp;lt;- rnorm(n, 0, sigma)  #residuals
&amp;gt; x &amp;lt;- gl(ngroups, nsample, n, lab = LETTERS[1:5])  #factor
&amp;gt; means &amp;lt;- rep(pop.means, rep(nsample, ngroups))
&amp;gt; X &amp;lt;- model.matrix(~x - 1)  #create a design matrix
&amp;gt; y &amp;lt;- as.numeric(X %*% pop.means + eps)
&amp;gt; data.het1 &amp;lt;- data.frame(y, x)
&amp;gt; boxplot(y ~ x, data.het1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/data_het_cat1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; plot(lm(y ~ x, data.het1), which = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/data_het_cat1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It is clear that there is gross heteroskedasticity. The residuals are obviously more spread in some groups than others yet there is no real pattern with means (the residual plot does not show an obvious wedge). Note, for assessing homogeneity of variance, it is best to use the standardised residuals. It turns out that if we switch over to maximum (log) likelihood estimation methods, we can model in a within-group heteroskedasticity structure rather than just assume one very narrow form of variance structure. Lets take a step back and reflect on our simple ANOVA (regression) model that has five groups each with &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; observations:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \mu + \alpha_i + \epsilon, \;\;\; \text{with} \;\;\; \epsilon \sim N(0, \sigma^2). \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is shorthand notation to indicate that the response variable is being modelled against a specific linear predictor and that the residuals follow a normal distribution with a certain variance (that is the same for each group). Rather than assume that the variance of each group is the same, we could relax this a little so as to permit different levels of variance per group:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \epsilon \sim N(0, \sigma^2_i).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To achieve this, we actually multiply the variance matrix by a weighting matrix, where the weights associated with each group are determined by the inverse of the ratio of each group to the first (reference) group:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \epsilon \sim N(0, \sigma^2_i \times \omega).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So returning to our five groups of &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; observations example, the weights would be determined as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.het1.sd &amp;lt;- with(data.het1, tapply(y, x, sd))
&amp;gt; 1/(data.het1.sd[1]/data.het1.sd)
        A         B         C         D         E 
1.0000000 0.6909012 0.4140893 0.1426207 0.3012881 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The weights determine the relative amount of each observation that goes into calculating variances. The basic premise is that those with lower variances are likely to be more precise and therefore should have greatest contribution to variance calculations.&lt;/p&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2 = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mu[i],tau[x[i]])
+   mu[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   
+   #Priors and derivatives
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0,1.0E-6)
+   
+   sigma[i] &amp;lt;- z[i]/sqrt(chSq[i])
+   z[i] ~ dnorm(0, 0.04)I(0,)
+   chSq[i] ~ dgamma(0.5, 0.5)
+   tau[i] &amp;lt;- pow(sigma[i], -2)
+   }
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;heteroskModel2.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X = model.matrix(~x, data.het1)
&amp;gt; data.het1.list &amp;lt;- with(data.het1, list(y = y, x = as.numeric(x), X = X,
+     n = nrow(data.het1), ngroups = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.het1.r2jags &amp;lt;- jags(data = data.het1.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;heteroskModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 50
   Unobserved stochastic nodes: 15
   Total graph size: 444

Initializing model
&amp;gt; 
&amp;gt; print(data.het1.r2jags)
Inference for Bugs model at &amp;quot;heteroskModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.282   1.227  37.861  39.518  40.278  41.044  42.731 1.001 11000
beta[2]    4.088   1.508   1.063   3.115   4.095   5.059   7.063 1.001  5000
beta[3]   14.553   1.336  11.874  13.714  14.566  15.402  17.177 1.001  5600
beta[4]   -0.655   1.242  -3.118  -1.425  -0.656   0.118   1.804 1.001 11000
beta[5]  -10.364   1.286 -12.875 -11.173 -10.353  -9.550  -7.830 1.001 12000
sigma[1]   3.748   0.971   2.378   3.062   3.583   4.231   6.071 1.001 13000
sigma[2]   2.647   0.729   1.640   2.143   2.504   2.995   4.461 1.001  5400
sigma[3]   1.629   0.456   1.001   1.314   1.541   1.846   2.767 1.001  4000
sigma[4]   0.570   0.169   0.346   0.454   0.537   0.647   1.001 1.001  3500
sigma[5]   1.181   0.336   0.727   0.950   1.118   1.342   2.021 1.001  7100
deviance 182.822   5.288 174.824 178.961 182.076 185.810 195.061 1.001 11000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 14.0 and DIC = 196.8
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MCMC diagnostics&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.het1.r2jags, parms = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_diag_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.het1.r2jags, parms = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_diag_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trace plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space. When there are a lot of parameters, this can result in a very large number of traceplots.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.het1.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data.het1$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data.het1$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_residuals_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above residual plot would make us believe that we had a homogeneity of variance issue (which we thought we were addressing by defining a model that allowed the variance to be proportional to the predictor). This is because we have plotted the raw residuals rather than residuals that have been standardized by the variances. The above plot is also what the residual plot would look like if we had not made any attempt to define a model in which the variance was related to the predictor. Whenever we fit a model that incorporates changes to the variance-covariance structures, we should explore standardized residuals. In this case, we should divide the residuals by the appropriate sigma for associated with that group (level of predictor).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Res_{ij} = \frac{Y_{ij} - \mu_j}{\sigma_j}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.het1.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; Xmat = model.matrix(~x, data.het1)
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = -1 * sweep(fit, 2, data.het1$y, &amp;quot;-&amp;quot;)
&amp;gt; wch = grep(&amp;quot;sigma&amp;quot;, colnames(mcmc))
&amp;gt; resid = apply(resid, 2, median)/rep(apply(mcmc[, wch], 2, median), table(data.het1$x))
&amp;gt; # resid = apply(resid,2,median)/(median(mcmc[,&amp;#39;sigma&amp;#39;]) * sqrt(data.het1$x))
&amp;gt; fit = apply(fit, 2, median)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_residuals2_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is certainly an improvement. Nevertheless, there is still an indication of a relationship between mean and variance. We could attempt to further address this by refining &lt;span class=&#34;math inline&#34;&gt;\(\omega\)&lt;/span&gt; in the Bayesian model. That is, rather than indicate that variance is proportional to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, we could indicate that variance is proportional to &lt;span class=&#34;math inline&#34;&gt;\(x^2\)&lt;/span&gt; (as an example) - we will leave this as an exercise for the reader. Residuals against predictors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = data.het1$x)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_residuals3_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.het1.r2jags$BUGSoutput$sims.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~x, data.het1)
&amp;gt; ## get median parameter estimates
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; wch = grep(&amp;quot;sigma&amp;quot;, colnames(mcmc))
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data.het1), fit[i, ],
+     mcmc[i, wch[as.numeric(data.het1$x[i])]]))
&amp;gt; newdata = data.frame(x = data.het1$x, yRep) %&amp;gt;% gather(key = Sample, value = Value,
+     -x)
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = x, fill = &amp;quot;Model&amp;quot;), alpha = 0.5) +
+     geom_violin(data = data.het1, aes(y = y, x = x, fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) +
+     geom_point(data = data.het1, aes(y = y, x = x), position = position_jitter(width = 0.1,
+         height = 0), color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_rep_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;parameter-estimates-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parameter estimates&lt;/h2&gt;
&lt;p&gt;First, we look at the results from the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.het1.r2jags)
Inference for Bugs model at &amp;quot;heteroskModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.282   1.227  37.861  39.518  40.278  41.044  42.731 1.001 11000
beta[2]    4.088   1.508   1.063   3.115   4.095   5.059   7.063 1.001  5000
beta[3]   14.553   1.336  11.874  13.714  14.566  15.402  17.177 1.001  5600
beta[4]   -0.655   1.242  -3.118  -1.425  -0.656   0.118   1.804 1.001 11000
beta[5]  -10.364   1.286 -12.875 -11.173 -10.353  -9.550  -7.830 1.001 12000
sigma[1]   3.748   0.971   2.378   3.062   3.583   4.231   6.071 1.001 13000
sigma[2]   2.647   0.729   1.640   2.143   2.504   2.995   4.461 1.001  5400
sigma[3]   1.629   0.456   1.001   1.314   1.541   1.846   2.767 1.001  4000
sigma[4]   0.570   0.169   0.346   0.454   0.537   0.647   1.001 1.001  3500
sigma[5]   1.181   0.336   0.727   0.950   1.118   1.342   2.021 1.001  7100
deviance 182.822   5.288 174.824 178.961 182.076 185.810 195.061 1.001 11000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 14.0 and DIC = 196.8
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; tidyMCMC(as.mcmc(data.het1.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 11 x 5
   term     estimate std.error conf.low conf.high
   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 beta[1]    40.3       1.23    37.9      42.7  
 2 beta[2]     4.09      1.51     0.980     6.97 
 3 beta[3]    14.6       1.34    12.0      17.3  
 4 beta[4]    -0.655     1.24    -3.15      1.76 
 5 beta[5]   -10.4       1.29   -12.9      -7.86 
 6 deviance  183.        5.29   174.      194.   
 7 sigma[1]    3.75      0.971    2.23      5.72 
 8 sigma[2]    2.65      0.729    1.53      4.12 
 9 sigma[3]    1.63      0.456    0.906     2.54 
10 sigma[4]    0.570     0.169    0.313     0.905
11 sigma[5]    1.18      0.336    0.656     1.82 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the mean of the first group (A) is &lt;span class=&#34;math inline&#34;&gt;\(40.3\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the mean of the second group (B) is &lt;span class=&#34;math inline&#34;&gt;\(4.12\)&lt;/span&gt; units greater than (A)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the mean of the third group (C) is &lt;span class=&#34;math inline&#34;&gt;\(14.6\)&lt;/span&gt; units greater than (A)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the mean of the forth group (D) is &lt;span class=&#34;math inline&#34;&gt;\(-0.637\)&lt;/span&gt; units greater (i.e. less) than (A)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the mean of the fifth group (E) is &lt;span class=&#34;math inline&#34;&gt;\(-10.3\)&lt;/span&gt; units greater (i.e. less) than (A)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of B, C and E do not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between group A and groups B, C and E. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }
&amp;gt; ## since values are less than zero
&amp;gt; mcmc = data.het1.r2jags$BUGSoutput$sims.matrix
&amp;gt; for (i in grep(&amp;quot;beta&amp;quot;, colnames(mcmc), value = TRUE)) print(paste(i, mcmcpvalue(mcmc[,i])))
[1] &amp;quot;beta[1] 0&amp;quot;
[1] &amp;quot;beta[2] 0.0116&amp;quot;
[1] &amp;quot;beta[3] 0&amp;quot;
[1] &amp;quot;beta[4] 0.567133333333333&amp;quot;
[1] &amp;quot;beta[5] 0&amp;quot;
&amp;gt; mcmcpvalue(mcmc[, grep(&amp;quot;beta&amp;quot;, colnames(mcmc))])
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of essentially &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, we would conclude that there is almost no evidence that the slope was likely to be equal to zero, suggesting there is a relationship.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graphical summaries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.het1.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = data.frame(x = levels(data.het1$x))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_post1_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you wanted to represent sample data on the figure in such a simple example (single predictor) we could simply over- (or under-) lay the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = data.het1,
+     aes(y = y, x = x), color = &amp;quot;gray&amp;quot;) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_post2_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A more general solution would be to add the partial residuals to the figure. Partial residuals are the fitted values plus the residuals. In this simple case, that equates to exactly the same as the raw observations since &lt;span class=&#34;math inline&#34;&gt;\(\text{resid}=\text{obs}−\text{fitted}\)&lt;/span&gt; and the fitted values depend only on the single predictor we are interested in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data.het1
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data.het1$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = rdata, aes(y = partial.resid),
+     color = &amp;quot;gray&amp;quot;) + geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
+     scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/heterogeneity-jags/2020-02-01-heterogeneity-jags_files/figure-html/mcmc_post3_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2006prior&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2006. “Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by Browne and Draper).” &lt;em&gt;Bayesian Analysis&lt;/em&gt; 1 (3): 515–34.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Factorial Analysis of Variance - JAGS</title>
      <link>/jags/factorial-anova-jags/factorial-anova-jags/</link>
      <pubDate>Thu, 06 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/factorial-anova-jags/factorial-anova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Factorial designs are an extension of single factor ANOVA designs in which additional factors are added such that each level of one factor is applied to all levels of the other factor(s) and these combinations are replicated. For example, we might design an experiment in which the effects of temperature (high vs low) and fertiliser (added vs not added) on the growth rate of seedlings are investigated by growing seedlings under the different temperature and fertilizer combinations. In addition to investigating the impacts of the main factors, factorial designs allow us to investigate whether the effects of one factor are consistent across levels of another factor. For example, is the effect of temperature on growth rate the same for both fertilised and unfertilized seedlings and similarly, does the impact of fertiliser treatment depend on the temperature under which the seedlings are grown?&lt;/p&gt;
&lt;p&gt;Arguably, these interactions give more sophisticated insights into the dynamics of the system we are investigating. Hence, we could add additional main effects, such as soil pH, amount of water, etc, along with all the two way (temp:fert, temp:pH, temp:water, etc), three-way (temp:fert:pH, temp:pH:water), four-way (and so on) interactions in order to explore how these various factors interact with one another to effect the response. However, the more interactions, the more complex the model becomes to specify, compute and interpret - not to mention the rate at which the number of required observations increases. Factorial designs can consist:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;entirely of crossed fixed factors (&lt;strong&gt;Model I ANOVA&lt;/strong&gt; - most common) in which conclusions are restricted to the specific combinations of levels selected for the experiment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;entirely of crossed random factors (&lt;strong&gt;Model II ANOVA&lt;/strong&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;a mixture of crossed fixed and random factors (&lt;strong&gt;Model III ANOVA&lt;/strong&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The latter are useful for investigating the generality of a main treatment effect (fixed) over broad spatial, temporal or clinical levels of organisation. That is whether the observed effects of temperature and/or fertiliser (for example) are observed across the entire genera or country.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear model&lt;/h2&gt;
&lt;p&gt;As with single factor ANOVA, the linear model could be constructed as either effects or means parameterisation, although only effects parameterisation will be considered here. The linear models for two and three factor design are&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \epsilon_{ijk},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_j + \gamma_k + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \epsilon_{ijkl},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the effect of Factor A, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of Factor B, &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the effect of Factor C and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component. Note that although the linear models for Model I, Model II and Model III designs are identical, the interpretation of terms (and thus null hypothesis) differ. Recall from the tutorial on single factor ANOVA, that categorical variables in linear models are actually re-parameterised dummy codes - and thus the &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; term above, actually represents one or more dummy codes. Thus, if we actually had two levels of Factor A (A1 and A2) and three levels of Factor B (B1, B2, B3), then the fully parameterised linear model would be:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y=\beta_{A1B1}+\beta_{A2B1−A1B1}+\beta_{A1B2−A1B1}+\beta_{A1B3−A1B1}+\beta_{A2B2−A1B2−A2B1−A1B1}+\beta_{A2B3−A1B3−A2B1−A1B1}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thus, such a model would have six parameters to estimate (in addition to the variance).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis&lt;/h2&gt;
&lt;p&gt;There are separate null hypothesis associated with each of the main effects and the interaction terms.&lt;/p&gt;
&lt;div id=&#34;model-1---fixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 1 - fixed effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Factor A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to an overall mean. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the overall mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The effect of each group equals zero. If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), the null hypothesis is rejected indicating that the treatment has been found to affect the response variable. Note, as with multiple regression models, these “effects” represent &lt;em&gt;partial effects&lt;/em&gt;. In the above, the effect of Factor A is actually the effect of Factor A at the first level of the Factor(s).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal - at the first level of Factor A. Equivalent interpretation to Factor A above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\mu_{ij}=\mu_i+\mu_j-\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. For any given combination of factor levels, the population group mean will be equal to the difference between the overall population mean and the simple additive effects of the individual factor group means. That is, the effects of the main treatment factors are purely additive and independent of one another. This is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(H_0(AB): \alpha\beta_{ij}=0\)&lt;/span&gt;, no interaction between Factor A and Factor B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-2---random-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 2 - random effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Factor A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\sigma^2_{\alpha}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of A.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\sigma^2_{\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of B.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\sigma^2_{\alpha\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is no added variance due to all possible interactions between all possible levels of A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-3---mixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 3 - mixed effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Fixed factor - e.g. A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (pooled over all levels of the random factor) is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to an overall mean pooling over all possible levels of the random factor. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the overall mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;No effect of any level of this factor pooled over all possible levels of the random factor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Random factor - e.g. B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\sigma^2_{\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of B.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The interaction of a fixed and random factor is always considered a random factor.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\sigma^2_{\alpha\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible interactions between all possible levels of A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;When fixed factorial designs are balanced, the total variance in the response variable can be sequentially partitioned into what is explained by each of the model terms (factors and their interactions) and what is left unexplained. For each of the specific null hypotheses, the overall unexplained variability is used as the denominator in F-ratio calculations, and when a null hypothesis is true, an F-ratio should follow an F distribution with an expected value less than &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;. Random factors are added to provide greater generality of conclusions. That is, to enable us to make conclusions about the effect of one factor (such as whether or not fertiliser is added) over all possible levels (not just those sampled) of a random factor (such as all possible locations, seasons, varieties, etc). In order to expand our conclusions beyond the specific levels used in the design, the hypothesis tests (and thus F-ratios) must reflect this extra generality by being more conservative.&lt;/p&gt;
&lt;p&gt;The appropriate F-ratios for fixed, random and mixed factorial designs are presented below. Generally, once the terms (factors and interactions) have been ordered into a hierarchy (single factors at the top, highest level interactions at the bottom and terms of same order given equivalent positions in the hierarchy), the denominator for any term is selected as the next appropriate random term (an interaction that includes the term to be tested) encountered lower in the hierarchy. Interaction terms that contain one or more random factors are considered themselves to be random terms, as is the overall residual term (as all observations are assumed to be random representations of the entire population(s)). Note, when designs include a mixture of fixed and random crossed effects, exact denominator degrees of freedoms for certain F-ratios are undefined and traditional approaches adopt rather inexact estimated approximate or “Quasi” F-ratios. Pooling of non-significant F-ratio denominator terms, in which lower random terms are added to the denominator (provided &lt;span class=&#34;math inline&#34;&gt;\(\alpha &amp;gt; 0.25\)&lt;/span&gt;), may also be useful. For random factors within mixed models, selecting F-ratio denominators that are appropriate for the intended hypothesis tests is a particularly complex and controversial issue. Traditionally, there are two alternative approaches and whilst the statistical resumes of each are complicated, essentially they differ in whether or not the interaction term is constrained for the test of the random factor.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;constrained or restricted method&lt;/em&gt; (&lt;strong&gt;Model I&lt;/strong&gt;), stipulates that for the calculation of a random factor F-ratio (which investigates the added variance added due to the random factor), the overall effect of the interaction is treated as zero. Consequently, the random factor is tested against the residual term. The &lt;em&gt;unconstrained or unrestrained method&lt;/em&gt; (&lt;strong&gt;Model II&lt;/strong&gt;) however, does not set the interaction effect to zero and therefore the interaction term is used as the random factor F-ratio denominator. This method assumes that the interaction terms for each level of the random factor are completely independent (correlations between the fixed factor must be consistent across all levels of the random factor). Some statisticians maintain that the independence of the interaction term is difficult to assess for clinical data and therefore, the restricted approach is more appropriate. However, others have suggested that the restricted method is only appropriate for balanced designs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quasi-f-ratios&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quasi F-ratios&lt;/h2&gt;
&lt;p&gt;An additional complication for three or more factor models that contain two or more random factors, is that there may not be a single appropriate interaction term to use as the denominator for many of the main effects F-ratios. For example, if Factors A and B are random and C is fixed, then there are two random interaction terms of equivalent level under Factor C (&lt;span class=&#34;math inline&#34;&gt;\(A^\prime \times C\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B^\prime \times C\)&lt;/span&gt;). As a result, the value of the of the &lt;em&gt;Mean Squares&lt;/em&gt; (MS) expected when the null hypothesis is true cannot be easily defined. The solutions for dealing with such situations (&lt;em&gt;quasi F-ratios&lt;/em&gt;) involve adding (and subtracting) terms together to create approximate estimates of F-ratio denominators. Alternatively, for random factors, variance components with confidence intervals can be used. These solutions are sufficiently unsatisfying as to lead many statisticians to recommend that factorial designs with two or more random factors should avoided if possible. Arguably however, linear mixed effects models offer more appropriate solutions to the above issues as they are more robust for unbalanced designs, accommodate covariates and provide a more comprehensive treatment and overview of all the underlying data structures.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; fact_anova_table
    df           MS       A,B fixed          A,B random       
A   &amp;quot;a-1&amp;quot;        &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;  &amp;quot;(MS A)/(MS AB)&amp;quot; 
B   &amp;quot;b-1&amp;quot;        &amp;quot;MS B&amp;quot;   &amp;quot;(MS B)/(MS res)&amp;quot;  &amp;quot;(MS B)/(MS AB)&amp;quot; 
AB  &amp;quot;(b-1)(a-1)&amp;quot; &amp;quot;MS AB&amp;quot;  &amp;quot;(MS AB)/(MS res)&amp;quot; &amp;quot;(MS AB)/(MS AB)&amp;quot;
Res &amp;quot;(n-1)ba&amp;quot;    &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;                 &amp;quot;&amp;quot;               
    A fixed B random (model I) A fixed B random (model II)
A   &amp;quot;(MS A)/(MS AB)&amp;quot;           &amp;quot;(MS A)/(MS AB)&amp;quot;           
B   &amp;quot;(MS B)/(MS res)&amp;quot;          &amp;quot;(MS B)/(MS AB)&amp;quot;           
AB  &amp;quot;(MS AB)/(MS res)&amp;quot;         &amp;quot;(MS AB)/(MS res)&amp;quot;         
Res &amp;quot;&amp;quot;                         &amp;quot;&amp;quot;                         &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The corresponding &lt;code&gt;R&lt;/code&gt; syntax is given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Type I SS (Balanced)
&amp;gt; anova(lm(y ~ A * B, data))
&amp;gt; 
&amp;gt; #Type II SS (Unbalanced)
&amp;gt; Anova(lm(y ~ A * B, data), type = &amp;quot;II&amp;quot;)
&amp;gt; 
&amp;gt; #Type III SS (Unbalanced)
&amp;gt; Anova(lm(y ~ A * B, data), type = &amp;quot;III&amp;quot;)
&amp;gt; 
&amp;gt; #Variance components
&amp;gt; summary(lmer(y ~ 1 + (1 | A) + (1 | B) + (1 | A:B), data))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that for fixed factor models, when null hypotheses of interactions are rejected, the null hypothesis of the individual constituent factors are unlikely to represent the true nature of the effects and thus are of little value. The nature of such interactions are further explored by fitting simpler linear models (containing at least one less factor) separately for each of the levels of the other removed factor(s). Such &lt;em&gt;Main effects&lt;/em&gt; tests are based on a subset of the data, and therefore estimates of the overall residual (unexplained) variability are unlikely to be as precise as the estimates based on the global model. Consequently, F-ratios involving &lt;code&gt;MSResid&lt;/code&gt; should use the estimate of &lt;code&gt;MSResid&lt;/code&gt; from the global model rather than that based on the smaller, theoretically less precise subset of data. For random and mixed models, since the objective is to generalise the effect of one factor over and above any interactions with other factors, the main factor effects can be interpreted even in the presence of significant interactions. Nevertheless, it should be noted that when a significant interaction is present in a mixed model, the power of the main fixed effects will be reduced (since the amount of variability explained by the interaction term will be relatively high, and this term is used as the denominator for the F-ratio calculation).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;Hypothesis tests assume that the residuals are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator (see table above) should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;independent of one another.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Planned and unplanned comparisons&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As with single factor analysis of variance, planned and unplanned multiple comparisons (such as &lt;em&gt;Tukey&lt;/em&gt;’s test) can be incorporated into or follow the linear model respectively so as to further investigate any patterns or trends within the main factors and/or the interactions. As with single factor analysis of variance, the contrasts must be defined prior to fitting the linear model, and no more than &lt;span class=&#34;math inline&#34;&gt;\(p−1\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the number of levels of the factor) contrasts can be defined for a factor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Unbalanced designs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A factorial design can be thought of as a table made up of rows (representing the levels of one factor), columns (levels of another factor), and cells (the individual combinations of the set of factors). Whilst the middle left table does not have equal sample sizes in each cell, the sample sizes are in proportion and as such, does not present the issues discussed below for unbalanced designs.&lt;/p&gt;
&lt;p&gt;In addition to impacting on normality and homogeneity of variance, unequal sample sizes in factorial designs have major implications for the partitioning of the total sums of squares into each of the model components. For balanced designs, the total sums of squares (&lt;code&gt;SSTotal&lt;/code&gt;) is equal to the additive sums of squares of each of the components (including the residual). For example, in a two factor balanced design, &lt;code&gt;SSTotal=SSA+SSB+SSAB+SSResid&lt;/code&gt;. This can be represented diagrammatically by a &lt;em&gt;Venn Diagram&lt;/em&gt; in which each of the &lt;code&gt;SS&lt;/code&gt; for the term components butt against one another and are surrounded by the &lt;code&gt;SSResid&lt;/code&gt;. However, in unbalanced designs, the sums of squares will be non-orthogonal and the sum of the individual components does not add up to the total sums of squares. Diagrammatically, the &lt;code&gt;SS&lt;/code&gt; of the terms intersect or are separated.&lt;/p&gt;
&lt;p&gt;In regular &lt;em&gt;sequential sums of squares&lt;/em&gt; (&lt;strong&gt;Type I SS&lt;/strong&gt;), the sum of the individual sums of squares must be equal to the total sums of squares, the sums of squares of the last factor to be estimated will be calculated as the difference between the total sums of squares and what has already been accounted for by other components. Consequently, the order in which factors are specified in the model (and thus estimated) will alter their sums of squares and therefore their F-ratios. To overcome this problem, traditionally there are two other alternative methods of calculating sums of squares.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Type II (hierarchical) SS&lt;/strong&gt; estimate the sums of squares of each term as the improvement it contributes upon addition of that term to a model of greater complexity and lower in the hierarchy (recall that the hierarchical structure descends from the simplest model down to the fully populated model). The SS for the interaction as well as the first factor to be estimated are the same as for Type I SS. Type II SS estimate the contribution of a factor over and above the contributions of other factors of equal or lower complexity but not above the contributions of the interaction terms or terms nested within the factor. However, these sums of squares are weighted by the sample sizes of each level and therefore are biased towards the trends produced by the groups (levels) that have higher sample sizes. As a result of the weightings, Type II SS actually test hypotheses about really quite complex combinations of factor levels. Rather than test a hypothesis that &lt;span class=&#34;math inline&#34;&gt;\(\mu_{High}=\mu_{Medium}=\mu_{Low}\)&lt;/span&gt;, Type II SS might be testing that &lt;span class=&#34;math inline&#34;&gt;\(4\times\mu_{High}=1\times\mu_{Medium}=0.25\times\mu_{Low}\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Type III (marginal or orthogonal) SS&lt;/strong&gt; estimate the sums of squares of each term as the improvement based on a comparison of models with and without the term and are unweighted by sample sizes. Type III SS essentially measure just the unique contribution of each factor over and above the contributions of the other factors and interactions. For unbalanced designs,Type III SS essentially test equivalent hypotheses to balanced Type I SS and are therefore arguably more appropriate for unbalanced factorial designs than Type II SS. Importantly, Type III SS are only interpretable if they are based on orthogonal contrasts (such as sum or helmert contrasts and not treatment contrasts).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The choice between Type II and III SS clearly depends on the nature of the question. For example, if we had measured the growth rate of seedlings subjected to two factors (temperature and fertiliser), Type II SS could address whether there was an effect of temperature across the level of fertiliser treatment, whereas Type III SS could assess whether there was an effect of temperature within each level of the fertiliser treatment.&lt;/p&gt;
&lt;p&gt;When an entire combination, or cell, is missing (perhaps due to unforeseen circumstances) it is not possible to test all the main effects and/or interactions. The bottom right table above depicts such as situation. One solution is to fit a large single factor ANOVA with as many levels as there are cells (this is known as a cell means model) and investigate various factor and interaction effects via specific contrasts (see the following tables). Difficulties in establishing appropriate error terms, makes missing cells in random and mixed factor designs substantially more complex.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Imagine we has designed an experiment in which we had measured the response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) under a combination of two different potential influences (Factor A: levels a1 and a2; and Factor B: levels b1, b2 and b3), each combination replicated &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; times (&lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; nA &amp;lt;- 2  #number of levels of A
&amp;gt; nB &amp;lt;- 3  #number of levels of B
&amp;gt; nsample &amp;lt;- 10  #number of reps in each
&amp;gt; A &amp;lt;- gl(nA, 1, nA, lab = paste(&amp;quot;a&amp;quot;, 1:nA, sep = &amp;quot;&amp;quot;))
&amp;gt; B &amp;lt;- gl(nB, 1, nB, lab = paste(&amp;quot;b&amp;quot;, 1:nB, sep = &amp;quot;&amp;quot;))
&amp;gt; data &amp;lt;- expand.grid(A = A, B = B, n = 1:nsample)
&amp;gt; X &amp;lt;- model.matrix(~A * B, data = data)
&amp;gt; eff &amp;lt;- c(40, 15, 5, 0, -15, 10)
&amp;gt; sigma &amp;lt;- 3  #residual standard deviation
&amp;gt; n &amp;lt;- nrow(data)
&amp;gt; eps &amp;lt;- rnorm(n, 0, sigma)  #residuals
&amp;gt; data$y &amp;lt;- as.numeric(X %*% eff + eps)
&amp;gt; head(data)  #print out the first six rows of the data set
   A  B n        y
1 a1 b1 1 38.31857
2 a2 b1 1 54.30947
3 a1 b2 1 49.67612
4 a2 b2 1 45.21153
5 a1 b3 1 40.38786
6 a2 b3 1 70.14519
&amp;gt; 
&amp;gt; with(data, interaction.plot(A, B, y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/generate_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ## ALTERNATIVELY, we could supply the population means and get the effect parameters from these.  To
&amp;gt; ## correspond to the model matrix, enter the population means in the order of: a1b1, a2b1, a1b1,
&amp;gt; ## a2b2,a1b3,a2b3
&amp;gt; pop.means &amp;lt;- as.matrix(c(40, 55, 45, 45, 40, 65), byrow = F)
&amp;gt; ## Generate a minimum model matrix for the effects
&amp;gt; XX &amp;lt;- model.matrix(~A * B, expand.grid(A = factor(1:2), B = factor(1:3)))
&amp;gt; ## Use the solve() function to solve what are effectively simultaneous equations
&amp;gt; (eff &amp;lt;- as.vector(solve(XX, pop.means)))
[1]  40  15   5   0 -15  10
&amp;gt; 
&amp;gt; data$y &amp;lt;- as.numeric(X %*% eff + eps)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type. Does treatment type effect the response?.&lt;/p&gt;
&lt;div id=&#34;assumptions-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;The assumptions are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All of the observations are independent - this must be addressed at the design and collection stages. Importantly, to be considered independent replicates, the replicates must be made at the same scale at which the treatment is applied. For example, if the experiment involves subjecting organisms housed in tanks to different water temperatures, then the unit of replication is the individual tanks not the individual organisms in the tanks. The individuals in a tank are strictly not independent with respect to the treatment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (and thus the residuals) should be normally distributed for each sampled populations (combination of factors). Boxplots of each treatment combination are useful for diagnosing major issues with normality.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately) for each combination of treatments. Again, boxplots are useful.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ A * B, data)
&amp;gt; 
&amp;gt; # OR via ggplot2
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = y, x = A, fill = B)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/exp1_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity&lt;/p&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X \boldsymbol \beta\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; represents the intercept associated with the first combination of groups, as well as the (effects) differences between this intercept and each other group. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X\)&lt;/span&gt; is the model matrix. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. Exploratory data analysis suggests that the intercept and effects could be drawn from similar distributions (with mean in the &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;’s and variances in the &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;’s). Whilst we might therefore be tempted to provide different priors for the intercept, compared to the effects, for a simple model such as this, it is unlikely to be necessary. However, for more complex models, where prior specification becomes more critical, separate priors would probably be necessary.&lt;/p&gt;
&lt;p&gt;We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Note the following example as group means calculated as derived posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau)
+   mean[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   #Priors
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) 
+   }
+   sigma ~ dunif(0, 100)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;fact_anovaModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X &amp;lt;- model.matrix(~A * B, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = X, n = nrow(data), ngroups = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;fact_anovaModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 60
   Unobserved stochastic nodes: 7
   Total graph size: 502

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;fact_anovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.187   0.927  38.381  39.572  40.186  40.810  42.028 1.001 15000
beta[2]   14.739   1.297  12.177  13.875  14.741  15.611  17.281 1.001 15000
beta[3]    4.997   1.301   2.439   4.127   4.996   5.850   7.555 1.001  6200
beta[4]   -0.335   1.302  -2.922  -1.201  -0.323   0.523   2.182 1.001  9300
beta[5]  -14.551   1.831 -18.188 -15.752 -14.535 -13.331 -10.976 1.001 15000
beta[6]   11.081   1.823   7.514   9.859  11.073  12.288  14.680 1.001 15000
sigma      2.909   0.286   2.410   2.707   2.886   3.092   3.525 1.001  3100
deviance 296.719   4.003 290.996 293.788 296.037 298.923 306.334 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 8.0 and DIC = 304.7
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trace plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters (such as &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;s).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3895  3746         1.040     
 beta[2]  2        3649  3746         0.974     
 beta[3]  2        3981  3746         1.060     
 beta[4]  2        3811  3746         1.020     
 beta[5]  2        3855  3746         1.030     
 beta[6]  2        3770  3746         1.010     
 deviance 2        3981  3746         1.060     
 sigma    4        5074  3746         1.350     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3729  3746         0.995     
 beta[2]  2        3853  3746         1.030     
 beta[3]  2        3649  3746         0.974     
 beta[4]  2        3770  3746         1.010     
 beta[5]  2        3853  3746         1.030     
 beta[6]  2        3770  3746         1.010     
 deviance 2        3649  3746         0.974     
 sigma    4        5366  3746         1.430     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
            beta[1]      beta[2]       beta[3]      beta[4]      beta[5]
Lag 0   1.000000000  1.000000000  1.0000000000  1.000000000  1.000000000
Lag 1  -0.002519333  0.009718890  0.0097211169  0.004831644  0.013455394
Lag 5  -0.004466196  0.013453425  0.0012166509 -0.009459535  0.010837730
Lag 10 -0.006418970 -0.004825081  0.0002148708 -0.003297864 -0.004528907
Lag 50  0.004241571  0.010613172 -0.0056258926 -0.002886136 -0.003130607
            beta[6]     deviance        sigma
Lag 0   1.000000000  1.000000000  1.000000000
Lag 1   0.004411377  0.194295905  0.335565370
Lag 5   0.004680461  0.011707557  0.003364317
Lag 10 -0.012377072  0.006873975  0.005557072
Lag 50  0.003484518 -0.008999031 -0.012155151&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.&lt;/p&gt;
&lt;p&gt;There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Standardised residuals&lt;/strong&gt;. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Studentised residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the residuals. Note that &lt;strong&gt;externally studentised residuals&lt;/strong&gt; are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pearson residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%) back thereby allowing us to train the model on &lt;span class=&#34;math inline&#34;&gt;\(75\)&lt;/span&gt;% of the data and then see how well the model can predict the withheld &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.&lt;/p&gt;
&lt;p&gt;Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within &lt;code&gt;JAGS&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; wch
[1] 1 2 3 4 5 6
&amp;gt; 
&amp;gt; head(mcmc)
      beta[1]  beta[2]  beta[3]     beta[4]   beta[5]  beta[6] deviance
[1,] 41.07993 14.73872 4.532543 -1.58279310 -14.91723 11.28780 292.8658
[2,] 40.30651 13.02455 4.475566 -0.86754574 -12.02942 13.36371 295.1239
[3,] 40.42144 14.71551 5.149725  0.09616707 -14.80497 10.82830 290.7322
[4,] 39.79269 16.35682 5.776724 -0.53251753 -17.64694 10.59484 295.1674
[5,] 39.40269 14.69470 5.237430 -0.29022676 -14.12951 12.81751 293.3136
[6,] 41.27115 12.58706 5.908648 -2.34899624 -13.31913 13.79862 302.0972
        sigma
[1,] 3.032059
[2,] 2.467221
[3,] 2.874167
[4,] 2.561227
[5,] 2.841503
[6,] 3.403891
&amp;gt; 
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; library(tidyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; print(coefs)
    beta[1]     beta[2]     beta[3]     beta[4]     beta[5]     beta[6] 
 40.1859804  14.7407405   4.9960673  -0.3233121 -14.5348136  11.0732139 
&amp;gt;  
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = B)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; #generate a model matrix
&amp;gt; Xmat = model.matrix(~A*B, data)
&amp;gt; ##get median parameter estimates
&amp;gt; coefs = mcmc[,wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,], mcmc[i, &amp;#39;sigma&amp;#39;]))
&amp;gt; newdata = data.frame(A=data$A, B=data$B, yRep) %&amp;gt;% gather(key=Sample, value=Value,-A,-B)
&amp;gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=A, fill=&amp;#39;Model&amp;#39;), alpha=0.5)+
+  geom_violin(data=data, aes(y=y,x=A,fill=&amp;#39;Obs&amp;#39;), alpha=0.5) +
+  geom_point(data=data, aes(y=y, x=A), position=position_jitter(width=0.1,height=0),
+             color=&amp;#39;black&amp;#39;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=B, fill=&amp;#39;Model&amp;#39;, group=B, color=A), alpha=0.5)+
+  geom_point(data=data, aes(y=y, x=B, group=B,color=A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;fact_anovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.187   0.927  38.381  39.572  40.186  40.810  42.028 1.001 15000
beta[2]   14.739   1.297  12.177  13.875  14.741  15.611  17.281 1.001 15000
beta[3]    4.997   1.301   2.439   4.127   4.996   5.850   7.555 1.001  6200
beta[4]   -0.335   1.302  -2.922  -1.201  -0.323   0.523   2.182 1.001  9300
beta[5]  -14.551   1.831 -18.188 -15.752 -14.535 -13.331 -10.976 1.001 15000
beta[6]   11.081   1.823   7.514   9.859  11.073  12.288  14.680 1.001 15000
sigma      2.909   0.286   2.410   2.707   2.886   3.092   3.525 1.001  3100
deviance 296.719   4.003 290.996 293.788 296.037 298.923 306.334 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 8.0 and DIC = 304.7
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 8 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    40.2       0.927    38.4      42.0 
2 beta[2]    14.7       1.30     12.2      17.3 
3 beta[3]     5.00      1.30      2.43      7.55
4 beta[4]    -0.335     1.30     -2.89      2.21
5 beta[5]   -14.6       1.83    -18.2     -11.0 
6 beta[6]    11.1       1.82      7.57     14.7 
7 deviance  297.        4.00    290.      304.  
8 sigma       2.91      0.286     2.37      3.47&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The intercept represents the mean of the first combination Aa1:Bb1 is &lt;span class=&#34;math inline&#34;&gt;\(40.2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb1 is &lt;span class=&#34;math inline&#34;&gt;\(14.7\)&lt;/span&gt; units greater than Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa1:Bb2 is &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; units greater Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa1:Bb3 is &lt;span class=&#34;math inline&#34;&gt;\(-0.335\)&lt;/span&gt; units greater Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb2 is &lt;span class=&#34;math inline&#34;&gt;\(-14.6\)&lt;/span&gt; units greater than the difference between (Aa1:Bb2 + Aa2:Bb1) and (2*Aa1:Bb1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb3 is &lt;span class=&#34;math inline&#34;&gt;\(11.1\)&lt;/span&gt; units greater than the difference between (Aa1:Bb3 + Aa2:Bb1) and (2*Aa1:Bb1)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility interval for both interactive effects (Aa2:Bb2 and Aa2:Bb3) do not contain &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, implying significant interactions between A and B. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])
[1] 0.0004666667
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[4]&amp;quot;])
[1] 0.7912667
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[5]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[6]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta[5]&amp;quot;, &amp;quot;beta[6]&amp;quot;)])
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence of an interaction between A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = expand.grid(A=levels(data$A), B=levels(data$B))
&amp;gt; Xmat = model.matrix(~A*B,newdata)
&amp;gt; coefs = mcmc[,wch]
&amp;gt; fit=coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int=TRUE, conf.method=&amp;#39;HPDinterval&amp;#39;))
&amp;gt; newdata
   A  B estimate std.error conf.low conf.high
1 a1 b1 40.18727 0.9270982 38.38136  42.02744
2 a2 b1 54.92636 0.9160115 53.12047  56.67452
3 a1 b2 45.18473 0.9196740 43.37733  46.98224
4 a2 b2 45.37262 0.9197287 43.61538  47.19883
5 a1 b3 39.85206 0.9156380 38.11053  41.70144
6 a2 b3 65.67189 0.9209489 63.84038  67.47931
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y=estimate, x=B, fill=A)) +
+  geom_blank() +
+  geom_line(aes(x=as.numeric(B), linetype=A)) +
+  geom_linerange(aes(ymin=conf.low, ymax=conf.high))+
+  geom_point(aes(shape=A), size=3)+
+  scale_y_continuous(&amp;#39;Y&amp;#39;)+
+  scale_x_discrete(&amp;#39;B&amp;#39;)+
+  scale_shape_manual(&amp;#39;A&amp;#39;,values=c(21,16))+
+  scale_fill_manual(&amp;#39;A&amp;#39;,values=c(&amp;#39;white&amp;#39;,&amp;#39;black&amp;#39;))+
+  scale_linetype_manual(&amp;#39;A&amp;#39;,values=c(&amp;#39;solid&amp;#39;,&amp;#39;dashed&amp;#39;))+
+  theme_classic() +
+  theme(legend.justification=c(0,1), legend.position=c(0.05,1),
+   axis.title.y=element_text(vjust=2, size=rel(1.25)),
+   axis.title.x=element_text(vjust=-2, size=rel(1.25)),
+   plot.margin=unit(c(0.5,0.5,2,2), &amp;#39;lines&amp;#39;),
+   legend.key.size=unit(1,&amp;#39;cm&amp;#39;)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A        10.4     0.917      8.65     12.3 
2 sd.B         3.06    0.640      1.79      4.28
3 sd.AB       10.4     0.734      9.04     11.9 
4 sd.resid     2.84    0.0836     2.72      3.00
# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A         39.1     1.95     35.2       42.8
2 sd.B         11.4     1.90      7.60      15.0
3 sd.AB        39.0     0.947    37.0       40.8
4 sd.resid     10.6     0.822     9.30      12.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/eff_pop1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(39\)&lt;/span&gt;% of the total finite population standard deviation is due to the interaction between factor A and factor B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; Xmat = model.matrix(~A * B, data)
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.913   0.00817    0.897     0.925
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ A * B, data))

Call:
lm(formula = y ~ A * B, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5694 -1.8517 -0.0589  1.7120  6.5966 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.1940     0.8980  44.760  &amp;lt; 2e-16 ***
Aa2          14.7163     1.2700  11.588 2.88e-16 ***
Bb2           4.9823     1.2700   3.923 0.000249 ***
Bb3          -0.3464     1.2700  -0.273 0.786077    
Aa2:Bb2     -14.5093     1.7960  -8.079 7.37e-11 ***
Aa2:Bb3      11.1056     1.7960   6.184 8.65e-08 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 2.84 on 54 degrees of freedom
Multiple R-squared:   0.92, Adjusted R-squared:  0.9125 
F-statistic: 124.1 on 5 and 54 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dealing-with-interactions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dealing with interactions&lt;/h1&gt;
&lt;p&gt;In the presence of interations, conclusions about the main effects are overly simplistic at best and completely inaccurate at worst. Therefore, in the presense of interactions we should attempt to tease the analysis appart a little. In the current working example, we have identified that there is a significant interaction between Factor A and Factor B. Our exploration of the regression coefficients, indicated that the pattern between b1, b2 and b3 might differ between a1 and a2. Similarly, if we consider the coefficients from the perspective of Factor A, we can see that the patterns between a1 and a2 are similar for b1 and b3, yet very different for b2.&lt;/p&gt;
&lt;p&gt;At this point, we can then split the two-factor model up into a series of single-factor models, either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;examining the effects of Factor B separately for each level of Factor A (two single-factor models) or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;examining the effects of Factor A separately for each level of Factor B (three single-factor models)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, rather than subset the data and fit isolated smaller models, it is arguably better to treat these explorations as contrasts. As such we could either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;apply specific contrasts to the already fit model&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;define the specific contrasts and use them to refit the model&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will do the former of these options since we have already fit the global model. For this demonstration, we will explore the effect of factor A at each level of factor B. I will illustrate two ways to perform these contrasts on an already fit model:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&amp;gt; Xmat = model.matrix(~A * B, data = newdata)
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; head(fit)
            1        2        3        4        5        6
[1,] 41.07993 55.81865 45.61247 45.43397 39.49714 65.52366
[2,] 40.30651 53.33106 44.78207 45.77720 39.43896 65.82722
[3,] 40.42144 55.13695 45.57116 45.48170 40.51761 66.06142
[4,] 39.79269 56.14951 45.56942 44.27930 39.26017 66.21183
[5,] 39.40269 54.09738 44.64012 45.20530 39.11246 66.62467
[6,] 41.27115 53.85821 47.17980 46.44773 38.92215 65.30783
&amp;gt; 
&amp;gt; ## we want to compare columns 2-1, 4-3 and 6-5
&amp;gt; comps = fit[, c(2, 4, 6)] - fit[, c(1, 3, 5)]
&amp;gt; tidyMCMC(comps, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 3 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2       14.7        1.30    12.2      17.3 
2 4        0.188      1.30    -2.30      2.83
3 6       25.8        1.30    23.2      28.4 &lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&amp;gt; Xmat = model.matrix(~A * B, data = newdata)
&amp;gt; contr = attr(Xmat, &amp;quot;contrasts&amp;quot;)
&amp;gt; newdata.a1 = model.frame(~A * B, expand.grid(A = levels(data$A)[1], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&amp;gt; Xmat.a1 = model.matrix(~A * B, data = newdata.a1, contrasts = contr)
&amp;gt; newdata.a2 = model.frame(~A * B, expand.grid(A = levels(data$A)[2], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&amp;gt; Xmat.a2 = model.matrix(~A * B, data = newdata.a2, contrasts = contr)
&amp;gt; Xmat = Xmat.a2 - Xmat.a1
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 3 x 4
  estimate std.error conf.low conf.high
     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1   14.7        1.30    12.2      17.3 
2    0.188      1.30    -2.30      2.83
3   25.8        1.30    23.2      28.4 &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Analysis of Covariance - JAGS</title>
      <link>/jags/ancova-jags/ancova-jags/</link>
      <pubDate>Wed, 05 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/ancova-jags/ancova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Previous tutorials have concentrated on designs for either continuous (Regression) or categorical (ANOVA) predictor variables. &lt;em&gt;Analysis of covariance&lt;/em&gt; (ANCOVA) models are essentially ANOVA models that incorporate one or more continuous and categorical variables (covariates). Although the relationship between a response variable and a covariate may itself be of substantial clinical interest, typically covariate(s) are incorporated to reduce the amount of unexplained variability in the model and thereby increase the power of any treatment effects.&lt;/p&gt;
&lt;p&gt;In ANCOVA, a reduction in unexplained variability is achieved by adjusting the response (to each treatment) according to slight differences in the covariate means as well as accounting for any underlying trends between the response and covariate(s). To do so, the extent to which the within treatment group small differences in covariate means between groups and treatment groups are essentially compared via differences in their &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercepts. The total variation is thereafter partitioned into explained (using the deviations between the overall trend and trends approximated for each of the treatment groups) and unexplained components (using the deviations between the observations and the approximated within group trends). In this way, ANCOVA can be visualized as a regular ANOVA in which the group and overall means are replaced by group and overall trendlines. Importantly, it should be apparent that ANCOVA is only appropriate when each of the within group trends have the same slope and are thus parallel to one another and the overall trend. Furthermore, ANCOVA is not appropriate when the resulting adjustments must be extrapolated from a linear relationship outside the measured range of the covariate.&lt;/p&gt;
&lt;p&gt;As an example, an experiment might be set up to investigate the energetic impacts of sexual vs parthenogenetic (egg development without fertilization) reproduction on leaf insect food consumption. To do so, researchers could measure the daily food intake of individual adult female leaf insects from female only (parthenogenetic) and mixed (sexual) populations. Unfortunately, the available individual leaf insects varied substantially in body size which was expected to increase the variability of daily food intake of treatment groups. Consequently, the researchers also measured the body mass of the individuals as a covariate, thereby providing a means by which daily food consumption could be standardized for body mass. ANCOVA attempts to reduce unexplained variability by standardising the response to the treatment by the effects of the specific covariate condition. Thus ANCOVA provides a means of exercising some statistical control over the variability when it is either not possible or not desirable to exercise experimental control (such as blocking or using otherwise homogeneous observations).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Factor A: the main treatment effect&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1(adj)=\mu_2(adj)=\ldots=\mu_i(adj)=\mu(adj)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The adjusted population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; adjusted for the covariate is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; adjusted for the covariate and so on, and thus all population means adjusted for the covariate are equal to an overall adjusted mean. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group adjusted mean and the overall adjusted mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i(adj)=\mu_i(adj)−\mu(adj)\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1(adj)=\alpha_2(adj)=\ldots=\alpha_i(adj)=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The effect of each group equals zero. If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i(adj)\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), the null hypothesis is not true, indicating that the treatment does affect the response variable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B: the covariate effect&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\beta_1(pooled)=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The pooled population slope equals zero. Note, that this null hypothesis is rarely of much interest. It is precisely because of this nuisance relationship that ANCOVA designs are applied.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models&lt;/h2&gt;
&lt;p&gt;One or more covariates can be incorporated into single factor, nested, factorial and partly nested designs in order to reduce the unexplained variation. Fundamentally, the covariate(s) are purely used to adjust the response values prior to the regular analysis. The difficulty is in determining the appropriate adjustments. Following is a list of the appropriate linear models and adjusted response calculations for a range of ANCOVA designs. Note that these linear models do not include interactions involving the covariates as these are assumed to be zero. The inclusion of these interaction terms is a useful means of testing the homogeneity of slopes assumption.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Single categorical and single covariate&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \beta(x_{ij}-\bar{x}) + \epsilon_{ij}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij(adj)}=y_{ij} - b(x_{ij} - \bar{x})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Single categorical and two covariates&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \beta_{YX}(x_{ij}-\bar{x}) + \beta_{YZ}(z_{ij}-\bar{z}) + \epsilon_{ij}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij(adj)}=y_{ij} - b_{YX}(x_{ij} - \bar{x}) - b_{YZ}(z_{ij} - \bar{z})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Factorial designs&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \gamma_j + (\alpha\gamma)_{ij}+ \beta(x_{ijk}-\bar{x}) + \epsilon_{ijk}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk(adj)}=y_{ijk} - b(x_{ijk} - \bar{x})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Nested designs&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk}=\mu + \alpha_i + \gamma_{j(i)} + \beta(x_{ijk}-\bar{x}) + \epsilon_{ijk}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk(adj)}=y_{ijk} - b(x_{ijk} - \bar{x})\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Partly nested designs&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Linear model: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijkl}=\mu + \alpha_i + \gamma_{j(i)} + \delta_k + (\alpha\delta)_{ik} + (\gamma\delta)_{j(i)k} + \beta(x_{ijk}-\bar{x}) + \epsilon_{ijkl}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adjustments: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk(adj)}=y_{ijkl} - b_{between}(x_{i} - \bar{x}) - b_{within}(x_{ijk} - \bar{x}_i)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;In ANCOVA, the total variability of the response variable is sequentially partitioned into components explained by each of the model terms, starting with the covariate and is therefore equivalent to performing a regular analysis of variance on the response variables that have been adjusted for the covariate. The appropriate unexplained residuals and therefore the appropriate &lt;em&gt;F-ratios&lt;/em&gt; for each factor differ according to the different null hypotheses associated with different linear models as well as combinations of fixed and random factors in the model (see the following tables). Note that since the covariate levels measured are typically different for each group, ANCOVA designs are inherently non-orthogonal (unbalanced). Consequently, sequential (Type I sums of squares) should not be used. For very simple Ancova designs that incorporate a single categorical and single covariate, Type I sums of squares can be used provided the covariate appears in the linear model first (and thus is partitioned out last) as we are typically not interested in estimating this effect.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ancova_table
          df       MS       F-ratio (A&amp;amp;B fixed) F-ratio (B fixed) 
Factor A  &amp;quot;a-1&amp;quot;    &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot; 
Factor B  &amp;quot;1&amp;quot;      &amp;quot;MS B&amp;quot;   &amp;quot;(MS B)/(MS res)&amp;quot;   &amp;quot;(MS B)/(MS res)&amp;quot; 
Factor AB &amp;quot;a-1&amp;quot;    &amp;quot;MS AB&amp;quot;  &amp;quot;(MS AB)/(MS res)&amp;quot;  &amp;quot;(MS AB)/(MS res)&amp;quot;
Residual  &amp;quot;(n-2)a&amp;quot; &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;                  &amp;quot;&amp;quot;                &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The corresponding &lt;code&gt;R&lt;/code&gt; syntax is given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(DV ~ B * A, dataset))
&amp;gt; # OR
&amp;gt; anova(aov(DV ~ B * A, dataset))
&amp;gt; # OR (make sure not using treatment contrasts)
&amp;gt; Anova(lm(DV ~ B * A, dataset), type = &amp;quot;III&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;As ANCOVA designs are essentially regular ANOVA designs that are first adjusted (centered) for the covariate(s), ANCOVA designs inherit all of the underlying assumptions of the appropriate ANOVA design. Specifically, hypothesis tests assume that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The appropriate residuals are normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator, see the above tables) should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The appropriate residuals are equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The appropriate residuals are independent of one another.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The relationship between the response variable and the covariate should be linear. Linearity can be explored using scatterplots and residual plots should reveal no patterns.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For repeated measures and other designs in which treatment levels within blocks can not be be randomly ordered, the variance/covariance matrix is assumed to display sphericity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For designs that utilise blocking, it is assumed that there are no block by within block interactions.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Homogeneity of Slopes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In addition to the above assumptions, ANCOVA designs also assume that slopes of relationships between the response variable and the covariate(s) are the same for each treatment level (group). That is, all the trends are parallel. If the individual slopes deviate substantially from each other (and thus the overall slope), then adjustments made to each of the observations are nonsensical. This situation is analogous to an interaction between two or more factors. In ANCOVA, interactions involving the covariate suggest that the nature of the relationship between the response and the covariate differs between the levels of the categorical treatment. More importantly, they also indicate that whether or not there is an effect of the treatment depends on what range of the covariate you are focussed on. Clearly then, it is not possible to make conclusions about the main effects of treatments in the presence of such interactions. The assumption of homogeneity of slopes can be examined via interaction plots or more formally, by testing hypotheses about the interactions between categorical variables and the covariate(s). There are three broad approaches for dealing with ANCOVA designs with heterogeneous slopes and selection depends on the primary focus of the study.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;When the primary objective of the analysis is to investigate the effects of categorical treatments, it is possible to adopt an approach similar to that taken when exploring interactions in multiple regression. The effect of treatments can be examined at specific values of the covariate (such as the mean and &lt;span class=&#34;math inline&#34;&gt;\(\pm\)&lt;/span&gt; one standard deviation). This approach is really only useful at revealing broad shifts in patterns over the range of the covariate and if the selected values of the covariate do not have some inherent clinical meaning (selected arbitrarily), then the outcomes can be of only limited clinical interest.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Alternatively, the &lt;em&gt;Johnson-Neyman technique&lt;/em&gt; (or Wilxon modification thereof) procedure indicates the ranges of the covariate over which the individual regression lines of pairs of treatment groups overlap or cross. Although less powerful than the previous approach, the &lt;em&gt;Wilcox(J-N)&lt;/em&gt; procedure has the advantage of revealing the important range (ranges for which the groups are different and not different) of the covariate rather than being constrained by specific levels selected.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use contrast treatments to split up the interaction term into its constituent contrasts for each level of the treatment. Essentially this compares each of the treatment level slopes to the slope from the “control” group and is useful if the primary focus is on the relationships between the response and the covariate.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Similar covariate ranges&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Adjustments made to the response means in an attempt to statistically account for differences in the covariate involve predicting mean response values along displaced linear relationships between the overall response and covariate variables. The degree of trend displacement for any given group is essentially calculated by multiplying the overall regression slope by the degree of difference between the overall covariate mean and the mean of the covariate for that group. However, when the ranges of the covariate within each of the groups differ substantially from one another, these adjustments are effectively extrapolations and therefore of unknown reliability. If a simple ANOVA of the covariate modelled against the categorical factor indicates that the covariate means differ significantly between groups, it may be necessary to either remove extreme observations or reconsider the analysis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Robust ANCOVA&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ANCOVA based on rank transformed data can be useful for accommodating data with numerous problematic outliers. Nevertheless, problems about the difficulties of detecting interactions from rank transformed data, obviously have implications for inferential tests of homogeneity of slopes. Randomisation tests that maintain response0covariate pairs and repeatedly randomise these observations amongst the levels of the treatments can also be useful, particularly when there is doubt over the independence of observations. Both planned and unplanned comparisons follow those of other ANOVA chapters without any real additional complications. Notably, recent implementations of the &lt;em&gt;Tukey’s test&lt;/em&gt; (within &lt;code&gt;R&lt;/code&gt;) accommodate unbalanced designs and thus negate the need for some of the more complicated and specialised techniques that have been highlighted in past texts.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Consider an experimental design aimed at exploring the effects of a categorical variable with three levels (Group A, Group B and Group C) on a response. From previous studies, we know that the response is influenced by another variable (covariate). Unfortunately, it was not possible to ensure that all sampling units were the same degree of the covariate. Therefore, in an attempt to account for this anticipated extra source of variability, we measured the level of the covariate for each sampling unit. Actually, in allocating treatments to the various treatment groups, we tried to ensure a similar mean and range of the covariate within each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n &amp;lt;- 10
&amp;gt; p &amp;lt;- 3
&amp;gt; A.eff &amp;lt;- c(40, -15, -20)
&amp;gt; beta &amp;lt;- -0.45
&amp;gt; sigma &amp;lt;- 4
&amp;gt; B &amp;lt;- rnorm(n * p, 0, 15)
&amp;gt; A &amp;lt;- gl(p, n, lab = paste(&amp;quot;Group&amp;quot;, LETTERS[1:3]))
&amp;gt; mm &amp;lt;- model.matrix(~A + B)
&amp;gt; data &amp;lt;- data.frame(A = A, B = B, Y = as.numeric(c(A.eff, beta) %*% t(mm)) + rnorm(n * p, 0, 4))
&amp;gt; data$B &amp;lt;- data$B + 20
&amp;gt; head(data)
        A        B        Y
1 Group A 11.59287 45.48907
2 Group A 16.54734 40.37341
3 Group A 43.38062 33.05922
4 Group A 21.05763 43.03660
5 Group A 21.93932 42.41363
6 Group A 45.72597 31.17787&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(car)
&amp;gt; scatterplot(Y ~ B | A, data = data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; boxplot(Y ~ A, data)
&amp;gt; 
&amp;gt; # OR via ggplot
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = Y, x = B, group = A)) + geom_point() + geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data, aes(y = Y, x = A)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_data-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is no evidence of obvious non-normality. The assumption of linearity seems reasonable. The variability of the three groups seems approximately equal. The slopes (&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; vs B trends) appear broadly similar for each treatment group.&lt;/p&gt;
&lt;p&gt;We can explore inferential evidence of unequal slopes by examining estimated effects of the interaction between the categorical variable and the covariate. Note, pay no attention to the main effects - only the interaction. Even though I intend to illustrate Bayesian analyses here, for such a simple model, it is considerably simpler to use traditional OLS for testing for the presence of an interaction.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(Y ~ B * A, data = data))
Analysis of Variance Table

Response: Y
          Df  Sum Sq Mean Sq  F value    Pr(&amp;gt;F)    
B          1  989.99  989.99  92.6782 1.027e-09 ***
A          2 2320.05 1160.02 108.5956 9.423e-13 ***
B:A        2   51.36   25.68   2.4041    0.1118    
Residuals 24  256.37   10.68                       
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is very little evidence to suggest that the assumption of equal slopes will be inappropriate.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X \boldsymbol \beta\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; represents the vector of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;’s - the intercept associated with the first group, the (effects) differences between this intercept and the intercepts for each other group as well as the slope associated with the continuous covariate. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X\)&lt;/span&gt; is the model matrix. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. Note, exploratory data analysis suggests that while the intercept (intercept of Group A) and categorical predictor effects (differences between intercepts of each of the Group and Group A’s intercept) could be drawn from a similar distribution (with mean in the &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;’s and variances in the &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;’s), the slope (effect associated with Group A linear relationship) is likely to be an order of magnitude less. We might therefore be tempted to provide different priors for the intercept, categorical effects and slope effect. For a simple model such as this, it is unlikely to be necessary. However, for more complex models, where prior specification becomes more critical, separate priors would probably be necessary.&lt;/p&gt;
&lt;p&gt;We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Note the following example as group means calculated as derived posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau)
+   mean[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   #Priors
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) 
+   }
+   sigma ~ dunif(0, 100)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;ancovaModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X &amp;lt;- model.matrix(~A + B, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = Y, X = X, n = nrow(data), ngroups = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;ancovaModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 30
   Unobserved stochastic nodes: 5
   Total graph size: 224

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;ancovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   51.001   1.529  47.977  50.009  50.995  52.016  53.980 1.001 15000
beta[2]  -16.254   1.623 -19.455 -17.342 -16.259 -15.170 -13.090 1.001 10000
beta[3]  -20.656   1.667 -23.941 -21.752 -20.672 -19.566 -17.330 1.001 15000
beta[4]   -0.484   0.048  -0.577  -0.516  -0.484  -0.453  -0.389 1.001 15000
sigma      3.607   0.526   2.740   3.236   3.546   3.912   4.793 1.001  7400
deviance 160.601   3.509 155.859 158.002 159.905 162.478 169.218 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 6.2 and DIC = 166.8
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trace plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters (such as &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;s).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3689  3746         0.985     
 beta[2]  2        3938  3746         1.050     
 beta[3]  2        3853  3746         1.030     
 beta[4]  2        3811  3746         1.020     
 deviance 2        3895  3746         1.040     
 sigma    5        5552  3746         1.480     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3770  3746         1.010     
 beta[2]  2        3729  3746         0.995     
 beta[3]  2        3811  3746         1.020     
 beta[4]  2        3895  3746         1.040     
 deviance 2        3855  3746         1.030     
 sigma    4        5247  3746         1.400     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
            beta[1]      beta[2]      beta[3]       beta[4]     deviance
Lag 0   1.000000000  1.000000000  1.000000000  1.0000000000  1.000000000
Lag 1   0.017910611 -0.003186598  0.009149022  0.0039919666  0.266991768
Lag 5  -0.004399550 -0.002747041 -0.001891657 -0.0213261543  0.005499734
Lag 10 -0.001972741  0.005855050 -0.004887402  0.0186597337 -0.008683579
Lag 50 -0.002269863  0.015348324 -0.001446494 -0.0004828212 -0.010725173
              sigma
Lag 0   1.000000000
Lag 1   0.382742913
Lag 5   0.007377659
Lag 10 -0.001255836
Lag 50  0.003892668&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.&lt;/p&gt;
&lt;p&gt;There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Standardised residuals&lt;/strong&gt;. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Studentised residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the residuals. Note that &lt;strong&gt;externally studentised residuals&lt;/strong&gt; are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pearson residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%) back thereby allowing us to train the model on &lt;span class=&#34;math inline&#34;&gt;\(75\)&lt;/span&gt;% of the data and then see how well the model can predict the withheld &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.&lt;/p&gt;
&lt;p&gt;Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within &lt;code&gt;JAGS&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$Y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(tidyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$Y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = B)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$Y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~A + B, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:4]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; newdata = data.frame(A = data$A, B = data$B, yRep) %&amp;gt;% gather(key = Sample,
+     value = Value, -A, -B)
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = A, fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_violin(data = data, aes(y = Y, x = A,
+     fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) + geom_point(data = data, aes(y = Y,
+     x = A), position = position_jitter(width = 0.1, height = 0),
+     color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = B, fill = &amp;quot;Model&amp;quot;,
+     group = B, color = A), alpha = 0.5) + geom_point(data = data,
+     aes(y = Y, x = B, group = B, color = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;ancovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   51.001   1.529  47.977  50.009  50.995  52.016  53.980 1.001 15000
beta[2]  -16.254   1.623 -19.455 -17.342 -16.259 -15.170 -13.090 1.001 10000
beta[3]  -20.656   1.667 -23.941 -21.752 -20.672 -19.566 -17.330 1.001 15000
beta[4]   -0.484   0.048  -0.577  -0.516  -0.484  -0.453  -0.389 1.001 15000
sigma      3.607   0.526   2.740   3.236   3.546   3.912   4.793 1.001  7400
deviance 160.601   3.509 155.859 158.002 159.905 162.478 169.218 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 6.2 and DIC = 166.8
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 6 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    51.0      1.53     48.0      53.9  
2 beta[2]   -16.3      1.62    -19.5     -13.1  
3 beta[3]   -20.7      1.67    -23.9     -17.3  
4 beta[4]    -0.484    0.0478   -0.577    -0.389
5 deviance  161.       3.51    155.      167.   
6 sigma       3.61     0.526     2.69      4.70 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The intercept of the first group (Group A) is &lt;span class=&#34;math inline&#34;&gt;\(51\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the second group (Group B) is &lt;span class=&#34;math inline&#34;&gt;\(-16.3\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the third group (Group C) is &lt;span class=&#34;math inline&#34;&gt;\(-20.7\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A one unit increase in B in Group A is associated with a &lt;span class=&#34;math inline&#34;&gt;\(-0.484\)&lt;/span&gt; units increase in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of Group B, Group C and the partial slope associated with B do not overlapp with 0 implying a significant difference between group A and groups B, C and a significant negative relationship with B. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])  # effect of (B-A = 0)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])  # effect of (C-A = 0)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[4]&amp;quot;])  # effect of (slope = 0)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, 2:4])  # effect of (model)
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence that the reponse differs between the groups.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = expand.grid(A = levels(data$A), B = seq(min(data$B), max(data$B),
+     len = 100))
&amp;gt; Xmat = model.matrix(~A + B, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;, &amp;quot;beta[4]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = B, fill = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~A + B, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$Y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = B, fill = A)) + geom_point(data = rdata,
+     aes(y = partial.resid, x = B, color = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posteriors&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Posteriors&lt;/h1&gt;
&lt;p&gt;In frequentist statistics, when we have more than two groups, we are typically not only interested in whether there is evidence for an overall “effect” of a factor - we are also interested in how various groups compare to one another. To explore these trends, we either compare each group to each other in a pairwise manner (controlling for family-wise Type I error rates) or we explore an independent subset of the possible comparisons. Although these alternate approaches can adequately address a specific research agenda, often they impose severe limitations and compromises on the scope and breadth of questions that can be asked of your data. The reason for these limitations is that in a frequentist framework, any single hypothesis carries with it a (nominally) &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% chance of a false rejection (since it is based on long-run frequency). Thus, performing multiple tests are likely to compound this error rate. The point is, that each comparison is compared to its own probability distribution (and each carries a &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% error rate). By contrast, in Bayesian statistics, all comparisons (contrasts) are drawn from the one (hopefully stable and convergent) posterior distribution and this posterior is invariant to the type and number of comparisons drawn. Hence, the theory clearly indicates that having generated our posterior distribution, we can then query this distribution in any way that we wish thereby allowing us to explore all of our research questions simultaneously.&lt;/p&gt;
&lt;p&gt;Bayesian “contrasts” can be performed either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;within the Bayesian sampling model or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;construct them from the returned MCMC samples (they are drawn from the posteriors)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Only the latter will be demonstrated as it provides a consistent approach across all routines. In order to allow direct comparison to the frequentist equivalents, I will explore the same set of planned and &lt;em&gt;Tukey&lt;/em&gt;’s test comparisons described here. For the “planned comparison” we defined two contrasts: 1) group B vs group C; and 2) group A vs the average of groups B and C. Of course each of these could be explored at multiple values of B, however, since we fit an additive model (which assumes that the slopes are homogeneous), the contrasts will be constant throughout the domain of B.&lt;/p&gt;
&lt;p&gt;Lets start by comparing each group to each other group in a pairwise manner. Arguably the most elegant way to do this is to generate a Tukey’s contrast matrix. This is a model matrix specific to comparing each group to each other group. Again, since the lines are parallel, it does not really matter what level of B we estimate these efffects at - so lets use the mean B.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:4]
&amp;gt; newdata &amp;lt;- data.frame(A = levels(data$A), B = mean(data$B))
&amp;gt; # A Tukeys contrast matrix
&amp;gt; library(multcomp)
&amp;gt; tuk.mat &amp;lt;- contrMat(n = table(newdata$A), type = &amp;quot;Tukey&amp;quot;)
&amp;gt; Xmat &amp;lt;- model.matrix(~A + B, data = newdata)
&amp;gt; pairwise.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; pairwise.mat
                  (Intercept) AGroup B AGroup C B
Group B - Group A           0        1        0 0
Group C - Group A           0        0        1 0
Group C - Group B           0       -1        1 0
&amp;gt; 
&amp;gt; mcmc_areas(coefs %*% t(pairwise.mat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/posterior1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; (comps = tidyMCMC(coefs %*% t(pairwise.mat), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 3 x 5
  term              estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 Group B - Group A   -16.3       1.62   -19.5     -13.1 
2 Group C - Group A   -20.7       1.67   -23.9     -17.3 
3 Group C - Group B    -4.40      1.69    -7.68     -1.04
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/posterior1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With a couple of modifications, we could also express this as percentage changes. A percentage change represents the change (difference between groups) divided by one of the groups (determined by which group you want to express the percentage change to). Hence, we generate an additional mcmc matrix that represents the cell means for the divisor group (group we want to express change relative to). Since the &lt;code&gt;tuk.mat&lt;/code&gt; defines comparisons as &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; pairs, if we simply replace all the &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, the eventual matrix multiplication will result in estimates of the divisor cell means instread of the difference. We can then divide the original mcmc matrix above with this new divisor mcmc matrix to yeild a mcmc matrix of percentage change.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # Modify the tuk.mat to replace -1 with 0.  This will allow us to get a
&amp;gt; # mcmc matrix of ..
&amp;gt; tuk.mat[tuk.mat == -1] = 0
&amp;gt; comp.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; comp.mat
                  (Intercept) AGroup B AGroup C        B
Group B - Group A           1        1        0 19.29344
Group C - Group A           1        0        1 19.29344
Group C - Group B           1        0        1 19.29344
&amp;gt; 
&amp;gt; comp.mcmc = 100 * (coefs %*% t(pairwise.mat))/coefs %*% t(comp.mat)
&amp;gt; (comps = tidyMCMC(comp.mcmc, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 3 x 5
  term              estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 Group B - Group A    -64.3      8.74    -82.4    -48.0 
2 Group C - Group A    -99.0     12.6    -124.     -74.8 
3 Group C - Group B    -21.4      9.02    -39.2     -4.13
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size (%)&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/posterior2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for the specific planned comparisons (Group B vs Group C as well as Group A vs the average of Groups B and C). This is achieved by generating our own contrast matrix (defining the contributions of each group to each contrast).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; c.mat = rbind(c(0, 1, -1), c(1/2, -1/3, -1/3))
&amp;gt; c.mat
     [,1]       [,2]       [,3]
[1,]  0.0  1.0000000 -1.0000000
[2,]  0.5 -0.3333333 -0.3333333
&amp;gt; 
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:4]
&amp;gt; newdata &amp;lt;- data.frame(A = levels(data$A), B = mean(data$B))
&amp;gt; Xmat &amp;lt;- model.matrix(~A + B, data = newdata)
&amp;gt; c.mat = c.mat %*% Xmat
&amp;gt; c.mat
     (Intercept)   AGroup B   AGroup C         B
[1,]   0.0000000  1.0000000 -1.0000000  0.000000
[2,]  -0.1666667 -0.3333333 -0.3333333 -3.215574
&amp;gt; 
&amp;gt; (comps = tidyMCMC(as.mcmc(coefs %*% t(c.mat)), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 2 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1      4.40     1.69      1.04      7.68
2 var2      5.36     0.790     3.80      6.93&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;      beta[1]   beta[2]   beta[3]    beta[4] deviance    sigma
[1,] 49.12140 -12.79223 -18.26477 -0.4972722 161.2762 3.888826
[2,] 51.03351 -16.80051 -20.03944 -0.4767683 156.2198 2.958015
[3,] 51.55756 -16.80292 -20.00531 -0.4479209 161.2724 3.984268
[4,] 50.15508 -15.15637 -21.01837 -0.4787121 158.5376 3.943798
[5,] 52.94683 -17.04043 -22.95279 -0.5209229 157.8834 3.194266
[6,] 52.16920 -17.91313 -23.53270 -0.4678091 159.4251 3.239537
# A tibble: 3 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A         3.12     1.18     0.739      5.41
2 sd.B         7.12     0.703    5.73       8.49
3 sd.resid     3.46     0.169    3.26       3.79
# A tibble: 3 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A         22.9      6.62     8.09      34.1
2 sd.B         52.3      4.54    43.1       61.2
3 sd.resid     24.9      3.22    20.8       31.9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/eff_pop1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(22.9\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat = model.matrix(~A + B, data)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$Y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.905    0.0148    0.877     0.922
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(Y ~ A + B, data))

Call:
lm(formula = Y ~ A + B, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.4381 -2.2244 -0.6829  2.1732  8.6607 

Coefficients:
             Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  51.00608    1.44814   35.22  &amp;lt; 2e-16 ***
AGroup B    -16.25472    1.54125  -10.55 6.92e-11 ***
AGroup C    -20.65596    1.57544  -13.11 5.74e-13 ***
B            -0.48399    0.04526  -10.69 5.14e-11 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 3.44 on 26 degrees of freedom
Multiple R-squared:  0.9149,    Adjusted R-squared:  0.9051 
F-statistic: 93.22 on 3 and 26 DF,  p-value: 4.901e-14&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dealing-with-heterogeneous-slopes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dealing with heterogeneous slopes&lt;/h1&gt;
&lt;p&gt;Generate the data with heterogeneous slope effects.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n &amp;lt;- 10
&amp;gt; p &amp;lt;- 3
&amp;gt; A.eff &amp;lt;- c(40, -15, -20)
&amp;gt; beta &amp;lt;- c(-0.45, -0.1, 0.5)
&amp;gt; sigma &amp;lt;- 4
&amp;gt; B &amp;lt;- rnorm(n * p, 0, 15)
&amp;gt; A &amp;lt;- gl(p, n, lab = paste(&amp;quot;Group&amp;quot;, LETTERS[1:3]))
&amp;gt; mm &amp;lt;- model.matrix(~A * B)
&amp;gt; data1 &amp;lt;- data.frame(A = A, B = B, Y = as.numeric(c(A.eff, beta) %*% t(mm)) + rnorm(n * p, 0, 4))
&amp;gt; data1$B &amp;lt;- data1$B + 20
&amp;gt; head(data1)
        A        B        Y
1 Group A 11.59287 45.48907
2 Group A 16.54734 40.37341
3 Group A 43.38062 33.05922
4 Group A 21.05763 43.03660
5 Group A 21.93932 42.41363
6 Group A 45.72597 31.17787&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; scatterplot(Y ~ B | A, data = data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; boxplot(Y ~ A, data1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; # OR via ggplot
&amp;gt; ggplot(data1, aes(y = Y, x = B, group = A)) + geom_point() + geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_het-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data1, aes(y = Y, x = A)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/exp_het-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The slopes (&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; vs B trends) do appear to differ between treatment groups - in particular, Group C seems to portray a different trend to Groups A and B.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(Y ~ B * A, data = data1))
Analysis of Variance Table

Response: Y
          Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
B          1  442.02  442.02  41.380 1.187e-06 ***
A          2 2760.60 1380.30 129.217 1.418e-13 ***
B:A        2  285.75  142.87  13.375 0.0001251 ***
Residuals 24  256.37   10.68                      
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is strong evidence to suggest that the assumption of equal slopes is violated.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fitting the model&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2 = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau)
+   mean[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   #Priors
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) 
+   }
+   sigma ~ dunif(0, 100)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;ancovaModel2.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X &amp;lt;- model.matrix(~A * B, data1)
&amp;gt; data1.list &amp;lt;- with(data1, list(y = Y, X = X, n = nrow(data1), ngroups = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data1.r2jags &amp;lt;- jags(data = data1.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;ancovaModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 30
   Unobserved stochastic nodes: 7
   Total graph size: 286

Initializing model
&amp;gt; 
&amp;gt; print(data1.r2jags)
Inference for Bugs model at &amp;quot;ancovaModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   48.194   2.035  44.200  46.864  48.200  49.531  52.217 1.001 15000
beta[2]  -10.562   2.884 -16.240 -12.453 -10.586  -8.688  -4.814 1.001  8100
beta[3]  -26.538   2.568 -31.636 -28.207 -26.525 -24.858 -21.431 1.001 15000
beta[4]   -0.351   0.082  -0.512  -0.404  -0.351  -0.297  -0.188 1.001 15000
beta[5]   -0.271   0.110  -0.491  -0.344  -0.270  -0.198  -0.055 1.001 15000
beta[6]    0.270   0.117   0.039   0.194   0.270   0.346   0.500 1.001 15000
sigma      3.454   0.535   2.601   3.074   3.396   3.757   4.689 1.002  1800
deviance 157.761   4.417 151.465 154.544 156.990 160.166 168.119 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 9.8 and DIC = 167.5
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;MCMC diagnostics&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; denplot(data1.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_diag_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data1.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_diag_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trace plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters (such as &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;s).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data1.mcmc = as.mcmc(data1.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data1.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3853  3746         1.030     
 beta[2]  2        3689  3746         0.985     
 beta[3]  2        3895  3746         1.040     
 beta[4]  2        3649  3746         0.974     
 beta[5]  2        3918  3746         1.050     
 beta[6]  2        3770  3746         1.010     
 deviance 2        3938  3746         1.050     
 sigma    4        5018  3746         1.340     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3853  3746         1.030     
 beta[2]  2        3570  3746         0.953     
 beta[3]  2        3811  3746         1.020     
 beta[4]  2        3770  3746         1.010     
 beta[5]  2        3770  3746         1.010     
 beta[6]  2        3895  3746         1.040     
 deviance 2        3981  3746         1.060     
 sigma    4        5131  3746         1.370     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data1.mcmc)
            beta[1]      beta[2]     beta[3]      beta[4]       beta[5]
Lag 0   1.000000000  1.000000000 1.000000000  1.000000000  1.0000000000
Lag 1  -0.002520665 -0.007698073 0.001992162  0.000509790 -0.0005326877
Lag 5   0.001007950  0.009095032 0.001511518 -0.006890623  0.0025773251
Lag 10 -0.011280919  0.007907450 0.005969613 -0.006999313  0.0040454668
Lag 50 -0.012861369 -0.019813696 0.002604518 -0.008791380 -0.0136623372
            beta[6]     deviance        sigma
Lag 0   1.000000000  1.000000000 1.0000000000
Lag 1   0.004381248  0.332075434 0.4518687724
Lag 5  -0.001182603  0.032092130 0.0351574955
Lag 10 -0.004191097  0.003338842 0.0005457235
Lag 50  0.002636154 -0.005426687 0.0039447210&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model validation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data1.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata1 = data1
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:6], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data1$Y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data1.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata1 = newdata1
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:6], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data1$Y - fit
&amp;gt; newdata1 = newdata1 %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata1) + geom_point(aes(y = resid, x = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals2_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata1) + geom_point(aes(y = resid, x = B)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals2_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data1.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata1 = data1
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:6], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data1$Y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data1 = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_residuals3_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data1.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~A * B, data1)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:6]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data1), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; newdata1 = data.frame(A = data1$A, B = data1$B, yRep) %&amp;gt;% gather(key = Sample,
+     value = Value, -A, -B)
&amp;gt; ggplot(newdata1) + geom_violin(aes(y = Value, x = A, fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_violin(data = data1, aes(y = Y, x = A,
+     fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) + geom_point(data = data1, aes(y = Y,
+     x = A), position = position_jitter(width = 0.1, height = 0),
+     color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata1) + geom_violin(aes(y = Value, x = B, fill = &amp;quot;Model&amp;quot;,
+     group = B, color = A), alpha = 0.5) + geom_point(data = data1,
+     aes(y = Y, x = B, group = B, color = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_intervals(data1.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep2_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data1.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_rep2_het-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Parameter estimates&lt;/h2&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data1.r2jags)
Inference for Bugs model at &amp;quot;ancovaModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   48.194   2.035  44.200  46.864  48.200  49.531  52.217 1.001 15000
beta[2]  -10.562   2.884 -16.240 -12.453 -10.586  -8.688  -4.814 1.001  8100
beta[3]  -26.538   2.568 -31.636 -28.207 -26.525 -24.858 -21.431 1.001 15000
beta[4]   -0.351   0.082  -0.512  -0.404  -0.351  -0.297  -0.188 1.001 15000
beta[5]   -0.271   0.110  -0.491  -0.344  -0.270  -0.198  -0.055 1.001 15000
beta[6]    0.270   0.117   0.039   0.194   0.270   0.346   0.500 1.001 15000
sigma      3.454   0.535   2.601   3.074   3.396   3.757   4.689 1.002  1800
deviance 157.761   4.417 151.465 154.544 156.990 160.166 168.119 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 9.8 and DIC = 167.5
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; tidyMCMC(as.mcmc(data1.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 8 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    48.2      2.03    44.2      52.2   
2 beta[2]   -10.6      2.88   -16.3      -4.94  
3 beta[3]   -26.5      2.57   -31.6     -21.4   
4 beta[4]    -0.351    0.0816  -0.510    -0.187 
5 beta[5]    -0.271    0.110   -0.491    -0.0541
6 beta[6]     0.270    0.117    0.0436    0.503 
7 deviance  158.       4.42   151.      167.    
8 sigma       3.45     0.535    2.51      4.50  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The intercept of the first group (Group A) is &lt;span class=&#34;math inline&#34;&gt;\(48.2\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the second group (Group B) is &lt;span class=&#34;math inline&#34;&gt;\(-10.6\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The mean of the third group (Group C) is &lt;span class=&#34;math inline&#34;&gt;\(-26.5\)&lt;/span&gt; units greater than (A).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A one unit increase in B in Group A is associated with a &lt;span class=&#34;math inline&#34;&gt;\(-0.351\)&lt;/span&gt; units increase in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;difference in slope between Group B and Group A &lt;span class=&#34;math inline&#34;&gt;\(-0.270\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;difference in slope between Group C and Group A &lt;span class=&#34;math inline&#34;&gt;\(0.270\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of Group B, Group C and the partial slope associated with B do not overlapp with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between group A and groups B, C (at the mean level of predictor B) and a significant negative relationship with B (for Group A). The slope associated with Group B was not found to be significantly different from that associated with Group A, however, the slope associated with Group C was found to be significantly less negative than the slope associated with Group A. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])  # effect of (B-A = 0)
[1] 0.0009333333
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])  # effect of (C-A = 0)
[1] 0
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[4]&amp;quot;])  # effect of (slope = 0)
[1] 0.0003333333
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[5]&amp;quot;])  # effect of (slopeB - slopeA = 0)
[1] 0.0152
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[6]&amp;quot;])  # effect of (slopeC - slopeA = 0)
[1] 0.0232
&amp;gt; mcmcpvalue(data1.r2jags$BUGSoutput$sims.matrix[, 2:6])  # effect of (model)
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence that the reponse differs between the groups.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graphical summaries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data1.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata1 = expand.grid(A = levels(data1$A), B = seq(min(data1$B), max(data1$B),
+     len = 100))
&amp;gt; Xmat = model.matrix(~A * B, newdata1)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;, &amp;quot;beta[4]&amp;quot;, &amp;quot;beta[5]&amp;quot;,
+     &amp;quot;beta[6]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata1 = newdata1 %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata1, aes(y = estimate, x = B, fill = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_post1_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata1 = rdata1 = data1
&amp;gt; fMat = rMat = model.matrix(~A * B, fdata1)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data1$Y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata1 = rdata1 %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; 
&amp;gt; ggplot(newdata1, aes(y = estimate, x = B, fill = A)) + geom_point(data = rdata1,
+     aes(y = partial.resid, x = B, color = A)) + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), alpha = 0.2) + geom_line() + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;B&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/ancova-jags/2020-02-01-ancova-jags_files/figure-html/mcmc_post2_het-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Single Factor Anova - JAGS</title>
      <link>/jags/single-factor-anova-jags/single-factor-anova-jags/</link>
      <pubDate>Tue, 04 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/single-factor-anova-jags/single-factor-anova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Single factor Analysis of Variance&lt;/em&gt; (ANOVA), also known as single factor classification, is used to investigate the effect of a single factor comprising two or more groups (treatment levels) from a completely randomised design. Completely randomised refers to the absence of restrictions on the random allocation of experimental or sampling units to factor levels.&lt;/p&gt;
&lt;p&gt;For example, consider a situation in which three types of treatments (A, B and C) are applied to replicate sampling units across the sampling domain. Importantly, the treatments are applied at the scale of the sampling units and the treatments applied to each sampling unit do not extend to any other neighbouring sampling units. Another possible situation is where the scale of a treatment is far larger than that of a sampling unit. This design features two treatments, each replicated three times. Note that additional sampling units within each Site (the scale at which the treatment occurs) would NOT constitute additional replication. Rather, these would be sub-replicates. That is, they would be replicates of the Sites, not the treatments (since the treatments occur at the level of whole sites). In order to genuinely increase the number of replicates, it is necessary to have more Sites. The random allocation of sampling units within the sampling domain (such as population) is appropriate provided either the underlying response is reasonably homogenous throughout the domain, or else, there is a large number of sampling units. If the conditions are relatively hetrogenous, then the exact location of the sampling units is likely to be highly influential and may mask any detectable effects of treatments.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fixed-and-random-effects&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fixed and random effects&lt;/h2&gt;
&lt;p&gt;From a frequentist perspective, &lt;em&gt;fixed factors&lt;/em&gt; are factors whose levels represent the specific populations of interest. For example, a factor that comprises “high”, “medium” and “low” temperature treatments is a fixed factor - we are only interested in comparing those three populations. Conclusions about the effects of a fixed factor are restricted to the specific treatment levels investigated and for any subsequent experiments to be comparable, the same specific treatments of the factor would need to be used. By contrast, &lt;em&gt;random factors&lt;/em&gt; are factors whose levels are randomly chosen from all the possible levels of populations and are used as random representatives of the populations. For example, five random temperature treatments could be used to represent a full spectrum of temperature treatments. In this case, conclusions are extrapolated to all the possible treatment (temperature) levels and for subsequent experiments, a new random set of treatments of the factor would be selected.&lt;/p&gt;
&lt;p&gt;Other common examples of random factors include sites and subjects - factors for which we are attempting to generalise over. Furthermore, the nature of random factors means that we have no indication of how a new level of that factor (such as another subject or site) are likely to respond and thus it is not possible to predict new observations from random factors. These differences between fixed and random factors are reflected in the way their respective null hypotheses are formulated and interpreted. Whilst fixed factors contrast the effects of the different levels of the factor, random factors are modelled as the amount of additional variability they introduce. Random factors are modelled with a mean of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and their variance is estimated as the effect coefficient.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear model&lt;/h2&gt;
&lt;p&gt;The linear model for single factor classification is similar to that of multiple linear regression. The linear model can thus be represented by either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Means parameterisation&lt;/strong&gt; - in which the regression slopes represent the means of each treatment group and the intercept is removed (to prevent over-parameterisation).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \beta_1(\text{level}_1)_{ij} + \beta_2(\text{level}_2)_{ij} + \ldots + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; respectively represent the means response of treatment level &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;. This is often simplified to &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\alpha_i + \epsilon_{ij}\)&lt;/span&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Effects parameterisation&lt;/strong&gt; - the intercept represents a property such as the mean of one of the treatment groups (treatment contrasts) or the overall mean (sum contrasts), and the slope parameters represent effects (differences between each other group and the reference mean for example).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \mu + \beta_2(\text{level}_2)_{ij} + \beta_3(\text{level}_3)_{ij} + \ldots + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the mean of the first treatment group, &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_3\)&lt;/span&gt; respectively represent the effects (change from level &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;) of level &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; on the mean response. This is often simplified to: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \epsilon_{ij}\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1=0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since we are traditionally interested in investigating effects (differences) rather than treatment means, effects parameterisation is far more common (particularly when coupled with hypothesis testing). In a Bayesian framework, it does not really matter whether models are fit with means or effects parameterisation since the posterior likelihood can be querried in any way and repeatedly - thus enabling us to explore any specific effects after the model has been fit. Nevertheless, to ease comparisons with frequentist approaches, we will stick with effects paramterisation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis-fixed-factor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis: fixed factor&lt;/h2&gt;
&lt;p&gt;We can associate a null hypothesis test with each estimated parameter. For example, in a cell for each estimated mean in a means model we could test a null hypothesis that the population mean is equal to zero (e.g. &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\alpha_2=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\ldots\)&lt;/span&gt;). However, this rarely would be of much interest. By contrast, individual null hypotheses associated with each parameter of the effects model can be used to investigate the differences between each group and a reference group (for example). In addition to the individual null hypothesis tests, a single fixed factor ANOVA tests the collective &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; that there are no differences between the population group means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt; (the population group means are all equal). That is, that the mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to one another - no effect of the factor on the response. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the mean of the first group (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu_1\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0 : \alpha_2=\alpha_3=\ldots=\alpha_i=0\)&lt;/span&gt; (the effect of each group equals zero). If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), there is evidence that the null hypothesis is not true indicating that the factor does affect the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis-random-factor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis: random factor&lt;/h2&gt;
&lt;p&gt;The collective &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; for a random factor is that the variance between all possible treatment groups equals zero:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0 : \sigma^2_{\alpha}=0\)&lt;/span&gt; (added variance due to this factor equals zero).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that whilst the null hypotheses for fixed and random factors are different (fixed: population group means all equal, random: variances between populations all equal zero), the linear model fitted for fixed and random factors in single factor ANOVA models is identical. For more complex multi-factor ANOVA models however, the distinction between fixed and random factors has important consequences for building and interpreting statistical models and null hypotheses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;When the null hypothesis is true (and the populations are identical), the amount of variation among observations within groups should be similar to the amount of variation in observations between groups. However, when the null hypothesis is false (and some means are different from other means), the amount of variation among observations might be expected to be less than the amount of variation within groups. Analysis of variance, or ANOVA, partitions the total variance in the response (dependent) variable into a component of the variance that is explained by combinations of one or more categorical predictor variables (called factors) and a component of the variance that cannot be explained (residual). The variance ratio (F-ratio) from this partitioning can then be used to test the null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;) that the population group or treatment means are all equal. Ttotal variation can be decomposed into components explained by the groups (&lt;span class=&#34;math inline&#34;&gt;\(MS_{groups}\)&lt;/span&gt;) and and unexplained (&lt;span class=&#34;math inline&#34;&gt;\(MS_{residual}\)&lt;/span&gt;) by the groups. The gray arrows in b) depict the relative amounts explained by the groups. The proposed groupings generally explain why the first few points are higher on the y-axis than the last three points. The probability of collecting our sample, and thus generating the sample ratio of explained to unexplained variation (or one more extreme), when the null hypothesis is true (and population means are equal) is the area under the F-distribution beyond our sample ratio (&lt;span class=&#34;math inline&#34;&gt;\(\text{F-ratio}=\frac{MS_{groups}}{MS_{residual}}\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;When the null hypothesis is true (and the test assumptions have not been violated), the ratio (F-ratio) of explained to unexplained variance follows a theoretical probability distribution (F-distribution). When the null hypothesis is true, and there is no effect of the treatment on the response variable, the ratio of explained variability to unexplained variability is expected to be &lt;span class=&#34;math inline&#34;&gt;\(\leq 1\)&lt;/span&gt;. Since the denominator should represent the expected numerator in the absence of an effect. Importantly, the denominator in an F-ratio calculation essentially represents what we would expect the numerator to be in the absence of a treatment effect. For simple analyses, identifying what these expected values are is relatively straightforward (equivalent to the degree of within group variability). However, in more complex designs (particularly involving random factors and hierarchical treatment levels), the logical “groups” can be more difficult (and in some cases impossible) to identify. In such cases, nominating the appropriate F-ratio denominator for estimating an specific effect requires careful consideration. The following table depicts the anatomy of the single factor ANOVA table&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova_table
         df       MS       F-ratio          
Factor A &amp;quot;a-1&amp;quot;    &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;
Residual &amp;quot;(n-1)a&amp;quot; &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;               &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and corresponding &lt;code&gt;R&lt;/code&gt; syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(DV ~ A, dataset))
&amp;gt; # OR
&amp;gt; anova(aov(DV ~ A, dataset))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An F-ratio substantially greater than &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; suggests that the model relating the response variable to the categorical variable explains substantially more variability than is left unexplained. In turn, this implies that the linear model does represent the data well and that differences between observations can be explained largely by differences in treatment levels rather than purely the result of random variation. If the probability of getting the observed (sample) F-ratio or one more extreme is less than some predefined critical value (typically &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% or &lt;span class=&#34;math inline&#34;&gt;\(0.05\)&lt;/span&gt;), we conclude that it is highly unlikely that the observed samples could have been collected from populations in which the treatment has no effect and therefore we would reject the null hypothesis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;An F-ratio from real data can only reliably relate to a theoretical F-distribution when the data conform to certain assumptions. Hypothesis testing for a single factor ANOVA model assumes that the residuals (and therefore the response variable for each of the treatment levels) are all:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;normally distributed&lt;/strong&gt; - although ANOVA is robust to non-normality provided sample sizes and variances are equal. Boxplots should be used to explore normality, skewness, bimodality and outliers. In the event of homogeneity of variance issues (see below), a Q-Q normal plot can also be useful for exploring normality (as this might be the cause of non-homogeneity). Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;equally varied&lt;/strong&gt; - provided sample sizes are equal and the largest to smallest variance ratio does not exceed 3:1 (9:1 for sd), ANOVA is reasonably robust to this assumption, however, relationships between variance and mean and/or sample size are of particular concern as they elevate the Type I error rate. Boxplots and plots of means against variance should be used to explore the spread of values. Residual plots should reveal no patterns. Since unequal variances are often the result of non-normality, transformations that improve normality will also improve variance homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;independent of one another&lt;/strong&gt; - this assumption must be addressed at the design and collection stages and cannot be compensated for later (unless a model is used that specifically accounts for particular types of non-independent data, such as that introduced with hierarchical designs or autocorrelation)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Violations of these assumptions reduce the reliability of the analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Lets say we had set up a natural experiment in which we measured a response from &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; sampling units (replicates) from each of &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; treatments. Hence, we have a single categorical factor with &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; levels - we might have five different locations, or five different habitat types or substrates etc. In statistical speak, we have sampled from &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; different populations. We have then randomly selected &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; independent and random (representative) units of each population to sample. That is, we have &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; samples (replicates) of each population. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; ngroups &amp;lt;- 5  #number of populations
&amp;gt; nsample &amp;lt;- 10  #number of reps in each
&amp;gt; pop.means &amp;lt;- c(40, 45, 55, 40, 30)  #population mean length
&amp;gt; sigma &amp;lt;- 3  #residual standard deviation
&amp;gt; n &amp;lt;- ngroups * nsample  #total sample size
&amp;gt; eps &amp;lt;- rnorm(n, 0, sigma)  #residuals
&amp;gt; x &amp;lt;- gl(ngroups, nsample, n, lab = LETTERS[1:5])  #factor
&amp;gt; means &amp;lt;- rep(pop.means, rep(nsample, ngroups))
&amp;gt; X &amp;lt;- model.matrix(~x - 1)  #create a design matrix
&amp;gt; y &amp;lt;- as.numeric(X %*% pop.means + eps)
&amp;gt; data &amp;lt;- data.frame(y, x)
&amp;gt; head(data)  #print out the first six rows of the data set
         y x
1 38.31857 A
2 39.30947 A
3 44.67612 A
4 40.21153 A
5 40.38786 A
6 45.14519 A
&amp;gt; 
&amp;gt; write.csv(data, &amp;quot;simpleAnova.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type.&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Normality and Homogeneity of variance&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ x, data)
&amp;gt; 
&amp;gt; # OR via ggplot2
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/exp_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = y, x = x)) + geom_boxplot() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/exp_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity. Obvious violations could be addressed either by, for example, transforming the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0+\boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the mean of the first group and the set of &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;’s represent the differences between each other group and the first group. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Note the following example as group means calculated as derived posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau.res)
+   mean[i] &amp;lt;- alpha+beta[x[i]]
+   }
+ 
+   #Priors and derivatives
+   alpha ~ dnorm(0,1.0E-6)
+   beta[1] &amp;lt;- 0
+   for (i in 2:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) #prior
+   }
+   sigma.res ~ dunif(0, 100)
+   tau.res &amp;lt;- 1 / (sigma.res * sigma.res)
+   sigma.group &amp;lt;- sd(beta[])
+ 
+   #Group mean posteriors (derivatives)
+   for (i in 1:ngroups) {
+   Group.means[i] &amp;lt;- beta[i]+alpha
+   }
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;anovaModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.list &amp;lt;- with(data, list(y = y, x = as.numeric(x), n = nrow(data),
+     ngroups = length(levels(data$x))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma.res&amp;quot;, &amp;quot;Group.means&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;anovaModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 50
   Unobserved stochastic nodes: 6
   Total graph size: 126

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;anovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
               mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat
Group.means[1]  40.232   0.908  38.424  39.631  40.237  40.837  41.991 1.001
Group.means[2]  45.632   0.902  43.858  45.022  45.626  46.231  47.432 1.002
Group.means[3]  53.730   0.913  51.947  53.113  53.722  54.334  55.543 1.001
Group.means[4]  40.962   0.906  39.188  40.350  40.968  41.563  42.734 1.001
Group.means[5]  29.974   0.915  28.173  29.367  29.974  30.586  31.746 1.001
alpha           40.232   0.908  38.424  39.631  40.237  40.837  41.991 1.001
beta[1]          0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000
beta[2]          5.400   1.278   2.889   4.551   5.395   6.244   7.896 1.001
beta[3]         13.498   1.286  11.017  12.639  13.485  14.354  16.049 1.001
beta[4]          0.730   1.283  -1.768  -0.122   0.722   1.582   3.261 1.001
beta[5]        -10.258   1.294 -12.820 -11.110 -10.253  -9.412  -7.721 1.001
sigma.res        2.864   0.320   2.313   2.638   2.832   3.056   3.578 1.001
deviance       245.540   3.787 240.323 242.761 244.832 247.511 254.843 1.001
               n.eff
Group.means[1] 15000
Group.means[2]  2200
Group.means[3]  3800
Group.means[4] 15000
Group.means[5] 15000
alpha          15000
beta[1]            1
beta[2]         2900
beta[3]        15000
beta[4]        15000
beta[5]        15000
sigma.res      15000
deviance       15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;model-matrix-formulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model matrix formulation&lt;/h2&gt;
&lt;p&gt;For very simple models such as this example, we can write the models as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2 = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau)
+   mean[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   #Priors
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) 
+   }
+   sigma ~ dunif(0, 100)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;anovaModel2.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the data to pass to &lt;code&gt;R2jags&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X &amp;lt;- model.matrix(~x, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = X, n = nrow(data), ngroups = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;anovaModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 50
   Unobserved stochastic nodes: 6
   Total graph size: 370

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;anovaModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.226   0.901  38.475  39.624  40.222  40.824  41.999 1.001  4800
beta[2]    5.401   1.272   2.906   4.552   5.397   6.242   7.900 1.001 15000
beta[3]   13.492   1.296  10.969  12.634  13.484  14.355  16.038 1.001  5100
beta[4]    0.734   1.279  -1.793  -0.114   0.740   1.582   3.263 1.001 15000
beta[5]  -10.248   1.283 -12.785 -11.108 -10.242  -9.380  -7.731 1.001  9800
sigma      2.863   0.315   2.321   2.642   2.838   3.053   3.558 1.001  6200
deviance 245.551   3.785 240.353 242.765 244.844 247.603 254.815 1.002  1800

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3895  3746         1.040     
 beta[2]  2        3729  3746         0.995     
 beta[3]  2        3811  3746         1.020     
 beta[4]  3        4115  3746         1.100     
 beta[5]  2        3853  3746         1.030     
 deviance 2        3729  3746         0.995     
 sigma    5        5834  3746         1.560     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3853  3746         1.03      
 beta[2]  2        3918  3746         1.05      
 beta[3]  2        3811  3746         1.02      
 beta[4]  2        3853  3746         1.03      
 beta[5]  2        3853  3746         1.03      
 deviance 2        3981  3746         1.06      
 sigma    4        5306  3746         1.42      &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
             beta[1]     beta[2]       beta[3]       beta[4]      beta[5]
Lag 0   1.0000000000 1.000000000  1.0000000000  1.0000000000  1.000000000
Lag 1   0.0015561854 0.001902670 -0.0023462263  0.0063854498 -0.008928813
Lag 5  -0.0006487164 0.003556616 -0.0008267107 -0.0003892349  0.004087306
Lag 10  0.0141414517 0.012308363  0.0064688638 -0.0029210457  0.009117446
Lag 50 -0.0019115790 0.005069522  0.0072096979 -0.0030858504  0.002938152
           deviance        sigma
Lag 0   1.000000000  1.000000000
Lag 1   0.198317688  0.334172270
Lag 5  -0.001425768  0.005514213
Lag 10 -0.000422188 -0.001600486
Lag 50 -0.008805916  0.007414425&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.&lt;/p&gt;
&lt;p&gt;There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Standardised residuals&lt;/strong&gt;. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Studentised residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the residuals. Note that &lt;strong&gt;externally studentised residuals&lt;/strong&gt; are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pearson residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%) back thereby allowing us to train the model on &lt;span class=&#34;math inline&#34;&gt;\(75\)&lt;/span&gt;% of the data and then see how well the model can predict the withheld &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.&lt;/p&gt;
&lt;p&gt;Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within &lt;code&gt;JAGS&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(tidyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = x)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:5]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; newdata = data.frame(x = data$x, yRep) %&amp;gt;% gather(key = Sample,
+     value = Value, -x)
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = x, fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_violin(data = data, aes(y = y, x = x,
+     fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) + geom_point(data = data, aes(y = y,
+     x = x), position = position_jitter(width = 0.1, height = 0),
+     color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;anovaModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.226   0.901  38.475  39.624  40.222  40.824  41.999 1.001  4800
beta[2]    5.401   1.272   2.906   4.552   5.397   6.242   7.900 1.001 15000
beta[3]   13.492   1.296  10.969  12.634  13.484  14.355  16.038 1.001  5100
beta[4]    0.734   1.279  -1.793  -0.114   0.740   1.582   3.263 1.001 15000
beta[5]  -10.248   1.283 -12.785 -11.108 -10.242  -9.380  -7.731 1.001  9800
sigma      2.863   0.315   2.321   2.642   2.838   3.053   3.558 1.001  6200
deviance 245.551   3.785 240.353 242.765 244.844 247.603 254.815 1.002  1800

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 7 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    40.2       0.901    38.5      42.0 
2 beta[2]     5.40      1.27      2.90      7.89
3 beta[3]    13.5       1.30     11.0      16.1 
4 beta[4]     0.734     1.28     -1.82      3.21
5 beta[5]   -10.2       1.28    -12.7      -7.68
6 deviance  246.        3.79    240.      253.  
7 sigma       2.86      0.315     2.26      3.48&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the mean of the first group (A) is &lt;span class=&#34;math inline&#34;&gt;\(40.2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the mean of the second group (B) is &lt;span class=&#34;math inline&#34;&gt;\(5.4\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the third group (C) is &lt;span class=&#34;math inline&#34;&gt;\(13.5\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the forth group (D) is &lt;span class=&#34;math inline&#34;&gt;\(0.74\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the fifth group (E) is &lt;span class=&#34;math inline&#34;&gt;\(-10.2\)&lt;/span&gt; units greater (i.e. less) than (A)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of B, C and E do not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between group A and groups B, C and E. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])  # effect of (B-A)
[1] 6.666667e-05
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])  # effect of (C-A)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[4]&amp;quot;])  # effect of (D-A)
[1] 0.5576
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[5]&amp;quot;])  # effect of (E-A)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, 2:5])  # effect of (all groups)
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence that the reponse differs between the groups. There is evidence suggesting that the response of group D differs from that of group A.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = rbind(data.frame(x = levels(data$x)))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;, &amp;quot;beta[4]&amp;quot;, &amp;quot;beta[5]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_linerange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_point() + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = as.numeric(x) - 0.1)) + geom_blank(aes(x = x)) +
+     geom_point(data = rdata, aes(y = partial.resid, x = as.numeric(x) +
+         0.1), color = &amp;quot;gray&amp;quot;) + geom_linerange(aes(ymin = conf.low, ymax = conf.high)) +
+     geom_point() + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posteriors&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Posteriors&lt;/h1&gt;
&lt;p&gt;In frequentist statistics, when we have more than two groups, we are typically not only interested in whether there is evidence for an overall “effect” of a factor - we are also interested in how various groups compare to one another. To explore these trends, we either compare each group to each other in a pairwise manner (controlling for family-wise Type I error rates) or we explore an independent subset of the possible comparisons. Although these alternate approaches can adequately address a specific research agenda, often they impose severe limitations and compromises on the scope and breadth of questions that can be asked of your data. The reason for these limitations is that in a frequentist framework, any single hypothesis carries with it a (nominally) &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% chance of a false rejection (since it is based on long-run frequency). Thus, performing multiple tests are likely to compound this error rate. The point is, that each comparison is compared to its own probability distribution (and each carries a &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% error rate). By contrast, in Bayesian statistics, all comparisons (contrasts) are drawn from the one (hopefully stable and convergent) posterior distribution and this posterior is invariant to the type and number of comparisons drawn. Hence, the theory clearly indicates that having generated our posterior distribution, we can then query this distribution in any way that we wish thereby allowing us to explore all of our research questions simultaneously.&lt;/p&gt;
&lt;p&gt;Bayesian “contrasts” can be performed either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;within the Bayesian sampling model or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;construct them from the returned MCMC samples (they are drawn from the posteriors)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Only the latter will be demonstrated as it povides a consistent approach across all routines. In order to allow direct comparison to the frequentist equivalents, I will explore the same set of planned and &lt;em&gt;Tukey&lt;/em&gt;’s test comparisons described here. For the “planned comparison” we defined two contrasts: 1) group 3 vs group 5; and 2) the average of groups 1 and 2 vs the average of groups 3, 4 and 5.&lt;/p&gt;
&lt;p&gt;Lets start by comparing each group to each other group in a pairwise manner. Arguably the most elegant way to do this is to generate a Tukey’s contrast matrix. This is a model matrix specific to comparing each group to each other group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:5]
&amp;gt; newdata &amp;lt;- data.frame(x = levels(data$x))
&amp;gt; # A Tukeys contrast matrix
&amp;gt; library(multcomp)
&amp;gt; # table(newdata$x) - gets the number of replicates of each level
&amp;gt; tuk.mat &amp;lt;- contrMat(n = table(newdata$x), type = &amp;quot;Tukey&amp;quot;)
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data = newdata)
&amp;gt; pairwise.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; pairwise.mat
      (Intercept) xB xC xD xE
B - A           0  1  0  0  0
C - A           0  0  1  0  0
D - A           0  0  0  1  0
E - A           0  0  0  0  1
C - B           0 -1  1  0  0
D - B           0 -1  0  1  0
E - B           0 -1  0  0  1
D - C           0  0 -1  1  0
E - C           0  0 -1  0  1
E - D           0  0  0 -1  1
&amp;gt; 
&amp;gt; mcmc_areas(coefs %*% t(pairwise.mat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; (comps = tidyMCMC(coefs %*% t(pairwise.mat), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 B - A    5.40       1.27     2.90      7.89
 2 C - A   13.5        1.30    11.0      16.1 
 3 D - A    0.734      1.28    -1.82      3.21
 4 E - A  -10.2        1.28   -12.7      -7.68
 5 C - B    8.09       1.29     5.58     10.7 
 6 D - B   -4.67       1.30    -7.19     -2.02
 7 E - B  -15.6        1.28   -18.1     -13.1 
 8 D - C  -12.8        1.31   -15.3     -10.2 
 9 E - C  -23.7        1.29   -26.2     -21.2 
10 E - D  -11.0        1.29   -13.5      -8.46
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With a couple of modifications, we could also express this as percentage changes. A percentage change represents the change (difference between groups) divided by one of the groups (determined by which group you want to express the percentage change to). Hence, we generate an additional mcmc matrix that represents the cell means for the divisor group (group we want to express change relative to). Since the &lt;code&gt;tuk.mat&lt;/code&gt; defines comparisons as &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; pairs, if we simply replace all the &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, the eventual matrix multiplication will result in estimates of the divisor cell means instread of the difference. We can then divide the original mcmc matrix above with this new divisor mcmc matrix to yeild a mcmc matrix of percentage change.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # Modify the tuk.mat to replace -1 with 0.  This will allow us to get a
&amp;gt; # mcmc matrix of ..
&amp;gt; tuk.mat[tuk.mat == -1] = 0
&amp;gt; comp.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; comp.mat
      (Intercept) xB xC xD xE
B - A           1  1  0  0  0
C - A           1  0  1  0  0
D - A           1  0  0  1  0
E - A           1  0  0  0  1
C - B           1  0  1  0  0
D - B           1  0  0  1  0
E - B           1  0  0  0  1
D - C           1  0  0  1  0
E - C           1  0  0  0  1
E - D           1  0  0  0  1
&amp;gt; 
&amp;gt; comp.mcmc = 100 * (coefs %*% t(pairwise.mat))/coefs %*% t(comp.mat)
&amp;gt; (comps = tidyMCMC(comp.mcmc, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 B - A    11.8       2.63     6.52     16.8 
 2 C - A    25.1       2.13    21.0      29.4 
 3 D - A     1.74      3.10    -4.30      7.88
 4 E - A   -34.3       5.09   -44.3     -24.4 
 5 C - B    15.0       2.24    10.4      19.2 
 6 D - B   -11.5       3.38   -18.1      -4.70
 7 E - B   -52.3       5.53   -63.2     -41.6 
 8 D - C   -31.2       3.73   -38.5     -23.9 
 9 E - C   -79.4       6.26   -91.9     -67.5 
10 E - D   -36.8       5.15   -47.1     -27.0 
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size (%)&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for the specific planned comparisons (Group 3 vs Group 5 and the average of Groups 1 and 2 vs the average of Groups 3, 4 and 5). This is achieved by generating our own contrast matrix (defining the contributions of each group to each contrast).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; c.mat = rbind(c(0, 0, -1, 0, 1), c(-1/2, -1/2, 1/3, 1/3, 1/3))
&amp;gt; c.mat
     [,1] [,2]       [,3]      [,4]      [,5]
[1,]  0.0  0.0 -1.0000000 0.0000000 1.0000000
[2,] -0.5 -0.5  0.3333333 0.3333333 0.3333333
&amp;gt; 
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:5]
&amp;gt; newdata &amp;lt;- data.frame(x = levels(data$x))
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data = newdata)
&amp;gt; c.mat = c.mat %*% Xmat
&amp;gt; c.mat
       (Intercept)   xB         xC        xD        xE
[1,]  0.000000e+00  0.0 -1.0000000 0.0000000 1.0000000
[2,] -1.110223e-16 -0.5  0.3333333 0.3333333 0.3333333
&amp;gt; 
&amp;gt; (comps = tidyMCMC(as.mcmc(coefs %*% t(c.mat)), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 2 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1    -23.7      1.29    -26.2    -21.2  
2 var2     -1.37     0.836    -3.01     0.273&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;      beta[1]  beta[2]  beta[3]    beta[4]    beta[5] deviance    sigma
[1,] 41.14988 5.425974 13.10634  0.5423808 -12.004913 245.9651 2.374957
[2,] 41.77436 3.165155 12.08478 -2.5284367 -11.070257 251.2837 3.546706
[3,] 39.87873 5.074910 13.46806  0.7805140  -7.932663 245.7947 3.020465
[4,] 41.15168 3.079048 10.80976 -0.5505218 -10.396170 249.3934 2.547300
[5,] 39.93263 4.548017 13.82126  1.2192389  -9.549601 242.2442 2.449639
[6,] 40.41198 4.705732 12.87972  2.3548628  -8.868949 250.1582 2.432338
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         9.94    0.528      8.86     10.9 
2 sd.resid     2.79    0.0903     2.67      2.96
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         78.3      1.07     76.0      79.7
2 sd.resid     21.7      1.07     20.3      24.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/eff_pop1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(78.3\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.887    0.0127    0.862     0.905
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ x, data))

Call:
lm(formula = y ~ x, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5257 -1.9000 -0.2589  1.4935  6.5330 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.2239     0.8801  45.702  &amp;lt; 2e-16 ***
xB            5.4020     1.2447   4.340 7.97e-05 ***
xC           13.5024     1.2447  10.848 3.82e-14 ***
xD            0.7423     1.2447   0.596    0.554    
xE          -10.2500     1.2447  -8.235 1.57e-10 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 2.783 on 45 degrees of freedom
Multiple R-squared:  0.8957,    Adjusted R-squared:  0.8865 
F-statistic: 96.64 on 4 and 45 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-model-selection&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bayesian model selection&lt;/h1&gt;
&lt;p&gt;A statistical model is by definition a low-dimensional (over simplification) representation of what is really likely to be a very complex system. As a result, no model is right. Some models however can provide useful insights into some of the processes operating on the system. Frequentist statistics have various methods (model selection, dredging, lasso, cross validation) for selecting parsimonious models. These are models that provide a good comprimise between minimizing unexplained patterns and minimizing model complexity. The basic premise is that since no model can hope to capture the full complexity of a system with all its subtleties, only the very major patterns can be estimated. Overly complex models are likely to be representing artificial complexity present only in the specific observed data (not the general population). The Bayesian approach is to apply priors to the non-variance parameters such that parameters close to zero are further shrunk towards zero whilst priors on parameters further away from zero are less effected. The most popular form of prior for sparsity is the &lt;em&gt;horseshoe prior&lt;/em&gt;, so called because the shape of a component of this prior resembles a horseshoe (with most of the mass either close to &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; or close to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Rather than apply weakly informative Gaussian priors on parameters as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\sigma^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the horseshoe prior is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2\lambda_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tau \sim \text{Cauchy}(0,1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j \sim \text{Cauchy}(0,1)\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(j=1,\ldots,D\)&lt;/span&gt;. Using this prior, &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is the number of (non-intercept or variance) parameters, &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; represents the global scale that weights or shrinks all parameters towards zero and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j\)&lt;/span&gt; are thick tailed local scales that allow some of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; parameters to escape shrinkage. More recently, &lt;span class=&#34;citation&#34;&gt;Piironen, Vehtari, and others (2017)&lt;/span&gt; have argued that whilst the above horseshoe priors do guarantee that strong effects (parameters) will not be over-shrunk, there is the potential for weekly identified effects (those based on relatively little data) to be misrepresented in the posteriors. As an alternative they advocated the use of regularised horseshoe priors in which the amount of shrinkage applied to the largest effects can be controlled. The prior is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2 \tilde{\lambda}_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tilde{\lambda}_j^2 = \frac{c^2\lambda^2_j}{c^2+\tau^2 \lambda^2_j}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is (slab width, actually variance) is a constant. For small effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;lt; c^2\)&lt;/span&gt;) the prior approaches a regular prior. However, for large effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;gt; c^2\)&lt;/span&gt;) the prior approaches &lt;span class=&#34;math inline&#34;&gt;\(N(0,c^2)\)&lt;/span&gt;. Finally, they recommend applying a inverse-gamma prior on &lt;span class=&#34;math inline&#34;&gt;\(c^2\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ c^2 \sim \text{Inv-Gamma}(\alpha,\beta),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\alpha=v/2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta=vs^2/2\)&lt;/span&gt;, which translates to a &lt;span class=&#34;math inline&#34;&gt;\(\text{Student-t}_ν(0, s^2)\)&lt;/span&gt; slab for the coefficients far from zero and is typically a good default choice for a weakly informative prior.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-piironen2017sparsity&#34;&gt;
&lt;p&gt;Piironen, Juho, Aki Vehtari, and others. 2017. “Sparsity Information and Regularization in the Horseshoe and Other Shrinkage Priors.” &lt;em&gt;Electronic Journal of Statistics&lt;/em&gt; 11 (2): 5018–51.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Multiple Linear Regression - JAGS</title>
      <link>/jags/multiple-linear-regression-jags/multiple-linear-regression-jags/</link>
      <pubDate>Mon, 03 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/multiple-linear-regression-jags/multiple-linear-regression-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Multiple regression is an extension of simple linear regression whereby a response variable is modelled against a linear combination of two or more simultaneously measured predictor variables. There are two main purposes of multiple linear regression:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;To develop a better predictive model (equation) than is possible from models based on single independent variables.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;To investigate the relative individual effects of each of the multiple independent variables above and beyond (standardised across) the effects of the other variables.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Although the relationship between response variable and the additive effect of all the predictor variables is represented overall by a single multidimensional plane (surface), the individual effects of each of the predictor variables on the response variable (standardised across the other variables) can be depicted by single partial regression lines. The slope of any single partial regression line (partial regression slope) thereby represents the rate of change or effect of that specific predictor variable (holding all the other predictor variables constant to their respective mean values) on the response variable. In essence, it is the effect of one predictor variable at one specific level (the means) of all the other predictor variables (i.e. when each of the other predictors are set to their averages).&lt;/p&gt;
&lt;p&gt;Multiple regression models can be constructed additively (containing only the predictor variables themselves) or in a multiplicative design (which incorporate interactions between predictor variables in addition to the predictor variables themselves). Multiplicative models are used primarily for testing inferences about the effects of various predictor variables and their interactions on the response variable. Additive models by contrast are used for generating predictive models and estimating the relative importance of individual predictor variables more so than hypothesis testing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additive-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additive Model&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_{i1} +  \beta_2x_{i2} + \ldots + \beta_Jx_{iJ} + \epsilon_i,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the population &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept (value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; when all partial slopes equal zero), &lt;span class=&#34;math inline&#34;&gt;\(\beta_1,\beta_2,\ldots,\beta_{J}\)&lt;/span&gt; are the partial population slopes of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(X_1,X_2,\ldots,X_J\)&lt;/span&gt; respectively holding the other &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; constant. &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_i\)&lt;/span&gt; is the random unexplained error or residual component. The additive model assumes that the effect of one predictor variable (partial slope) is independent of the levels of the other predictor variables.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiplicative-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiplicative Model&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_{i1} +  \beta_2x_{i2} + \beta_3x_{i1}x_{i2} + \ldots + \beta_Jx_{iJ} + \epsilon_i,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_3x_{i1}x_{i2}\)&lt;/span&gt; is the interactive effect of &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(X_2\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; and it examines the degree to which the effect of one of the predictor variables depends on the levels of the other predictor variable(s).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Lets say we had set up a natural experiment in which we measured a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) from each of &lt;span class=&#34;math inline&#34;&gt;\(20\)&lt;/span&gt; sampling units (&lt;span class=&#34;math inline&#34;&gt;\(n=20\)&lt;/span&gt;) across a landscape. At the same time, we also measured two other continuous covariates (&lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;) from each of the sampling units. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n = 100
&amp;gt; intercept = 5
&amp;gt; temp = runif(n)
&amp;gt; nitro = runif(n) + 0.8 * temp
&amp;gt; int.eff = 2
&amp;gt; temp.eff &amp;lt;- 0.85
&amp;gt; nitro.eff &amp;lt;- 0.5
&amp;gt; res = rnorm(n, 0, 1)
&amp;gt; coef &amp;lt;- c(int.eff, temp.eff, nitro.eff, int.eff)
&amp;gt; mm &amp;lt;- model.matrix(~temp * nitro)
&amp;gt; 
&amp;gt; y &amp;lt;- t(coef %*% t(mm)) + res
&amp;gt; data &amp;lt;- data.frame(y, x1 = temp, x2 = nitro, cx1 = scale(temp,
+     scale = F), cx2 = scale(nitro, scale = F))
&amp;gt; head(data)
         y        x1        x2         cx1         cx2
1 2.426468 0.2875775 0.8300510 -0.21098147 -0.08302110
2 4.927690 0.7883051 0.9634676  0.28974614  0.05039557
3 3.176118 0.4089769 0.8157946 -0.08958207 -0.09727750
4 6.166652 0.8830174 1.6608878  0.38445841  0.74781568
5 4.788890 0.9404673 1.2352762  0.44190829  0.32220415
6 2.541536 0.0455565 0.9267954 -0.45300249  0.01372335&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the components linear predictor (continuous predictors). We could model the relationship via either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;An additive model in which the effects of each predictor contribute in an additive way to the response - we do not allow for an interaction as we consider an interaction either not of great importance or likely to be absent.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A multiplicative model in which the effects of each predictor and their interaction contribute to the response - we allow for the impact of one predictor to vary across the range of the other predictor.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;centering-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Centering the data&lt;/h2&gt;
&lt;p&gt;When a linear model contains a covariate (continuous predictor variable) in addition to another predictor (continuous or categorical), it is nearly always advisable that the continuous predictor variables are centered prior to the analysis. Centering is a process by which the mean of a variable is subtracted from each of the values such that the scale of the variable is shifted so as to be centered around &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Hence the mean of the new centered variable will be &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, yet it will retain the same variance.&lt;/p&gt;
&lt;p&gt;There are multiple reasons for this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;It provides some clinical meaning to the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept. Recall that the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is equal to zero. If &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is centered, then the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept represents the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at the mid-point of the &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; range. The &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept of an uncentered &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; typically represents a unreal value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; (as an &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; is often beyond the reasonable range of values).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In multiplicative models (in which predictors and their interactions are included), main effects and interaction terms built from centered predictors will not be correlated to one another.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For more complex models, centering the covariates can increase the likelihood that the modelling engine converges (arrives at a numerically stable and reliable outcome).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note, centering will not effect the slope estimates. In &lt;code&gt;R&lt;/code&gt;, centering is easily achieved with the &lt;code&gt;scale&lt;/code&gt; function, which centers and scales (divides by standard deviation) the data. We only really need to center the data, so we provide the argument &lt;code&gt;scale=FALSE&lt;/code&gt;. Also note that the &lt;code&gt;scale&lt;/code&gt; function attaches the pre-centered mean (and standard deviation if scaling is performed) as attributes to the scaled data in order to facilitate back-scaling to the original scale. While these attributes are often convenient, they do cause issues for some of the Bayesian routines and so we will strip these attributes using the &lt;code&gt;as.numeric&lt;/code&gt; function. Instead, we will create separate scalar variables to store the pre-scaled means.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data &amp;lt;- within(data, {
+     cx1 &amp;lt;- as.numeric(scale(x1, scale = FALSE))
+     cx2 &amp;lt;- as.numeric(scale(x2, scale = FALSE))
+ })
&amp;gt; head(data)
         y        x1        x2         cx1         cx2
1 2.426468 0.2875775 0.8300510 -0.21098147 -0.08302110
2 4.927690 0.7883051 0.9634676  0.28974614  0.05039557
3 3.176118 0.4089769 0.8157946 -0.08958207 -0.09727750
4 6.166652 0.8830174 1.6608878  0.38445841  0.74781568
5 4.788890 0.9404673 1.2352762  0.44190829  0.32220415
6 2.541536 0.0455565 0.9267954 -0.45300249  0.01372335
&amp;gt; 
&amp;gt; mean.x1 = mean(data$x1)
&amp;gt; mean.x2 = mean(data$x2)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Assumptions&lt;/h1&gt;
&lt;p&gt;The assumptions of the model are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All of the observations are independent - this must be addressed at the design and collection stages.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (and thus the residuals) should be normally distributed. A boxplot of the entire variable is usually useful for diagnosing major issues with normality.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately). Scatterplots with linear smoothers can be useful for exploring the spread of observations around the trendline. The spread of observations around the trendline should not increase (or decrease) along its length.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The predictor variables should be uniformly or normally distributed. Again, boxplots can be useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The relationships between the linear predictors (right hand side of the regression formula) and the response variable should be linear. Scatterplots with smoothers can be useful for identifying possible non-linearity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;(Multi)collinearity&lt;/strong&gt;. The number of predictor variables must be less than the number of observations otherwise the linear model will be over-parameterized (more parameters to estimate than there are independent data from which estimates are calculated).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Multi)collinearity breaks the assumption that a predictor variable must not be correlated to the combination of other predictor variables (known collectively as the linear predictor). Multicollinearity has major detrimental effects on model fitting:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Instability of the estimated partial regression slopes (small changes in the data or variable inclusion can cause dramatic changes in parameter estimates).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Inflated standard errors and confidence intervals of model parameters, thereby increasing the type II error rate (reducing power) of parameter hypothesis tests.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Multicollinearity can be diagnosed with the following situatons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Investigate pairwise correlations between all the predictor variables either by a correlation matrix or a scatterplot matrix&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Calculate the &lt;strong&gt;tolerance&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\((1−r^2)\)&lt;/span&gt; of the relationship between a predictor variable and all the other predictor variables for each of the predictor variables. Tolerance is a measure of the degree of collinearity and values less than &lt;span class=&#34;math inline&#34;&gt;\(0.2\)&lt;/span&gt; should be considered and values less than &lt;span class=&#34;math inline&#34;&gt;\(0.1\)&lt;/span&gt; should be given serious attention. &lt;strong&gt;Variance inflation factor&lt;/strong&gt; (VIF) is the inverse of tolerance and thus values greater than &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;, or worse, &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; indicate collinearity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;PCA&lt;/strong&gt; (principle components analysis) eigenvalues (from a correlation matrix for all the predictor variables) close to zero indicate collinearity and component loadings may be useful in determining which predictor variables cause collinearity.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are several approaches to dealing with collinearity (however the first two of these are likely to result in biased parameter estimates):&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Remove the highly correlated predictor variable(s), starting with the least most clinically interesting variable(s)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;PCA (principle components analysis) regression - regress the response variable against the principal components resulting from a correlation matrix for all the predictor variables. Each of these principal components by definition are completely independent, but the resulting parameter estimates must be back-calculated in order to have any clinical meaning.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Apply a regression tree - regression trees recursively partitioning (subsetting) the data in accordance to individual variables that explain the greatest remaining variance. Since at each iteration, each predictor variable is effectively evaluated in isolation, (multi)collinearity is not an issue.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;Multiple linear regression models can include predictors (terms) that are incorporated additively (no interactions) or multiplicatively (with interactions). As such we will explore these separately for each modelling tool. The observed responses (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values are themselves determined by the linear predictor. In this case, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept (value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; when all of the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;’s are equal to zero) and the set of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;’s represent the rates of change in y for every unit change in each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; (the effect) holding each other &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; constant. Note that since we should always center all predictors (by subtracting the mean of each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; from the repective values of each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;), the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept represents the value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at the average value of each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying “uninformative” priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\mu_i, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 + \boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;. Priors are specified as: &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta \sim \text{Normal}(0,1000)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. We will explore Bayesian modelling of multiple linear regression using &lt;code&gt;JAGS&lt;/code&gt;. Remember that in this software normal distributions are specified in terms of precision &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mu[i],tau)
+   mu[i] &amp;lt;- beta0 + inprod(beta[],X[i,])
+   }
+   #Priors
+   beta0 ~ dnorm(0.01,1.0E-6)
+   for (j in 1:nX) {
+   beta[j] ~ dnorm(0.01,1.0E-6)
+   }
+   tau &amp;lt;- 1 / (sigma * sigma)
+   sigma~dunif(0,100)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;ttestModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;additive-model-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additive Model&lt;/h2&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X = model.matrix(~cx1 + cx2, data = data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = X[, -1], nX = ncol(X) -
+     1, n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags.add &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;ttestModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 4
   Total graph size: 614

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags.add)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]    2.830   0.442   1.964   2.538   2.830   3.125   3.694 1.001  7400
beta[2]    1.582   0.380   0.833   1.327   1.581   1.834   2.319 1.001 14000
beta0      3.799   0.100   3.603   3.733   3.797   3.865   3.997 1.001 15000
sigma      0.996   0.074   0.864   0.944   0.992   1.043   1.154 1.001 15000
deviance 281.420   2.961 277.779 279.260 280.727 282.888 288.827 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.4 and DIC = 285.8
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;multiplicative-model-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiplicative Model&lt;/h2&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X = model.matrix(~cx1 * cx2, data = data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = X[, -1], nX = ncol(X) - 1, n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags.mult &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;ttestModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 5
   Total graph size: 715

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags.mult)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]    2.800   0.451   1.914   2.500   2.801   3.104   3.680 1.001 15000
beta[2]    1.504   0.389   0.744   1.237   1.505   1.766   2.267 1.001 15000
beta[3]    1.451   1.210  -0.933   0.643   1.456   2.238   3.849 1.001 15000
beta0      3.715   0.122   3.475   3.633   3.715   3.797   3.957 1.001  6000
sigma      0.994   0.073   0.863   0.944   0.989   1.039   1.151 1.001 15000
deviance 280.964   3.307 276.617 278.541 280.281 282.649 289.157 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 5.5 and DIC = 286.4
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;. Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags.mult, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags.mult, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags.mult)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3609  3746         0.963     
 beta[2]  2        3811  3746         1.020     
 beta[3]  2        3811  3746         1.020     
 beta0    2        3770  3746         1.010     
 deviance 2        3729  3746         0.995     
 sigma    4        4989  3746         1.330     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3729  3746         0.995     
 beta[2]  2        3730  3746         0.996     
 beta[3]  2        3811  3746         1.020     
 beta0    2        3729  3746         0.995     
 deviance 2        3751  3746         1.000     
 sigma    4        5306  3746         1.420     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
            beta[1]       beta[2]      beta[3]        beta0      deviance
Lag 0   1.000000000  1.0000000000  1.000000000  1.000000000  1.000000e+00
Lag 1  -0.007495093 -0.0002601039 -0.004404658 -0.016267523  1.340676e-01
Lag 5   0.004013980 -0.0121560194  0.004193180  0.006361847  7.319664e-05
Lag 10 -0.009167511 -0.0004423631  0.007960201  0.005194172 -5.183038e-03
Lag 50  0.001459434  0.0077668977 -0.006551273 -0.003063066 -5.021565e-03
              sigma
Lag 0   1.000000000
Lag 1   0.262166680
Lag 5  -0.020700390
Lag 10 -0.006918124
Lag 50  0.001501713&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.&lt;/p&gt;
&lt;p&gt;There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Standardised residuals&lt;/strong&gt;. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Studentised residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the residuals. Note that &lt;strong&gt;externally studentised residuals&lt;/strong&gt; are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pearson residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%) back thereby allowing us to train the model on &lt;span class=&#34;math inline&#34;&gt;\(75\)&lt;/span&gt;% of the data and then see how well the model can predict the withheld &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.&lt;/p&gt;
&lt;p&gt;Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within &lt;code&gt;JAGS&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(ggplot2)
&amp;gt; library(dplyr)
&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;% dplyr:::select(beta0,
+     contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(tidyr)
&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;% dplyr:::select(beta0,
+     contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = data %&amp;gt;% cbind(fit, resid)
&amp;gt; newdata.melt = newdata %&amp;gt;% gather(key = Pred, value = Value, cx1:cx2)
&amp;gt; ggplot(newdata.melt) + geom_point(aes(y = resid, x = Value)) + facet_wrap(~Pred)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;% dplyr:::select(beta0, 
+   contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:4], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(beta0, contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~cx1 * cx2, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:4]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; ggplot() + geom_density(data = NULL, aes(x = as.vector(yRep),
+     fill = &amp;quot;Model&amp;quot;), alpha = 0.5) + geom_density(data = data,
+     aes(x = y, fill = &amp;quot;Obs&amp;quot;), alpha = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(data.r2jags.mult$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data.r2jags.mult$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags.add)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]    2.830   0.442   1.964   2.538   2.830   3.125   3.694 1.001  7400
beta[2]    1.582   0.380   0.833   1.327   1.581   1.834   2.319 1.001 14000
beta0      3.799   0.100   3.603   3.733   3.797   3.865   3.997 1.001 15000
sigma      0.996   0.074   0.864   0.944   0.992   1.043   1.154 1.001 15000
deviance 281.420   2.961 277.779 279.260 280.727 282.888 288.827 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.4 and DIC = 285.8
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags.add), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 5 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]     2.83     0.442     1.96       3.69
2 beta[2]     1.58     0.380     0.844      2.33
3 beta0       3.80     0.1000    3.60       3.99
4 deviance  281.       2.96    277.       287.  
5 sigma       0.996    0.0742    0.857      1.14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;When &lt;code&gt;cx2&lt;/code&gt; is held constant, a one unit increase in &lt;code&gt;cx1&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(2.83\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(2.83\)&lt;/span&gt; per unit increase in &lt;code&gt;cx1&lt;/code&gt; when standardised for &lt;code&gt;cx2&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When &lt;code&gt;cx1&lt;/code&gt; is held constant, a one unit increase in &lt;code&gt;cx2&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(1.58\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(1.58\)&lt;/span&gt; per unit increase in &lt;code&gt;cx2&lt;/code&gt; when standardised for &lt;code&gt;cx1&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note, as this is an additive model, the rates associated with &lt;code&gt;cx1&lt;/code&gt; are assumed to be constant throughtout the range of &lt;code&gt;cx2&lt;/code&gt; and vice versa. The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for each partial slope does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant effects of &lt;code&gt;cx1&lt;/code&gt; and &lt;code&gt;cx2&lt;/code&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags.add$BUGSoutput$sims.matrix[, &amp;quot;beta[1]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags.add$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])
[1] 0.0001333333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of essentially &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, we would conclude that there is almost no evidence that the slope was likely to be equal to zero, suggesting there is a relationship. Next, we look at the results from the multiplicative model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags.mult)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]    2.800   0.451   1.914   2.500   2.801   3.104   3.680 1.001 15000
beta[2]    1.504   0.389   0.744   1.237   1.505   1.766   2.267 1.001 15000
beta[3]    1.451   1.210  -0.933   0.643   1.456   2.238   3.849 1.001 15000
beta0      3.715   0.122   3.475   3.633   3.715   3.797   3.957 1.001  6000
sigma      0.994   0.073   0.863   0.944   0.989   1.039   1.151 1.001 15000
deviance 280.964   3.307 276.617 278.541 280.281 282.649 289.157 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 5.5 and DIC = 286.4
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags.mult), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 6 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]     2.80     0.451     1.91       3.67
2 beta[2]     1.50     0.389     0.746      2.27
3 beta[3]     1.45     1.21     -0.976      3.79
4 beta0       3.71     0.122     3.47       3.95
5 deviance  281.       3.31    276.       287.  
6 sigma       0.994    0.0729    0.856      1.14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;At the average level of &lt;code&gt;cx2 (=0)&lt;/code&gt;, a one unit increase in &lt;code&gt;cx1&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(2.80\)&lt;/span&gt; change in y. That is, y increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(2.80\)&lt;/span&gt; per unit increase in &lt;code&gt;cx1&lt;/code&gt; when standardised for &lt;code&gt;cx2&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;At the average level of &lt;code&gt;cx1 (=0)&lt;/code&gt;, a one unit increase in &lt;code&gt;cx2&lt;/code&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(1.50\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; increases at a rate of &lt;span class=&#34;math inline&#34;&gt;\(1.50\)&lt;/span&gt; per unit increase in &lt;code&gt;cx2&lt;/code&gt; when standardised for &lt;code&gt;cx1&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The degree to which the rate of change in response associated with a one unit change in &lt;code&gt;cx1&lt;/code&gt; changes over the range of &lt;code&gt;cx2&lt;/code&gt; (and vice versa) is &lt;span class=&#34;math inline&#34;&gt;\(1.45\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence intervals for the interaction partial slope does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant interaction between &lt;code&gt;cx1&lt;/code&gt; and &lt;code&gt;cx2&lt;/code&gt;. This suggests that the nature of the relationship between &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;code&gt;cx1&lt;/code&gt; depends on the level of &lt;code&gt;cx2&lt;/code&gt; (and vice versa). The estimates of the effect of &lt;code&gt;cx1&lt;/code&gt; are only appropriate when &lt;code&gt;cx2 = 0&lt;/code&gt; etc. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags.mult$BUGSoutput$sims.matrix[, &amp;quot;beta[1]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags.mult$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])
[1] 6.666667e-05
&amp;gt; mcmcpvalue(data.r2jags.mult$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])
[1] 0.2236&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of essentially &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, we would conclude that there is almost no evidence that the slope was likely to be equal to zero, suggesting there is a relationship.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;p&gt;With appropriate use of model matrices and data wrangling, it is possible to produce a single prediction data set along with &lt;code&gt;ggplot&lt;/code&gt; syntax to produce a multi-panel figure. First we look at the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags.add$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = rbind(data.frame(cx1 = seq(min(data$cx1, na.rm = TRUE), max(data$cx1,
+     na.rm = TRUE), len = 100), cx2 = 0, Pred = 1), data.frame(cx1 = 0,
+     cx2 = seq(min(data$cx2, na.rm = TRUE), max(data$cx2, na.rm = TRUE),
+         len = 100), Pred = 2))
&amp;gt; Xmat = model.matrix(~cx1 + cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)) %&amp;gt;%
+     mutate(x = dplyr:::recode(Pred, x1, x2))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X&amp;quot;) + theme_classic() + facet_wrap(~Pred)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We cannot simply add the raw data to this figure. The reason for this is that the trends represent the effect of one predictor holding the other variable constant. Therefore, the observations we represent on the figure must likewise be standardised. We can achieve this by adding the partial residuals to the figure. Partial residuals are the fitted values plus the residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = rbind(data.frame(cx1 = data$cx1, cx2 = 0, Pred = 1), data.frame(cx1 = 0,
+     cx2 = data$cx2, Pred = 2))
&amp;gt; fMat = rMat = model.matrix(~cx1 + cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2) %&amp;gt;% mutate(x = dplyr:::recode(Pred, x1,
+     x2))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = rdata, aes(y = partial.resid),
+     color = &amp;quot;gray&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low, ymax = conf.high),
+     fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) + theme_classic() +
+     facet_wrap(~Pred, strip.position = &amp;quot;bottom&amp;quot;, labeller = label_bquote(&amp;quot;x&amp;quot; *
+         .(Pred))) + theme(axis.title.x = element_blank(), strip.background = element_blank(),
+     strip.placement = &amp;quot;outside&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;However, this method (whist partially elegant) does become overly opaque if we need more extensive axes labels since the x-axes labels are actually strip labels (which must largely be defined outside of the &lt;code&gt;ggplot&lt;/code&gt; structure). The alternative is to simply produce each partial plot separately before arranging them together in the one figure using the package &lt;code&gt;gridExtra&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(gridExtra)
&amp;gt; mcmc = data.r2jags.add$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = data.frame(cx1 = seq(min(data$cx1, na.rm = TRUE), max(data$cx1,
+     na.rm = TRUE), len = 100), cx2 = 0)
&amp;gt; Xmat = model.matrix(~cx1 + cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; ## Now the partial residuals
&amp;gt; fdata = rdata = data.frame(cx1 = data$cx1, cx2 = 0)
&amp;gt; fMat = rMat = model.matrix(~cx1 + cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2)
&amp;gt; g1 = ggplot(newdata, aes(y = estimate, x = x1)) + geom_point(data = rdata,
+     aes(y = partial.resid), color = &amp;quot;grey&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X1&amp;quot;) + theme_classic()
&amp;gt; 
&amp;gt; newdata = data.frame(cx2 = seq(min(data$cx2, na.rm = TRUE), max(data$cx2,
+     na.rm = TRUE), len = 100), cx1 = 0)
&amp;gt; Xmat = model.matrix(~cx1 + cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; ## Now the partial residuals
&amp;gt; fdata = rdata = data.frame(cx1 = 0, cx2 = data$cx2)
&amp;gt; fMat = rMat = model.matrix(~cx1 + cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2)
&amp;gt; g2 = ggplot(newdata, aes(y = estimate, x = x2)) + geom_point(data = rdata,
+     aes(y = partial.resid), color = &amp;quot;grey&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X2&amp;quot;) + theme_classic()
&amp;gt; 
&amp;gt; grid.arrange(g1, g2, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_post3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the multiplicative model, we could elect to split the trends up so as to explore the effects of one predictor at several set levels of another predictor. In this example, we will explore the effects of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; is equal to its mean in the original data as well as one and two standard deviations below and above this mean.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(fields)
&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = expand.grid(cx1 = seq(min(data$cx1, na.rm = TRUE), max(data$cx1,
+     na.rm = TRUE), len = 100), cx2 = mean(data$cx2) + sd(data$cx2) %*%
+     -2:2)
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% mutate(x1 = cx1 + mean.x1, x2 = cx2 + mean.x2) %&amp;gt;%
+     cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)) %&amp;gt;%
+     mutate(x2 = factor(x2, labels = paste(&amp;quot;X2:~&amp;quot;, c(-2, -1, 0, 1, 2), &amp;quot;*sigma&amp;quot;)))
&amp;gt; ## Partial residuals
&amp;gt; fdata = rdata = expand.grid(cx1 = data$cx1, cx2 = mean(data$cx2) + sd(data$cx2) *
+     -2:2)
&amp;gt; fMat = rMat = model.matrix(~cx1 * cx2, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit) %&amp;gt;% mutate(x1 = cx1 +
+     mean.x1, x2 = cx2 + mean.x2)
&amp;gt; ## Partition the partial residuals such that each x1 trend only includes
&amp;gt; ## x2 data that is within that range in the observed data
&amp;gt; findNearest = function(x, y) {
+     ff = fields:::rdist(x, y)
+     apply(ff, 1, function(x) which(x == min(x)))
+ }
&amp;gt; fn = findNearest(x = data[, c(&amp;quot;x1&amp;quot;, &amp;quot;x2&amp;quot;)], y = rdata[, c(&amp;quot;x1&amp;quot;, &amp;quot;x2&amp;quot;)])
&amp;gt; rdata = rdata[fn, ] %&amp;gt;% mutate(x2 = factor(x2, labels = paste(&amp;quot;X2:~&amp;quot;, c(-2,
+     -1, 0, 1, 2), &amp;quot;*sigma&amp;quot;)))
&amp;gt; ggplot(newdata, aes(y = estimate, x = x1)) + geom_line() + geom_blank(aes(y = 9)) +
+     geom_point(data = rdata, aes(y = partial.resid), color = &amp;quot;grey&amp;quot;) +
+     geom_ribbon(aes(ymin = conf.low, ymax = conf.high), fill = &amp;quot;blue&amp;quot;,
+         alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_continuous(&amp;quot;X1&amp;quot;) +
+     facet_wrap(~x2, labeller = label_parsed, nrow = 1, scales = &amp;quot;free_y&amp;quot;) +
+     theme_classic() + theme(strip.background = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/mcmc_post4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Alternatively, we could explore the interaction by plotting a two dimensional surface as a heat map.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;effect-sizes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Effect sizes&lt;/h1&gt;
&lt;p&gt;In addition to deriving the distribution means for the slope parameter, we could make use of the Bayesian framework to derive the distribution of the effect size. In so doing, effect size could be considered as either the rate of change or alternatively, the difference between pairs of values along the predictor gradient. For the latter case, there are multiple ways of calculating an effect size, but the two most common are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Raw effect size&lt;/em&gt;. The difference between two groups (as already calculated)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Cohen’s D&lt;/em&gt;. The effect size standardized by division with the pooled standard deviation: &lt;span class=&#34;math inline&#34;&gt;\(D=\frac{(\mu_A-\mu_B)}{\sigma}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Percentage change&lt;/em&gt;. Express the effect size as a percent of one of the pairs. That is, whether you expressing a percentage increase or a percentage decline depends on which of the pairs of values are considered a reference value. Care must be exercised to ensure no division by zeros occur.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For simple linear models, effect size based on a rate is essentially the same as above except that it is expressed per unit of the predictor. Of course in many instances, one unit change in the predictor represents too subtle a shift in the underlying gradient to likely yield any clinically meaningful or appreciable change in response.&lt;/p&gt;
&lt;p&gt;Probability that a change in &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; is associated with greater than a &lt;span class=&#34;math inline&#34;&gt;\(50\)&lt;/span&gt;% increase in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at various levels of &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;. Clearly, in order to explore this inference, we must first express the change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; as a percentage. This in turn requires us to calculate start and end points from which to calculate the magnitude of the effect (amount of increase in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) as well as the percentage decline. Hence, we start by predicting the distribution of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at the lowest and highest values of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; at five levels of &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; (representing two standard deviations below the &lt;code&gt;cx2&lt;/code&gt; mean, one standard deviation below the &lt;code&gt;cx2&lt;/code&gt; mean, the &lt;code&gt;cx2&lt;/code&gt; mean, one standard deviation above the &lt;code&gt;cx2&lt;/code&gt; mean and &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; standard deviations above the &lt;code&gt;cx2&lt;/code&gt; mean. For this exercise we will only use the multiplicative model. Needless to say, the process would be very similar for the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags.mult$BUGSoutput$sims.matrix
&amp;gt; newdata = expand.grid(cx1 = c(min(data$cx1), max(data$cx1)), cx2 = (-2:2) *
+     sd(data$cx2))
&amp;gt; Xmat = model.matrix(~cx1 * cx2, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; s1 = seq(1, 9, b = 2)
&amp;gt; s2 = seq(2, 10, b = 2)
&amp;gt; ## Raw effect size
&amp;gt; (RES = tidyMCMC(as.mcmc(fit[, s2] - fit[, s1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         1.82     0.938  -0.0378      3.64
2 4         2.30     0.616   1.13        3.54
3 6         2.78     0.448   1.90        3.65
4 8         3.26     0.586   2.12        4.42
5 10        3.74     0.899   2.02        5.55
&amp;gt; ## Cohen&amp;#39;s D
&amp;gt; cohenD = (fit[, s2] - fit[, s1])/sqrt(mcmc[, &amp;quot;sigma&amp;quot;])
&amp;gt; (cohenDES = tidyMCMC(as.mcmc(cohenD), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         1.83     0.940   0.0489      3.74
2 4         2.31     0.622   1.11        3.57
3 6         2.80     0.461   1.89        3.68
4 8         3.28     0.599   2.10        4.45
5 10        3.76     0.910   1.98        5.54
&amp;gt; # Percentage change (relative to Group A)
&amp;gt; ESp = 100 * (fit[, s2] - fit[, s1])/fit[, s1]
&amp;gt; (PES = tidyMCMC(as.mcmc(ESp), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         124.     142.     -19.5      318.
2 4         117.      45.2     33.1      205.
3 6         123.      32.9     62.1      187.
4 8         135.      50.0     48.0      230.
5 10        150.      89.1     29.4      308.
&amp;gt; # Probability that the effect is greater than 50% (an increase of &amp;gt;50%)
&amp;gt; (p50 = apply(ESp, 2, function(x) sum(x &amp;gt; 50)/length(x)))
        2         4         6         8        10 
0.7996667 0.9576667 0.9978667 0.9925333 0.9723333 
&amp;gt; ## fractional change
&amp;gt; (FES = tidyMCMC(as.mcmc(fit[, s2]/fit[, s1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 5 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2         2.24     1.42     0.805      4.18
2 4         2.17     0.452    1.33       3.05
3 6         2.23     0.329    1.62       2.87
4 8         2.35     0.500    1.48       3.30
5 10        2.50     0.891    1.29       4.08&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On average, when &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; is equal to its mean, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by &lt;span class=&#34;math inline&#34;&gt;\(2.79\)&lt;/span&gt; over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the increase is between &lt;span class=&#34;math inline&#34;&gt;\(1.91\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(3.66\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Cohen’s D associated change over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(2.80\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by &lt;span class=&#34;math inline&#34;&gt;\(124\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; (at average &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;). We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the increase is between &lt;span class=&#34;math inline&#34;&gt;\(65\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(190\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The probability that &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by more than &lt;span class=&#34;math inline&#34;&gt;\(50\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; (average &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;) is &lt;span class=&#34;math inline&#34;&gt;\(0.998\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases by a factor of &lt;span class=&#34;math inline&#34;&gt;\(2.24\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; (average &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;). We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between a factor of &lt;span class=&#34;math inline&#34;&gt;\(1.65\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(2.90\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 4 x 5
  term     estimate std.error   conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x1       0.798    0.129  0.544          1.05 
2 sd.x2       0.501    0.130  0.249          0.756
3 sd.x1x2     0.136    0.0877 0.00000784     0.296
4 sd.resid    0.981    0.0128 0.965          1.01 
# A tibble: 4 x 5
  term     estimate std.error  conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x1       33.1       4.97 23.4           42.7
2 sd.x2       20.8       5.14 10.4           30.3
3 sd.x1x2      5.27      3.46  0.000322      11.7
4 sd.resid    40.5       2.15 36.7           44.9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/multiple-linear-regression-jags/2020-02-01-multiple-linear-regression-jags_files/figure-html/effects_modelv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(59\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt; and their interaction.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags.mult$BUGSoutput$sims.matrix
&amp;gt; Xmat = model.matrix(~cx1 * cx2, data)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.605    0.0400    0.526     0.676
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ cx1 * cx2, data))

Call:
lm(formula = y ~ cx1 * cx2, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.8173 -0.7167 -0.1092  0.5890  3.3861 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)   3.7152     0.1199  30.987  &amp;lt; 2e-16 ***
cx1           2.8072     0.4390   6.394 5.84e-09 ***
cx2           1.4988     0.3810   3.934 0.000158 ***
cx1:cx2       1.4464     1.1934   1.212 0.228476    
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 0.9804 on 96 degrees of freedom
Multiple R-squared:  0.6115,    Adjusted R-squared:  0.5994 
F-statistic: 50.37 on 3 and 96 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-model-selection&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bayesian model selection&lt;/h1&gt;
&lt;p&gt;A statistical model is by definition a low-dimensional (over simplification) representation of what is really likely to be a very complex system. As a result, no model is right. Some models however can provide useful insights into some of the processes operating on the system. Frequentist statistics have various methods (model selection, dredging, lasso, cross validation) for selecting parsimonious models. These are models that provide a good comprimise between minimizing unexplained patterns and minimizing model complexity. The basic premise is that since no model can hope to capture the full complexity of a system with all its subtleties, only the very major patterns can be estimated. Overly complex models are likely to be representing artificial complexity present only in the specific observed data (not the general population). The Bayesian approach is to apply priors to the non-variance parameters such that parameters close to zero are further shrunk towards zero whilst priors on parameters further away from zero are less effected. The most popular form of prior for sparsity is the &lt;em&gt;horseshoe prior&lt;/em&gt;, so called because the shape of a component of this prior resembles a horseshoe (with most of the mass either close to &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; or close to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Rather than apply weakly informative Gaussian priors on parameters as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\sigma^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the horseshoe prior is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2\lambda_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tau \sim \text{Cauchy}(0,1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j \sim \text{Cauchy}(0,1)\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(j=1,\ldots,D\)&lt;/span&gt;. Using this prior, &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is the number of (non-intercept or variance) parameters, &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; represents the global scale that weights or shrinks all parameters towards zero and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j\)&lt;/span&gt; are thick tailed local scales that allow some of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; parameters to escape shrinkage. More recently, &lt;span class=&#34;citation&#34;&gt;Piironen, Vehtari, and others (2017)&lt;/span&gt; have argued that whilst the above horseshoe priors do guarantee that strong effects (parameters) will not be over-shrunk, there is the potential for weekly identified effects (those based on relatively little data) to be misrepresented in the posteriors. As an alternative they advocated the use of regularised horseshoe priors in which the amount of shrinkage applied to the largest effects can be controlled. The prior is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2 \tilde{\lambda}_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tilde{\lambda}_j^2 = \frac{c^2\lambda^2_j}{c^2+\tau^2 \lambda^2_j}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is (slab width, actually variance) is a constant. For small effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;lt; c^2\)&lt;/span&gt;) the prior approaches a regular prior. However, for large effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;gt; c^2\)&lt;/span&gt;) the prior approaches &lt;span class=&#34;math inline&#34;&gt;\(N(0,c^2)\)&lt;/span&gt;. Finally, they recommend applying a inverse-gamma prior on &lt;span class=&#34;math inline&#34;&gt;\(c^2\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ c^2 \sim \text{Inv-Gamma}(\alpha,\beta),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\alpha=v/2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta=vs^2/2\)&lt;/span&gt;, which translates to a &lt;span class=&#34;math inline&#34;&gt;\(\text{Student-t}_ν(0, s^2)\)&lt;/span&gt; slab for the coefficients far from zero and is typically a good default choice for a weakly informative prior.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-piironen2017sparsity&#34;&gt;
&lt;p&gt;Piironen, Juho, Aki Vehtari, and others. 2017. “Sparsity Information and Regularization in the Horseshoe and Other Shrinkage Priors.” &lt;em&gt;Electronic Journal of Statistics&lt;/em&gt; 11 (2): 5018–51.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simple Linear Regression - JAGS</title>
      <link>/jags/simple-linear-regression-jags/simple-linear-regression-jags/</link>
      <pubDate>Sun, 02 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/simple-linear-regression-jags/simple-linear-regression-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Many clinicians get a little twitchy and nervous around mathematical and statistical formulae and nomenclature. Whilst it is possible to perform basic statistics without too much regard for the actual equation (model) being employed, as the complexity of the analysis increases, the need to understand the underlying model becomes increasingly important. Moreover, model specification in &lt;code&gt;BUGS/JAGS/STAN&lt;/code&gt; (the language used to program Bayesian modelling) aligns very closely to the underlying formulae. Hence a good understanding of the underlying model is vital to be able to create a sensible Bayesian model. Consequently, I will always present the linear model formulae along with the analysis.&lt;/p&gt;
&lt;p&gt;To introduce the philosophical and mathematical differences between classical (frequentist) and Bayesian statistics, based on previous works, we present a provocative yet compelling trend analysis of two hypothetical populations (A vs B). The temporal trend of population A shows very little variability from a very subtle linear decline (&lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{slope}=-0.10\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{p-value}=0.048\)&lt;/span&gt;). By contrast, the B population appears to decline more dramatically, yet has substantially more variability (&lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{slope}=-10.23\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{p-value}=0.058\)&lt;/span&gt;). From a traditional frequentist perspective, we would conclude that there is a “significant” relationship in Population A (&lt;span class=&#34;math inline&#34;&gt;\(p&amp;lt;0.05\)&lt;/span&gt;), yet not in Population B (&lt;span class=&#34;math inline&#34;&gt;\(p&amp;gt;0.05\)&lt;/span&gt;). However, if we consider a third population C which is exactly the same as populstion B but with a higher number of observations, then we may end up with a completely different conclusion compared with that based on population B (&lt;span class=&#34;math inline&#34;&gt;\(n=100\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{slope}=-10.47\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\text{p-value}&amp;lt;0.001\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;The above illustrates a couple of things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;statistical significance does not necessarily translate into clinical importance. Indeed, population B is declining at nearly &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; times the rate of population A. That sounds rather important, yet on the basis of the hypothesis test, we would dismiss the decline in population B.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;that a p-value is just the probability of detecting an effect or relationship - what is the probability that the sample size is large enough to pick up a difference.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let us now look at it from a Bayesian perspective, with a focus on population A and B. We would conclude that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the mean (plus or minus CI) slopes for Population A and B are &lt;span class=&#34;math inline&#34;&gt;\(-0.1 (-0.21,0)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(-10.08 (-20.32,0.57)\)&lt;/span&gt; respectively&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the Bayesian approach allows us to query the posterior distribution is many other ways in order to ask sensible clinical questions. For example, we might consider that a rate of change of &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% or greater represents an important biological impact. For population A and B, the probability that the rate is &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% or greater is &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(0.85\)&lt;/span&gt; respectively.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear regression&lt;/h2&gt;
&lt;p&gt;Simple linear regression is a linear modelling process that models a continuous response against a single continuous predictor. The linear model is expressed as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_i + \epsilon_i, \;\;\; \epsilon_i \sim \text{Normal}(0,\sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; is the response variable for each of the &lt;span class=&#34;math inline&#34;&gt;\(i=1\ldots,n\)&lt;/span&gt; observations, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the intercept (value when &lt;span class=&#34;math inline&#34;&gt;\(x=0\)&lt;/span&gt;), &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is the slope (rate of change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; per unit change in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;), &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; is the predictor variable, &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_i\)&lt;/span&gt; is the residual value (difference between the observed value and the value expected by the model). The parameters of the trendline &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta=(\beta_0,\beta_1)\)&lt;/span&gt; are determined by &lt;em&gt;Ordinary Least Squares&lt;/em&gt; (OLS) in which the sum of the squared residuals is minimized. A non-zero population slope is indicative of a relationship.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Lets say we had set up an experiment in which we applied a continuous treatment (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) ranging in magnitude from &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(16\)&lt;/span&gt; to a total of &lt;span class=&#34;math inline&#34;&gt;\(16\)&lt;/span&gt; sampling units (&lt;span class=&#34;math inline&#34;&gt;\(n=16\)&lt;/span&gt;) and then measured a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) from each unit. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n &amp;lt;- 16
&amp;gt; a &amp;lt;- 40  #intercept
&amp;gt; b &amp;lt;- -1.5  #slope
&amp;gt; sigma2 &amp;lt;- 25  #residual variance (sd=5)
&amp;gt; x &amp;lt;- 1:n  #values of the year covariate
&amp;gt; eps &amp;lt;- rnorm(n, mean = 0, sd = sqrt(sigma2))  #residuals
&amp;gt; y &amp;lt;- a + b * x + eps  #response variable
&amp;gt; # OR
&amp;gt; y &amp;lt;- (model.matrix(~x) %*% c(a, b)) + eps
&amp;gt; data &amp;lt;- data.frame(y, x)  #dataset
&amp;gt; head(data)  #print out the first six rows of the data set
         y x
1 35.69762 1
2 35.84911 2
3 43.29354 3
4 34.35254 4
5 33.14644 5
6 39.57532 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the linear predictor (single continuous predictor).&lt;/p&gt;
&lt;div id=&#34;centering-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Centering the data&lt;/h2&gt;
&lt;p&gt;When a linear model contains a covariate (continuous predictor variable) in addition to another predictor (continuous or categorical), it is nearly always advisable that the continuous predictor variables are centered prior to the analysis. Centering is a process by which the mean of a variable is subtracted from each of the values such that the scale of the variable is shifted so as to be centered around &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Hence the mean of the new centered variable will be &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, yet it will retain the same variance.&lt;/p&gt;
&lt;p&gt;There are multiple reasons for this:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;It provides some clinical meaning to the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept. Recall that the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is equal to zero. If &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is centered, then the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept represents the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at the mid-point of the &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; range. The &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept of an uncentered &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; typically represents a unreal value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; (as an &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; is often beyond the reasonable range of values).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In multiplicative models (in which predictors and their interactions are included), main effects and interaction terms built from centered predictors will not be correlated to one another.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For more complex models, centering the covariates can increase the likelihood that the modelling engine converges (arrives at a numerically stable and reliable outcome).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note, centering will not effect the slope estimates. In &lt;code&gt;R&lt;/code&gt;, centering is easily achieved with the &lt;code&gt;scale&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data &amp;lt;- within(data, {
+     cx &amp;lt;- as.numeric(scale(x, scale = FALSE))
+ })
&amp;gt; head(data)
         y x   cx
1 35.69762 1 -7.5
2 35.84911 2 -6.5
3 43.29354 3 -5.5
4 34.35254 4 -4.5
5 33.14644 5 -3.5
6 39.57532 6 -2.5&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Exploratory data analysis&lt;/h1&gt;
&lt;div id=&#34;normality&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Normality&lt;/h2&gt;
&lt;p&gt;Estimation and inference testing in linear regression assumes that the response is normally distributed in each of the populations. In this case, the populations are all possible measurements that could be collected at each level of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; - hence there are &lt;span class=&#34;math inline&#34;&gt;\(16\)&lt;/span&gt; populations. Typically however, we only collect a single observation from each population (as is also the case here). How then can be evaluate whether each of these populations are likely to have been normal? For a given response, the population distributions should follow much the same distribution shapes. Therefore provided the single samples from each population are unbiased representations of those populations, a boxplot of all observations should reflect the population distributions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;homogeneity-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Homogeneity of variance&lt;/h2&gt;
&lt;p&gt;Simple linear regression also assumes that each of the populations are equally varied. Actually, it is prospect of a relationship between the mean and variance of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-values across x-values that is of the greatest concern. Strictly the assumption is that the distribution of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; values at each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; value are equally varied and that there is no relationship between mean and variance. However, as we only have a single &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-value for each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;-value, it is difficult to directly determine whether the assumption of &lt;em&gt;homogeneity of variance&lt;/em&gt; is likely to have been violated (mean of one value is meaningless and variability can’t be assessed from a single value). If we then plot the residuals (difference between observed values and those predicted by the trendline) against the predict values and observe a definite presence of a pattern, then it is indicative of issues with the assumption of homogeneity of variance.&lt;/p&gt;
&lt;p&gt;Hence looking at the spread of values around a trendline on a scatterplot of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; against &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is a useful way of identifying gross violations of homogeneity of variance. Residual plots provide an even better diagnostic. The presence of a &lt;em&gt;wedge shape&lt;/em&gt; is indicative that the population mean and variance are related.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linearity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linearity&lt;/h2&gt;
&lt;p&gt;Linear regression fits a straight (linear) line through the data. Therefore, prior to fitting such a model, it is necessary to establish whether this really is the most sensible way of describing the relationship. That is, does the relationship appear to be linearly related or could some other non-linear function describe the relationship better. Scatterplots and residual plots are useful diagnostics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model assumptions&lt;/h2&gt;
&lt;p&gt;The typical assumptions which need to be checked when fitting a standard linear regression model are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All of the observations are independent - this must be addressed at the design and collection stages&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (and thus the residuals) should be normally distributed&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The relationship between the linear predictor (right hand side of the regression formula) and the link function should be linear. A scatterplot with smoother can be useful for identifying possible non-linearity.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So lets explore normality, homogeneity of variances and linearity by constructing a scatterplot of the relationship between the response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) and the predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;). We will also include a range of smoothers (linear and lowess) and marginal boxplots on the scatterplot to assist in exploring linearity and normality respectively.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # scatterplot
&amp;gt; library(car)
&amp;gt; scatterplot(y ~ x, data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/scatter-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;There is no evidence that the response variable is non-normal. The spread of values around the trendline seems fairly even (hence it there is no evidence of non-homogeneity). The data seems well represented by the linear trendline. Furthermore, the lowess smoother does not appear to have a consistent shift trajectory. Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Consider a non-linear linear predictor (such as a polynomial, spline or other non-linear function)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Transform the scale of the response variables (e.g. to address normality)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The purpose of fitting a model in this case is to explore the relationship between &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Since both &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; are continuous, a simple regression line is a good start. The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0+\beta_1\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept (value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is equal to zero) and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; represents the rate of change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; for every unit change in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; (the effect).&lt;/p&gt;
&lt;p&gt;Note that in this form, the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept is of little interest. Indeed for many applications, a value of x would be outside the domain of the collected data, outside the logical bounds of the actual variable or else outside the domain of interest. If however, we center the predictor variable (by subtracting the mean of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; from each &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, then the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-intercept represents the value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at the average value of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. This certainly has more meaning. Note that centering the predictor does not effect the estimate of slope. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying “uninformative” priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important.&lt;/p&gt;
&lt;p&gt;For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (1000) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=25\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\mu_i, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0+\beta_1x_i\)&lt;/span&gt;. Priors are specified as: &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta \sim \text{Normal}(0,1000)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,25)\)&lt;/span&gt;. We will explore Bayesian modelling of simple linear regression using &lt;code&gt;JAGS&lt;/code&gt;. Remember that in this software normal distributions are specified in terms of precision &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;. In addition, we will derive the following quantities.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The percentage decline &lt;span class=&#34;math inline&#34;&gt;\(\left(100 \times \frac{(\text{max}(x) - \text{min}(x))\beta_1 + \text{min}(y)}{\text{min}(y)} \right)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The probability that &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; decline by more than &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The finite-population variance components&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mu[i],tau)
+   mu[i] &amp;lt;- beta0+beta1*x[i]
+   y.err[i] &amp;lt;- y[i] - mu[i]
+   }
+   
+   #Priors
+   beta0 ~ dnorm(0.01,1.0E-6)
+   beta1 ~ dnorm(0,1.0E-6)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   sigma~dunif(0,100)
+   
+   #Other Derived parameters 
+   p.decline &amp;lt;- 1-step(beta1)
+   ymin&amp;lt;-beta0+beta1*min(x)                  
+   xrange &amp;lt;- max(x) - min(x)       
+   decline &amp;lt;- 100*((xrange*beta1)+ymin)/ymin 
+   p.decline25 &amp;lt;- step(decline-25)
+   
+   #finite-population variance components
+   sd.x &amp;lt;- abs(beta1)*sd(x[])
+   sd.resid &amp;lt;- sd(y.err)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;ttestModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.list &amp;lt;- with(data, list(y = y, x = x, n = nrow(data)))
&amp;gt; data.list
$y
 [1] 35.69762 35.84911 43.29354 34.35254 33.14644 39.57532 31.80458 21.67469
 [9] 23.06574 22.77169 29.62041 23.79907 22.50386 19.55341 14.72079 24.93457

$x
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16

$n
[1] 16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the initial values for the chain. Reasonable starting points can be gleaned from the data themselves.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; inits &amp;lt;- rep(list(list(beta0 = mean(data$y), beta1 = diff(tapply(data$y,
+     data$x, mean)), sigma = sd(data$y))), 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;, &amp;quot;sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When using the &lt;code&gt;jags&lt;/code&gt; function (&lt;code&gt;R2jags&lt;/code&gt; package), it is not necessary to provide initial values. However, if they are to be supplied, the inital values must be provided as a list of the same length as the number of chains. Then print the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params, model.file = &amp;quot;ttestModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter, n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 16
   Unobserved stochastic nodes: 3
   Total graph size: 109

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%   97.5%  Rhat n.eff
beta0     40.332   2.779 34.814 38.547 40.341 42.142  45.768 1.001 15000
beta1     -1.390   0.283 -1.957 -1.571 -1.390 -1.209  -0.822 1.001 15000
sigma      5.187   1.125  3.549  4.399  5.009  5.772   7.848 1.001 14000
deviance  96.319   2.919 93.005 94.208 95.578 97.595 103.875 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.3 and DIC = 100.6
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    3        4115  3746         1.10      
 beta1    2        3855  3746         1.03      
 deviance 3        4026  3746         1.07      
 sigma    4        4907  3746         1.31      


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta0    2        3938  3746         1.05      
 beta1    2        3770  3746         1.01      
 deviance 2        3811  3746         1.02      
 sigma    4        4853  3746         1.30      &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
              beta0         beta1     deviance       sigma
Lag 0   1.000000000  1.0000000000  1.000000000  1.00000000
Lag 1  -0.007010696  0.0009369893  0.397147648  0.46491253
Lag 5   0.002086800  0.0011849092  0.049133264  0.05413994
Lag 10  0.005430778  0.0054667236  0.008226042  0.01218053
Lag 50 -0.011848951 -0.0054465800 -0.014357351 -0.01271746&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model.&lt;/p&gt;
&lt;p&gt;Although residuals can be computed directly within &lt;code&gt;R2jags&lt;/code&gt;, we can calculate them manually from the posteriors to be consistent across other approaches.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(ggplot2)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = data$x))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentized residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentized residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; ggplot() + geom_density(data = NULL, aes(x = as.vector(yRep),
+     fill = &amp;quot;Model&amp;quot;), alpha = 0.5) + geom_density(data = data,
+     aes(x = y, fill = &amp;quot;Obs&amp;quot;), alpha = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect   2.5%    25%    50%    75%   97.5%  Rhat n.eff
beta0     40.332   2.779 34.814 38.547 40.341 42.142  45.768 1.001 15000
beta1     -1.390   0.283 -1.957 -1.571 -1.390 -1.209  -0.822 1.001 15000
sigma      5.187   1.125  3.549  4.399  5.009  5.772   7.848 1.001 14000
deviance  96.319   2.919 93.005 94.208 95.578 97.595 103.875 1.001 15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.3 and DIC = 100.6
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta0       40.3      2.78     34.9     45.8  
2 beta1       -1.39     0.283    -1.94    -0.812
3 deviance    96.3      2.92     92.8    102.   
4 sigma        5.19     1.13      3.31     7.38 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A one unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is associated with a &lt;span class=&#34;math inline&#34;&gt;\(-1.39\)&lt;/span&gt; change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. That is, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; declines at a rate of &lt;span class=&#34;math inline&#34;&gt;\(-1.39\)&lt;/span&gt; per unit increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the slope does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }
&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta1&amp;quot;)])
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of essentially &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, we would conclude that there is almost no evidence that the slope was likely to be equal to zero, suggesting there is a relationship.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group. We do this by loading functions in the package &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = data.frame(x = seq(min(data$x, na.rm = TRUE), max(data$x, na.rm = TRUE),
+     len = 1000))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you wanted to represent sample data on the figure in such a simple example (single predictor) we could simply over- (or under-) lay the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = data, aes(y = y,
+     x = x), color = &amp;quot;gray&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low,
+     ymax = conf.high), fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) +
+     scale_x_continuous(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A more general solution would be to add the partial residuals to the figure. Partial residuals are the fitted values plus the residuals. In this simple case, that equates to exactly the same as the raw observations since &lt;span class=&#34;math inline&#34;&gt;\(\text{resid}=\text{obs}−\text{fitted}\)&lt;/span&gt; and the fitted values depend only on the single predictor we are interested in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = rdata, aes(y = partial.resid),
+     color = &amp;quot;gray&amp;quot;) + geom_line() + geom_ribbon(aes(ymin = conf.low, ymax = conf.high),
+     fill = &amp;quot;blue&amp;quot;, alpha = 0.3) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_continuous(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/mcmc_post3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;effect-sizes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Effect sizes&lt;/h1&gt;
&lt;p&gt;Lets explore a range of effect sizes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Raw effect size&lt;/em&gt; between the largest and smallest &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Cohen’s D&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Percentage change&lt;/em&gt; between the largest and smallest &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Fractional change&lt;/em&gt; between the largest and smallest &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Probability&lt;/em&gt; that a change in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is associated with greater than a &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;% decline in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Clearly, in order to explore this inference, we must first express the change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; as a percentage. This in turn requires us to calculate start and end points from which to calculate the magnitude of the effect (amount of decline in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) as well as the percentage decline. Hence, we start by predicting the distribution of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at the lowest and highest values of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; newdata = data.frame(x = c(min(data$x, na.rm = TRUE), max(data$x, na.rm = TRUE)))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## Raw effect size
&amp;gt; (RES = tidyMCMC(as.mcmc(fit[, 2] - fit[, 1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     -20.9      4.24    -29.2     -12.2
&amp;gt; ## Cohen&amp;#39;s D
&amp;gt; cohenD = (fit[, 2] - fit[, 1])/mcmc[, &amp;quot;sigma&amp;quot;]
&amp;gt; (cohenDES = tidyMCMC(as.mcmc(cohenD), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     -4.19      1.14    -6.40     -1.94
&amp;gt; # Percentage change (relative to Group A)
&amp;gt; ESp = 100 * (fit[, 2] - fit[, 1])/fit[, 1]
&amp;gt; (PES = tidyMCMC(as.mcmc(ESp), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     -53.2      8.25    -69.4     -36.5
&amp;gt; # Probability that the effect is greater than 25% (a decline of &amp;gt;25%)
&amp;gt; sum(-1 * ESp &amp;gt; 25)/length(ESp)
[1] 0.9964667
&amp;gt; ## fractional change
&amp;gt; fit = fit[fit[, 2] &amp;gt; 0, ]
&amp;gt; (FES = tidyMCMC(as.mcmc(fit[, 2]/fit[, 1]), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.468    0.0825    0.306     0.635&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by &lt;span class=&#34;math inline&#34;&gt;\(-20.9\)&lt;/span&gt; over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between &lt;span class=&#34;math inline&#34;&gt;\(-29.2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(-12.2\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Cohen’s D associated with a change over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(-4.19\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by &lt;span class=&#34;math inline&#34;&gt;\(-53.2\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between &lt;span class=&#34;math inline&#34;&gt;\(-69.4\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(-36.5\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The probability that &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by more than &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(0.996\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On average, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; declines by a factor of &lt;span class=&#34;math inline&#34;&gt;\(0.468\)&lt;/span&gt;% over the observed range of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. We are &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confident that the decline is between a factor of &lt;span class=&#34;math inline&#34;&gt;\(0.306\)&lt;/span&gt;% and &lt;span class=&#34;math inline&#34;&gt;\(0.635\)&lt;/span&gt;%.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         6.62     1.35      3.87      9.26
2 sd.resid     4.72     0.279     4.54      5.28
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         59.3      5.71     46.6      63.9
2 sd.resid     40.7      5.71     36.1      53.4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/simple-linear-regression-jags/2020-02-01-simple-linear-regression-jags_files/figure-html/effects_modelv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(59.3\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta1&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.649     0.106    0.433     0.758
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ x, data))

Call:
lm(formula = y ~ x, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5427 -3.3510 -0.3309  2.0411  7.5791 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.3328     2.4619  16.382 1.58e-10 ***
x            -1.3894     0.2546  -5.457 8.45e-05 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 4.695 on 14 degrees of freedom
Multiple R-squared:  0.6802,    Adjusted R-squared:  0.6574 
F-statistic: 29.78 on 1 and 14 DF,  p-value: 8.448e-05&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Comparing Two Populations - JAGS</title>
      <link>/jags/comparing-two-populations-jags/comparing-two-populations-jags/</link>
      <pubDate>Sat, 01 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/comparing-two-populations-jags/comparing-two-populations-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to explore differences between two populations. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of R, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;BUGS/JAGS/STAN&lt;/code&gt; languages and algorithms are very powerful and flexible. However, the cost of this power and flexibility is complexity and the need for a firm understanding of the model you wish to fit as well as the priors to be used. The algorithms requires the following inputs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Within the model:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The likelihood function relating the response to the predictors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The definition of the priors.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Chain properties:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The number of chains.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The length of chains (number of iterations).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The burn-in length (number of initial iterations to ignore).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The thinning rate (number of iterations to count on before storing a sample).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The initial estimates to start an MCMC chain. If there are multiple chains, these starting values can differ between chains.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The list of model parameters and derivatives to monitor (and return the posterior distributions of)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;We will start by generating a random data set. Note, I am creating two versions of the predictor variable (a numeric version and a factorial version).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; nA &amp;lt;- 60  #sample size from Population A
&amp;gt; nB &amp;lt;- 40  #sample size from Population B
&amp;gt; muA &amp;lt;- 105  #population mean of Population A
&amp;gt; muB &amp;lt;- 77.5  #population mean of Population B
&amp;gt; sigma &amp;lt;- 3  #standard deviation of both populations (equally varied)
&amp;gt; yA &amp;lt;- rnorm(nA, muA, sigma)  #Population A sample
&amp;gt; yB &amp;lt;- rnorm(nB, muB, sigma)  #Population B sample
&amp;gt; y &amp;lt;- c(yA, yB)
&amp;gt; x &amp;lt;- factor(rep(c(&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;), c(nA, nB)))  #categorical listing of the populations
&amp;gt; xn &amp;lt;- as.numeric(x)  #numerical version of the population category for means parameterization. # Should not start at 0.
&amp;gt; data &amp;lt;- data.frame(y, x, xn)  # dataset&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let inspect the first few rows of the dataset using the command &lt;code&gt;head&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; head(data)
         y x xn
1 103.3186 A  1
2 104.3095 A  1
3 109.6761 A  1
4 105.2115 A  1
5 105.3879 A  1
6 110.1452 A  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also perform some exploratory data analysis - in this case, a boxplot of the response for each level of the predictor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ x, data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/boxplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-one-sample-t-test&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The One Sample t-test&lt;/h1&gt;
&lt;p&gt;A &lt;em&gt;t-test&lt;/em&gt; is essentially just a simple regression model in which the categorical predictor is represented by a binary variable in which one level is coded as &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and the other &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;. For the model itself, the observed response &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; are assumed to be drawn from a normal distribution with a given mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. The expected values are themselves determined by the linear predictor &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0+\beta_1x_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the mean of the first treatment group and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; represents the difference between the mean of the first group and the mean of the second group (the effect of interest).&lt;/p&gt;
&lt;p&gt;MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying “uninformative” priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(1000\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (scale=&lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;) for the standard deviation (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim \text{Normal}(\mu_i, \sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0+\beta_1x_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Priors are defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim \text{Normal}(0,1000),  \;\;\; \text{and} \;\;\; \sigma \sim \text{Cauchy}(0,25),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for &lt;span class=&#34;math inline&#34;&gt;\(j=0,1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;fitting-the-model-in-jags&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fitting the model in JAGS&lt;/h2&gt;
&lt;p&gt;Broadly, there are two ways of parameterising (expressing the unknown (to be estimated) components of a model) a model. Either we can estimate the means of each group (&lt;em&gt;Means parameterisation&lt;/em&gt;) or we can estimate the mean of one group and the difference between this group and the other group(s) (&lt;em&gt;Effects parameterisation&lt;/em&gt;). The latter is commonly used for frequentist null hypothesis testing as its parameters are more consistent with the null hypothesis of interest (that the difference between the two groups equals zero).&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Effects parameterisation&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_{j}x_i + \epsilon_i, \;\;\; \text{with} \;\;\; \epsilon_i \sim \text{Normal}(0,\sigma).  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Each &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; is modelled by an intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; (mean of group A) plus a difference parameter &lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt; (difference between mean of group A and group B) multiplied by an indicator of which group the observation came from (&lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;), plus a residual drawn from a normal distribution with mean &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Actually, there are as many &lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt; parameters as there are groups but one of them (typically the first) is set to be equal to zero (to avoid over-parameterization). Expected values of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; are modelled assuming they are drawn from a normal distribution whose mean is determined by a linear combination of effect parameters and whose variance is defined by the degree of variability in this mean. The parameters are: &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Means parameterisation&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_{j} + \epsilon_i, \;\;\; \text{with} \;\;\; \epsilon_i \sim \text{Normal}(0,\sigma).  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Each &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; is modelled as the mean &lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt; of each group (&lt;span class=&#34;math inline&#34;&gt;\(j=1,2\)&lt;/span&gt;) plus a residual drawn from a normal distribution with a mean of zero and a standard deviation of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Actually, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; is a set of &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; coefficients corresponding to the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; dummy coded factor levels. Expected values of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; are modelled assuming they are drawn from a normal distribution whose mean is determined by a linear combination of means parameters and whose variance is defined by the degree of variability in this mean. The parameters are: &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;JAGS&lt;/code&gt;, distributions are defined by their precision &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than their standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Precision is just the inverse of variance (&lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;) and are chosen as they permit the gamma distribution to be used as the conjugate prior of the variance of a normal distribution. Bayesian analyses require that priors are specified for all the parameters. We will define vague (non-informative) priors for each of the parameters such that the posterior distributions are almost entirely influenced by the likelihood (and thus the data). Hence, appropriate (conjugate) priors for the effects parameterisation could be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta \sim \text{Normal}(0,1.0\text{E-}6)\)&lt;/span&gt; - a very flat normal distribution centered around zero. Note, &lt;span class=&#34;math inline&#34;&gt;\(1.0\text{E-}6\)&lt;/span&gt; is scientific notation for &lt;span class=&#34;math inline&#34;&gt;\(0.000001\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\tau \sim \text{Gamma}(0.1,0.1)\)&lt;/span&gt; a vague gamma distribution with a shape parameter close to zero (must be greater than &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;JAGS&lt;/code&gt; language very closely matches the above model and prior definitions - hence the importance on understanding the model you wish to fit. The &lt;code&gt;JAGS&lt;/code&gt; language resembles &lt;code&gt;R&lt;/code&gt; in many respects. It basically consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;stochastic nodes - those that appear on the left hand side of &lt;span class=&#34;math inline&#34;&gt;\(\sim\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;deterministic nodes - those that appear on the left hand side of &lt;code&gt;&amp;lt;-&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;-like for loops and functions to transform and summarise the data&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That said, &lt;code&gt;JAGS&lt;/code&gt; is based on a declarative language, which means: the order with which statements appear in the model definition are not important; nodes should not be defined more than once (you cannot change a value).We are now in a good position to define the model (Likelihood function and prior distributions).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Effects Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;  
+  model {
+   #Likelihood
+   for (i in 1:n) {
+     y[i]~dnorm(mu[i],tau)
+     mu[i] &amp;lt;- beta0+beta[x[i]]
+   }
+  
+   #Priors
+   beta0 ~ dnorm(0,1.0E-06)
+   beta[1] &amp;lt;- 0
+   beta[2] ~ dnorm(0,1.0E-06)
+   tau ~ dgamma(0.1,0.1)
+   sigma&amp;lt;-1/sqrt(tau)
+ 
+   #Other Derived parameters 
+   # Group means (note, beta is a vector)
+   Group.means &amp;lt;-beta0+beta  
+  }
+  &amp;quot;
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;ttestModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Means Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString.means = &amp;quot;  
+   model {
+    #Likelihood 
+    for (i in 1:n) {
+      y[i]~dnorm(mu[i],tau)
+      mu[i] &amp;lt;- beta[x[i]]
+    }
+  
+    #Priors
+    for (j in min(x):max(x)) {
+      beta[j] ~ dnorm(0,0.001)
+    }
+  
+    tau~dgamma(0.1,0.1)
+    sigma&amp;lt;-1/sqrt(tau)
+  
+    #Other Derived parameters 
+    effect &amp;lt;-beta[2]-beta[1]
+  }
+  &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString.means, con = &amp;quot;ttestModelMeans.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). Note, all variables must be numeric, therefore we use the numeric version of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Furthermore, the first level must be &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.list &amp;lt;- with(data, list(y = y, x = xn, n = nrow(data)))
&amp;gt; data.list.means &amp;lt;- with(data, list(y = y, x = xn, n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the initial values for the chain. Reasonable starting points can be gleaned from the data themselves.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; inits &amp;lt;- list(beta0 = mean(data$y), beta = c(NA, diff(tapply(data$y,
+     data$x, mean))), sigma = sd(data$y/2))
&amp;gt; inits.means &amp;lt;- list(beta = tapply(data$y, data$x, mean), sigma = sd(data$y/2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;Group.means&amp;quot;)
&amp;gt; params.means &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;effect&amp;quot;, &amp;quot;sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; adaptSteps = 1000  # the number of steps over which to establish a good stepping distance
&amp;gt; burnInSteps = 2000  # the number of initial samples to discard
&amp;gt; nChains = 2  # the number of independed sampling chains to perform 
&amp;gt; numSavedSteps = 50000  # the total number of samples to store
&amp;gt; thinSteps = 1  # the thinning rate
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When using the &lt;code&gt;jags&lt;/code&gt; function (&lt;code&gt;R2jags&lt;/code&gt; package), it is not necessary to provide initial values. However, if they are to be supplied, the inital values must be provided as a list of the same length as the number of chains.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Effects Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data=data.list,
+ inits=NULL, #or inits=list(inits,inits) # since there are two chains
+ parameters.to.save=params,
+ model.file=&amp;quot;ttestModel.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 3
   Total graph size: 214

Initializing model
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;ttestModel.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
               mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat
Group.means[1] 105.200   0.357 104.497 104.959 105.201 105.441 105.900 1.001
Group.means[2]  77.882   0.438  77.018  77.589  77.882  78.174  78.746 1.001
beta[1]          0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000
beta[2]        -27.318   0.563 -28.426 -27.696 -27.315 -26.943 -26.212 1.001
beta0          105.200   0.357 104.497 104.959 105.201 105.441 105.900 1.001
sigma            2.771   0.202   2.408   2.630   2.759   2.900   3.198 1.001
deviance       487.192   2.485 484.376 485.370 486.547 488.331 493.506 1.001
               n.eff
Group.means[1] 46000
Group.means[2] 15000
beta[1]            1
beta[2]        35000
beta0          46000
sigma          46000
deviance       46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.1 and DIC = 490.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Means Parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags.means &amp;lt;- jags(data=data.list.means,
+ inits=NULL, #or inits=list(inits.means,inits.means) # since there are two chains
+ parameters.to.save=params.means,
+ model.file=&amp;quot;ttestModelMeans.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 3
   Total graph size: 211

Initializing model
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.r2jags.means)
Inference for Bugs model at &amp;quot;ttestModelMeans.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]  105.184   0.357 104.481 104.947 105.184 105.423 105.884 1.001 46000
beta[2]   77.867   0.439  77.001  77.575  77.866  78.160  78.736 1.001 39000
effect   -27.317   0.566 -28.433 -27.696 -27.317 -26.940 -26.197 1.001 46000
sigma      2.768   0.201   2.408   2.626   2.755   2.897   3.192 1.001 34000
deviance 487.195   2.498 484.360 485.377 486.540 488.323 493.721 1.001 46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.1 and DIC = 490.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If &lt;code&gt;inits=NULL&lt;/code&gt; the &lt;code&gt;jags&lt;/code&gt; function will generate vaguely sensible initial values for each chain based on the data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In addition to the mean and quantiles of each of the sample nodes, the &lt;code&gt;jags&lt;/code&gt; function will calculate.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The &lt;em&gt;effective sample size&lt;/em&gt; for each sample - if &lt;code&gt;n.eff&lt;/code&gt; for a node is substantially less than the number of iterations, then it suggests poor mixing.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;em&gt;Potential scale reduction factor&lt;/em&gt; or &lt;code&gt;Rhat&lt;/code&gt; values for each sample - these are a convergence diagnostic (values of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; indicate full convergence, values greater than &lt;span class=&#34;math inline&#34;&gt;\(1.01\)&lt;/span&gt; are indicative of non-convergence.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;An &lt;em&gt;information criteria&lt;/em&gt; (DIC) for model selection.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The total number samples collected is &lt;span class=&#34;math inline&#34;&gt;\(46000\)&lt;/span&gt;. That is, there are &lt;span class=&#34;math inline&#34;&gt;\(46000\)&lt;/span&gt; samples collected from the multidimensional posterior distribution and thus, &lt;span class=&#34;math inline&#34;&gt;\(46000\)&lt;/span&gt; samples collected from the posterior distributions of each parameter. The effective number of samples column indicates the number of independent samples represented in the total. It is clear that for all parameters the chains were well mixed.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta[2]&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta0&amp;quot;,&amp;quot;beta[2]&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model.&lt;/p&gt;
&lt;p&gt;Residuals are not computed directly within &lt;code&gt;R2jags&lt;/code&gt;. However, we can calculate them manually form the posteriors and plot them using the package &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(ggplot2)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; # generate a model matrix
&amp;gt; newdata = data.frame(x = data$x)
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc, 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is no evidence that the mcmc chain did not converge on a stable posterior distribution. We are now in a position to examine the summaries of the parameters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 7 x 5
  term           estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 Group.means[1]   105.       0.357   105.      106.  
2 Group.means[2]    77.9      0.438    77.0      78.7 
3 beta[1]            0        0         0         0   
4 beta[2]          -27.3      0.563   -28.4     -26.2 
5 beta0            105.       0.357   105.      106.  
6 deviance         487.       2.49    484.      492.  
7 sigma              2.77     0.202     2.39      3.17&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Group A is typically &lt;span class=&#34;math inline&#34;&gt;\(27.3\)&lt;/span&gt; units greater than Group B. The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the difference between Group A and B does not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between the two groups.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group. We do this by loading functions in the package &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = data.frame(x = levels(data$x))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta0&amp;quot;, &amp;quot;beta[2]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you wanted to represent sample data on the figure in such a simple example (single predictor) we could simply over- (or under-) lay the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = data, aes(y = y,
+     x = x), color = &amp;quot;gray&amp;quot;) + geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
+     scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A more general solution would be to add the partial residuals to the figure. Partial residuals are the fitted values plus the residuals. In this simple case, that equates to exactly the same as the raw observations since &lt;span class=&#34;math inline&#34;&gt;\(\text{resid}=\text{obs}−\text{fitted}\)&lt;/span&gt; and the fitted values depend only on the single predictor we are interested in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_point(data = rdata, aes(y = partial.resid),
+     color = &amp;quot;gray&amp;quot;) + geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
+     scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/mcmc_post3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;effect-sizes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Effect sizes&lt;/h1&gt;
&lt;p&gt;In addition to deriving the distribution means for the second group, we could make use of the Bayesian framework to derive the distribution of the effect size. There are multiple ways of calculating an effect size, but the most common are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Raw effect size&lt;/em&gt; - the difference between two groups (as already calculated)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Cohen’s D&lt;/em&gt; - the effect size standardised by division with the pooled standard deviation&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Percent&lt;/em&gt; - the effect size expressed as a percent of the reference group mean&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Calculating the percent effect size involves division by an estimate of &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;. The very first sample collected of each parameter (including &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;) is based on the initial values supplied. If &lt;code&gt;inits=NULL&lt;/code&gt; the &lt;code&gt;jags&lt;/code&gt; function appears to generate initial values from the priors. Recall that in the previous model definition, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; was deemed to be distributed as a normal distribution with a mean of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Hence, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; would initially be assigned a value of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Division by zero is of course illegal and thus an error would be thrown. There are two ways to overcome this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Modify the prior such that it has a mean close to zero (and thus the first &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; sample is not zero), yet not actually zero (such as &lt;span class=&#34;math inline&#34;&gt;\(0.0001\)&lt;/span&gt;). This is the method used here.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Define initial values that are based on the observed data (and not zero).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; paramsv2 &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;Group.means&amp;quot;, &amp;quot;cohenD&amp;quot;, &amp;quot;ES&amp;quot;, &amp;quot;p10&amp;quot;)
&amp;gt; data.r2jagsv2 &amp;lt;- jags(data=data.list,
+ inits=NULL, #or inits=list(inits,inits) # since there are two chains
+ parameters.to.save=paramsv2,
+ model.file=&amp;quot;ttestModelv2.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 3
   Total graph size: 224

Initializing model
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.r2jagsv2)
Inference for Bugs model at &amp;quot;ttestModelv2.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
               mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat
ES             -25.965   0.488 -26.918 -26.294 -25.967 -25.637 -24.992 1.001
Group.means[1] 105.197   0.358 104.495 104.957 105.199 105.437 105.900 1.001
Group.means[2]  77.881   0.439  77.020  77.586  77.882  78.174  78.748 1.001
beta[1]          0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000
beta[2]        -27.316   0.567 -28.428 -27.696 -27.317 -26.934 -26.191 1.001
beta0          105.197   0.358 104.495 104.957 105.199 105.437 105.900 1.001
cohenD          -9.914   0.736 -11.390 -10.402  -9.905  -9.413  -8.503 1.001
p10              1.000   0.000   1.000   1.000   1.000   1.000   1.000 1.000
sigma            2.770   0.199   2.413   2.631   2.758   2.897   3.190 1.001
deviance       487.184   2.473 484.372 485.370 486.546 488.317 493.572 1.001
               n.eff
ES             46000
Group.means[1] 46000
Group.means[2] 46000
beta[1]            1
beta[2]        46000
beta0          46000
cohenD         46000
p10                1
sigma          46000
deviance       46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.1 and DIC = 490.2
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Cohen’s D value is &lt;span class=&#34;math inline&#34;&gt;\(-9.91\)&lt;/span&gt;. This value is far greater than the nominal “large effect” guidelines outlined by Cohen and thus we might proclaim the treatment as having a large negative effect. The effect size expressed as a percentage of the Group A mean is &lt;span class=&#34;math inline&#34;&gt;\(-27.3\)&lt;/span&gt;. Hence the treatment was associated with a &lt;span class=&#34;math inline&#34;&gt;\(27.3\)&lt;/span&gt;% reduction.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;probability-statements&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Probability statements&lt;/h1&gt;
&lt;p&gt;Bayesian statistics provide a natural means to generate probability statements. For example, we could calculate the probability that there is an effect of the treatment. Moreover, we could calculate the probability that the treatment effect exceeds some threshold (which might be based on a measure of clinically important difference or other compliance guidelines for example).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jagsv2$BUGSoutput$sims.matrix
&amp;gt; # Percentage change (relative to Group A)
&amp;gt; ES = 100 * mcmc[, &amp;quot;beta[2]&amp;quot;]/mcmc[, &amp;quot;beta0&amp;quot;]
&amp;gt; hist(ES)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/comparing-two-populations-jags/2020-02-01-comparing-two-populations-jags_files/figure-html/prob_stat-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; # Probability that the effect is greater than 10% (a decline of &amp;gt;10%)
&amp;gt; sum(-1 * ES &amp;gt; 10)/length(ES)
[1] 1
&amp;gt; # Probability that the effect is greater than 25% (a decline of &amp;gt;25%)
&amp;gt; sum(-1 * ES &amp;gt; 25)/length(ES)
[1] 0.9741304&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have defined two additional probability derivatives, both of which utilize the step function (which generates a binary vector based on whether values evaluate less than zero or not).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P0 - the probability (mean of 1-step()) that the raw effect is greater than zero.&lt;/li&gt;
&lt;li&gt;P25 - the probability (mean of 1-step()) that the percent effect size is greater than &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; paramsv3 &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;Group.means&amp;quot;, &amp;quot;cohenD&amp;quot;, &amp;quot;ES&amp;quot;, &amp;quot;P0&amp;quot;, &amp;quot;P25&amp;quot;)
&amp;gt; data.r2jagsv3 &amp;lt;- jags(data=data.list,
+ inits=NULL, #or inits=list(inits,inits) # since there are two chains
+ parameters.to.save=paramsv3,
+ model.file=&amp;quot;ttestModelv3.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 3
   Total graph size: 225

Initializing model
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.r2jagsv3)
Inference for Bugs model at &amp;quot;ttestModelv3.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
               mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat
ES             -25.964   0.489 -26.920 -26.293 -25.965 -25.637 -24.999 1.001
Group.means[1] 105.197   0.359 104.485 104.959 105.196 105.435 105.897 1.001
Group.means[2]  77.882   0.441  77.022  77.585  77.881  78.178  78.748 1.001
P0               1.000   0.000   1.000   1.000   1.000   1.000   1.000 1.000
P25              0.975   0.156   0.000   1.000   1.000   1.000   1.000 1.001
beta[1]          0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000
beta[2]        -27.315   0.568 -28.427 -27.696 -27.314 -26.935 -26.195 1.001
beta0          105.197   0.359 104.485 104.959 105.196 105.435 105.897 1.001
cohenD          -9.912   0.740 -11.385 -10.405  -9.903  -9.412  -8.477 1.001
sigma            2.770   0.200   2.411   2.631   2.758   2.896   3.198 1.001
deviance       487.202   2.492 484.364 485.378 486.557 488.334 493.696 1.001
               n.eff
ES             46000
Group.means[1] 46000
Group.means[2] 46000
P0                 1
P25            46000
beta[1]            1
beta[2]        46000
beta0          46000
cohenD         37000
sigma          27000
deviance       46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.1 and DIC = 490.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;It is often useful to be able to estimate the relative amount of variability associated with each predictor (or term) in a model. This can provide a sort of relative importance measure for each predictor.&lt;/p&gt;
&lt;p&gt;In frequentist statistics, such measures are only available for so called random factors (factors whose observational levels are randomly selected to represent all possible levels rather than to represent specific treatment levels). For such random factors, the collective variances (or standard deviation) of each factor are known as the variance components. Each component can also be expressed as a percentage of the total so as to provide a percentage breakdown of the relative contributions of each scale of sampling. Frequentist approaches model random factors according to the variance they add to the model, whereas fixed factors are modelled according to their effects (deviations from reference means). The model does not seek to generalise beyond the observed levels of a given fixed factor (such as control vs treatment) and thus it apparently does not make sense to estimate the population variability between levels (which is what variance components estimate).&lt;/p&gt;
&lt;p&gt;The notion of “fixed” and “random” factors is somewhat arbitrary and does not really have any meaning within a Bayesian context (as all parameters and thus factors are considered random). Instead, the spirit of what many consider is that the difference between fixed and random factors can be captured by conceptualising whether the levels of a factor are drawn from a &lt;em&gt;finite population&lt;/em&gt; (from which the observed factor levels are the only ones possible) or a &lt;em&gt;superpopulation&lt;/em&gt; (from which the observed factor levels are just a random selection of the infinite possible levels possible). Hence, variance components could be defined in terms of either finite population or superpopulation standard deviations. Superpopulation standard deviations have traditionally been used to describe the relative scale of sampling variation (e.g. where is the greatest source of variability; plots, subplots within plots, individual quadrats within subplots, …. or years, months within years, weeks within months, days within weeks, …) and are most logically applicable to factors that have a relatively large number of levels (such as spatial or temporal sampling units). On the other hand, finite population standard deviations can be used to explore the relative impact or effect of a set of (fixed) treatments.&lt;/p&gt;
&lt;p&gt;Calculate the amount of unexplained (residual) variance absorbed by the factor. This is generated by fitting a model with (full model) and without (reduced model) the term and subtracting the standard deviations of the residuals one another.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \sigma_A = \sigma_{reduced} - \sigma_{full} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This approach works fine for models that only include fixed factors (indeed it is somewhat analogous to the partitioning of variance employed by an ANOVA table), but cannot be used when the model includes random factors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.lmFull &amp;lt;- lm(y ~ x, data)
&amp;gt; data.lmRed &amp;lt;- lm(y ~ 1, data)
&amp;gt; sd.a &amp;lt;- sd(data.lmRed$resid) - sd(data.lmFull$resid)
&amp;gt; sd.resid &amp;lt;- sd(data.lmFull$resid)
&amp;gt; sds &amp;lt;- c(sd.a, sd.resid)
&amp;gt; 100 * sds/sum(sds)
[1] 80.05772 19.94228&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, options are somewhat limiting if we want to estimate the relative impacts of a mixture of “fixed” and “random” terms. For example, we may wish to explore the relative importance of a treatment compared to the spatial and/or temporal sampling heterogeneity. The Bayesian framework provides a relatively simple way to generate both finite population and superpopulation standard deviation estimates for all factors.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Finite populations&lt;/strong&gt;. The standard deviations of the MCMC samples across each of the parameters associated with a factor (eg, &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; in the effects parameterisation model) provide natural estimates of the variability between group levels (and thus the finite population standard deviation).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Superpopulation&lt;/strong&gt;. The mechanism of defining priors also provides a mechanism for calculating infinite population standard deviations. Recall that in the means model, the prior for &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; specifies that each of the &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; values are drawn from a normal distribution with a particular mean and a certain level of precision (reciprocal of variability). We could further parameterise this prior into an estimatable mean and precision via hyperpriors &lt;span class=&#34;math inline&#34;&gt;\(\beta_0 \sim \text{Normal}(\mu,\tau)\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\mu \sim \text{Normal}(0,1.0\text{E}-6)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tau \sim \text{Gamma}(0.1,0.1)\)&lt;/span&gt;. Since the normal distribution in line one above represents the distribution from which the (infinite) population means are drawn, &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; provides a direct measure of the variability of the population from which the means are drawn.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When the number of levels of a factor are large, the finite population and superpopulation standard deviation point estimates will be very similar. However, when the number of factor levels is small (such as two levels), the finite population estimate will be very precise whereas the superpopulation standard deviation estimate will be very imprecise (highly varied). For this reason, if the purpose of estimating standard deviations is to compare relative contributions of various predictors (some of which have small numbers of levels and others large), then it is best to use finite population standard deviation estimates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; paramsv4 &amp;lt;- c(&amp;quot;beta0&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;sd.a&amp;quot;, &amp;quot;sd.resid&amp;quot;, &amp;quot;sigma.a&amp;quot;)
&amp;gt; data.r2jagsv4 &amp;lt;- jags(data=data.list,
+ inits=NULL, #or inits=list(inits,inits) # since there are two chains
+ parameters.to.save=paramsv4,
+ model.file=&amp;quot;ttestModelv4.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 4
   Total graph size: 319

Initializing model
&amp;gt; 
&amp;gt; #print results
&amp;gt; print(data.r2jagsv4)
Inference for Bugs model at &amp;quot;ttestModelv4.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
               mu.vect      sd.vect    2.5%     25%     50%     75%
beta[1]   0.000000e+00 0.000000e+00   0.000   0.000   0.000   0.000
beta[2]  -2.731400e+01 5.670000e-01 -28.417 -27.694 -27.314 -26.937
beta0     1.051970e+02 3.590000e-01 104.490 104.955 105.198 105.440
sd.a      1.931400e+01 4.010000e-01  18.521  19.047  19.314  19.583
sd.resid  2.751000e+00 2.000000e-02   2.737   2.738   2.743   2.755
sigma     2.769000e+00 1.990000e-01   2.411   2.629   2.757   2.895
sigma.a   1.095446e+22 1.956638e+24   0.323   1.712  13.394 440.403
deviance  4.871890e+02 2.480000e+00 484.365 485.386 486.550 488.303
                97.5%  Rhat n.eff
beta[1]         0.000 1.000     1
beta[2]       -26.193 1.001 46000
beta0         105.899 1.001 46000
sd.a           20.094 1.001 46000
sd.resid        2.808 1.001 46000
sigma           3.187 1.001 46000
sigma.a  43469187.743 1.001 46000
deviance      493.637 1.001 46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 3.1 and DIC = 490.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The between group (finite population) standard deviation is &lt;span class=&#34;math inline&#34;&gt;\(20.1\)&lt;/span&gt; whereas the within group standard deviation is &lt;span class=&#34;math inline&#34;&gt;\(2.81\)&lt;/span&gt;. These equate to respectively. Compared to the finite population standard deviation, the superpopulation between group standard deviation estimate (&lt;span class=&#34;math inline&#34;&gt;\(\sigma_a\)&lt;/span&gt;) is both very large and highly variable. This is to be expected, whilst the finite population standard deviation represents the degree of variation between the observed levels, the superpopulation standard deviation seeks to estimate the variability of the population from which the group means of the observed levels &lt;strong&gt;AND&lt;/strong&gt; all other possible levels are drawn. There are only two levels from which to estimate this standard deviation and therefore, its value and variability are going to be higher than those pertaining only to the scope of the current data.&lt;/p&gt;
&lt;p&gt;Examination of the quantiles for &lt;span class=&#34;math inline&#34;&gt;\(\sigma_a\)&lt;/span&gt; suggest that its samples are not distributed normally. Consequently, the mean is not an appropriate measure of its location. We will instead characterise the superpopulation between group and within group standard deviations via their respective medians and as percent medians. The contrast between finite population and superpopulation standard deviations is also emphasised by the respective estimates for the residuals. The residuals are of course a “random” factor with a large number of observed levels. It is therefore not surprising that the point estimates for the residuals variance components are very similar. However, also notice that the precision of the finite population standard deviation estimate is substantially higher (lower standard deviation of the standard deviation estimate) than that of the superpopulation estimate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;unequally-varied-populations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Unequally varied populations&lt;/h1&gt;
&lt;p&gt;We can also generate data assuming two populations with different variances, e.g. between male and female subgroups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; n1 &amp;lt;- 60  #sample size from population 1
&amp;gt; n2 &amp;lt;- 40  #sample size from population 2
&amp;gt; mu1 &amp;lt;- 105  #population mean of population 1
&amp;gt; mu2 &amp;lt;- 77.5  #population mean of population 2
&amp;gt; sigma1 &amp;lt;- 3  #standard deviation of population 1
&amp;gt; sigma2 &amp;lt;- 2  #standard deviation of population 2
&amp;gt; n &amp;lt;- n1 + n2  #total sample size
&amp;gt; y1 &amp;lt;- rnorm(n1, mu1, sigma1)  #population 1 sample
&amp;gt; y2 &amp;lt;- rnorm(n2, mu2, sigma2)  #population 2 sample
&amp;gt; y &amp;lt;- c(y1, y2)
&amp;gt; x &amp;lt;- factor(rep(c(&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;), c(n1, n2)))  #categorical listing of the populations
&amp;gt; xn &amp;lt;- rep(c(0, 1), c(n1, n2))  #numerical version of the population category
&amp;gt; data2 &amp;lt;- data.frame(y, x, xn)  # dataset
&amp;gt; head(data2)  #print out the first six rows of the data set
         y x xn
1 103.3186 A  0
2 104.3095 A  0
3 109.6761 A  0
4 105.2115 A  0
5 105.3879 A  0
6 110.1452 A  0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start by defining the model&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i = \beta_0 + \beta_1x_i + \epsilon, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_1 \sim \text{Normal}(0,\sigma_1)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(x_1=0\)&lt;/span&gt; (females), and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_2 \sim \text{Normal}(0,\sigma_2)\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(x_2=1\)&lt;/span&gt; (males). In &lt;code&gt;JAGS&lt;/code&gt; code, the model becomes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelStringv5=&amp;quot;
+  model {
+  #Likelihood
+  for (i in 1:n1) {
+  y1[i]~dnorm(mu1,tau1)
+  }
+  for (i in 1:n2) {
+  y2[i]~dnorm(mu2,tau2)
+  }
+  
+  #Priors
+  mu1 ~ dnorm (0,0.001)
+  mu2 ~ dnorm(0,0.001)
+  tau1 &amp;lt;- 1 / (sigma1 * sigma1)
+  sigma1~dunif(0,100)
+  tau2 &amp;lt;- 1 / (sigma2 * sigma2)
+  sigma2~dunif(0,100)
+  
+  #Other Derived parameters 
+  delta &amp;lt;- mu2 - mu1
+  }
+  &amp;quot;
&amp;gt; ## write the model to a text file 
&amp;gt; writeLines(modelStringv5,con=&amp;quot;ttestModelv5.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We specify priors directly on &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_2\)&lt;/span&gt; using Uniform distributions between &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;, and then express &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; as a deterministic function of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Next, arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;) and define the MCMC parameters. Note, all variables must be numeric, therefore we use the numeric version of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Define the initial values for two chains so that the initial values list must include two elements (if provided).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data2.list &amp;lt;- with(data2,list(y1=y[xn==0], y2=y[xn==1], 
+   n1=length(y[xn==0]), n2=length(y[xn==1])))
&amp;gt; inits &amp;lt;- list(list(mu1=rnorm(1), mu2=rnorm(1), sigma1=rlnorm(1), sigma2=rlnorm(1)),
+ list(mu1=rnorm(1), mu2=rnorm(1), sigma1=rlnorm(1), sigma2=rlnorm(1)))
&amp;gt; paramsv5 &amp;lt;- c(&amp;quot;mu1&amp;quot;,&amp;quot;mu2&amp;quot;,&amp;quot;delta&amp;quot;,&amp;quot;sigma1&amp;quot;,&amp;quot;sigma2&amp;quot;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 2000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 50000
&amp;gt; thinSteps = 1
&amp;gt; nIter = ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, fit the model in &lt;code&gt;JAGS&lt;/code&gt; and print the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data2.r2jagsv5 &amp;lt;- jags(data=data2.list,
+ inits=NULL, #or inits=list(inits,inits) # since there are two chains
+ parameters.to.save=paramsv5,
+ model.file=&amp;quot;ttestModelv5.txt&amp;quot;,
+ n.chains=nChains,
+ n.iter=nIter,
+ n.burnin=burnInSteps,
+ n.thin=1)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 100
   Unobserved stochastic nodes: 4
   Total graph size: 115

Initializing model
&amp;gt; 
&amp;gt; print(data2.r2jagsv5)
Inference for Bugs model at &amp;quot;ttestModelv5.txt&amp;quot;, fit using jags,
 2 chains, each with 25000 iterations (first 2000 discarded)
 n.sims = 46000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
delta    -27.435   0.473 -28.367 -27.755 -27.433 -27.116 -26.508 1.001 27000
mu1      105.181   0.360 104.478 104.937 105.181 105.422 105.891 1.001 44000
mu2       77.746   0.306  77.142  77.543  77.748  77.948  78.347 1.001 46000
sigma1     2.787   0.265   2.328   2.602   2.767   2.951   3.361 1.001 16000
sigma2     1.913   0.225   1.534   1.753   1.893   2.049   2.414 1.001 21000
deviance 455.879   2.945 452.217 453.714 455.215 457.354 463.257 1.001 46000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 4.3 and DIC = 460.2
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2006prior&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2006. “Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by Browne and Draper).” &lt;em&gt;Bayesian Analysis&lt;/em&gt; 1 (3): 515–34.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
