<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>anova on Andrea Gabrio</title>
    <link>/categories/anova/</link>
    <description>Recent content in anova on Andrea Gabrio</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Feb 2020 21:13:14 -0500</lastBuildDate>
    
	    <atom:link href="/categories/anova/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Randomised Complete Block Anova - JAGS</title>
      <link>/jags/block-anova-jags/block-anova-jags/</link>
      <pubDate>Mon, 10 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/block-anova-jags/block-anova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the previous tutorial (nested ANOVA), we introduced the concept of employing sub-replicates that are nested within the main treatment levels as a means of absorbing some of the unexplained variability that would otherwise arise from designs in which sampling units are selected from amongst highly heterogeneous conditions. Such (nested) designs are useful in circumstances where the levels of the main treatment (such as burnt and un-burnt sites) occur at a much larger temporal or spatial scale than the experimental/sampling units (e.g. vegetation monitoring quadrats). For circumstances in which the main treatments can be applied (or naturally occur) at the same scale as the sampling units (such as whether a stream rock is enclosed by a fish proof fence or not), an alternative design is available. In this design (&lt;strong&gt;randomised complete block design&lt;/strong&gt;), each of the levels of the main treatment factor are grouped (blocked) together (in space and/or time) and therefore, whilst the conditions between the groups (referred to as “blocks”) might vary substantially, the conditions under which each of the levels of the treatment are tested within any given block are far more homogeneous.&lt;/p&gt;
&lt;p&gt;If any differences between blocks (due to the heterogeneity) can account for some of the total variability between the sampling units (thereby reducing the amount of variability that the main treatment(s) failed to explain), then the main test of treatment effects will be more powerful/sensitive. As an simple example of a randomised complete block (RCB) design, consider an investigation into the roles of different organism scales (microbial, macro invertebrate and vertebrate) on the breakdown of leaf debris packs within streams. An experiment could consist of four treatment levels - leaf packs protected by fish-proof mesh, leaf packs protected by fine macro invertebrate exclusion mesh, leaf packs protected by dissolving antibacterial tablets, and leaf packs relatively unprotected as controls. As an acknowledgement that there are many other unmeasured factors that could influence leaf pack breakdown (such as flow velocity, light levels, etc) and that these are likely to vary substantially throughout a stream, the treatments are to be arranged into groups or “blocks” (each containing a single control, microbial, macro invertebrate and fish protected leaf pack). Blocks of treatment sets are then secured in locations haphazardly selected throughout a particular reach of stream. Importantly, the arrangement of treatments in each block must be randomized to prevent the introduction of some systematic bias - such as light angle, current direction etc.&lt;/p&gt;
&lt;p&gt;Blocking does however come at a cost. The blocks absorb both unexplained variability as well as degrees of freedom from the residuals. Consequently, if the amount of the total unexplained variation that is absorbed by the blocks is not sufficiently large enough to offset the reduction in degrees of freedom (which may result from either less than expected heterogeneity, or due to the scale at which the blocks are established being inappropriate to explain much of the variation), for a given number of sampling units (leaf packs), the tests of main treatment effects will suffer power reductions. Treatments can also be applied sequentially or repeatedly at the scale of the entire block, such that at any single time, only a single treatment level is being applied (see the lower two sub-figures above). Such designs are called repeated measures. A repeated measures ANOVA is to an single factor ANOVA as a paired t-test is to a independent samples t-test. One example of a repeated measures analysis might be an investigation into the effects of a five different diet drugs (four doses and a placebo) on the food intake of lab rats. Each of the rats (“subjects”) is subject to each of the four drugs (within subject effects) which are administered in a random order. In another example, temporal recovery responses of sharks to bi-catch entanglement stresses might be simulated by analyzing blood samples collected from captive sharks (subjects) every half hour for three hours following a stress inducing restraint. This repeated measures design allows the anticipated variability in stress tolerances between individual sharks to be accounted for in the analysis (so as to permit more powerful test of the main treatments). Furthermore, by performing repeated measures on the same subjects, repeated measures designs reduce the number of subjects required for the investigation. Essentially, this is a randomised complete block design except that the within subject (block) effect (e.g. time since stress exposure) cannot be randomised.&lt;/p&gt;
&lt;p&gt;To suppress contamination effects resulting from the proximity of treatment sampling units within a block, units should be adequately spaced in time and space. For example, the leaf packs should not be so close to one another that the control packs are effected by the antibacterial tablets and there should be sufficient recovery time between subsequent drug administrations. In addition, the order or arrangement of treatments within the blocks must be randomized so as to prevent both confounding as well as computational complications. Whilst this is relatively straight forward for the classic randomized complete block design (such as the leaf packs in streams), it is logically not possible for repeated measures designs. Blocking factors are typically random factors that represent all the possible blocks that could be selected. As such, no individual block can truly be replicated. Randomised complete block and repeated measures designs can therefore also be thought of as un-replicated factorial designs in which there are two or more factors but that the interactions between the blocks and all the within block factors are not replicated.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models&lt;/h2&gt;
&lt;p&gt;The linear models for two and three factor nested design are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \mu + \beta_i + \alpha_j + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \beta_i + \alpha_j + \gamma_k + (\beta\alpha)_{ij} + (\beta\gamma)_{ik} + (\alpha\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \epsilon_{ijk}, \;\;\; \text{(Model 1)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \beta_i + \alpha_j + \gamma_k + (\alpha\gamma)_{jk} + \epsilon_{ijk}, \;\;\; \text{(Model 2)},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of the Blocking Factor B (&lt;span class=&#34;math inline&#34;&gt;\(\sum \beta=0\)&lt;/span&gt;), &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; are the effects of withing block Factor A and Factor C, respectively, and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon \sim N(0,\sigma^2)\)&lt;/span&gt; is the random unexplained or residual component.&lt;/p&gt;
&lt;p&gt;Tests for the effects of blocks as well as effects within blocks assume that there are no interactions between blocks and the within block effects. That is, it is assumed that any effects are of similar nature within each of the blocks. Whilst this assumption may well hold for experiments that are able to consciously set the scale over which the blocking units are arranged, when designs utilize arbitrary or naturally occurring blocking units, the magnitude and even polarity of the main effects are likely to vary substantially between the blocks. The preferred (non-additive or “Model 1”) approach to un-replicated factorial analysis of some bio-statisticians is to include the block by within subject effect interactions (e.g. &lt;span class=&#34;math inline&#34;&gt;\(\beta\alpha\)&lt;/span&gt;). Whilst these interaction effects cannot be formally tested, they can be used as the denominators in F-ratio calculations of their respective main effects tests. Proponents argue that since these blocking interactions cannot be formally tested, there is no sound inferential basis for using these error terms separately. Alternatively, models can be fitted additively (“Model 2”) whereby all the block by within subject effect interactions are pooled into a single residual term (&lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;). Although the latter approach is simpler, each of the within subject effects tests do assume that there are no interactions involving the blocks and that perhaps even more restrictively, that sphericity holds across the entire design.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;As with other ANOVA designs, the reliability of hypothesis tests is dependent on the residuals being:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;independent of one another. Although the observations within a block may not strictly be independent, provided the treatments are applied or ordered randomly within each block or subject, within block proximity effects on the residuals should be random across all blocks and thus the residuals should still be independent of one another. Nevertheless, it is important that experimental units within blocks are adequately spaced in space and time so as to suppress contamination or carryover effects.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;simple-rcb&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simple RCB&lt;/h1&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Imagine we has designed an experiment in which we intend to measure a response (y) to one of treatments (three levels; “a1”, “a2” and “a3”). Unfortunately, the system that we intend to sample is spatially heterogeneous and thus will add a great deal of noise to the data that will make it difficult to detect a signal (impact of treatment). Thus in an attempt to constrain this variability you decide to apply a design (RCB) in which each of the treatments within each of 35 blocks dispersed randomly throughout the landscape. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(plyr)
&amp;gt; set.seed(123)
&amp;gt; nTreat &amp;lt;- 3
&amp;gt; nBlock &amp;lt;- 35
&amp;gt; sigma &amp;lt;- 5
&amp;gt; sigma.block &amp;lt;- 12
&amp;gt; n &amp;lt;- nBlock*nTreat
&amp;gt; Block &amp;lt;- gl(nBlock, k=1)
&amp;gt; A &amp;lt;- gl(nTreat,k=1)
&amp;gt; dt &amp;lt;- expand.grid(A=A,Block=Block)
&amp;gt; #Xmat &amp;lt;- model.matrix(~Block + A + Block:A, data=dt)
&amp;gt; Xmat &amp;lt;- model.matrix(~-1+Block + A, data=dt)
&amp;gt; block.effects &amp;lt;- rnorm(n = nBlock, mean = 40, sd = sigma.block)
&amp;gt; A.effects &amp;lt;- c(30,40)
&amp;gt; all.effects &amp;lt;- c(block.effects,A.effects)
&amp;gt; lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; # OR
&amp;gt; Xmat &amp;lt;- cbind(model.matrix(~-1+Block,data=dt),model.matrix(~-1+A,data=dt))
&amp;gt; ## Sum to zero block effects
&amp;gt; block.effects &amp;lt;- rnorm(n = nBlock, mean = 0, sd = sigma.block)
&amp;gt; A.effects &amp;lt;- c(40,70,80)
&amp;gt; all.effects &amp;lt;- c(block.effects,A.effects)
&amp;gt; lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; 
&amp;gt; 
&amp;gt; ## the quadrat observations (within sites) are drawn from
&amp;gt; ## normal distributions with means according to the site means
&amp;gt; ## and standard deviations of 5
&amp;gt; y &amp;lt;- rnorm(n,lin.pred,sigma)
&amp;gt; data.rcb &amp;lt;- data.frame(y=y, expand.grid(A=A, Block=Block))
&amp;gt; head(data.rcb)  #print out the first six rows of the data set
         y A Block
1 45.80853 1     1
2 66.71784 2     1
3 93.29238 3     1
4 43.10101 1     2
5 73.20697 2     2
6 91.77487 3     2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y~A, data.rcb)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. . More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Block by within-Block interaction&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(car)
&amp;gt; with(data.rcb, interaction.plot(A,Block,y))
&amp;gt; 
&amp;gt; #OR with ggplot
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data.rcb, aes(y=y, x=A, group=Block,color=Block)) + geom_line() +
+   guides(color=guide_legend(ncol=3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; residualPlots(lm(y~Block+A, data.rcb))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;           Test stat Pr(&amp;gt;|Test stat|)
Block                                
A                                    
Tukey test   -1.4163           0.1567
&amp;gt; 
&amp;gt; # the Tukey&amp;#39;s non-additivity test by itself can be obtained via an internal function
&amp;gt; # within the car package
&amp;gt; car:::tukeyNonaddTest(lm(y~Block+A, data.rcb))
      Test     Pvalue 
-1.4163343  0.1566776 
&amp;gt; 
&amp;gt; # alternatively, there is also a Tukey&amp;#39;s non-additivity test within the
&amp;gt; # asbio package
&amp;gt; library(asbio)
&amp;gt; with(data.rcb,tukey.add.test(y,A,Block))

Tukey&amp;#39;s one df test for additivity 
F = 2.0060029   Denom df = 67    p-value = 0.1613102&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there is no visual or inferential evidence of any major interactions between Block and the within-Block effect (A). Any trends appear to be reasonably consistent between Blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Full parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\beta_0 + \beta_i + \gamma_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{ij)} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0, \beta_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The &lt;em&gt;full parameterisation&lt;/em&gt;, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\beta_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Matrix parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\boldsymbol \beta \boldsymbol X + \gamma_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{ij} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta \sim MVN(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The full parameterisation, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\beta_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;). The &lt;em&gt;matrix parameterisation&lt;/em&gt; is a compressed notation, In this parameterisation, there are three alpha parameters (one representing the mean of treatment a1, and the other two representing the treatment effects (differences between a2 and a1 and a3 and a1). In generating priors for each of these three alpha parameters, we could loop through each and define a non-informative normal prior to each (as in the Full parameterisation version). However, it turns out that it is more efficient (in terms of mixing and thus the number of necessary iterations) to define the priors from a multivariate normal distribution. This has as many means as there are parameters to estimate (&lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt;) and a &lt;span class=&#34;math inline&#34;&gt;\(3\times3\)&lt;/span&gt; matrix of zeros and &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; in the diagonals.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol \mu =
  \begin{bmatrix} 0  \\ 0  \\ 0 \end{bmatrix}, \;\;\; \sigma^2 \sim   
  \begin{bmatrix}
   1000000 &amp;amp; 0 &amp;amp; 0 \\
   0 &amp;amp; 1000000 &amp;amp; 0 \\
   0 &amp;amp; 0 &amp;amp; 1000000
   \end{bmatrix}. \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}= \beta_0 + \beta_i + \gamma_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{ij} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0, \beta_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Rather than assume a specific variance-covariance structure, just like &lt;code&gt;lme&lt;/code&gt; we can incorporate an appropriate structure to account for different dependency/correlation structures in our data. In RCB designs, it is prudent to capture the residuals to allow checks that there are no outstanding dependency issues following model fitting.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;full-effect-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full effect parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- beta0 + beta[A[i]] + gamma[Block[i]]
+       res[i] &amp;lt;- y[i]-mu[i]
+    }
+    
+    #Priors
+    beta0 ~ dnorm(0, 1.0E-6)
+    beta[1] &amp;lt;- 0
+    for (i in 2:nA) {
+      beta[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    for (i in 1:nBlock) {
+      gamma[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;- z/sqrt(chSq) 
+    z ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;- z/sqrt(chSq.B) 
+    z.B ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.B ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;fullModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.list &amp;lt;- with(data.rcb,
+         list(y=y,
+                  Block=as.numeric(Block),
+          A=as.numeric(A),
+          n=nrow(data.rcb),
+          nBlock=length(levels(Block)),
+                  nA = length(levels(A))
+          )
+ )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;,&amp;#39;gamma&amp;#39;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;quot;res&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.r2jags.f &amp;lt;- jags(data = data.rcb.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;fullModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 105
   Unobserved stochastic nodes: 42
   Total graph size: 582

Initializing model
&amp;gt; 
&amp;gt; print(data.rcb.r2jags.f)
Inference for Bugs model at &amp;quot;fullModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
          mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]     0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000     1
beta[2]    27.923   1.236  25.587  27.086  27.918  28.736  30.363 1.001  3000
beta[3]    40.263   1.229  37.821  39.463  40.271  41.070  42.706 1.001  3000
beta0      41.834   2.154  37.519  40.406  41.833  43.338  46.002 1.001  3000
gamma[1]    3.731   3.394  -2.865   1.418   3.748   6.043  10.452 1.001  3000
gamma[2]    4.534   3.439  -2.033   2.182   4.508   6.865  11.317 1.003   690
gamma[3]   -3.951   3.464 -10.690  -6.324  -3.884  -1.600   2.829 1.001  3000
gamma[4]   -4.129   3.454 -10.758  -6.477  -4.200  -1.784   2.630 1.003   780
gamma[5]   -5.314   3.480 -12.143  -7.633  -5.325  -2.947   1.594 1.001  3000
gamma[6]   -6.050   3.377 -12.486  -8.331  -6.071  -3.700   0.524 1.001  3000
gamma[7]   -0.709   3.373  -7.083  -3.017  -0.728   1.585   6.032 1.001  3000
gamma[8]  -15.033   3.446 -21.689 -17.322 -15.065 -12.741  -7.939 1.001  3000
gamma[9]   27.856   3.444  20.996  25.498  27.927  30.226  34.525 1.001  3000
gamma[10]  12.830   3.591   5.798  10.453  12.809  15.249  20.065 1.001  3000
gamma[11] -14.936   3.427 -21.825 -17.228 -14.945 -12.635  -8.165 1.001  3000
gamma[12]  -7.878   3.427 -14.571 -10.161  -7.929  -5.551  -1.275 1.001  3000
gamma[13] -10.865   3.430 -17.569 -13.203 -10.852  -8.555  -4.076 1.001  2100
gamma[14]   9.153   3.466   2.557   6.679   9.161  11.473  15.941 1.002  1100
gamma[15]  -3.897   3.495 -10.811  -6.227  -3.882  -1.565   2.866 1.001  3000
gamma[16]   1.321   3.437  -5.486  -0.927   1.328   3.539   8.066 1.001  3000
gamma[17]  -4.137   3.445 -11.102  -6.451  -4.046  -1.802   2.384 1.001  2300
gamma[18]  -4.257   3.449 -10.970  -6.607  -4.280  -1.978   2.695 1.001  2900
gamma[19]  16.435   3.468   9.749  14.031  16.449  18.830  23.059 1.002  1600
gamma[20]  -5.108   3.439 -11.784  -7.392  -5.100  -2.851   1.708 1.001  3000
gamma[21]  18.935   3.517  12.023  16.632  18.857  21.210  25.944 1.001  3000
gamma[22] -20.654   3.459 -27.290 -23.041 -20.593 -18.341 -14.063 1.001  3000
gamma[23]   7.325   3.570   0.265   4.959   7.346   9.652  14.226 1.001  2500
gamma[24]  -1.300   3.500  -8.248  -3.680  -1.256   1.043   5.590 1.001  3000
gamma[25]  -6.114   3.419 -12.672  -8.442  -6.078  -3.725   0.554 1.001  2500
gamma[26]   1.038   3.451  -5.502  -1.351   1.018   3.415   7.820 1.001  3000
gamma[27]  -4.346   3.400 -10.942  -6.604  -4.351  -1.980   2.254 1.001  3000
gamma[28]  -4.721   3.368 -11.281  -6.939  -4.724  -2.572   2.057 1.001  3000
gamma[29] -12.328   3.513 -19.166 -14.660 -12.295 -10.096  -5.361 1.001  3000
gamma[30] -12.858   3.534 -19.927 -15.216 -12.782 -10.455  -5.999 1.001  3000
gamma[31]   0.272   3.457  -6.677  -2.020   0.279   2.562   7.061 1.002  1700
gamma[32]   8.682   3.389   1.905   6.358   8.769  10.986  15.304 1.002  1100
gamma[33]   0.315   3.433  -6.393  -2.013   0.292   2.624   7.101 1.001  3000
gamma[34]   9.586   3.491   2.775   7.232   9.621  11.954  16.438 1.002  1600
gamma[35]  23.906   3.429  17.230  21.620  23.976  26.208  30.709 1.004   660
res[1]      0.243   2.906  -5.276  -1.686   0.233   2.121   5.940 1.001  3000
res[2]     -6.771   2.869 -12.345  -8.647  -6.778  -4.904  -1.088 1.001  3000
res[3]      7.465   2.940   1.587   5.472   7.482   9.382  13.252 1.001  3000
res[4]     -3.267   2.927  -8.857  -5.249  -3.282  -1.245   2.325 1.003   710
res[5]     -1.085   2.946  -6.792  -3.130  -1.110   0.894   4.685 1.003   580
res[6]      5.144   2.913  -0.568   3.244   5.128   7.112  11.094 1.003   600
res[7]     -0.049   2.992  -5.806  -2.023  -0.081   1.917   5.915 1.002  1400
res[8]     -2.652   3.020  -8.617  -4.629  -2.690  -0.658   3.254 1.001  2100
res[9]      2.018   2.992  -3.965  -0.008   1.989   4.022   7.816 1.001  1900
res[10]    -2.071   2.894  -7.884  -4.016  -2.075  -0.143   3.626 1.003   790
res[11]     0.729   2.960  -5.122  -1.274   0.754   2.666   6.590 1.003   660
res[12]     0.287   2.974  -5.811  -1.700   0.396   2.232   5.977 1.003   700
res[13]    -2.939   2.956  -8.894  -4.938  -2.989  -0.959   2.831 1.001  3000
res[14]     4.213   2.943  -1.578   2.254   4.220   6.162  10.013 1.002  3000
res[15]    -2.451   2.949  -8.246  -4.449  -2.478  -0.503   3.535 1.001  3000
res[16]    -2.462   2.911  -8.169  -4.429  -2.422  -0.560   3.167 1.001  3000
res[17]     3.440   2.912  -2.164   1.559   3.394   5.390   9.051 1.001  3000
res[18]    -2.208   2.908  -7.897  -4.117  -2.183  -0.279   3.505 1.001  3000
res[19]    -5.249   2.902 -10.958  -7.149  -5.263  -3.289   0.456 1.001  2800
res[20]     4.201   2.886  -1.484   2.238   4.217   6.100   9.930 1.001  3000
res[21]     1.085   2.889  -4.579  -0.852   1.104   2.988   6.981 1.001  3000
res[22]     0.756   2.958  -5.385  -1.108   0.712   2.747   6.541 1.001  3000
res[23]     1.284   2.979  -4.882  -0.642   1.295   3.319   6.941 1.001  3000
res[24]    -5.388   2.941 -11.391  -7.320  -5.410  -3.425   0.336 1.001  3000
res[25]     3.141   2.979  -2.786   1.153   3.135   5.090   9.051 1.001  3000
res[26]    -4.587   2.978 -10.372  -6.597  -4.605  -2.589   1.268 1.001  3000
res[27]     7.011   2.963   1.359   4.983   6.994   8.965  12.803 1.001  3000
res[28]     7.495   3.018   1.549   5.443   7.508   9.538  13.331 1.002  1600
res[29]     0.730   3.013  -5.133  -1.311   0.723   2.759   6.603 1.001  2200
res[30]    -5.563   3.054 -11.597  -7.683  -5.577  -3.452   0.255 1.001  2100
res[31]    -3.927   2.962  -9.656  -5.903  -3.900  -1.965   1.925 1.001  3000
res[32]     2.986   2.928  -2.794   1.134   2.985   4.946   8.735 1.001  3000
res[33]    -1.871   2.951  -7.734  -3.824  -1.864   0.076   4.020 1.001  3000
res[34]    -0.528   2.951  -6.322  -2.505  -0.516   1.395   5.205 1.001  3000
res[35]    -1.472   2.949  -7.285  -3.350  -1.439   0.455   4.220 1.001  3000
res[36]     0.722   2.938  -4.922  -1.223   0.716   2.663   6.487 1.001  3000
res[37]    -0.493   2.928  -6.329  -2.503  -0.515   1.546   5.111 1.002   940
res[38]    -2.832   2.938  -8.610  -4.822  -2.827  -0.812   2.778 1.002  1300
res[39]     1.268   2.931  -4.339  -0.752   1.281   3.287   6.896 1.002  1200
res[40]     2.968   2.956  -2.952   0.972   2.987   4.925   8.768 1.003   540
res[41]    -2.427   2.942  -8.293  -4.383  -2.363  -0.534   3.629 1.003   660
res[42]     1.150   2.922  -4.453  -0.813   1.176   3.054   7.197 1.003   620
res[43]    -7.026   2.953 -12.859  -8.930  -7.097  -5.036  -1.170 1.001  3000
res[44]     2.862   2.915  -2.600   0.922   2.711   4.854   8.438 1.001  3000
res[45]     3.397   2.955  -2.273   1.404   3.364   5.361   9.127 1.001  3000
res[46]     1.390   2.972  -4.597  -0.607   1.321   3.366   7.167 1.001  2000
res[47]     2.490   2.991  -3.362   0.502   2.495   4.531   8.375 1.001  3000
res[48]    -3.582   2.963  -9.351  -5.573  -3.608  -1.606   2.286 1.001  2700
res[49]    -2.288   2.916  -7.729  -4.298  -2.366  -0.291   3.588 1.003  1000
res[50]    -1.083   2.906  -6.569  -3.067  -1.105   0.863   4.716 1.002  1300
res[51]     2.286   2.912  -3.216   0.331   2.244   4.222   8.075 1.002  1200
res[52]    -2.829   2.903  -8.540  -4.796  -2.804  -0.891   2.706 1.001  3000
res[53]     1.533   2.928  -4.178  -0.380   1.544   3.452   7.214 1.001  2700
res[54]     0.366   2.907  -5.326  -1.576   0.391   2.274   6.016 1.001  3000
res[55]     7.373   2.957   1.529   5.353   7.414   9.358  13.176 1.002  1300
res[56]    -3.029   2.984  -9.041  -4.985  -2.963  -1.047   2.888 1.002  1000
res[57]    -0.932   2.961  -6.889  -2.936  -0.824   0.995   4.741 1.002  1100
res[58]     0.955   2.941  -4.752  -1.089   0.981   2.907   6.650 1.001  3000
res[59]    -2.168   2.938  -8.052  -4.106  -2.164  -0.262   3.668 1.001  3000
res[60]    -0.054   2.957  -5.874  -2.011   0.024   1.879   5.755 1.001  3000
res[61]     4.652   3.013  -1.277   2.681   4.595   6.649  10.447 1.001  3000
res[62]     1.763   3.015  -4.198  -0.283   1.800   3.811   7.690 1.001  3000
res[63]    -2.627   2.975  -8.515  -4.603  -2.640  -0.650   3.124 1.001  3000
res[64]    -1.878   3.019  -7.923  -3.808  -1.879   0.207   3.832 1.001  3000
res[65]    -7.955   2.986 -14.124  -9.906  -7.908  -5.914  -2.185 1.001  3000
res[66]     5.629   3.022  -0.370   3.651   5.702   7.692  11.441 1.001  3000
res[67]    -9.447   2.997 -15.297 -11.427  -9.472  -7.515  -3.360 1.002  1100
res[68]     3.633   3.011  -2.241   1.639   3.558   5.638   9.647 1.002  1400
res[69]     7.139   3.005   1.189   5.081   7.118   9.082  13.136 1.002  1300
res[70]    -6.267   2.959 -11.956  -8.323  -6.249  -4.253  -0.493 1.001  3000
res[71]     6.538   2.978   0.563   4.494   6.525   8.512  12.391 1.001  3000
res[72]    -0.621   2.967  -6.432  -2.609  -0.683   1.364   5.125 1.001  3000
res[73]    -0.989   2.943  -6.875  -2.968  -0.975   0.949   4.951 1.001  3000
res[74]     1.375   2.946  -4.265  -0.614   1.336   3.269   7.187 1.001  2400
res[75]    -1.399   2.934  -7.135  -3.371  -1.401   0.618   4.478 1.001  2700
res[76]    -0.971   2.970  -6.912  -2.914  -1.004   1.027   4.841 1.001  3000
res[77]    -3.549   2.958  -9.315  -5.540  -3.567  -1.572   2.143 1.001  3000
res[78]     4.860   2.940  -0.988   2.887   4.805   6.835  10.606 1.001  3000
res[79]     6.984   2.964   1.461   4.967   6.920   9.004  12.824 1.001  3000
res[80]    -7.875   3.011 -13.687  -9.926  -7.936  -5.815  -1.954 1.001  3000
res[81]     0.160   2.947  -5.484  -1.824   0.127   2.155   6.047 1.001  3000
res[82]     2.734   2.915  -3.183   0.820   2.794   4.729   8.263 1.001  3000
res[83]     2.626   2.932  -3.161   0.748   2.624   4.515   8.266 1.001  3000
res[84]    -6.416   2.954 -12.297  -8.315  -6.382  -4.439  -0.826 1.001  3000
res[85]    -2.326   3.020  -8.242  -4.293  -2.308  -0.307   3.564 1.001  3000
res[86]    -1.054   3.030  -7.047  -3.116  -1.048   0.971   4.956 1.001  3000
res[87]     0.823   3.034  -5.036  -1.236   0.832   2.846   6.820 1.001  3000
res[88]    -3.700   3.021  -9.662  -5.732  -3.744  -1.656   2.141 1.001  3000
res[89]     5.124   3.000  -0.700   3.125   5.166   7.053  10.967 1.001  3000
res[90]    -3.973   3.026  -9.965  -5.967  -3.979  -1.965   2.004 1.001  3000
res[91]     6.800   2.936   1.114   4.888   6.726   8.792  12.683 1.001  2100
res[92]    -1.633   2.932  -7.382  -3.615  -1.645   0.303   4.342 1.002  1500
res[93]    -5.027   2.937 -10.801  -6.975  -5.090  -3.114   0.895 1.002  1600
res[94]    11.068   2.894   5.415   9.144  11.037  12.950  16.844 1.017   920
res[95]    -5.145   2.871 -10.758  -7.025  -5.209  -3.257   0.653 1.002   920
res[96]    -3.909   2.889  -9.670  -5.821  -3.975  -2.083   2.104 1.002  1000
res[97]     1.670   2.927  -4.070  -0.286   1.655   3.647   7.528 1.001  2600
res[98]    -1.855   2.902  -7.533  -3.814  -1.846   0.085   3.932 1.001  3000
res[99]     0.809   2.905  -4.984  -1.113   0.807   2.832   6.509 1.001  3000
res[100]    1.492   2.952  -4.294  -0.488   1.451   3.471   7.192 1.001  2000
res[101]    0.647   2.987  -5.287  -1.341   0.649   2.697   6.465 1.002  1500
res[102]   -0.289   2.974  -6.080  -2.262  -0.296   1.781   5.395 1.002  1600
res[103]   -1.309   2.976  -7.063  -3.273  -1.394   0.728   4.790 1.004   440
res[104]   11.580   2.959   5.725   9.638  11.567  13.515  17.434 1.003   770
res[105]   -5.108   2.939 -10.788  -7.110  -5.108  -3.165   0.707 1.006   490
sigma       5.090   0.453   4.294   4.775   5.059   5.360   6.091 1.002   980
sigma.B    11.494   1.491   8.926  10.487  11.365  12.348  14.912 1.002   920
deviance  637.702  11.556 618.449 629.190 636.668 645.140 663.417 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 66.8 and DIC = 704.5
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- inprod(beta[],X[i,]) + gamma[Block[i]]
+     res[i] &amp;lt;- y[i]-mu[i]
+    } 
+    
+    #Priors
+    beta ~ dmnorm(a0,A0)
+    for (i in 1:nBlock) {
+      gamma[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;- z/sqrt(chSq) 
+    z ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;- z/sqrt(chSq.B) 
+    z.B ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.B ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;matrixModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; A.Xmat &amp;lt;- model.matrix(~A,data.rcb)
&amp;gt; data.rcb.list &amp;lt;- with(data.rcb,
+         list(y=y,
+                  Block=as.numeric(Block),
+          X=A.Xmat,
+          n=nrow(data.rcb),
+          nBlock=length(levels(Block)),
+          a0=rep(0,3), A0=diag(3)
+          )
+ )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;#39;gamma&amp;#39;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;quot;res&amp;quot;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.r2jags.m &amp;lt;- jags(data = data.rcb.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;matrixModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 105
   Unobserved stochastic nodes: 40
   Total graph size: 910

Initializing model
&amp;gt; 
&amp;gt; print(data.rcb.r2jags.m)
Inference for Bugs model at &amp;quot;matrixModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
          mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]     0.550   1.010  -1.396  -0.163   0.543   1.212   2.618 1.001  3000
beta[2]     0.624   0.969  -1.267  -0.021   0.609   1.267   2.494 1.002   830
beta[3]     1.556   1.005  -0.458   0.886   1.564   2.248   3.495 1.001  3000
gamma[1]   64.957  12.115  41.593  56.722  64.856  72.937  89.019 1.001  3000
gamma[2]   65.491  12.061  40.343  57.573  65.450  73.443  89.230 1.001  3000
gamma[3]   57.107  11.937  34.004  49.204  56.969  65.191  79.840 1.001  3000
gamma[4]   56.660  11.705  32.676  48.922  56.796  64.418  79.244 1.002   980
gamma[5]   55.496  12.269  30.868  47.463  55.494  63.576  79.632 1.001  3000
gamma[6]   54.801  11.877  31.954  46.951  54.385  62.674  78.056 1.002  3000
gamma[7]   60.234  11.740  36.788  52.823  60.472  67.916  83.053 1.001  3000
gamma[8]   45.171  11.789  21.628  37.438  45.279  53.104  69.031 1.002  3000
gamma[9]   89.740  11.870  66.877  81.784  89.985  97.893 112.876 1.001  3000
gamma[10]  74.392  11.959  51.486  65.937  74.289  82.703  98.386 1.002  1500
gamma[11]  45.824  11.994  22.631  37.864  45.861  53.737  69.411 1.002  1100
gamma[12]  52.874  11.847  29.777  44.934  53.044  61.009  75.635 1.002  1800
gamma[13]  49.828  12.010  26.670  41.934  49.809  57.903  73.611 1.001  3000
gamma[14]  70.252  11.879  46.842  62.471  70.259  78.152  93.618 1.001  3000
gamma[15]  56.956  11.790  34.318  48.968  56.782  65.102  79.771 1.001  3000
gamma[16]  62.229  12.088  39.561  53.779  62.120  70.801  85.754 1.002  1500
gamma[17]  56.154  11.923  32.379  48.260  56.301  64.248  79.156 1.004   840
gamma[18]  56.302  11.789  32.839  48.585  56.477  64.399  79.221 1.001  3000
gamma[19]  78.011  12.127  53.246  69.932  78.041  86.393 100.917 1.001  3000
gamma[20]  55.445  11.822  32.414  47.480  55.477  63.566  78.456 1.002  3000
gamma[21]  79.975  11.935  56.573  72.184  80.069  87.728 103.091 1.001  3000
gamma[22]  39.667  11.800  16.288  31.836  39.723  47.341  62.882 1.001  3000
gamma[23]  68.605  11.860  45.831  60.540  68.721  76.702  91.376 1.001  3000
gamma[24]  59.858  12.057  36.038  51.799  59.900  67.940  83.312 1.001  2200
gamma[25]  54.974  11.970  31.161  47.135  55.153  62.882  78.327 1.002  1400
gamma[26]  62.397  11.915  38.745  54.113  62.260  70.437  86.239 1.002  3000
gamma[27]  56.526  11.968  32.943  48.610  56.627  64.491  80.067 1.003  1800
gamma[28]  56.062  12.002  33.315  48.254  56.158  64.016  79.264 1.001  3000
gamma[29]  47.976  11.787  24.940  39.984  47.840  55.752  71.140 1.001  3000
gamma[30]  47.866  11.894  24.408  40.161  47.877  55.955  70.787 1.001  3000
gamma[31]  61.528  12.021  37.815  53.617  61.620  69.800  84.596 1.001  3000
gamma[32]  70.047  11.805  46.872  62.230  70.224  78.030  93.180 1.001  3000
gamma[33]  61.830  11.934  38.654  53.718  61.828  69.563  85.450 1.002  1800
gamma[34]  70.909  12.075  47.408  62.788  70.805  78.794  95.338 1.002  3000
gamma[35]  85.532  12.138  61.716  77.422  85.479  93.434 109.336 1.001  3000
res[1]    -19.698  12.037 -43.684 -27.635 -19.684 -11.694   3.838 1.001  3000
res[2]      0.587  12.062 -23.374  -7.403   0.579   8.638  24.005 1.001  2500
res[3]     26.230  12.050   2.155  18.315  26.057  34.356  50.024 1.001  3000
res[4]    -22.940  11.997 -46.569 -30.787 -23.060 -15.111   2.226 1.001  3000
res[5]      6.542  11.989 -16.855  -1.311   6.542  14.381  31.699 1.001  3000
res[6]     24.179  11.977   0.862  16.176  24.040  31.902  49.149 1.001  3000
res[7]    -19.824  11.904 -42.484 -27.853 -19.648 -11.889   3.474 1.001  3000
res[8]      4.872  11.923 -17.801  -3.160   4.933  12.798  28.368 1.001  3000
res[9]     20.951  11.893  -1.904  12.827  21.045  28.785  44.008 1.001  3000
res[10]   -21.576  11.660 -44.079 -29.235 -21.708 -13.770   2.548 1.002   920
res[11]     8.523  11.658 -14.011   0.830   8.435  16.332  32.472 1.002  1100
res[12]    19.489  11.657  -2.829  11.774  19.266  27.343  43.385 1.002   910
res[13]   -22.465  12.167 -46.486 -30.516 -22.434 -14.565   2.114 1.001  3000
res[14]    11.986  12.183 -11.847   3.842  12.016  20.032  36.714 1.001  3000
res[15]    16.730  12.218  -7.281   8.522  16.737  24.706  41.406 1.001  3000
res[16]   -22.029  11.845 -45.221 -29.925 -21.621 -14.244   0.444 1.001  3000
res[17]    11.172  11.874 -12.338   3.326  11.433  18.964  33.977 1.001  3000
res[18]    16.933  11.886  -6.385   8.941  17.228  24.796  39.651 1.001  3000
res[19]   -24.908  11.723 -47.784 -32.552 -25.170 -17.491  -1.875 1.001  3000
res[20]    11.841  11.745 -11.265   4.268  11.662  19.369  35.065 1.001  3000
res[21]    20.133  11.744  -2.743  12.424  19.956  27.740  43.426 1.001  3000
res[22]   -18.164  11.729 -41.484 -26.023 -18.365 -10.358   5.425 1.001  3000
res[23]     9.664  11.740 -13.656   1.865   9.491  17.451  33.025 1.001  3000
res[24]    14.399  11.768  -8.920   6.550  14.224  22.160  38.381 1.001  3000
res[25]   -17.459  11.814 -40.240 -25.508 -17.731  -9.597   5.503 1.001  3000
res[26]     2.112  11.834 -20.695  -5.859   1.791   9.903  25.291 1.001  3000
res[27]    25.119  11.869   2.237  17.073  24.856  33.014  48.190 1.001  3000
res[28]   -12.783  11.927 -36.486 -21.081 -12.685  -4.484  10.101 1.002  1600
res[29]     7.751  11.951 -16.443  -0.606   7.820  16.063  30.397 1.001  2100
res[30]    12.866  11.971 -10.922   4.637  12.799  21.163  36.114 1.002  1600
res[31]   -23.404  11.959 -47.054 -31.381 -23.430 -15.471  -0.221 1.002  1200
res[32]    10.809  11.960 -12.765   2.757  10.883  18.657  33.990 1.002  1400
res[33]    17.359  11.972  -6.134   9.343  17.364  25.293  40.617 1.002  1100
res[34]   -19.997  11.800 -42.736 -28.106 -20.202 -12.124   3.343 1.002  2500
res[35]     6.359  11.812 -16.232  -1.893   6.081  14.115  29.804 1.002  1900
res[36]    19.960  11.807  -2.519  11.753  19.730  27.900  43.458 1.002  2600
res[37]   -19.902  11.980 -43.600 -27.871 -19.843 -12.058   3.587 1.001  3000
res[38]     5.059  12.005 -18.429  -3.025   5.164  12.756  28.837 1.001  3000
res[39]    20.566  11.996  -3.070  12.608  20.634  28.366  44.009 1.001  3000
res[40]   -16.847  11.831 -39.884 -24.766 -17.012  -9.239   6.596 1.001  3000
res[41]     5.057  11.855 -18.074  -2.883   4.927  12.687  28.394 1.001  3000
res[42]    20.042  11.830  -3.241  12.206  20.003  27.718  43.766 1.001  3000
res[43]   -26.596  11.746 -49.680 -34.580 -26.349 -18.627  -3.862 1.001  3000
res[44]    10.592  11.735 -12.047   2.531  10.659  18.547  33.288 1.001  3000
res[45]    22.535  11.759  -0.427  14.411  22.577  30.481  45.274 1.001  3000
res[46]   -18.234  12.031 -41.669 -26.696 -18.076  -9.978   4.443 1.002  1200
res[47]    10.165  12.061 -13.282   1.662  10.365  18.474  33.054 1.002  1500
res[48]    15.501  12.060  -7.938   7.051  15.690  23.578  38.325 1.002  1200
res[49]   -21.296  11.891 -44.247 -29.499 -21.509 -13.441   2.004 1.002  1000
res[50]     7.208  11.902 -15.618  -0.939   6.981  15.152  30.441 1.002   860
res[51]    21.986  11.895  -0.592  13.867  21.799  29.853  45.640 1.002  1000
res[52]   -22.104  11.729 -44.941 -29.987 -22.312 -14.241   1.133 1.001  3000
res[53]     9.556  11.751 -13.024   1.751   9.257  17.457  33.011 1.001  3000
res[54]    19.797  11.734  -2.966  11.838  19.629  27.542  43.295 1.001  3000
res[55]   -12.918  12.097 -35.949 -21.363 -12.982  -4.866  11.578 1.001  3000
res[56]     3.979  12.106 -19.166  -4.374   3.889  12.063  28.610 1.001  3000
res[57]    17.484  12.122  -5.688   8.981  17.300  25.557  42.114 1.001  3000
res[58]   -18.315  11.797 -41.135 -26.620 -18.209 -10.520   4.471 1.001  3000
res[59]     5.862  11.815 -16.900  -2.341   6.146  13.803  29.023 1.001  3000
res[60]    19.383  11.783  -3.464  11.144  19.447  27.072  42.559 1.001  3000
res[61]   -15.105  11.900 -38.125 -22.888 -15.284  -7.276   8.233 1.001  3000
res[62]     9.306  11.923 -13.585   1.507   9.128  17.140  32.775 1.001  3000
res[63]    16.323  11.956  -6.322   8.357  16.116  24.316  39.779 1.001  3000
res[64]   -20.915  11.793 -44.085 -28.598 -21.048 -13.147   2.444 1.001  3000
res[65]     0.307  11.820 -22.750  -7.598   0.334   7.975  23.864 1.001  3000
res[66]    25.298  11.813   2.156  17.551  25.247  33.151  48.893 1.001  3000
res[67]   -29.443  11.830 -52.213 -37.430 -29.692 -21.434  -6.575 1.001  3000
res[68]    10.936  11.848 -11.706   2.810  10.811  18.885  33.881 1.001  3000
res[69]    25.850  11.873   2.835  17.722  25.645  33.821  48.845 1.001  3000
res[70]   -26.142  11.991 -49.697 -34.072 -26.243 -18.049  -2.711 1.001  2300
res[71]    13.963  11.984  -9.101   6.160  13.990  22.029  37.049 1.001  3000
res[72]    18.211  12.015  -4.983  10.314  18.104  26.258  41.685 1.001  2300
res[73]   -20.794  11.932 -43.963 -28.725 -20.938 -12.958   3.106 1.002  1600
res[74]     8.870  11.937 -14.459   0.895   8.787  16.905  32.822 1.001  2000
res[75]    17.504  11.929  -5.274   9.402  17.317  25.457  41.765 1.002  1600
res[76]   -21.046  11.851 -44.910 -28.922 -21.131 -12.843   2.003 1.002  3000
res[77]     3.675  11.857 -19.985  -4.059   3.613  11.706  27.196 1.003  3000
res[78]    23.492  11.881  -0.028  15.552  23.399  31.576  46.776 1.003  3000
res[79]   -12.603  11.937 -35.961 -20.361 -12.719  -4.579  10.948 1.002  2900
res[80]    -0.163  11.955 -23.303  -8.120  -0.343   7.789  23.405 1.002  2200
res[81]    19.279  11.963  -4.001  11.319  19.160  27.293  42.755 1.002  3000
res[82]   -16.766  11.961 -39.955 -24.721 -16.887  -9.030   6.016 1.001  3000
res[83]    10.426  11.958 -13.000   2.504  10.510  18.221  32.859 1.001  3000
res[84]    12.792  11.939 -10.192   4.873  12.720  20.537  35.661 1.001  3000
res[85]   -21.347  11.725 -44.125 -28.923 -21.164 -13.609   1.848 1.001  3000
res[86]     7.224  11.690 -15.758  -0.362   7.382  15.079  30.544 1.001  3000
res[87]    20.510  11.739  -2.412  12.708  20.647  28.327  43.283 1.001  3000
res[88]   -23.140  11.838 -46.005 -31.274 -23.099 -15.502  -0.066 1.001  3000
res[89]    12.983  11.858  -9.972   4.729  13.009  20.680  36.860 1.001  3000
res[90]    15.293  11.892  -7.122   6.928  15.405  23.032  38.696 1.001  3000
res[91]   -13.173  11.935 -36.126 -21.376 -13.267  -5.416  10.293 1.001  3000
res[92]     5.694  11.935 -17.082  -2.485   5.640  13.450  29.247 1.001  3000
res[93]    13.708  11.936  -9.020   5.488  13.624  21.589  37.402 1.001  3000
res[94]    -9.013  11.766 -31.685 -16.863  -9.233  -1.091  14.418 1.001  3000
res[95]     2.073  11.780 -20.569  -5.756   1.871   9.830  25.639 1.001  3000
res[96]    14.717  11.782  -8.181   6.737  14.422  22.602  37.767 1.001  3000
res[97]   -18.561  11.906 -41.914 -26.360 -18.779 -10.492   4.073 1.002  1300
res[98]     5.213  11.908 -18.272  -2.559   5.068  13.190  28.414 1.002  1100
res[99]    19.285  11.939  -4.469  11.483  19.203  27.469  42.441 1.002  1300
res[100]  -18.547  12.018 -42.274 -26.484 -18.430 -10.631   5.083 1.001  3000
res[101]    7.907  12.020 -16.041  -0.084   8.072  15.733  31.471 1.001  3000
res[102]   18.379  12.034  -5.679  10.333  18.514  26.429  41.930 1.001  3000
res[103]  -21.652  12.104 -45.310 -29.603 -21.605 -13.692   1.709 1.001  2500
res[104]   18.537  12.095  -5.105  10.797  18.645  26.404  42.117 1.001  1900
res[105]   13.256  12.137 -10.949   5.489  13.253  21.341  36.897 1.001  2600
sigma      20.838   1.809  17.597  19.556  20.736  21.936  24.751 1.002  1000
sigma.B    63.500   7.812  50.201  58.005  62.978  68.138  80.806 1.001  3000
deviance  934.350  11.459 914.767 926.442 933.465 941.520 959.367 1.004   460

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 65.5 and DIC = 999.9
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For a simple model with only two hierarchical levels, the model is the same as above. If you want to include finite-population standard deviations in the model you can use the following code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString3=&amp;quot;
+ model {
+    #Likelihood (esimating site means (gamma.site)
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- gamma[Block[i]] + inprod(beta[], X[i,]) 
+       y.err[i]&amp;lt;- mu[i]-y[i]
+    }
+    for (i in 1:nBlock) {
+       gamma[i] ~ dnorm(0, tau.block)
+    }
+    #Priors
+    for (i in 1:nX) {
+      beta[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    sigma ~ dunif(0, 100)
+    tau &amp;lt;- 1 / (sigma * sigma)
+    sigma.block ~ dunif(0, 100)
+    tau.block &amp;lt;- 1 / (sigma.block * sigma.block)
+ 
+    sd.y &amp;lt;- sd(y.err)
+    sd.block &amp;lt;- sd(gamma)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString3, con = &amp;quot;SDModel.txt&amp;quot;)
&amp;gt; 
&amp;gt; #data list
&amp;gt; A.Xmat &amp;lt;- model.matrix(~A,ddply(data.rcb,~Block,catcolwise(unique)))
&amp;gt; data.rcb.list &amp;lt;- with(data.rcb,
+         list(y=y,
+                  Block=Block,
+          X= A.Xmat,
+          n=nrow(data.rcb),
+          nBlock=length(levels(Block)),
+                  nX = ncol(A.Xmat)
+          )
+ )
&amp;gt; 
&amp;gt; #parameters and chain details
&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sd.y&amp;quot;,&amp;#39;sd.block&amp;#39;,&amp;#39;sigma.block&amp;#39;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.rcb.r2jagsSD &amp;lt;- jags(data = data.rcb.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;SDModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 105
   Unobserved stochastic nodes: 40
   Total graph size: 899

Initializing model
&amp;gt; 
&amp;gt; print(data.rcb.r2jagsSD)
Inference for Bugs model at &amp;quot;SDModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
            mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]      41.715   2.196  37.449  40.231  41.710  43.183  45.995 1.001  3000
beta[2]      27.928   1.209  25.537  27.146  27.918  28.713  30.317 1.002   980
beta[3]      40.272   1.210  37.832  39.461  40.267  41.096  42.658 1.001  2300
sd.block     11.358   0.519  10.353  11.029  11.345  11.706  12.370 1.001  3000
sd.y          5.014   0.260   4.592   4.827   4.986   5.172   5.609 1.002  1300
sigma         5.074   0.443   4.322   4.752   5.045   5.350   6.036 1.001  3000
sigma.block  11.692   1.546   9.114  10.589  11.586  12.612  15.118 1.002  3000
deviance    637.262  10.949 618.392 629.413 636.321 644.252 660.930 1.001  2200

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 59.9 and DIC = 697.2
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calculate &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; from the posterior of the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.mcmc.listSD &amp;lt;- as.mcmc(data.rcb.r2jagsSD)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~A, data.rcb)
&amp;gt; coefs &amp;lt;- data.rcb.r2jagsSD$BUGSoutput$sims.list[[&amp;#39;beta&amp;#39;]]
&amp;gt; fitted &amp;lt;- coefs %*% t(Xmat)
&amp;gt; X.var &amp;lt;- aaply(fitted,1,function(x){var(x)})
&amp;gt; Z.var &amp;lt;- data.rcb.r2jagsSD$BUGSoutput$sims.list[[&amp;#39;sd.block&amp;#39;]]^2
&amp;gt; R.var &amp;lt;- data.rcb.r2jagsSD$BUGSoutput$sims.list[[&amp;#39;sd.y&amp;#39;]]^2
&amp;gt; R2.marginal &amp;lt;- (X.var)/(X.var+Z.var+R.var)
&amp;gt; R2.marginal &amp;lt;- data.frame(Mean=mean(R2.marginal), Median=median(R2.marginal), HPDinterval(as.mcmc(R2.marginal)))
&amp;gt; R2.conditional &amp;lt;- (X.var+Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.conditional &amp;lt;- data.frame(Mean=mean(R2.conditional),
+    Median=median(R2.conditional), HPDinterval(as.mcmc(R2.conditional)))
&amp;gt; R2.block &amp;lt;- (Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.block &amp;lt;- data.frame(Mean=mean(R2.block), Median=median(R2.block), HPDinterval(as.mcmc(R2.block)))
&amp;gt; R2.res&amp;lt;-(R.var)/(X.var+Z.var+R.var)
&amp;gt; R2.res &amp;lt;- data.frame(Mean=mean(R2.res), Median=median(R2.res), HPDinterval(as.mcmc(R2.res)))
&amp;gt; 
&amp;gt; rbind(R2.block=R2.block, R2.marginal=R2.marginal, R2.res=R2.res, R2.conditional=R2.conditional)
                    Mean     Median      lower      upper
R2.block       0.2927774 0.29248056 0.24902731 0.33605200
R2.marginal    0.6500204 0.65101312 0.60509352 0.68965593
R2.res         0.0572022 0.05628758 0.04596228 0.07055798
R2.conditional 0.9427978 0.94371242 0.92944202 0.95403772&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;planned-comparisonsand-pairwise-tests&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Planned comparisonsand pairwise tests&lt;/h2&gt;
&lt;p&gt;Since there are no restrictions on the type and number of comparisons derived from the posteriors, Bayesian analyses provide a natural framework for exploring additional contrasts and comparisons. For example, to compare all possible levels:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; coefs &amp;lt;- data.rcb.r2jags.m$BUGSoutput$sims.list[[c(&amp;#39;beta&amp;#39;)]]
&amp;gt; head(coefs)
           [,1]        [,2]       [,3]
[1,] -1.0697767 -0.46647636  0.4808020
[2,]  0.6186153  1.46210386  2.3592529
[3,] -1.5100302  0.09180824  1.1835869
[4,] -0.3127107  0.66392714 -0.5681012
[5,]  1.5552936  1.06785499  2.6443403
[6,]  0.7282182  0.59829747  2.8548669
&amp;gt; 
&amp;gt; newdata &amp;lt;- data.frame(A=levels(data.rcb$A))
&amp;gt; # A Tukeys contrast matrix
&amp;gt; library(multcomp)
&amp;gt; tuk.mat &amp;lt;- contrMat(n=table(newdata$A), type=&amp;quot;Tukey&amp;quot;)
&amp;gt; Xmat &amp;lt;- model.matrix(~A, data=newdata)
&amp;gt; pairwise.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; pairwise.mat
      (Intercept) A2 A3
2 - 1           0  1  0
3 - 1           0  0  1
3 - 2           0 -1  1
&amp;gt; 
&amp;gt; comps &amp;lt;- coefs %*% t(pairwise.mat)
&amp;gt; 
&amp;gt; MCMCsum &amp;lt;- function(x) {
+    data.frame(Median=median(x, na.rm=TRUE), t(quantile(x,na.rm=TRUE)),
+               HPDinterval(as.mcmc(x)),HPDinterval(as.mcmc(x),p=0.5))
+ }
&amp;gt; 
&amp;gt; (comps &amp;lt;-plyr:::adply(comps,2,MCMCsum))
     X1    Median       X0.         X25.      X50.     X75.    X100.      lower
1 2 - 1 0.6093838 -2.556240 -0.020575421 0.6093838 1.267051 4.786166 -1.2766747
2 3 - 1 1.5638199 -1.833977  0.886430287 1.5638199 2.248195 4.835948 -0.4024791
3 3 - 2 0.9310770 -4.672228 -0.003765539 0.9310770 1.864871 5.592247 -1.5970184
     upper     lower.1  upper.1
1 2.479999  0.03512204 1.316762
2 3.539364  0.92897200 2.273364
3 3.728297 -0.03345687 1.823124&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;rcb-repeated-measures---continuous-within&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;RCB (repeated measures) - continuous within&lt;/h1&gt;
&lt;div id=&#34;data-generation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Imagine now that we has designed an experiment to investigate the effects of a continuous predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, for example time) on a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;). Again, the system that we intend to sample is spatially heterogeneous and thus will add a great deal of noise to the data that will make it difficult to detect a signal (impact of treatment). Thus in an attempt to constrain this variability, we again decide to apply a design (RCB) in which each of the levels of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; (such as time) treatments within each of &lt;span class=&#34;math inline&#34;&gt;\(35\)&lt;/span&gt; blocks dispersed randomly throughout the landscape. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; slope &amp;lt;- 30
&amp;gt; intercept &amp;lt;- 200
&amp;gt; nBlock &amp;lt;- 35
&amp;gt; nTime &amp;lt;- 10
&amp;gt; sigma &amp;lt;- 50
&amp;gt; sigma.block &amp;lt;- 30
&amp;gt; n &amp;lt;- nBlock*nTime
&amp;gt; Block &amp;lt;- gl(nBlock, k=1)
&amp;gt; Time &amp;lt;- 1:10
&amp;gt; rho &amp;lt;- 0.8
&amp;gt; dt &amp;lt;- expand.grid(Time=Time,Block=Block)
&amp;gt; Xmat &amp;lt;- model.matrix(~-1+Block + Time, data=dt)
&amp;gt; block.effects &amp;lt;- rnorm(n = nBlock, mean = intercept, sd = sigma.block)
&amp;gt; #A.effects &amp;lt;- c(30,40)
&amp;gt; all.effects &amp;lt;- c(block.effects,slope)
&amp;gt; lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; # OR
&amp;gt; Xmat &amp;lt;- cbind(model.matrix(~-1+Block,data=dt),model.matrix(~Time,data=dt))
&amp;gt; ## Sum to zero block effects
&amp;gt; ##block.effects &amp;lt;- rnorm(n = nBlock, mean = 0, sd = sigma.block)
&amp;gt; ###A.effects &amp;lt;- c(40,70,80)
&amp;gt; ##all.effects &amp;lt;- c(block.effects,intercept,slope)
&amp;gt; ##lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; ## the quadrat observations (within sites) are drawn from
&amp;gt; ## normal distributions with means according to the site means
&amp;gt; ## and standard deviations of 5
&amp;gt; eps &amp;lt;- NULL
&amp;gt; eps[1] &amp;lt;- 0
&amp;gt; for (j in 2:n) {
+   eps[j] &amp;lt;- rho*eps[j-1] #residuals
+ }
&amp;gt; y &amp;lt;- rnorm(n,lin.pred,sigma)+eps
&amp;gt; 
&amp;gt; #OR
&amp;gt; eps &amp;lt;- NULL
&amp;gt; # first value cant be autocorrelated
&amp;gt; eps[1] &amp;lt;- rnorm(1,0,sigma)
&amp;gt; for (j in 2:n) {
+   eps[j] &amp;lt;- rho*eps[j-1] + rnorm(1, mean = 0, sd = sigma)  #residuals
+ }
&amp;gt; y &amp;lt;- lin.pred + eps
&amp;gt; data.rm &amp;lt;- data.frame(y=y, dt)
&amp;gt; head(data.rm)  #print out the first six rows of the data set
         y Time Block
1 282.1142    1     1
2 321.1404    2     1
3 278.7700    3     1
4 285.8709    4     1
5 336.6390    5     1
6 333.5961    6     1
&amp;gt; 
&amp;gt; ggplot(data.rm, aes(y=y, x=Time)) + geom_smooth(method=&amp;#39;lm&amp;#39;) + geom_point() + facet_wrap(~Block)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/generate_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y~Time, data.rm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp1_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data.rm, aes(y=y, x=factor(Time))) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp1_data_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Block by within-Block interaction&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; with(data.rm, interaction.plot(Time,Block,y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data.rm, aes(y=y, x=Time, color=Block, group=Block)) + geom_line() +
+   guides(color=guide_legend(ncol=3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; residualPlots(lm(y~Block+Time, data.rm))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp2_data_ex2-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;           Test stat Pr(&amp;gt;|Test stat|)
Block                                
Time         -0.7274           0.4675
Tukey test   -0.9809           0.3267
&amp;gt; 
&amp;gt; # the Tukey&amp;#39;s non-additivity test by itself can be obtained via an internal function
&amp;gt; # within the car package
&amp;gt; car:::tukeyNonaddTest(lm(y~Block+Time, data.rm))
      Test     Pvalue 
-0.9808606  0.3266615 
&amp;gt; 
&amp;gt; # alternatively, there is also a Tukey&amp;#39;s non-additivity test within the
&amp;gt; # asbio package
&amp;gt; with(data.rm,tukey.add.test(y,Time,Block))

Tukey&amp;#39;s one df test for additivity 
F = 0.3997341   Denom df = 305    p-value = 0.5277003&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there is no visual or inferential evidence of any major interactions between Block and the within-Block effect (Time). Any trends appear to be reasonably consistent between Blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Sphericity&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Since the levels of Time cannot be randomly assigned, it is likely that sphericity is not met. We can explore whether there is an auto-correlation patterns in the residuals. Note, as there was only ten time periods, it does not make logical sense to explore lags above &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(nlme)
&amp;gt; data.rm.lme &amp;lt;- lme(y~Time, random=~1|Block, data=data.rm)
&amp;gt; acf(resid(data.rm.lme), lag=10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/exp3_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;The autocorrelation factor (ACF) at a range of lags up to &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;, indicate that there is a cyclical pattern of residual auto-correlation. We really should explore incorporating some form of correlation structure into our model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;full-effect-parameterisation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full effect parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- beta0 + beta*Time[i] + gamma[Block[i]]
+       res[i] &amp;lt;- y[i]-mu[i]
+    }
+    
+    #Priors
+    beta0 ~ dnorm(0, 1.0E-6)
+    beta ~ dnorm(0, 1.0E-6) #prior
+    
+    for (i in 1:nBlock) {
+      gamma[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;- z/sqrt(chSq) 
+    z ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;- z/sqrt(chSq.B) 
+    z.B ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.B ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;fullModel2.txt&amp;quot;)
&amp;gt; 
&amp;gt; data.rm.list &amp;lt;- with(data.rm,
+         list(y=y,
+                  Block=as.numeric(Block),
+          Time=Time,
+          n=nrow(data.rm),
+          nBlock=length(levels(Block))
+              )
+ )
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;quot;beta0&amp;quot;,&amp;quot;beta&amp;quot;,&amp;#39;gamma&amp;#39;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;quot;res&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.rm.r2jags.f &amp;lt;- jags(data = data.rm.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;fullModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 350
   Unobserved stochastic nodes: 41
   Total graph size: 1815

Initializing model
&amp;gt; 
&amp;gt; print(data.rm.r2jags.f)
Inference for Bugs model at &amp;quot;fullModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
           mu.vect sd.vect     2.5%      25%      50%      75%    97.5%  Rhat
beta        30.689   1.047   28.609   30.017   30.687   31.401   32.705 1.001
beta0      189.009  12.648  164.589  180.318  189.054  197.523  213.976 1.001
gamma[1]   -35.015  20.219  -74.991  -47.706  -35.021  -21.382    3.826 1.002
gamma[2]   -52.026  20.114  -91.663  -65.012  -52.008  -38.575  -12.685 1.001
gamma[3]    20.417  19.878  -19.313    7.462   20.587   33.579   60.228 1.001
gamma[4]     0.671  20.295  -38.799  -12.839    0.882   14.490   39.807 1.001
gamma[5]    67.812  19.967   29.683   54.189   67.514   81.150  109.392 1.001
gamma[6]    36.338  19.760   -2.575   22.780   36.203   49.381   76.772 1.001
gamma[7]    24.072  20.155  -14.701   10.740   24.009   36.728   63.397 1.001
gamma[8]   -31.199  20.016  -70.564  -44.687  -31.149  -17.691    7.011 1.001
gamma[9]    73.971  20.034   35.053   60.309   73.846   87.726  113.132 1.003
gamma[10]   58.034  19.900   19.397   44.730   58.085   71.380   97.283 1.001
gamma[11]  141.644  20.387  101.956  127.950  141.240  154.897  181.751 1.001
gamma[12]    5.655  20.094  -32.833   -7.787    5.349   19.065   47.017 1.001
gamma[13]  -44.187  20.168  -84.778  -57.576  -44.641  -30.571   -5.599 1.001
gamma[14]  -23.866  19.908  -63.673  -37.311  -23.653  -10.578   14.435 1.001
gamma[15]   30.407  20.239   -8.109   16.928   30.379   43.830   70.587 1.001
gamma[16]  103.433  20.123   64.608   90.052  103.087  116.736  143.495 1.002
gamma[17]   91.556  20.060   53.115   77.561   91.725  104.473  131.814 1.002
gamma[18]  -63.563  20.127 -102.913  -77.195  -63.210  -50.190  -24.916 1.002
gamma[19]   16.404  19.820  -21.892    2.880   16.232   29.420   55.497 1.001
gamma[20]  -26.858  19.837  -66.283  -39.890  -26.676  -13.651   12.760 1.002
gamma[21] -104.771  19.743 -143.174 -117.701 -105.347  -92.448  -64.620 1.001
gamma[22]  -14.307  19.903  -54.617  -27.704  -14.041   -0.901   23.918 1.001
gamma[23]  -81.493  19.863 -121.932  -94.860  -81.367  -67.618  -43.350 1.001
gamma[24]  -86.520  20.067 -125.826 -100.133  -86.297  -73.003  -47.481 1.001
gamma[25]  -47.166  20.417  -86.549  -61.568  -47.155  -33.479   -6.020 1.001
gamma[26]  -92.375  19.497 -130.380 -105.540  -92.310  -79.043  -54.017 1.002
gamma[27]   20.875  20.031  -18.328    6.625   20.873   34.275   60.661 1.002
gamma[28]   74.464  19.909   36.179   61.091   74.369   87.433  114.480 1.001
gamma[29]   -0.792  19.771  -39.202  -14.402   -0.589   12.677   36.999 1.001
gamma[30]  -75.855  20.350 -116.077  -89.286  -76.179  -62.465  -35.911 1.001
gamma[31]  -58.457  20.104  -97.479  -72.394  -58.390  -44.695  -19.492 1.001
gamma[32]  -53.274  20.080  -91.482  -66.984  -53.201  -40.309  -13.057 1.001
gamma[33]   15.405  20.131  -22.770    1.695   15.048   28.831   55.869 1.001
gamma[34]   59.338  20.334   19.750   45.810   59.517   72.790   99.194 1.001
gamma[35]   56.933  20.301   15.197   43.906   57.388   70.588   94.583 1.001
res[1]      97.432  17.921   62.629   85.359   97.337  109.111  134.580 1.002
res[2]     105.769  17.698   71.182   93.805  105.826  117.408  142.144 1.002
res[3]      32.710  17.534   -1.148   20.909   32.522   44.178   68.460 1.002
res[4]       9.121  17.431  -23.865   -2.637    8.871   20.532   44.239 1.002
res[5]      29.201  17.391   -4.021   17.641   28.835   40.540   64.071 1.002
res[6]      -4.531  17.414  -38.094  -16.092   -4.863    6.832   30.205 1.002
res[7]    -107.185  17.500 -140.651 -118.950 -107.516  -95.741  -72.125 1.002
res[8]     -37.350  17.647  -71.015  -49.217  -37.556  -25.708   -1.746 1.002
res[9]     -67.307  17.855 -101.635  -79.246  -67.326  -55.699  -31.035 1.002
res[10]    -78.614  18.121 -113.985  -90.735  -78.654  -66.764  -42.063 1.002
res[11]     49.884  18.193   13.728   37.834   50.102   61.789   84.845 1.001
res[12]     11.595  17.930  -23.183   -0.446   11.692   23.269   46.321 1.001
res[13]     61.820  17.726   27.566   49.860   61.924   73.375   96.299 1.001
res[14]     -3.458  17.582  -37.401  -15.192   -3.465    8.046   30.969 1.001
res[15]    -10.511  17.499  -44.587  -21.767  -10.459    1.089   24.112 1.001
res[16]     -2.243  17.479  -36.572  -13.604   -2.049    9.337   32.255 1.001
res[17]    -50.520  17.522  -85.179  -61.867  -50.373  -38.782  -16.278 1.001
res[18]    -62.585  17.627  -97.953  -73.969  -62.501  -50.564  -28.305 1.001
res[19]    -42.079  17.792  -77.762  -53.482  -42.166  -30.142   -7.621 1.001
res[20]      9.165  18.018  -26.988   -2.455    9.147   21.271   43.778 1.001
res[21]    -77.926  17.501 -113.047  -89.469  -78.006  -66.052  -43.688 1.002
res[22]    -73.189  17.257 -108.057  -84.536  -73.411  -61.442  -39.850 1.002
res[23]    -14.228  17.075  -48.379  -25.553  -14.413   -2.773   18.665 1.002
res[24]    -31.958  16.955  -66.594  -43.263  -32.141  -20.655    0.554 1.002
res[25]     -7.975  16.900  -42.439  -19.028   -8.192    3.408   24.762 1.002
res[26]     24.320  16.909   -9.262   13.308   24.202   35.576   57.313 1.002
res[27]     38.799  16.983    5.216   27.563   38.571   50.247   72.421 1.002
res[28]     69.516  17.120   35.582   58.330   69.291   80.872  103.259 1.002
res[29]     55.153  17.321   20.895   43.887   54.848   66.615   89.335 1.002
res[30]     28.976  17.581   -5.726   17.342   28.565   40.577   63.635 1.002
res[31]   -121.587  17.872 -156.152 -133.567 -121.526 -109.634  -87.382 1.001
res[32]   -100.256  17.618 -133.884 -111.966 -100.063  -88.659  -66.409 1.001
res[33]    -57.168  17.423  -90.542  -68.902  -57.110  -45.627  -22.964 1.001
res[34]    -17.580  17.290  -51.232  -29.462  -17.603   -6.075   16.449 1.001
res[35]    -40.581  17.219  -74.430  -52.498  -40.599  -29.045   -6.738 1.001
res[36]     57.619  17.212   23.794   45.812   57.457   69.114   91.210 1.001
res[37]     61.388  17.269   27.008   49.782   61.277   72.884   95.367 1.004
res[38]     56.259  17.389   21.473   44.753   56.294   67.702   90.416 1.001
res[39]    109.316  17.570   73.992   97.577  109.390  120.643  143.528 1.001
res[40]     52.088  17.811   16.206   39.944   52.135   63.655   86.709 1.001
res[41]    -38.914  17.643  -73.656  -50.658  -38.634  -26.860   -5.046 1.001
res[42]     77.326  17.420   42.616   65.720   77.575   89.215  111.120 1.001
res[43]     50.865  17.258   16.915   39.497   51.222   62.617   84.564 1.001
res[44]    110.679  17.159   76.469   99.239  111.186  122.203  144.204 1.001
res[45]      4.790  17.122  -29.711   -6.616    5.343   16.301   38.330 1.001
res[46]    -17.661  17.150  -52.491  -29.227  -17.113   -5.957   16.017 1.001
res[47]     -7.311  17.242  -42.494  -18.933   -6.757    4.462   26.166 1.001
res[48]     -3.089  17.396  -38.865  -14.616   -2.473    8.846   31.113 1.001
res[49]    -65.133  17.611 -101.697  -76.777  -64.519  -53.174  -30.398 1.001
res[50]    -63.661  17.886 -100.707  -75.693  -63.048  -51.501  -28.264 1.001
res[51]    -31.518  17.144  -65.465  -43.209  -31.355  -19.712    1.672 1.001
res[52]     14.815  16.893  -18.897    3.470   14.776   26.305   47.890 1.001
res[53]     70.347  16.704   36.921   58.939   70.092   81.766  102.877 1.001
res[54]    -50.853  16.579  -83.834  -62.055  -51.073  -39.619  -18.942 1.001
res[55]     25.083  16.520   -8.057   14.027   24.935   36.357   56.754 1.001
res[56]    -38.143  16.527  -71.222  -49.423  -38.357  -26.836   -6.450 1.001
res[57]     -4.070  16.600  -36.763  -15.317   -4.236    7.197   27.724 1.001
res[58]     33.306  16.738    0.513   22.191   33.191   44.522   65.598 1.001
res[59]     20.080  16.940  -12.937    8.828   19.836   31.550   52.764 1.001
res[60]    -12.900  17.204  -46.161  -24.276  -13.088   -1.463   20.472 1.001
res[61]    -17.368  17.885  -51.348  -29.241  -17.425   -5.291   18.072 1.001
res[62]      7.369  17.652  -26.193   -4.253    7.234   19.236   42.448 1.001
res[63]     49.245  17.479   15.639   37.647   49.046   60.880   83.698 1.001
res[64]    -64.174  17.368  -97.742  -75.711  -64.357  -52.534  -30.120 1.001
res[65]   -134.249  17.320 -167.266 -146.107 -134.437 -122.586 -100.604 1.001
res[66]    -37.107  17.334  -70.680  -48.991  -37.270  -25.543   -3.298 1.001
res[67]     21.279  17.412  -12.492    9.532   21.267   33.096   55.105 1.001
res[68]     37.284  17.552    3.245   25.564   37.265   49.184   71.420 1.001
res[69]     63.944  17.753   29.095   52.068   63.864   75.938   98.781 1.001
res[70]     95.234  18.013   60.203   83.123   95.270  107.455  130.632 1.001
res[71]    -48.396  17.620  -83.102  -60.471  -48.230  -36.426  -13.894 1.001
res[72]     16.818  17.403  -17.131    4.932   16.936   28.621   50.566 1.001
res[73]    -10.912  17.247  -44.871  -22.609  -10.795    0.606   22.307 1.001
res[74]      2.547  17.154  -31.372   -8.982    2.664   14.012   35.509 1.001
res[75]    -13.113  17.125  -47.212  -24.603  -12.951   -1.578   20.054 1.001
res[76]     32.577  17.159   -1.807   20.989   32.596   44.219   65.805 1.001
res[77]      7.970  17.257  -27.008   -3.791    7.911   19.682   41.186 1.001
res[78]     31.495  17.418   -3.602   19.914   31.400   43.395   65.506 1.001
res[79]      4.718  17.639  -30.550   -6.860    4.806   16.702   39.109 1.001
res[80]    -51.946  17.919  -87.119  -63.726  -51.922  -39.897  -17.025 1.001
res[81]    -63.210  17.647  -97.791  -75.690  -63.212  -51.190  -29.440 1.002
res[82]    -31.067  17.390  -65.386  -43.236  -31.079  -19.273    2.374 1.002
res[83]     43.678  17.193    9.558   31.772   43.540   55.495   76.981 1.002
res[84]     20.380  17.058  -13.497    8.805   20.360   32.176   53.934 1.002
res[85]     54.597  16.986   21.096   43.276   54.749   66.249   87.971 1.002
res[86]    124.353  16.979   90.938  113.063  124.583  135.902  157.927 1.002
res[87]     67.176  17.037   33.903   55.809   67.439   78.691  101.104 1.002
res[88]    -30.778  17.158  -64.046  -42.370  -30.407  -19.292    2.913 1.002
res[89]    -55.098  17.342  -88.751  -66.851  -54.716  -43.392  -21.208 1.002
res[90]    -73.427  17.586 -107.590  -85.203  -73.116  -61.615  -38.693 1.002
res[91]    -39.879  17.759  -75.389  -51.772  -39.985  -28.068   -4.896 1.001
res[92]     40.803  17.486    5.829   29.249   40.623   52.320   75.462 1.001
res[93]      3.288  17.272  -30.880   -8.346    3.017   14.813   37.091 1.001
res[94]      8.096  17.120  -26.071   -3.487    7.840   19.496   41.421 1.001
res[95]    -18.230  17.031  -51.683  -29.609  -18.372   -6.678   14.819 1.001
res[96]    -27.022  17.006  -60.187  -38.426  -27.134  -15.863    6.296 1.001
res[97]    -19.513  17.045  -52.825  -30.880  -19.632   -8.423   13.668 1.001
res[98]     37.064  17.149    3.831   25.570   37.124   48.265   70.659 1.001
res[99]     21.843  17.315  -12.203   10.180   21.878   33.093   55.675 1.001
res[100]    39.105  17.542    5.025   27.487   38.948   50.788   73.056 1.001
res[101]    29.449  17.991   -5.205   17.155   29.781   41.807   63.442 1.001
res[102]    49.685  17.766   15.218   37.673   50.072   61.814   82.819 1.001
res[103]    -8.723  17.601  -43.029  -20.739   -8.303    3.244   24.590 1.001
res[104]    54.477  17.498   20.833   42.653   54.759   66.407   87.773 1.001
res[105]     4.508  17.456  -29.390   -7.159    4.817   16.421   37.676 1.001
res[106]   -21.847  17.477  -55.720  -33.395  -21.535   -9.860   11.772 1.001
res[107]    32.423  17.561   -2.084   20.791   32.811   44.448   66.578 1.001
res[108]    70.203  17.706   35.619   58.406   70.311   82.156  104.571 1.001
res[109]   -18.915  17.912  -54.616  -30.740  -18.911   -6.868   15.481 1.001
res[110]   -79.501  18.176 -115.834  -91.501  -79.578  -67.080  -44.590 1.001
res[111]   -35.407  17.785  -70.692  -46.976  -35.584  -23.160   -0.930 1.001
res[112]   -16.834  17.533  -51.394  -28.356  -17.011   -4.647   17.012 1.001
res[113]    -2.964  17.342  -37.311  -14.283   -3.253    9.068   30.829 1.001
res[114]    17.958  17.211  -16.244    6.888   17.697   29.740   51.566 1.001
res[115]    43.960  17.144    9.743   32.909   43.779   55.749   77.773 1.002
res[116]     6.922  17.141  -27.302   -4.089    6.746   18.522   41.245 1.002
res[117]   -42.437  17.202  -76.634  -53.389  -42.592  -31.097   -7.471 1.002
res[118]    18.962  17.325  -15.305    7.723   18.882   30.432   53.655 1.003
res[119]    54.157  17.511   19.505   42.669   54.007   65.841   88.924 1.003
res[120]   -30.836  17.757  -66.091  -42.472  -31.031  -18.943    4.597 1.003
res[121]    29.694  17.913   -5.583   17.603   29.789   41.163   65.302 1.001
res[122]    -8.428  17.668  -42.894  -20.446   -8.260    2.790   26.838 1.001
res[123]   -97.805  17.483 -132.040 -109.658  -97.722  -86.688  -63.003 1.001
res[124]   -58.400  17.360  -92.551  -70.268  -58.013  -47.184  -24.118 1.001
res[125]   -38.480  17.298  -72.858  -50.159  -38.072  -27.272   -4.162 1.001
res[126]   -23.590  17.301  -58.378  -35.298  -23.103  -12.266   10.906 1.001
res[127]     3.860  17.366  -31.068   -7.655    4.299   15.220   38.206 1.001
res[128]    58.998  17.494   23.758   47.395   59.472   70.391   93.062 1.001
res[129]    69.127  17.683   33.354   57.321   69.673   80.505  103.147 1.001
res[130]    35.991  17.931   -0.747   24.279   36.423   47.825   70.397 1.001
res[131]   -18.707  17.753  -53.599  -30.549  -18.607   -6.714   16.819 1.003
res[132]   -14.747  17.516  -48.954  -26.537  -14.555   -2.845   20.061 1.003
res[133]    10.374  17.340  -23.749   -1.370   10.597   22.133   44.664 1.003
res[134]   -37.152  17.225  -70.611  -48.839  -37.026  -25.712   -3.136 1.002
res[135]   -32.541  17.174  -65.860  -44.108  -32.536  -21.077    1.265 1.002
res[136]    28.588  17.186   -4.848   17.066   28.625   39.992   62.044 1.002
res[137]    23.576  17.262  -10.078   11.987   23.698   35.092   57.117 1.002
res[138]   -10.078  17.401  -43.670  -21.709   -9.920    1.610   23.933 1.001
res[139]   -16.016  17.601  -49.961  -27.799  -15.770   -4.358   18.774 1.001
res[140]    48.626  17.861   14.303   36.410   48.905   60.610   83.764 1.001
res[141]     4.593  17.780  -29.625   -7.191    4.424   16.505   38.788 1.001
res[142]    57.463  17.544   23.749   45.968   57.368   69.300   91.358 1.001
res[143]    44.743  17.368   11.543   33.225   44.780   56.414   78.495 1.001
res[144]    47.987  17.253   14.659   36.564   48.140   59.625   81.776 1.001
res[145]     2.009  17.202  -31.053   -9.596    2.094   13.679   35.963 1.001
res[146]    23.279  17.214   -9.893   11.605   23.253   34.820   57.175 1.001
res[147]   -15.427  17.290  -49.433  -27.118  -15.449   -4.007   19.070 1.001
res[148]   -92.242  17.428 -126.419 -104.123  -92.223  -80.822  -57.405 1.001
res[149]   -76.403  17.628 -110.319  -88.293  -76.440  -64.957  -41.280 1.001
res[150]    27.022  17.887   -7.788   14.991   26.934   38.901   62.553 1.001
res[151]    56.524  17.435   23.497   44.650   56.376   68.008   91.937 1.002
res[152]    94.888  17.193   62.473   83.265   94.748  106.107  129.551 1.001
res[153]    85.122  17.012   53.069   73.707   84.983   96.084  119.032 1.001
res[154]    28.800  16.893   -3.079   17.754   28.668   39.844   62.380 1.001
res[155]     3.921  16.839  -28.102   -7.248    3.904   15.053   37.301 1.001
res[156]   -19.671  16.850  -51.711  -30.814  -19.649   -8.511   13.270 1.001
res[157]   -48.454  16.926  -81.115  -59.563  -48.405  -37.301  -15.678 1.001
res[158]   -12.976  17.067  -46.088  -24.257  -12.925   -1.706   20.012 1.001
res[159]   -79.807  17.269 -113.216  -91.035  -79.682  -68.569  -46.865 1.001
res[160]   -30.224  17.532  -64.395  -41.789  -29.847  -18.816    2.893 1.001
res[161]   -10.710  17.984  -46.042  -22.979  -10.276    1.572   24.298 1.002
res[162]   -82.452  17.740 -118.119  -94.601  -82.059  -70.317  -47.916 1.002
res[163]   -48.077  17.555  -83.627  -59.974  -47.795  -35.994  -13.951 1.002
res[164]    68.821  17.431   33.752   56.976   68.995   80.691  102.233 1.005
res[165]    12.830  17.369  -22.123    1.019   12.897   24.719   45.628 1.002
res[166]    38.006  17.370    3.280   26.085   37.983   49.937   71.003 1.002
res[167]   -23.347  17.435  -58.240  -35.377  -23.237  -11.414    9.865 1.002
res[168]    22.078  17.561  -13.256    9.887   22.185   34.157   55.218 1.001
res[169]    15.237  17.749  -20.525    3.105   15.325   27.296   48.552 1.001
res[170]    79.730  17.996   43.542   67.295   79.674   91.820  113.635 1.002
res[171]    63.717  17.877   28.767   51.218   63.625   75.992   98.346 1.002
res[172]    50.693  17.611   16.356   38.398   50.624   62.696   84.475 1.001
res[173]    16.355  17.405  -17.386    4.388   16.412   28.087   49.899 1.001
res[174]     5.229  17.259  -28.246   -6.690    5.281   16.848   38.937 1.001
res[175]   -25.424  17.176  -58.537  -37.419  -25.426  -13.955    7.970 1.001
res[176]   -60.299  17.157  -93.240  -72.218  -60.299  -48.754  -26.651 1.001
res[177]   -17.707  17.202  -50.497  -29.605  -17.777   -6.222   15.477 1.001
res[178]   -67.087  17.310  -99.859  -79.145  -67.067  -55.435  -33.398 1.001
res[179]    21.851  17.480  -10.981    9.770   21.871   33.713   56.070 1.001
res[180]   -40.647  17.711  -73.957  -52.771  -40.513  -28.613   -5.841 1.001
res[181]   -19.458  17.542  -54.333  -31.085  -19.422   -7.722   15.640 1.001
res[182]    13.382  17.297  -20.657    2.031   13.446   24.888   47.985 1.001
res[183]    42.203  17.113    8.488   30.978   42.207   53.606   75.709 1.001
res[184]    20.699  16.991  -12.648    9.734   20.572   32.070   53.897 1.001
res[185]    22.419  16.933  -10.796   11.505   22.206   33.885   55.335 1.001
res[186]    67.746  16.941   34.410   57.004   67.445   79.392  100.423 1.001
res[187]   -17.017  17.012  -50.239  -27.920  -17.298   -5.427   15.763 1.001
res[188]   -51.228  17.148  -84.441  -62.328  -51.548  -39.688  -18.069 1.001
res[189]   -23.628  17.345  -57.805  -34.767  -23.760  -11.997   10.684 1.001
res[190]   -39.945  17.603  -74.634  -51.215  -40.154  -28.208   -5.214 1.001
res[191]    52.530  17.512   18.626   41.139   52.206   64.088   87.150 1.006
res[192]    79.593  17.246   46.248   68.448   79.388   91.100  113.049 1.017
res[193]    71.051  17.040   37.868   59.980   70.793   82.571  104.153 1.021
res[194]   -14.917  16.897  -48.034  -25.902  -15.296   -3.462   18.041 1.005
res[195]    -7.135  16.817  -39.943  -18.047   -7.544    4.215   25.897 1.005
res[196]   -18.174  16.803  -51.133  -29.182  -18.623   -6.895   14.827 1.005
res[197]   -16.439  16.854  -48.969  -27.463  -16.762   -5.147   16.557 1.004
res[198]   -69.150  16.970 -102.173  -80.328  -69.361  -57.572  -35.980 1.004
res[199]   -27.445  17.149  -60.854  -38.683  -27.690  -15.800    6.299 1.003
res[200]   -71.100  17.389 -104.684  -82.727  -71.394  -59.189  -37.691 1.003
res[201]     1.426  17.309  -34.407   -9.571    1.332   12.962   35.011 1.001
res[202]    36.131  17.046    0.771   25.266   36.227   47.347   69.464 1.001
res[203]     5.510  16.844  -28.967   -5.374    5.685   16.535   38.753 1.001
res[204]    49.200  16.705   15.453   38.505   49.435   60.187   82.079 1.001
res[205]   -10.960  16.631  -44.546  -21.713  -10.492   -0.147   21.703 1.001
res[206]  -133.889  16.623 -167.539 -144.693 -133.301 -123.036 -101.431 1.001
res[207]   -68.634  16.681 -102.616  -79.683  -67.975  -57.769  -36.182 1.001
res[208]     2.212  16.804  -31.897   -8.838    2.830   13.283   34.752 1.001
res[209]     2.431  16.991  -31.627   -8.767    3.000   13.550   35.269 1.001
res[210]    41.968  17.240    6.811   30.539   42.440   53.467   75.061 1.001
res[211]   -67.622  17.508 -102.075  -79.236  -67.541  -56.136  -32.937 1.001
res[212]   -57.530  17.266  -91.092  -68.962  -57.500  -46.025  -22.873 1.001
res[213]  -140.313  17.084 -173.718 -151.700 -140.155 -128.926 -105.859 1.002
res[214]   -50.542  16.964  -83.840  -61.841  -50.386  -39.139  -16.241 1.002
res[215]    55.074  16.909   22.122   43.726   55.352   66.374   89.195 1.002
res[216]   100.133  16.919   67.118   88.860  100.592  111.422  133.899 1.002
res[217]    80.975  16.993   48.141   69.704   81.338   92.108  115.080 1.002
res[218]    65.212  17.132   32.285   53.430   65.470   76.536  100.152 1.001
res[219]   -21.674  17.332  -55.118  -33.640  -21.456  -10.022   13.856 1.002
res[220]    24.003  17.593   -9.530   11.811   24.101   35.907   59.852 1.002
res[221]    60.185  17.783   25.820   48.457   59.813   72.436   96.171 1.001
res[222]    26.825  17.539   -6.907   15.267   26.510   38.780   62.320 1.001
res[223]   -37.765  17.355  -71.270  -49.250  -38.173  -25.946   -2.142 1.001
res[224]   -33.962  17.232  -67.496  -45.390  -34.499  -22.046    1.130 1.001
res[225]   -58.522  17.173  -91.829  -70.044  -59.083  -46.732  -23.657 1.001
res[226]   -55.706  17.177  -88.390  -67.397  -56.263  -44.042  -21.182 1.001
res[227]   -94.620  17.245 -127.457 -106.411  -95.119  -82.969  -60.749 1.001
res[228]    19.371  17.375  -13.948    7.607   19.044   31.010   53.459 1.001
res[229]    25.246  17.568   -8.529   13.626   24.828   37.075   59.410 1.001
res[230]    84.355  17.820   50.467   72.405   83.982   96.570  118.968 1.001
res[231]   -31.497  18.030  -66.696  -43.447  -31.785  -19.738    3.853 1.001
res[232]   -33.555  17.750  -68.255  -45.064  -33.695  -22.067    1.221 1.001
res[233]   -46.454  17.529  -80.525  -58.085  -46.585  -35.121  -11.905 1.001
res[234]   -84.283  17.368 -118.128  -95.729  -84.398  -73.094  -50.480 1.001
res[235]    23.792  17.270   -9.429   12.004   23.713   34.911   57.625 1.001
res[236]   -37.979  17.234  -71.525  -49.693  -38.039  -26.826   -3.726 1.001
res[237]    -0.851  17.262  -34.217  -12.666   -0.823   10.179   33.380 1.001
res[238]    55.116  17.354   21.132   43.276   55.278   66.313   89.932 1.001
res[239]    66.340  17.507   31.871   54.397   66.435   77.816  102.154 1.001
res[240]    22.509  17.721  -12.331   10.444   22.467   34.188   58.690 1.001
res[241]    48.779  17.985   13.144   36.603   49.101   61.358   82.744 1.001
res[242]    54.607  17.728   19.723   42.634   54.853   67.014   88.097 1.001
res[243]    -2.573  17.531  -36.920  -14.310   -2.250    9.522   31.153 1.001
res[244]   -64.682  17.394  -98.704  -76.398  -64.353  -52.693  -31.136 1.001
res[245]    59.232  17.320   25.143   47.518   59.597   70.983   92.873 1.001
res[246]    19.963  17.309  -14.316    8.145   20.310   31.886   53.371 1.001
res[247]   -70.443  17.361 -105.373  -82.320  -70.049  -58.397  -36.717 1.001
res[248]   -23.463  17.476  -58.679  -35.360  -23.248  -11.587   10.598 1.001
res[249]     2.831  17.652  -32.482   -8.951    3.087   14.786   37.287 1.001
res[250]   -59.475  17.888  -95.014  -71.176  -59.315  -47.543  -24.802 1.001
res[251]  -118.664  17.326 -151.645 -130.208 -118.894 -107.309  -83.446 1.002
res[252]   -91.020  17.066 -123.512 -102.427  -91.199  -79.836  -57.008 1.001
res[253]    -6.258  16.868  -38.555  -17.830   -6.464    4.709   27.751 1.001
res[254]    36.251  16.734    4.248   24.639   35.981   47.226   70.217 1.001
res[255]    13.667  16.664  -18.023    2.118   13.400   24.523   47.428 1.001
res[256]   -21.601  16.659  -53.042  -33.062  -21.878  -10.646   12.267 1.001
res[257]     5.310  16.721  -26.340   -6.021    5.033   16.411   39.015 1.001
res[258]    21.015  16.847  -10.852    9.662   20.790   32.193   55.145 1.001
res[259]    57.059  17.037   24.518   45.611   56.831   68.241   92.442 1.002
res[260]    34.481  17.288    1.254   23.094   34.411   45.908   70.086 1.001
res[261]    50.413  17.715   15.780   38.279   50.907   62.488   84.294 1.002
res[262]     1.013  17.462  -32.559  -11.003    1.463   13.068   33.840 1.002
res[263]   -13.632  17.268  -46.927  -25.466  -13.251   -1.826   18.917 1.002
res[264]    28.083  17.137   -5.178   16.694   28.340   39.623   60.566 1.003
res[265]    73.774  17.069   40.522   62.477   73.840   85.174  106.109 1.003
res[266]   -36.234  17.065  -69.304  -47.505  -35.963  -24.747   -3.793 1.003
res[267]   -22.093  17.125  -55.763  -33.330  -21.828  -10.616   10.070 1.003
res[268]    14.160  17.249  -19.827    3.041   14.507   25.776   46.182 1.003
res[269]   -59.954  17.435  -93.778  -71.235  -59.514  -48.101  -27.315 1.003
res[270]   -22.812  17.681  -57.121  -34.293  -22.324  -10.851   10.918 1.003
res[271]  -125.907  17.458 -160.933 -137.188 -125.802 -114.461  -92.053 1.001
res[272]   -62.314  17.229  -97.496  -73.416  -62.473  -50.835  -29.085 1.001
res[273]   -35.666  17.061  -70.145  -46.545  -35.800  -24.427   -3.232 1.001
res[274]    -2.957  16.956  -37.392  -13.883   -2.813    8.075   29.213 1.001
res[275]    -9.344  16.916  -43.467  -20.207   -9.343    1.681   22.885 1.001
res[276]    22.554  16.940  -11.628   11.868   22.593   33.645   54.629 1.001
res[277]    73.779  17.029   39.473   63.039   73.780   84.850  106.184 1.001
res[278]   143.908  17.181  109.484  132.820  143.915  155.171  176.723 1.001
res[279]   100.141  17.395   65.573   88.965  100.141  111.576  133.506 1.001
res[280]   -46.044  17.669  -80.667  -57.400  -45.955  -34.590  -12.407 1.001
res[281]    -5.699  17.595  -39.468  -17.381   -5.770    5.983   28.301 1.001
res[282]     0.419  17.343  -33.174  -10.923    0.288   11.974   34.262 1.001
res[283]   -12.869  17.152  -46.211  -24.317  -13.049   -1.401   20.398 1.001
res[284]    12.545  17.023  -20.331    1.056   12.458   24.113   45.686 1.001
res[285]    54.857  16.958   22.320   43.310   54.741   66.049   88.406 1.001
res[286]    12.136  16.958  -20.207    0.644   11.947   23.530   45.348 1.001
res[287]   -10.984  17.022  -43.192  -22.616  -10.977    0.294   22.275 1.001
res[288]     4.979  17.150  -27.724   -6.762    5.048   16.454   38.007 1.001
res[289]   -29.791  17.340  -62.952  -41.651  -29.779  -18.299    3.958 1.001
res[290]   -25.671  17.591  -59.797  -37.708  -25.457  -14.066    8.558 1.001
res[291]    28.550  17.963   -7.697   16.728   28.845   40.812   62.212 1.001
res[292]    -9.089  17.712  -45.024  -20.553   -8.933    2.924   24.333 1.001
res[293]   -49.732  17.521  -85.124  -61.052  -49.636  -38.060  -16.508 1.001
res[294]   -58.677  17.390  -93.259  -69.572  -58.567  -47.134  -25.799 1.001
res[295]   -57.955  17.322  -92.707  -68.933  -57.842  -46.344  -25.049 1.001
res[296]    -3.734  17.317  -38.668  -14.858   -3.653    7.873   29.033 1.001
res[297]    69.494  17.375   34.053   58.293   69.643   81.139  102.719 1.001
res[298]    42.465  17.496    6.356   31.206   42.578   54.056   75.774 1.001
res[299]     7.231  17.678  -29.387   -4.288    7.395   19.167   40.819 1.001
res[300]   -23.337  17.919  -60.558  -34.994  -23.228  -11.302   10.882 1.001
res[301]   -51.903  17.982  -88.248  -63.876  -52.309  -39.714  -17.303 1.001
res[302]   -37.852  17.747  -73.574  -49.599  -38.337  -25.637   -3.466 1.001
res[303]     9.383  17.571  -25.880   -2.168    9.060   21.337   43.272 1.001
res[304]     6.786  17.457  -27.982   -4.692    6.466   18.794   40.534 1.001
res[305]   -83.287  17.404 -117.576  -94.688  -83.511  -71.384  -50.132 1.001
res[306]   -56.131  17.415  -90.605  -67.604  -56.382  -44.092  -22.768 1.001
res[307]    29.387  17.488   -5.255   17.630   29.168   41.485   62.770 1.001
res[308]    97.884  17.624   63.110   86.054   97.739  110.020  131.499 1.001
res[309]    53.516  17.820   18.505   41.582   53.468   65.807   87.676 1.001
res[310]   -20.057  18.074  -55.492  -32.169  -20.032   -7.574   14.442 1.001
res[311]   101.300  17.549   67.220   89.168  101.137  113.302  135.233 1.001
res[312]    83.175  17.312   49.506   71.360   82.808   95.098  116.774 1.001
res[313]    71.785  17.135   37.980   60.064   71.677   83.600  105.227 1.001
res[314]    88.437  17.022   55.339   76.901   88.506  100.014  122.116 1.001
res[315]    -0.110  16.972  -33.336  -11.341    0.071   11.200   33.192 1.001
res[316]   -26.794  16.987  -60.411  -38.159  -26.771  -15.599    6.418 1.001
res[317]   -88.891  17.067 -122.585 -100.389  -88.824  -77.593  -55.404 1.001
res[318]   -96.339  17.209 -130.866 -107.673  -96.328  -84.910  -62.716 1.001
res[319]   -61.837  17.414  -96.679  -73.288  -61.840  -50.019  -28.051 1.001
res[320]  -108.552  17.679 -143.474 -120.010 -108.694  -96.508  -74.344 1.001
res[321]   -74.410  17.625 -109.575  -85.816  -74.485  -62.663  -39.753 1.001
res[322]   -41.400  17.380  -75.871  -52.760  -41.519  -29.797   -7.178 1.001
res[323]   -74.807  17.196 -108.901  -86.261  -74.760  -63.308  -41.163 1.001
res[324]   -45.144  17.074  -79.209  -56.502  -45.026  -33.729  -12.103 1.001
res[325]     4.537  17.016  -29.468   -6.710    4.542   15.856   37.618 1.001
res[326]    59.794  17.022   26.116   48.375   59.758   71.282   93.240 1.001
res[327]    40.165  17.092    6.814   28.767   40.355   51.655   73.479 1.001
res[328]    30.285  17.226   -3.464   18.692   30.679   41.872   63.673 1.001
res[329]    22.589  17.422  -10.860   10.756   23.053   34.110   56.454 1.001
res[330]    92.703  17.678   58.616   80.766   93.284  104.245  126.965 1.001
res[331]    95.283  17.977   59.650   83.167   95.192  107.412  130.221 1.001
res[332]   112.719  17.720   77.424  100.669  112.724  124.693  147.222 1.001
res[333]    70.443  17.522   35.436   58.422   70.438   82.385  104.268 1.001
res[334]    69.514  17.384   34.563   57.587   69.353   81.410  102.556 1.001
res[335]    70.134  17.309   35.643   58.219   69.855   81.817  103.521 1.001
res[336]    -1.755  17.297  -35.726  -13.635   -1.976   10.018   31.941 1.001
res[337]   -93.736  17.349 -127.604 -105.548  -93.768  -81.835  -60.000 1.001
res[338]   -48.951  17.463  -82.779  -60.869  -49.029  -36.839  -14.994 1.001
res[339]  -121.819  17.638 -156.071 -133.910 -122.015 -109.591  -87.286 1.001
res[340]  -103.701  17.874 -138.279 -115.672 -103.713  -91.305  -68.978 1.001
res[341]   -69.317  18.059 -103.485  -81.639  -69.415  -57.406  -33.457 1.001
res[342]   -32.346  17.788  -65.785  -44.511  -32.362  -20.467    2.839 1.001
res[343]   -21.629  17.575  -54.850  -33.597  -21.808   -9.882   13.449 1.001
res[344]   -59.307  17.422  -92.307  -71.080  -59.415  -47.483  -24.425 1.001
res[345]    -3.627  17.331  -36.621  -15.370   -3.984    8.092   31.060 1.001
res[346]    78.394  17.304   46.202   66.537   78.021   90.261  112.620 1.001
res[347]   100.999  17.339   68.667   89.254  100.770  113.032  135.290 1.001
res[348]   -22.296  17.438  -55.281  -34.095  -22.507  -10.328   12.264 1.001
res[349]    46.092  17.598   12.847   34.241   46.001   58.157   80.422 1.001
res[350]    27.883  17.819   -5.915   15.648   27.735   40.121   63.077 1.001
sigma       55.917   2.244   51.705   54.351   55.829   57.468   60.369 1.003
sigma.B     64.474   8.406   50.251   58.466   63.695   69.675   83.144 1.006
deviance  3809.753   9.145 3794.047 3803.114 3809.077 3815.608 3829.461 1.003
          n.eff
beta       3000
beta0      3000
gamma[1]   1800
gamma[2]   3000
gamma[3]   2100
gamma[4]   3000
gamma[5]   3000
gamma[6]   3000
gamma[7]   3000
gamma[8]   3000
gamma[9]   2800
gamma[10]  3000
gamma[11]  2100
gamma[12]  3000
gamma[13]  3000
gamma[14]  3000
gamma[15]  2500
gamma[16]  1700
gamma[17]  1700
gamma[18]  1800
gamma[19]  3000
gamma[20]  1500
gamma[21]  3000
gamma[22]  3000
gamma[23]  3000
gamma[24]  3000
gamma[25]  3000
gamma[26]  1700
gamma[27]  1500
gamma[28]  3000
gamma[29]  2300
gamma[30]  3000
gamma[31]  3000
gamma[32]  3000
gamma[33]  2500
gamma[34]  3000
gamma[35]  3000
res[1]     1100
res[2]     1000
res[3]      990
res[4]      940
res[5]      910
res[6]      880
res[7]      860
res[8]      850
res[9]      840
res[10]     840
res[11]    3000
res[12]    3000
res[13]    3000
res[14]    3000
res[15]    3000
res[16]    3000
res[17]    3000
res[18]    3000
res[19]    3000
res[20]    3000
res[21]    1200
res[22]    1200
res[23]    1100
res[24]    1000
res[25]    1000
res[26]     970
res[27]     950
res[28]    1200
res[29]     920
res[30]     920
res[31]    3000
res[32]    3000
res[33]    3000
res[34]    3000
res[35]    3000
res[36]    3000
res[37]    3000
res[38]    3000
res[39]    3000
res[40]    3000
res[41]    3000
res[42]    3000
res[43]    3000
res[44]    3000
res[45]    3000
res[46]    3000
res[47]    3000
res[48]    3000
res[49]    3000
res[50]    3000
res[51]    3000
res[52]    3000
res[53]    3000
res[54]    3000
res[55]    3000
res[56]    3000
res[57]    3000
res[58]    3000
res[59]    3000
res[60]    3000
res[61]    3000
res[62]    3000
res[63]    3000
res[64]    3000
res[65]    3000
res[66]    3000
res[67]    3000
res[68]    3000
res[69]    3000
res[70]    3000
res[71]    3000
res[72]    3000
res[73]    3000
res[74]    3000
res[75]    3000
res[76]    3000
res[77]    3000
res[78]    3000
res[79]    3000
res[80]    3000
res[81]    1100
res[82]    1100
res[83]    1000
res[84]     970
res[85]     930
res[86]     930
res[87]    1100
res[88]     860
res[89]     850
res[90]     850
res[91]    3000
res[92]    3000
res[93]    3000
res[94]    3000
res[95]    3000
res[96]    3000
res[97]    3000
res[98]    3000
res[99]    3000
res[100]   3000
res[101]   2700
res[102]   2700
res[103]   2800
res[104]   3000
res[105]   3000
res[106]   3000
res[107]   3000
res[108]   3000
res[109]   3000
res[110]   3000
res[111]   3000
res[112]   3000
res[113]   3000
res[114]   3000
res[115]   3000
res[116]   3000
res[117]   3000
res[118]   3000
res[119]   3000
res[120]   3000
res[121]   3000
res[122]   3000
res[123]   3000
res[124]   3000
res[125]   3000
res[126]   3000
res[127]   3000
res[128]   3000
res[129]   3000
res[130]   3000
res[131]   3000
res[132]   3000
res[133]   3000
res[134]   3000
res[135]   3000
res[136]   3000
res[137]   3000
res[138]   3000
res[139]   3000
res[140]   3000
res[141]   2700
res[142]   2700
res[143]   2800
res[144]   3000
res[145]   3000
res[146]   3000
res[147]   3000
res[148]   3000
res[149]   3000
res[150]   3000
res[151]   1700
res[152]   2200
res[153]   2300
res[154]   1900
res[155]   1900
res[156]   2000
res[157]   2200
res[158]   2300
res[159]   2500
res[160]   2700
res[161]   1500
res[162]   1500
res[163]   1500
res[164]   1000
res[165]   1600
res[166]   1700
res[167]   1800
res[168]   1900
res[169]   2000
res[170]   1600
res[171]   3000
res[172]   1900
res[173]   1900
res[174]   2000
res[175]   2000
res[176]   2100
res[177]   2300
res[178]   2400
res[179]   2600
res[180]   2800
res[181]   3000
res[182]   3000
res[183]   3000
res[184]   3000
res[185]   3000
res[186]   3000
res[187]   3000
res[188]   3000
res[189]   3000
res[190]   3000
res[191]   1500
res[192]    630
res[193]    570
res[194]   1600
res[195]   1700
res[196]   1800
res[197]   1900
res[198]   2000
res[199]   2100
res[200]   2300
res[201]   3000
res[202]   3000
res[203]   3000
res[204]   3000
res[205]   3000
res[206]   3000
res[207]   3000
res[208]   3000
res[209]   3000
res[210]   3000
res[211]   2000
res[212]   1900
res[213]   1700
res[214]   1600
res[215]   1600
res[216]   1700
res[217]   1700
res[218]   1900
res[219]   1400
res[220]   1400
res[221]   3000
res[222]   3000
res[223]   3000
res[224]   3000
res[225]   3000
res[226]   3000
res[227]   3000
res[228]   3000
res[229]   3000
res[230]   3000
res[231]   3000
res[232]   3000
res[233]   3000
res[234]   3000
res[235]   3000
res[236]   3000
res[237]   3000
res[238]   3000
res[239]   3000
res[240]   3000
res[241]   3000
res[242]   3000
res[243]   3000
res[244]   3000
res[245]   3000
res[246]   3000
res[247]   3000
res[248]   3000
res[249]   3000
res[250]   3000
res[251]   1800
res[252]   1800
res[253]   1900
res[254]   1900
res[255]   2000
res[256]   2100
res[257]   2200
res[258]   2400
res[259]   3000
res[260]   2800
res[261]    930
res[262]    880
res[263]    830
res[264]    790
res[265]    750
res[266]    740
res[267]    720
res[268]    710
res[269]    710
res[270]    710
res[271]   3000
res[272]   3000
res[273]   3000
res[274]   3000
res[275]   3000
res[276]   3000
res[277]   3000
res[278]   3000
res[279]   3000
res[280]   3000
res[281]   2600
res[282]   2600
res[283]   2700
res[284]   2800
res[285]   3000
res[286]   3000
res[287]   3000
res[288]   3000
res[289]   3000
res[290]   3000
res[291]   3000
res[292]   3000
res[293]   3000
res[294]   3000
res[295]   3000
res[296]   3000
res[297]   3000
res[298]   3000
res[299]   3000
res[300]   3000
res[301]   3000
res[302]   3000
res[303]   3000
res[304]   3000
res[305]   3000
res[306]   3000
res[307]   3000
res[308]   3000
res[309]   3000
res[310]   3000
res[311]   3000
res[312]   3000
res[313]   3000
res[314]   3000
res[315]   3000
res[316]   3000
res[317]   3000
res[318]   3000
res[319]   3000
res[320]   3000
res[321]   2700
res[322]   2800
res[323]   2900
res[324]   3000
res[325]   3000
res[326]   3000
res[327]   3000
res[328]   3000
res[329]   3000
res[330]   3000
res[331]   3000
res[332]   3000
res[333]   3000
res[334]   3000
res[335]   3000
res[336]   3000
res[337]   3000
res[338]   3000
res[339]   3000
res[340]   3000
res[341]   3000
res[342]   3000
res[343]   3000
res[344]   3000
res[345]   3000
res[346]   3000
res[347]   3000
res[348]   3000
res[349]   3000
res[350]   3000
sigma       700
sigma.B    1000
deviance    720

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 41.8 and DIC = 3851.5
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- inprod(beta[],X[i,]) + gamma[Block[i]]
+     res[i] &amp;lt;- y[i]-mu[i]
+    } 
+    
+    #Priors
+    beta ~ dmnorm(a0,A0)
+    for (i in 1:nBlock) {
+      gamma[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;- z/sqrt(chSq) 
+    z ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;- z/sqrt(chSq.B) 
+    z.B ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.B ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;matrixModel2.txt&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~Time,data.rm)
&amp;gt; data.rm.list &amp;lt;- with(data.rm,
+         list(y=y,
+                  Block=as.numeric(Block),
+          X=Xmat,
+          n=nrow(data.rm),
+          nBlock=length(levels(Block)),
+          a0=rep(0,ncol(Xmat)), A0=diag(ncol(Xmat))
+          )
+ )
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;#39;gamma&amp;#39;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;quot;res&amp;quot;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.rm.r2jags.m &amp;lt;- jags(data = data.rm.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;matrixModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 350
   Unobserved stochastic nodes: 40
   Total graph size: 2521

Initializing model
&amp;gt; 
&amp;gt; print(data.rm.r2jags.m)
Inference for Bugs model at &amp;quot;matrixModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
           mu.vect sd.vect     2.5%      25%      50%      75%    97.5%  Rhat
beta[1]      0.118   0.993   -1.825   -0.560    0.127    0.772    2.136 1.002
beta[2]      9.067   1.041    6.989    8.384    9.085    9.754   11.096 1.009
gamma[1]   268.496  28.003  214.165  249.963  268.515  287.365  322.199 1.002
gamma[2]   249.357  27.207  196.523  230.541  249.374  268.093  303.009 1.001
gamma[3]   326.337  28.472  271.718  306.769  325.694  345.668  383.423 1.002
gamma[4]   305.015  28.782  249.411  285.199  305.040  324.243  361.356 1.001
gamma[5]   377.709  27.831  324.335  358.940  377.037  396.616  432.150 1.001
gamma[6]   343.430  27.578  288.864  325.843  342.939  361.444  396.819 1.001
gamma[7]   332.166  27.783  278.248  313.377  331.664  351.388  385.777 1.002
gamma[8]   271.616  27.163  217.184  253.588  271.956  289.628  322.963 1.001
gamma[9]   384.589  27.386  332.007  366.136  384.502  402.093  440.209 1.001
gamma[10]  367.756  27.587  314.137  349.123  368.026  386.501  421.707 1.001
gamma[11]  457.715  27.438  405.652  439.504  457.268  476.098  513.423 1.001
gamma[12]  312.867  27.216  262.216  293.798  313.154  331.284  366.377 1.001
gamma[13]  258.804  27.818  201.324  240.475  259.644  276.264  313.330 1.002
gamma[14]  279.449  28.042  224.175  260.014  279.067  298.411  335.404 1.001
gamma[15]  337.363  28.099  284.866  317.715  336.998  356.109  394.348 1.001
gamma[16]  416.383  27.354  363.925  397.826  416.595  434.011  473.215 1.002
gamma[17]  403.080  27.501  349.003  384.921  403.079  421.627  456.974 1.002
gamma[18]  237.418  27.946  183.713  218.161  237.435  256.648  290.420 1.001
gamma[19]  323.886  27.728  270.777  305.233  323.114  342.641  377.533 1.001
gamma[20]  275.462  28.013  220.684  255.987  275.838  294.317  330.957 1.001
gamma[21]  194.059  27.398  141.539  175.756  194.167  211.807  248.181 1.002
gamma[22]  289.821  27.693  236.092  271.210  289.707  307.332  344.403 1.001
gamma[23]  217.663  28.050  164.441  197.887  217.932  235.812  274.184 1.002
gamma[24]  212.748  27.923  159.816  193.937  211.567  231.708  268.892 1.001
gamma[25]  255.843  26.839  204.539  237.181  255.916  274.542  309.265 1.003
gamma[26]  206.396  28.055  152.547  187.160  206.227  225.611  261.170 1.001
gamma[27]  327.559  27.486  273.350  309.633  327.509  345.364  380.375 1.002
gamma[28]  384.714  27.705  330.300  365.884  384.552  403.155  437.847 1.003
gamma[29]  304.783  28.077  251.111  284.961  304.255  323.437  360.045 1.001
gamma[30]  225.251  28.017  168.742  206.532  226.000  243.944  279.897 1.001
gamma[31]  242.036  28.513  184.632  223.534  242.114  260.552  297.438 1.001
gamma[32]  250.059  27.603  197.965  231.432  249.373  268.506  305.275 1.003
gamma[33]  321.386  27.863  266.714  302.647  321.462  340.165  377.552 1.003
gamma[34]  368.704  27.907  314.047  350.229  368.434  387.452  423.293 1.001
gamma[35]  365.968  27.738  311.338  347.444  365.930  385.018  420.415 1.005
res[1]       4.433  27.784  -48.877  -14.717    4.562   22.705   58.869 1.002
res[2]      34.393  27.628  -18.119   15.474   34.478   52.583   88.788 1.002
res[3]     -17.044  27.510  -69.264  -35.707  -16.883    0.972   37.088 1.002
res[4]     -19.010  27.431  -70.907  -37.537  -18.756   -0.634   35.109 1.002
res[5]      22.692  27.391  -29.376    4.107   22.942   41.160   77.308 1.001
res[6]      10.582  27.391  -41.038   -7.968   10.837   28.907   65.778 1.001
res[7]     -70.449  27.431 -121.778  -88.991  -69.960  -52.214  -14.834 1.001
res[8]      21.008  27.509  -30.615    2.408   21.241   39.197   76.881 1.001
res[9]      12.673  27.627  -39.023   -6.003   12.972   31.145   68.777 1.001
res[10]     22.988  27.783  -29.250    4.168   22.937   41.683   79.296 1.001
res[11]    -40.986  26.942  -94.515  -59.717  -41.262  -22.608   11.356 1.001
res[12]    -57.652  26.765 -110.392  -76.201  -57.806  -39.438   -5.452 1.001
res[13]     14.195  26.627  -37.606   -4.203   14.145   32.218   66.504 1.001
res[14]    -29.460  26.529  -81.001  -47.601  -29.683  -11.482   22.755 1.001
res[15]    -14.892  26.472  -66.711  -32.886  -15.051    3.149   37.784 1.001
res[16]     15.000  26.456  -36.965   -3.255   14.703   33.011   68.048 1.001
res[17]    -11.656  26.481  -63.530  -29.872  -12.202    6.352   41.041 1.001
res[18]     -2.098  26.546  -53.836  -20.736   -2.884   15.886   51.209 1.001
res[19]     40.030  26.652  -11.158   21.366   39.102   58.171   93.729 1.001
res[20]    112.896  26.799   61.236   94.306  112.162  131.227  167.261 1.001
res[21]   -173.333  28.266 -230.343 -192.502 -172.496 -153.934 -119.008 1.002
res[22]   -146.973  28.095 -203.369 -166.084 -146.394 -127.937  -93.044 1.002
res[23]    -66.390  27.961 -122.215  -85.409  -65.713  -47.492  -12.298 1.002
res[24]    -62.498  27.865 -117.833  -81.428  -61.625  -43.630   -7.786 1.001
res[25]    -16.892  27.808  -71.818  -35.704  -16.206    2.104   37.863 1.001
res[26]     37.026  27.790  -17.773   18.140   37.505   55.996   91.643 1.001
res[27]     73.127  27.811   18.616   54.532   73.671   91.725  127.823 1.001
res[28]    125.466  27.871   71.518  106.855  125.737  144.036  180.266 1.001
res[29]    132.725  27.969   78.584  113.924  133.004  151.381  187.753 1.001
res[30]    128.171  28.106   73.520  109.247  128.243  147.168  184.155 1.001
res[31]   -215.417  28.519 -271.907 -234.515 -215.477 -196.031 -160.014 1.001
res[32]   -172.464  28.331 -228.398 -191.559 -172.626 -153.223 -117.470 1.001
res[33]   -107.754  28.180 -163.519 -126.542 -107.988  -88.710  -53.225 1.001
res[34]    -46.543  28.067 -102.122  -65.407  -46.791  -27.844    8.278 1.001
res[35]    -47.922  27.992 -103.460  -66.793  -48.157  -29.112    7.029 1.001
res[36]     71.901  27.955   16.630   52.816   71.633   90.451  126.471 1.001
res[37]     97.292  27.958   42.344   78.098   97.282  115.785  151.917 1.001
res[38]    113.786  27.999   59.110   94.749  113.857  132.397  169.334 1.001
res[39]    188.465  28.078  134.278  169.268  188.455  207.026  244.767 1.001
res[40]    152.859  28.196   98.827  133.783  152.725  171.438  209.588 1.001
res[41]   -138.298  27.589 -192.214 -157.018 -137.668 -119.884  -85.511 1.001
res[42]     -0.435  27.414  -54.092  -19.066    0.070   17.947   51.755 1.001
res[43]     -5.275  27.278  -58.296  -23.835   -4.661   12.955   46.693 1.001
res[44]     76.163  27.182   23.390   57.931   76.757   94.384  128.160 1.001
res[45]     -8.105  27.124  -60.470  -26.335   -7.526   10.317   43.968 1.001
res[46]     -8.933  27.107  -61.592  -27.005   -8.421    9.419   43.130 1.001
res[47]     23.039  27.130  -29.532    5.000   23.698   41.485   75.548 1.001
res[48]     48.884  27.192   -3.759   30.945   49.511   67.086  101.297 1.001
res[49]      8.462  27.295  -44.134   -9.630    8.812   26.700   61.215 1.001
res[50]     31.557  27.436  -20.973   13.381   31.746   50.020   84.424 1.001
res[51]   -128.097  27.415 -180.770 -146.327 -127.910 -110.576  -73.568 1.001
res[52]    -60.141  27.254 -112.252  -78.239  -59.732  -42.653   -5.561 1.001
res[53]     17.013  27.132  -35.210   -1.266   17.578   34.265   71.525 1.001
res[54]    -82.564  27.049 -134.784 -100.658  -82.293  -65.282  -27.984 1.002
res[55]     14.994  27.006  -36.578   -3.173   15.282   32.302   69.851 1.002
res[56]    -26.609  27.004  -78.326  -44.704  -26.580   -9.314   28.128 1.002
res[57]     29.085  27.041  -22.987   10.998   29.221   46.243   83.856 1.002
res[58]     88.084  27.118   35.657   69.858   88.230  105.263  142.463 1.004
res[59]     96.481  27.235   43.718   78.058   96.354  113.557  150.554 1.004
res[60]     85.123  27.391   32.058   66.554   85.013  102.661  139.651 1.005
res[61]   -114.949  27.627 -168.618 -134.296 -114.394  -96.450  -60.949 1.001
res[62]    -68.590  27.512 -121.492  -87.723  -68.056  -50.063  -14.649 1.001
res[63]     -5.091  27.435  -57.658  -24.187   -4.767   13.171   48.423 1.001
res[64]    -96.888  27.399 -149.185 -115.932  -96.721  -78.893  -43.557 1.001
res[65]   -145.340  27.401 -197.553 -164.388 -145.424 -127.432  -91.411 1.001
res[66]    -26.577  27.444  -78.399  -45.694  -26.594   -8.455   27.555 1.001
res[67]     53.432  27.525    1.678   34.253   53.095   71.854  107.546 1.001
res[68]     91.059  27.646   39.251   71.830   90.780  109.558  145.538 1.003
res[69]    139.341  27.805   87.022  120.095  138.966  157.961  193.921 1.001
res[70]    192.254  28.001  139.613  173.011  191.889  211.174  247.685 1.001
res[71]   -140.697  26.945 -192.131 -158.462 -140.921 -122.682  -86.498 1.001
res[72]    -53.861  26.803 -104.692  -71.382  -53.867  -36.045   -0.026 1.001
res[73]    -59.969  26.701 -110.888  -77.531  -60.116  -42.419   -5.779 1.001
res[74]    -24.888  26.639  -75.800  -42.339  -25.220   -7.759   28.792 1.001
res[75]    -18.925  26.617  -70.569  -36.419  -19.228   -1.820   34.501 1.001
res[76]     48.388  26.637   -3.281   30.722   48.168   65.796  102.013 1.001
res[77]     45.403  26.697   -6.795   27.656   45.293   62.830   99.324 1.001
res[78]     90.550  26.797   38.062   72.851   90.464  108.076  144.636 1.001
res[79]     85.396  26.937   32.309   67.374   84.992  103.181  139.994 1.001
res[80]     50.353  27.116   -2.874   32.360   50.071   68.275  105.635 1.001
res[81]   -163.315  27.183 -218.512 -180.651 -163.268 -145.149 -111.213 1.001
res[82]   -109.549  27.050 -164.522 -126.836 -109.407  -91.446  -57.185 1.001
res[83]    -13.182  26.957  -68.058  -30.309  -13.185    4.672   38.759 1.001
res[84]    -14.857  26.904  -69.375  -32.207  -15.130    2.965   37.149 1.001
res[85]     40.982  26.891  -12.987   23.736   40.580   58.715   93.178 1.001
res[86]    132.360  26.918   78.198  115.020  131.926  150.358  184.466 1.001
res[87]     96.805  26.986   42.362   79.456   96.215  114.807  149.347 1.001
res[88]     20.474  27.093  -33.942    3.067   19.924   38.470   72.341 1.001
res[89]     17.776  27.240  -36.170    0.154   17.205   35.757   69.869 1.001
res[90]     21.069  27.426  -33.512    3.375   20.566   38.921   73.507 1.001
res[91]   -139.087  27.401 -192.251 -157.857 -139.429 -120.731  -85.751 1.001
res[92]    -36.783  27.249  -89.549  -55.363  -37.012  -18.606   16.371 1.001
res[93]    -52.676  27.136 -105.357  -71.142  -52.862  -34.505    0.149 1.001
res[94]    -26.246  27.062  -78.812  -44.487  -26.694   -8.200   27.216 1.001
res[95]    -30.949  27.028  -83.569  -49.064  -31.432  -12.883   22.822 1.001
res[96]    -18.119  27.035  -70.366  -36.181  -18.630   -0.071   35.799 1.001
res[97]     11.013  27.081  -42.062   -7.308   10.371   29.090   64.960 1.001
res[98]     89.212  27.167   36.723   70.825   88.487  107.474  143.357 1.001
res[99]     95.614  27.293   43.369   77.242   94.962  114.096  150.199 1.001
res[100]   134.498  27.457   80.966  116.052  134.051  153.002  189.417 1.001
res[101]   -76.108  27.204 -130.082  -94.332  -75.847  -57.878  -24.353 1.001
res[102]   -34.250  27.032  -87.681  -52.048  -34.152  -16.151   17.341 1.001
res[103]   -71.035  26.900 -124.029  -88.589  -71.012  -53.026  -19.557 1.001
res[104]    13.787  26.807  -38.887   -3.638   13.685   31.994   65.003 1.001
res[105]   -14.560  26.754  -67.146  -32.253  -14.734    3.512   36.383 1.001
res[106]   -19.293  26.742  -72.025  -36.855  -19.308   -1.263   32.398 1.001
res[107]    56.600  26.770    3.888   38.981   56.413   74.590  108.690 1.001
res[108]   116.002  26.839   62.639   98.370  115.911  133.987  168.211 1.001
res[109]    48.507  26.948   -4.467   30.803   48.406   66.425  100.281 1.001
res[110]     9.543  27.096  -43.482   -8.442    9.395   27.710   61.257 1.001
res[111]  -132.106  27.068 -185.510 -150.360 -132.361 -113.290  -81.768 1.002
res[112]   -91.911  26.941 -144.896 -110.112  -92.368  -73.497  -41.675 1.002
res[113]   -56.418  26.853 -110.121  -74.546  -56.821  -38.144   -6.066 1.002
res[114]   -13.873  26.805  -66.754  -32.098  -14.064    4.250   36.754 1.002
res[115]    33.751  26.798  -19.527   15.438   33.439   51.710   84.504 1.002
res[116]    18.335  26.831  -34.945   -0.042   17.997   36.508   69.231 1.003
res[117]    -9.402  26.904  -62.947  -27.827   -9.801    8.739   41.996 1.003
res[118]    73.620  27.018   20.102   55.043   73.349   91.735  125.589 1.003
res[119]   130.437  27.170   77.165  111.769  130.243  148.448  183.288 1.003
res[120]    67.067  27.362   14.395   48.375   66.985   85.315  120.963 1.004
res[121]   -62.784  27.602 -117.124  -80.547  -63.554  -44.541   -5.745 1.002
res[122]   -79.284  27.432 -132.901  -96.959  -80.152  -61.213  -23.216 1.002
res[123]  -147.038  27.300 -200.594 -164.755 -147.987 -129.337  -91.122 1.002
res[124]   -86.011  27.208 -139.363 -103.583  -87.079  -68.166  -30.561 1.001
res[125]   -44.469  27.155  -96.901  -61.934  -45.519  -26.882   10.835 1.001
res[126]    -7.957  27.143  -60.233  -25.501   -9.007    9.627   47.109 1.001
res[127]    41.116  27.170  -10.769   23.449   40.140   58.470   96.951 1.001
res[128]   117.876  27.237   66.278   99.824  117.103  135.377  173.458 1.003
res[129]   149.628  27.343   98.060  131.402  148.903  167.283  205.474 1.002
res[130]   138.114  27.489   85.817  119.560  137.512  155.791  194.856 1.002
res[131]  -111.510  27.838 -167.229 -130.194 -111.277  -92.014  -56.583 1.002
res[132]   -85.928  27.671 -141.664 -104.693  -85.568  -66.741  -30.867 1.002
res[133]   -39.184  27.543  -95.068  -57.826  -39.100  -20.158   15.452 1.002
res[134]   -65.087  27.454 -120.528  -83.757  -65.031  -46.398  -10.806 1.002
res[135]   -38.854  27.404  -94.235  -57.313  -38.905  -20.233   15.932 1.002
res[136]    43.897  27.394  -11.085   25.502   43.662   62.725   99.335 1.002
res[137]    60.508  27.423    5.661   42.259   60.002   79.149  116.033 1.002
res[138]    48.476  27.491   -6.511   30.204   47.961   67.171  103.838 1.002
res[139]    64.161  27.599    9.521   45.658   63.389   82.927  119.918 1.002
res[140]   150.425  27.745   95.799  131.748  149.642  169.252  206.380 1.003
res[141]   -91.850  27.881 -148.268 -110.602  -91.492  -72.233  -39.029 1.001
res[142]   -17.357  27.708  -73.303  -36.036  -17.162    1.868   35.260 1.001
res[143]    -8.456  27.572  -63.972  -27.298   -8.090   10.649   43.948 1.001
res[144]    16.411  27.476  -38.675   -2.242   16.566   35.463   68.828 1.001
res[145]    -7.945  27.418  -62.620  -26.453   -7.775   11.028   44.009 1.001
res[146]    34.948  27.400  -19.537   16.194   35.119   53.767   87.148 1.001
res[147]    17.864  27.422  -36.519   -0.769   17.959   36.562   70.397 1.001
res[148]   -37.328  27.483  -92.124  -55.967  -37.389  -18.410   15.393 1.001
res[149]     0.133  27.583  -54.930  -18.289    0.029   18.855   53.369 1.001
res[150]   125.181  27.722   69.744  106.772  124.931  144.185  179.294 1.001
res[151]   -45.913  27.112 -101.600  -63.384  -46.504  -27.406    6.233 1.002
res[152]    14.074  26.949  -41.422   -3.190   13.364   32.310   66.645 1.001
res[153]    25.930  26.825  -28.692    8.617   25.258   43.842   78.335 1.001
res[154]    -8.769  26.741  -62.803  -25.915   -9.134    8.810   43.512 1.001
res[155]   -12.026  26.698  -66.536  -29.146  -12.358    5.538   40.695 1.001
res[156]   -13.996  26.695  -68.442  -31.190  -14.374    3.511   39.057 1.001
res[157]   -21.157  26.732  -75.444  -38.415  -21.645   -3.442   32.176 1.001
res[158]    35.944  26.810  -17.938   18.462   35.409   53.573   89.820 1.001
res[159]    -9.265  26.928  -63.044  -26.958   -9.879    8.560   44.932 1.001
res[160]    61.941  27.086    8.272   44.148   61.146   79.841  116.112 1.001
res[161]  -111.720  27.299 -164.219 -130.281 -111.941  -93.352  -57.961 1.002
res[162]  -161.840  27.142 -214.803 -180.270 -162.077 -143.321 -108.335 1.002
res[163]  -105.843  27.025 -158.096 -124.374 -106.136  -87.584  -52.496 1.002
res[164]    32.678  26.947  -18.932   14.279   32.115   50.832   85.368 1.002
res[165]    -1.691  26.909  -53.352  -20.188   -2.310   16.517   51.266 1.002
res[166]    45.107  26.912   -6.211   26.808   44.518   63.279   97.999 1.002
res[167]     5.376  26.954  -46.126  -12.677    4.882   23.392   58.513 1.002
res[168]    72.424  27.037   20.741   54.308   72.204   90.456  125.956 1.002
res[169]    87.205  27.159   35.982   68.965   87.205  105.288  141.275 1.002
res[170]   173.321  27.321  121.880  155.039  173.059  191.695  228.030 1.003
res[171]   -26.750  27.741  -79.583  -45.635  -26.886   -7.432   26.470 1.001
res[172]   -18.152  27.612  -70.442  -37.010  -18.270    0.993   35.150 1.001
res[173]   -30.868  27.522  -82.411  -49.842  -30.897  -11.752   22.359 1.001
res[174]   -20.371  27.471  -72.112  -39.216  -20.399   -1.090   32.975 1.001
res[175]   -29.402  27.460  -81.284  -48.575  -29.553   -9.855   23.536 1.001
res[176]   -42.654  27.488  -94.488  -61.958  -42.932  -23.151   10.118 1.001
res[177]    21.559  27.555  -30.491    2.158   21.213   40.881   74.590 1.001
res[178]    -6.198  27.662  -58.988  -25.815   -6.244   13.036   47.593 1.001
res[179]   104.363  27.807   51.627   84.332  104.497  123.625  158.553 1.001
res[180]    63.487  27.989   10.897   43.415   63.657   82.927  118.256 1.002
res[181]  -116.426  27.477 -170.058 -135.254 -115.973  -98.040  -63.859 1.001
res[182]   -61.964  27.315 -115.028  -80.596  -61.367  -43.741   -8.748 1.001
res[183]   -11.520  27.191  -65.196  -29.915  -10.904    6.736   41.954 1.001
res[184]   -11.403  27.107  -64.157  -29.928  -10.938    7.033   42.438 1.001
res[185]    11.940  27.063  -40.738   -6.618   12.599   30.143   65.828 1.001
res[186]    78.890  27.059   26.180   60.481   79.578   97.004  132.471 1.001
res[187]    15.749  27.094  -36.961   -2.786   16.169   33.923   68.912 1.001
res[188]     3.160  27.170  -49.311  -15.573    3.325   21.357   56.992 1.001
res[189]    52.382  27.285   -0.331   33.687   52.699   70.616  106.503 1.001
res[190]    57.688  27.439    4.937   38.848   57.982   75.882  112.335 1.001
res[191]   -39.277  27.823  -93.946  -58.037  -39.479  -19.984   14.965 1.001
res[192]     9.409  27.662  -44.962   -9.063    9.312   28.464   63.569 1.001
res[193]    22.489  27.540  -32.351    3.890   22.479   41.387   76.748 1.001
res[194]   -41.856  27.457  -96.305  -60.387  -41.784  -23.180   12.866 1.001
res[195]   -12.452  27.413  -66.510  -31.155  -12.405    6.113   42.359 1.001
res[196]    -1.869  27.408  -55.985  -20.561   -1.913   16.685   53.271 1.001
res[197]    21.489  27.443  -32.127    2.711   21.389   39.871   76.814 1.001
res[198]    -9.600  27.518  -62.931  -28.632   -9.617    8.338   45.590 1.002
res[199]    53.727  27.631   -0.059   34.427   53.676   71.736  108.974 1.002
res[200]    31.695  27.783  -22.231   12.143   31.743   49.979   87.523 1.002
res[201]   -86.890  27.181 -140.177 -104.770  -87.118  -68.603  -35.106 1.001
res[202]   -30.563  27.031  -83.642  -48.350  -31.011  -12.345   20.910 1.002
res[203]   -39.562  26.920  -92.523  -57.243  -39.987  -21.390   11.887 1.002
res[204]    25.751  26.850  -27.313    8.074   25.467   43.881   77.877 1.002
res[205]   -12.787  26.819  -65.884  -30.405  -13.246    5.237   39.562 1.002
res[206]  -114.094  26.829 -166.864 -131.854 -114.195  -96.423  -61.166 1.002
res[207]   -27.215  26.880  -80.040  -44.971  -27.431   -9.544   26.079 1.002
res[208]    65.253  26.970   12.034   47.409   65.333   82.874  119.333 1.002
res[209]    87.094  27.100   33.577   69.194   87.081  104.945  141.467 1.003
res[210]   148.253  27.269   94.421  130.305  148.113  166.284  203.466 1.002
res[211]  -161.236  27.503 -215.889 -178.736 -161.122 -142.886 -108.375 1.001
res[212]  -129.522  27.348 -183.477 -146.819 -129.294 -111.282  -76.871 1.001
res[213]  -190.682  27.231 -243.930 -208.062 -190.524 -172.562 -138.450 1.001
res[214]   -79.289  27.154 -132.322  -96.647  -79.209  -61.143  -27.250 1.001
res[215]    47.949  27.116   -4.985   30.474   48.166   66.107  100.695 1.001
res[216]   114.631  27.119   61.912   96.825  114.839  132.864  167.496 1.001
res[217]   117.095  27.161   63.624   99.215  117.216  135.276  169.783 1.001
res[218]   122.954  27.243   68.976  105.183  123.040  140.999  175.833 1.001
res[219]    57.691  27.364    2.985   40.012   57.620   75.929  110.855 1.001
res[220]   124.990  27.525   70.453  107.235  124.767  143.105  178.606 1.001
res[221]   -28.457  27.809  -85.147  -46.709  -28.877   -8.749   24.203 1.001
res[222]   -40.195  27.642  -96.634  -58.154  -40.465  -20.895   12.714 1.001
res[223]   -83.163  27.513 -139.662 -101.235  -83.213  -63.910  -30.005 1.001
res[224]   -57.737  27.424 -113.878  -75.793  -57.651  -38.683   -5.179 1.001
res[225]   -60.675  27.373 -116.422  -78.560  -60.376  -41.718   -8.273 1.001
res[226]   -36.237  27.363  -91.706  -54.143  -35.975  -17.495   16.397 1.001
res[227]   -53.528  27.391 -108.591  -71.787  -53.313  -34.530   -0.302 1.001
res[228]    82.085  27.460   27.176   63.546   82.505  100.972  135.212 1.001
res[229]   109.582  27.567   54.642   90.994  110.106  128.598  162.713 1.001
res[230]   190.314  27.713  135.634  171.529  190.765  209.465  244.223 1.001
res[231]  -120.252  27.694 -175.928 -138.875 -119.474 -101.313  -68.003 1.001
res[232]  -100.688  27.530 -155.801 -119.226  -99.978  -81.979  -48.238 1.001
res[233]   -91.964  27.405 -146.450 -110.666  -91.280  -73.148  -39.619 1.001
res[234]  -108.171  27.319 -162.489 -126.710 -107.330  -89.436  -55.884 1.001
res[235]    21.527  27.273  -32.755    3.074   22.292   40.459   73.543 1.001
res[236]   -18.622  27.266  -73.068  -36.988  -18.139    0.348   33.406 1.001
res[237]    40.129  27.299  -14.569   21.865   40.523   59.257   92.027 1.001
res[238]   117.718  27.372   62.996   99.591  118.175  136.830  169.568 1.001
res[239]   150.564  27.484   95.949  132.308  150.955  169.833  203.577 1.001
res[240]   128.355  27.634   73.287  109.633  128.714  147.821  181.492 1.001
res[241]   -43.717  26.592  -96.442  -61.945  -43.778  -25.366    7.706 1.002
res[242]   -16.266  26.421  -68.915  -34.345  -16.394    1.657   34.738 1.002
res[243]   -51.824  26.290 -104.250  -69.666  -51.904  -34.191   -0.773 1.002
res[244]   -92.310  26.200 -144.512 -109.770  -92.356  -74.742  -41.007 1.002
res[245]    53.225  26.151    1.165   35.773   53.155   70.545  104.484 1.002
res[246]    35.579  26.143  -16.717   18.099   35.633   52.862   86.869 1.001
res[247]   -33.204  26.177  -85.575  -50.833  -33.098  -15.939   18.146 1.001
res[248]    35.397  26.252  -16.792   17.809   35.174   52.691   87.176 1.001
res[249]    83.314  26.368   30.491   65.761   83.032  100.631  135.542 1.001
res[250]    42.630  26.524   -9.672   24.976   42.309   59.916   95.055 1.001
res[251]  -206.923  27.800 -260.529 -225.880 -206.782 -187.968 -153.986 1.001
res[252]  -157.656  27.629 -211.249 -176.383 -157.567 -138.906 -104.887 1.001
res[253]   -51.271  27.496 -104.867  -70.030  -51.271  -32.412    1.659 1.001
res[254]    12.860  27.402  -40.341   -5.856   13.103   31.625   65.496 1.001
res[255]    11.898  27.348  -41.371   -7.218   11.887   30.504   64.701 1.001
res[256]    -1.747  27.333  -54.813  -20.847   -1.807   16.587   50.997 1.001
res[257]    46.786  27.357   -6.081   27.648   46.704   65.069  100.383 1.001
res[258]    84.114  27.422   31.253   65.110   83.938  102.405  137.813 1.001
res[259]   141.780  27.525   88.996  122.717  141.448  159.933  195.838 1.001
res[260]   140.825  27.667   88.214  121.349  140.766  158.831  195.301 1.001
res[261]   -45.758  27.262  -98.677  -63.456  -45.803  -28.120    8.017 1.002
res[262]   -73.536  27.103 -126.119  -91.086  -73.677  -55.880  -19.998 1.001
res[263]   -66.558  26.984 -118.944  -84.155  -66.732  -49.089  -12.830 1.001
res[264]    -3.221  26.904  -55.491  -20.926   -3.268   14.217   50.110 1.001
res[265]    64.093  26.864   12.275   46.220   64.035   81.487  117.920 1.001
res[266]   -24.292  26.865  -75.837  -42.281  -24.457   -6.832   29.548 1.001
res[267]    11.470  26.906  -40.398   -6.459   11.267   29.011   65.223 1.001
res[268]    69.347  26.987   17.413   51.396   68.896   87.025  123.112 1.001
res[269]    16.854  27.108  -35.179   -1.244   16.533   34.478   70.967 1.001
res[270]    75.619  27.268   23.067   57.629   75.329   93.227  129.655 1.001
res[271]  -225.643  27.480 -278.886 -243.823 -225.694 -207.386 -171.764 1.003
res[272]  -140.428  27.320 -193.206 -158.567 -140.609 -122.309  -86.874 1.003
res[273]   -92.158  27.198 -145.009 -110.346  -92.252  -74.095  -38.573 1.003
res[274]   -37.826  27.116  -90.730  -55.873  -38.139  -19.735   15.494 1.002
res[275]   -22.591  27.074  -75.243  -40.456  -22.982   -4.368   30.621 1.002
res[276]    30.930  27.072  -22.094   13.172   30.419   49.127   84.548 1.002
res[277]   103.777  27.109   50.599   85.820  102.988  121.948  157.742 1.002
res[278]   195.528  27.187  142.165  177.513  194.832  213.701  249.967 1.002
res[279]   173.383  27.304  119.414  155.128  172.627  191.796  228.591 1.001
res[280]    48.822  27.460   -5.443   30.590   47.952   67.271  104.943 1.001
res[281]  -100.761  27.924 -155.664 -119.211 -100.098  -81.104  -47.734 1.001
res[282]   -73.020  27.777 -127.369  -91.266  -72.520  -53.694  -20.563 1.001
res[283]   -64.686  27.669 -119.132  -82.823  -64.075  -45.417  -12.494 1.001
res[284]   -17.650  27.599  -72.206  -35.666  -17.169    1.377   35.020 1.001
res[285]    46.285  27.569   -7.652   28.252   46.815   65.328   99.260 1.001
res[286]    25.187  27.577  -28.572    7.101   25.553   44.083   78.569 1.001
res[287]    23.689  27.625  -29.512    5.427   23.865   42.895   77.192 1.001
res[288]    61.274  27.713    8.220   42.691   61.404   80.495  114.966 1.001
res[289]    48.126  27.838   -5.127   29.210   48.155   67.369  102.003 1.001
res[290]    73.868  28.002   20.444   54.993   73.670   93.109  128.079 1.001
res[291]   -62.043  27.792 -115.822  -80.494  -62.779  -43.673   -4.435 1.001
res[292]   -78.060  27.657 -131.681  -96.527  -78.957  -60.027  -21.083 1.001
res[293]   -97.080  27.560 -150.130 -115.697  -97.882  -79.080  -40.450 1.001
res[294]   -84.403  27.502 -137.305 -103.193  -85.127  -66.419  -27.873 1.001
res[295]   -62.058  27.484 -115.409  -80.974  -62.634  -43.885   -5.395 1.001
res[296]    13.785  27.505  -39.891   -5.375   13.338   32.209   69.885 1.001
res[297]   108.636  27.565   55.243   89.343  108.404  127.130  164.689 1.001
res[298]   103.229  27.665   49.562   83.789  102.942  122.033  159.137 1.001
res[299]    89.617  27.803   35.620   70.171   89.485  108.312  146.507 1.001
res[300]    80.672  27.979   26.414   60.959   80.808   99.562  137.744 1.001
res[301]  -141.883  28.305 -196.509 -160.420 -141.920 -123.442  -84.721 1.001
res[302]  -106.210  28.157 -160.120 -124.453 -106.309  -87.823  -49.394 1.001
res[303]   -37.352  28.047  -91.475  -55.335  -37.285  -19.229   19.895 1.001
res[304]   -18.327  27.975  -72.662  -36.286  -18.237   -0.397   38.713 1.001
res[305]   -86.778  27.942 -140.890 -105.114  -86.791  -68.788  -29.209 1.001
res[306]   -37.999  27.947  -91.849  -56.327  -37.867  -20.131   19.461 1.001
res[307]    69.141  27.991   14.641   50.665   69.178   86.859  126.516 1.001
res[308]   159.261  28.074  104.599  140.704  159.387  177.180  216.359 1.001
res[309]   136.516  28.195   80.873  118.244  136.554  154.819  193.892 1.001
res[310]    84.565  28.354   28.496   66.131   84.693  102.951  142.719 1.002
res[311]     8.480  27.336  -47.030   -9.792    8.978   27.073   59.498 1.003
res[312]    11.977  27.128  -43.062   -5.921   12.427   30.119   62.594 1.003
res[313]    22.210  26.959  -32.858    4.243   22.751   40.219   72.580 1.003
res[314]    60.484  26.829    5.199   42.716   60.942   78.598  110.330 1.002
res[315]    -6.440  26.739  -61.507  -24.246   -6.091   11.508   43.556 1.002
res[316]   -11.502  26.689  -66.443  -29.364  -11.033    6.418   38.397 1.002
res[317]   -51.977  26.680 -107.165  -69.981  -51.390  -33.782   -1.318 1.002
res[318]   -37.802  26.711  -93.392  -55.747  -37.309  -19.574   12.624 1.002
res[319]    18.322  26.783  -37.480    0.309   19.012   36.680   68.620 1.001
res[320]    -6.770  26.895  -62.754  -24.603   -5.931   11.437   44.809 1.001
res[321]  -169.878  27.641 -225.412 -188.557 -170.087 -150.812 -115.846 1.003
res[322]  -115.245  27.475 -170.155 -133.481 -115.610  -96.509  -61.338 1.002
res[323]  -127.030  27.348 -181.991 -145.028 -127.405 -108.460  -73.235 1.002
res[324]   -75.745  27.260 -130.493  -94.150  -76.056  -57.347  -21.877 1.002
res[325]    -4.442  27.211  -59.066  -22.893   -4.731   14.091   49.373 1.002
res[326]    72.438  27.202   17.923   54.115   72.083   90.962  125.624 1.002
res[327]    74.431  27.233   20.320   56.096   74.054   93.130  128.264 1.001
res[328]    86.173  27.303   32.254   68.056   86.103  104.893  140.473 1.001
res[329]   100.100  27.413   46.110   82.027  100.161  118.754  154.311 1.001
res[330]   191.836  27.562  137.087  173.612  191.900  210.527  246.650 1.001
res[331]    -3.568  27.677  -58.111  -22.218   -3.240   14.872   51.330 1.001
res[332]    35.490  27.505  -18.504   16.700   35.467   53.896   89.971 1.001
res[333]    14.836  27.372  -38.705   -3.945   14.883   33.326   69.479 1.001
res[334]    35.529  27.278  -17.795   16.742   35.624   53.845   89.880 1.001
res[335]    57.772  27.224    4.745   39.406   57.712   76.032  112.258 1.001
res[336]     7.505  27.209  -45.201  -11.277    7.241   25.550   61.787 1.001
res[337]   -62.853  27.234 -115.231  -81.656  -63.102  -44.830   -8.470 1.001
res[338]     3.554  27.299  -48.771  -15.196    3.261   21.590   57.887 1.001
res[339]   -47.691  27.403 -100.181  -66.462  -48.175  -29.624    6.870 1.001
res[340]    -7.951  27.546  -60.486  -26.990   -8.417   10.133   47.240 1.001
res[341]  -167.838  27.534 -221.260 -186.767 -167.997 -149.518 -113.530 1.005
res[342]  -109.245  27.409 -162.241 -128.030 -109.426  -91.138  -55.319 1.005
res[343]   -76.905  27.323 -129.335  -95.553  -76.780  -58.727  -23.086 1.004
res[344]   -92.961  27.276 -144.845 -111.585  -92.688  -74.742  -39.601 1.004
res[345]   -15.658  27.269  -67.414  -34.298  -15.410    2.716   37.316 1.004
res[346]    87.984  27.302   36.319   69.290   88.171  106.278  140.902 1.003
res[347]   132.212  27.374   80.204  113.503  132.167  150.380  185.832 1.003
res[348]    30.540  27.486  -21.770   11.869   30.461   48.883   84.590 1.003
res[349]   120.550  27.636   67.565  101.960  120.450  138.866  174.815 1.002
res[350]   123.963  27.825   70.604  105.055  123.691  142.633  178.437 1.002
sigma       86.053   4.095   78.239   83.300   85.994   88.737   94.268 1.013
sigma.B    317.817  38.958  252.469  291.832  313.873  339.888  405.125 1.002
deviance  4111.820  21.476 4069.687 4097.266 4111.765 4126.251 4152.352 1.008
          n.eff
beta[1]    1400
beta[2]     230
gamma[1]   1000
gamma[2]   3000
gamma[3]   1300
gamma[4]   2800
gamma[5]   3000
gamma[6]   3000
gamma[7]   1800
gamma[8]   3000
gamma[9]   1800
gamma[10]  2900
gamma[11]  3000
gamma[12]  1800
gamma[13]  1900
gamma[14]  3000
gamma[15]  3000
gamma[16]  1300
gamma[17]  1100
gamma[18]  3000
gamma[19]  3000
gamma[20]  3000
gamma[21]  3000
gamma[22]  3000
gamma[23]  1800
gamma[24]  3000
gamma[25]   810
gamma[26]  3000
gamma[27]  1500
gamma[28]   570
gamma[29]  3000
gamma[30]  3000
gamma[31]  3000
gamma[32]   660
gamma[33]   730
gamma[34]  3000
gamma[35]   340
res[1]     1100
res[2]     1200
res[3]     1400
res[4]     1700
res[5]     2100
res[6]     2700
res[7]     3000
res[8]     3000
res[9]     3000
res[10]    3000
res[11]    3000
res[12]    3000
res[13]    3000
res[14]    3000
res[15]    3000
res[16]    3000
res[17]    3000
res[18]    3000
res[19]    3000
res[20]    3000
res[21]    1200
res[22]    1400
res[23]    1700
res[24]    2000
res[25]    2500
res[26]    3000
res[27]    3000
res[28]    3000
res[29]    3000
res[30]    3000
res[31]    3000
res[32]    3000
res[33]    3000
res[34]    3000
res[35]    3000
res[36]    3000
res[37]    3000
res[38]    3000
res[39]    3000
res[40]    3000
res[41]    3000
res[42]    3000
res[43]    3000
res[44]    3000
res[45]    3000
res[46]    3000
res[47]    3000
res[48]    3000
res[49]    3000
res[50]    3000
res[51]    3000
res[52]    2800
res[53]    2200
res[54]    1700
res[55]    1400
res[56]    1200
res[57]    1000
res[58]     710
res[59]     630
res[60]     550
res[61]    2000
res[62]    2400
res[63]    3000
res[64]    3000
res[65]    3000
res[66]    3000
res[67]    3000
res[68]    3000
res[69]    3000
res[70]    3000
res[71]    3000
res[72]    3000
res[73]    3000
res[74]    3000
res[75]    3000
res[76]    3000
res[77]    3000
res[78]    3000
res[79]    3000
res[80]    3000
res[81]    2100
res[82]    2600
res[83]    3000
res[84]    3000
res[85]    3000
res[86]    3000
res[87]    3000
res[88]    3000
res[89]    3000
res[90]    3000
res[91]    3000
res[92]    3000
res[93]    3000
res[94]    3000
res[95]    3000
res[96]    3000
res[97]    3000
res[98]    3000
res[99]    3000
res[100]   3000
res[101]   3000
res[102]   3000
res[103]   3000
res[104]   3000
res[105]   3000
res[106]   3000
res[107]   3000
res[108]   3000
res[109]   3000
res[110]   3000
res[111]   1700
res[112]   1400
res[113]   1100
res[114]    980
res[115]    840
res[116]    740
res[117]    650
res[118]    580
res[119]    600
res[120]    480
res[121]   1600
res[122]   2000
res[123]   2400
res[124]   3000
res[125]   3000
res[126]   3000
res[127]   3000
res[128]   3000
res[129]   3000
res[130]   3000
res[131]   3000
res[132]   3000
res[133]   3000
res[134]   3000
res[135]   3000
res[136]   3000
res[137]   3000
res[138]   3000
res[139]   2700
res[140]   3000
res[141]   3000
res[142]   3000
res[143]   3000
res[144]   3000
res[145]   3000
res[146]   3000
res[147]   3000
res[148]   3000
res[149]   3000
res[150]   3000
res[151]   1600
res[152]   1900
res[153]   2300
res[154]   3000
res[155]   3000
res[156]   3000
res[157]   3000
res[158]   3000
res[159]   3000
res[160]   3000
res[161]   1000
res[162]   1200
res[163]   1400
res[164]   1700
res[165]   2100
res[166]   2600
res[167]   3000
res[168]   3000
res[169]   3000
res[170]   3000
res[171]   3000
res[172]   3000
res[173]   3000
res[174]   3000
res[175]   3000
res[176]   3000
res[177]   2700
res[178]   2200
res[179]   2000
res[180]   1500
res[181]   3000
res[182]   3000
res[183]   3000
res[184]   3000
res[185]   3000
res[186]   3000
res[187]   3000
res[188]   3000
res[189]   3000
res[190]   3000
res[191]   3000
res[192]   3000
res[193]   3000
res[194]   3000
res[195]   3000
res[196]   2500
res[197]   2000
res[198]   1700
res[199]   1400
res[200]   1200
res[201]   3000
res[202]   3000
res[203]   2700
res[204]   2100
res[205]   1700
res[206]   1400
res[207]   1200
res[208]   1000
res[209]    890
res[210]   1100
res[211]   3000
res[212]   3000
res[213]   3000
res[214]   3000
res[215]   3000
res[216]   3000
res[217]   3000
res[218]   3000
res[219]   3000
res[220]   3000
res[221]   1800
res[222]   2200
res[223]   2800
res[224]   3000
res[225]   3000
res[226]   3000
res[227]   3000
res[228]   3000
res[229]   3000
res[230]   3000
res[231]   3000
res[232]   3000
res[233]   3000
res[234]   3000
res[235]   3000
res[236]   3000
res[237]   3000
res[238]   3000
res[239]   3000
res[240]   3000
res[241]    900
res[242]   1000
res[243]   1200
res[244]   1400
res[245]   1800
res[246]   2200
res[247]   2800
res[248]   3000
res[249]   3000
res[250]   3000
res[251]   3000
res[252]   3000
res[253]   3000
res[254]   3000
res[255]   3000
res[256]   3000
res[257]   3000
res[258]   3000
res[259]   2600
res[260]   2100
res[261]   1600
res[262]   1900
res[263]   2400
res[264]   3000
res[265]   3000
res[266]   3000
res[267]   3000
res[268]   3000
res[269]   3000
res[270]   3000
res[271]    590
res[272]    650
res[273]    730
res[274]    830
res[275]    960
res[276]   1100
res[277]   1200
res[278]   1500
res[279]   1800
res[280]   2500
res[281]   3000
res[282]   3000
res[283]   3000
res[284]   3000
res[285]   3000
res[286]   3000
res[287]   3000
res[288]   3000
res[289]   3000
res[290]   2800
res[291]   3000
res[292]   3000
res[293]   3000
res[294]   3000
res[295]   3000
res[296]   3000
res[297]   3000
res[298]   3000
res[299]   3000
res[300]   3000
res[301]   3000
res[302]   3000
res[303]   3000
res[304]   3000
res[305]   3000
res[306]   3000
res[307]   3000
res[308]   2700
res[309]   2300
res[310]   1700
res[311]    610
res[312]    670
res[313]    760
res[314]    860
res[315]    990
res[316]   1200
res[317]   1400
res[318]   1700
res[319]   2100
res[320]   2600
res[321]    770
res[322]    870
res[323]   1000
res[324]   1200
res[325]   1400
res[326]   1600
res[327]   2000
res[328]   2600
res[329]   2700
res[330]   3000
res[331]   3000
res[332]   3000
res[333]   3000
res[334]   3000
res[335]   3000
res[336]   3000
res[337]   3000
res[338]   3000
res[339]   3000
res[340]   3000
res[341]    350
res[342]    380
res[343]    420
res[344]    460
res[345]    510
res[346]    570
res[347]    810
res[348]    740
res[349]   1200
res[350]   1500
sigma       130
sigma.B    3000
deviance    200

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 229.5 and DIC = 4341.4
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Given that Time cannot be randomized, there is likely to be a temporal dependency structure to the data. The above analyses assume no temporal dependency - actually, they assume that the variance-covariance matrix demonstrates a structure known as sphericity. Lets specifically model in a first order autoregressive correlation structure in an attempt to accommodate the expected temporal autocorrelation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString3=&amp;quot;
+ model {
+    #Likelihood
+    y[1]~dnorm(mu[1],tau)
+    mu[1] &amp;lt;- eta1[1]
+    eta1[1] ~ dnorm(eta[1], taueps)
+    eta[1] &amp;lt;- inprod(beta[],X[1,]) + gamma[Block[1]]
+    res[1] &amp;lt;- y[1]-mu[1]
+    for (i in 2:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- eta1[i]
+       eta1[i] ~ dnorm(temp[i], taueps)
+       temp[i] &amp;lt;- eta[i] + -rho*(mu[i-1]-y[i-1])
+       eta[i] &amp;lt;- inprod(beta[],X[i,]) + gamma[Block[i]]
+     res[i] &amp;lt;- y[i]-mu[i]
+    } 
+    beta ~ dmnorm(a0,A0)
+    for (i in 1:nBlock) {
+      gamma[i] ~ dnorm(0, tau.B) #prior
+    }
+    rho ~ dunif(-1,1)
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;- z/sqrt(chSq) 
+    z ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq ~ dgamma(0.5, 0.5)
+    taueps &amp;lt;- pow(sigma.eps,-2)
+    sigma.eps &amp;lt;- z/sqrt(chSq.eps) 
+    z.eps ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.eps ~ dgamma(0.5, 0.5)
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;- z/sqrt(chSq.B) 
+    z.B ~ dnorm(0, 0.0016)I(0,)  #1/25^2 = 0.0016
+    chSq.B ~ dgamma(0.5, 0.5)
+    sd.y &amp;lt;- sd(res)
+    sd.block &amp;lt;- sd(gamma)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString3, con = &amp;quot;matrixModel3.txt&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~Time,data.rm)
&amp;gt; data.rm.list &amp;lt;- with(data.rm,
+         list(y=y,
+                  Block=as.numeric(Block),
+          X=Xmat,
+          n=nrow(data.rm),
+          nBlock=length(levels(Block)),
+          a0=rep(0,ncol(Xmat)), A0=diag(ncol(Xmat))
+          )
+ )
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;#39;gamma&amp;#39;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;quot;res&amp;quot;,&amp;#39;sigma.eps&amp;#39;,&amp;#39;rho&amp;#39;,&amp;#39;sd.y&amp;#39;,&amp;#39;sd.block&amp;#39;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.rm.r2jags.mt &amp;lt;- jags(data = data.rm.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;matrixModel3.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 350
   Unobserved stochastic nodes: 393
   Total graph size: 3931

Initializing model
&amp;gt; 
&amp;gt; data.rm.mt.mcmc &amp;lt;- data.rm.r2jags.mt$BUGSoutput$sims.matrix
&amp;gt; summary(as.mcmc(data.rm.mt.mcmc[,grep(&amp;#39;beta|sigma|rho&amp;#39;,colnames(data.rm.mt.mcmc))]))

Iterations = 1:3000
Thinning interval = 1 
Number of chains = 1 
Sample size per chain = 3000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

              Mean      SD Naive SE Time-series SE
beta[1]     0.1093  1.0090 0.018422       0.018422
beta[2]     9.1917  1.0421 0.019026       0.019026
rho         0.6991  0.1635 0.002985       0.002985
sigma      63.1901  7.6813 0.140241       0.140241
sigma.B   314.5779 38.4731 0.702419       0.702419
sigma.eps  32.8263  9.4551 0.172625       0.172625

2. Quantiles for each variable:

              2.5%      25%       50%      75%    97.5%
beta[1]    -1.8402  -0.5698   0.09792   0.7920   2.0576
beta[2]     7.2315   8.4966   9.19938   9.8961  11.2232
rho         0.4549   0.5508   0.68313   0.8453   0.9746
sigma      49.8811  56.9814  62.70134  69.5262  77.4328
sigma.B   251.2601 286.7395 310.40901 338.2187 398.3167
sigma.eps  14.8598  25.5907  35.65555  40.2488  46.3558
&amp;gt; 
&amp;gt; #head(data.rm.r2jags.mt$BUGSoutput$sims.list[[c(&amp;#39;beta&amp;#39;,&amp;#39;rho&amp;#39;,&amp;#39;sigma&amp;#39;)]]) 
&amp;gt; #print(data.rm.r2jags.mt)
&amp;gt; data.rm.mcmc.list.mt &amp;lt;- as.mcmc(data.rm.r2jags.mt)
&amp;gt; Data.Rm.mcmc.list.mt &amp;lt;- data.rm.mcmc.list.mt
&amp;gt; 
&amp;gt; # R2 calculations
&amp;gt; Xmat &amp;lt;- model.matrix(~Time, data.rm)
&amp;gt; coefs &amp;lt;- data.rm.r2jags.mt$BUGSoutput$sims.list[[&amp;#39;beta&amp;#39;]]
&amp;gt; fitted &amp;lt;- coefs %*% t(Xmat)
&amp;gt; X.var &amp;lt;- aaply(fitted,1,function(x){var(x)})
&amp;gt; X.var[1:10]
       1        2        3        4        5        6        7        8 
814.3418 591.0181 634.1438 685.5362 900.1883 740.2397 864.5962 435.7952 
       9       10 
672.4743 584.2064 
&amp;gt; 
&amp;gt; Z.var &amp;lt;- data.rm.r2jags.mt$BUGSoutput$sims.list[[&amp;#39;sd.block&amp;#39;]]^2
&amp;gt; R.var &amp;lt;- data.rm.r2jags.mt$BUGSoutput$sims.list[[&amp;#39;sd.y&amp;#39;]]^2
&amp;gt; R2.marginal &amp;lt;- (X.var)/(X.var+Z.var+R.var)
&amp;gt; R2.marginal &amp;lt;- data.frame(Mean=mean(R2.marginal), Median=median(R2.marginal), HPDinterval(as.mcmc(R2.marginal)))
&amp;gt; R2.conditional &amp;lt;- (X.var+Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.conditional &amp;lt;- data.frame(Mean=mean(R2.conditional),
+    Median=median(R2.conditional), HPDinterval(as.mcmc(R2.conditional)))
&amp;gt; R2.block &amp;lt;- (Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.block &amp;lt;- data.frame(Mean=mean(R2.block), Median=median(R2.block), HPDinterval(as.mcmc(R2.block)))
&amp;gt; R2.res&amp;lt;-(R.var)/(X.var+Z.var+R.var)
&amp;gt; R2.res &amp;lt;- data.frame(Mean=mean(R2.res), Median=median(R2.res), HPDinterval(as.mcmc(R2.res)))
&amp;gt; 
&amp;gt; (r2 &amp;lt;- rbind(R2.block=R2.block, R2.marginal=R2.marginal, R2.res=R2.res, R2.conditional=R2.conditional))
                     Mean     Median      lower     upper
R2.block       0.52595295 0.52197768 0.40289527 0.6376026
R2.marginal    0.07190426 0.06983026 0.03887103 0.1087763
R2.res         0.40214279 0.40351594 0.28261806 0.5200679
R2.conditional 0.59785721 0.59648406 0.47993214 0.7173819&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It would appear that the incorporation of a first order autocorrelation structure is indeed appropriate. The degree of correlation between successive points is &lt;span class=&#34;math inline&#34;&gt;\(0.733\)&lt;/span&gt;. Let’s have a look at a summary figure.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; coefs &amp;lt;- data.rm.r2jags.mt$BUGSoutput$sims.list[[&amp;#39;beta&amp;#39;]]
&amp;gt; newdata &amp;lt;- with(data.rm, data.frame(Time=seq(min(Time, na.rm=TRUE), max(Time, na.rm=TRUE), len=100)))
&amp;gt; Xmat &amp;lt;- model.matrix(~Time, newdata)
&amp;gt; pred &amp;lt;- (coefs %*% t(Xmat))
&amp;gt; pred &amp;lt;- adply(pred, 2, function(x) {
+    data.frame(Mean=mean(x), Median=median(x, na.rm=TRUE), t(quantile(x,na.rm=TRUE)),
+               HPDinterval(as.mcmc(x)),HPDinterval(as.mcmc(x),p=0.5))
+ })
&amp;gt; newdata &amp;lt;- cbind(newdata, pred)
&amp;gt; #Also calculate the partial observations
&amp;gt; Xmat &amp;lt;- model.matrix(~Time, data.rm)
&amp;gt; pred &amp;lt;- colMeans(as.vector(coefs %*% t(Xmat))+data.rm.r2jags.mt$BUGSoutput$sims.list[[&amp;#39;res&amp;#39;]])
&amp;gt; part.obs &amp;lt;- cbind(data.rm,Median=pred)
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y=Median, x=Time)) +
+   geom_point(data=part.obs, aes(y=Median))+
+   geom_ribbon(aes(ymin=lower, ymax=upper), fill=&amp;#39;blue&amp;#39;,alpha=0.2) +
+   geom_line()+
+   scale_x_continuous(&amp;#39;Time&amp;#39;) +
+   scale_y_continuous(&amp;#39;Y&amp;#39;) +
+   theme_classic() +
+   theme(axis.title.y = element_text(vjust=2, size=rel(1.2)),
+         axis.title.x = element_text(vjust=-2, size=rel(1.2)),
+         plot.margin=unit(c(0.5,0.5,2,2), &amp;#39;lines&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/block-anova-jags/2020-02-01-block-anova-jags_files/figure-html/R2sd_model_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Randomised Complete Block Anova - STAN</title>
      <link>/stan/block-anova-stan/block-anova-stan/</link>
      <pubDate>Mon, 10 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/stan/block-anova-stan/block-anova-stan/</guid>
      <description>


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;STAN&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman, Lee, and Guo (2015)&lt;/span&gt;) using the package &lt;code&gt;rstan&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Stan Development Team (2018)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In the previous tutorial (nested ANOVA), we introduced the concept of employing sub-replicates that are nested within the main treatment levels as a means of absorbing some of the unexplained variability that would otherwise arise from designs in which sampling units are selected from amongst highly heterogeneous conditions. Such (nested) designs are useful in circumstances where the levels of the main treatment (such as burnt and un-burnt sites) occur at a much larger temporal or spatial scale than the experimental/sampling units (e.g. vegetation monitoring quadrats). For circumstances in which the main treatments can be applied (or naturally occur) at the same scale as the sampling units (such as whether a stream rock is enclosed by a fish proof fence or not), an alternative design is available. In this design (&lt;strong&gt;randomised complete block design&lt;/strong&gt;), each of the levels of the main treatment factor are grouped (blocked) together (in space and/or time) and therefore, whilst the conditions between the groups (referred to as “blocks”) might vary substantially, the conditions under which each of the levels of the treatment are tested within any given block are far more homogeneous.&lt;/p&gt;
&lt;p&gt;If any differences between blocks (due to the heterogeneity) can account for some of the total variability between the sampling units (thereby reducing the amount of variability that the main treatment(s) failed to explain), then the main test of treatment effects will be more powerful/sensitive. As an simple example of a randomised complete block (RCB) design, consider an investigation into the roles of different organism scales (microbial, macro invertebrate and vertebrate) on the breakdown of leaf debris packs within streams. An experiment could consist of four treatment levels - leaf packs protected by fish-proof mesh, leaf packs protected by fine macro invertebrate exclusion mesh, leaf packs protected by dissolving antibacterial tablets, and leaf packs relatively unprotected as controls. As an acknowledgement that there are many other unmeasured factors that could influence leaf pack breakdown (such as flow velocity, light levels, etc) and that these are likely to vary substantially throughout a stream, the treatments are to be arranged into groups or “blocks” (each containing a single control, microbial, macro invertebrate and fish protected leaf pack). Blocks of treatment sets are then secured in locations haphazardly selected throughout a particular reach of stream. Importantly, the arrangement of treatments in each block must be randomized to prevent the introduction of some systematic bias - such as light angle, current direction etc.&lt;/p&gt;
&lt;p&gt;Blocking does however come at a cost. The blocks absorb both unexplained variability as well as degrees of freedom from the residuals. Consequently, if the amount of the total unexplained variation that is absorbed by the blocks is not sufficiently large enough to offset the reduction in degrees of freedom (which may result from either less than expected heterogeneity, or due to the scale at which the blocks are established being inappropriate to explain much of the variation), for a given number of sampling units (leaf packs), the tests of main treatment effects will suffer power reductions. Treatments can also be applied sequentially or repeatedly at the scale of the entire block, such that at any single time, only a single treatment level is being applied (see the lower two sub-figures above). Such designs are called repeated measures. A repeated measures ANOVA is to an single factor ANOVA as a paired t-test is to a independent samples t-test. One example of a repeated measures analysis might be an investigation into the effects of a five different diet drugs (four doses and a placebo) on the food intake of lab rats. Each of the rats (“subjects”) is subject to each of the four drugs (within subject effects) which are administered in a random order. In another example, temporal recovery responses of sharks to bi-catch entanglement stresses might be simulated by analyzing blood samples collected from captive sharks (subjects) every half hour for three hours following a stress inducing restraint. This repeated measures design allows the anticipated variability in stress tolerances between individual sharks to be accounted for in the analysis (so as to permit more powerful test of the main treatments). Furthermore, by performing repeated measures on the same subjects, repeated measures designs reduce the number of subjects required for the investigation. Essentially, this is a randomised complete block design except that the within subject (block) effect (e.g. time since stress exposure) cannot be randomised.&lt;/p&gt;
&lt;p&gt;To suppress contamination effects resulting from the proximity of treatment sampling units within a block, units should be adequately spaced in time and space. For example, the leaf packs should not be so close to one another that the control packs are effected by the antibacterial tablets and there should be sufficient recovery time between subsequent drug administrations. In addition, the order or arrangement of treatments within the blocks must be randomized so as to prevent both confounding as well as computational complications. Whilst this is relatively straight forward for the classic randomized complete block design (such as the leaf packs in streams), it is logically not possible for repeated measures designs. Blocking factors are typically random factors that represent all the possible blocks that could be selected. As such, no individual block can truly be replicated. Randomised complete block and repeated measures designs can therefore also be thought of as un-replicated factorial designs in which there are two or more factors but that the interactions between the blocks and all the within block factors are not replicated.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models&lt;/h2&gt;
&lt;p&gt;The linear models for two and three factor nested design are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \mu + \beta_i + \alpha_j + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \beta_i + \alpha_j + \gamma_k + (\beta\alpha)_{ij} + (\beta\gamma)_{ik} + (\alpha\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \epsilon_{ijk}, \;\;\; \text{(Model 1)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \beta_i + \alpha_j + \gamma_k + (\alpha\gamma)_{jk} + \epsilon_{ijk}, \;\;\; \text{(Model 2)},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of the Blocking Factor B (&lt;span class=&#34;math inline&#34;&gt;\(\sum \beta=0\)&lt;/span&gt;), &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; are the effects of withing block Factor A and Factor C, respectively, and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon \sim N(0,\sigma^2)\)&lt;/span&gt; is the random unexplained or residual component.&lt;/p&gt;
&lt;p&gt;Tests for the effects of blocks as well as effects within blocks assume that there are no interactions between blocks and the within block effects. That is, it is assumed that any effects are of similar nature within each of the blocks. Whilst this assumption may well hold for experiments that are able to consciously set the scale over which the blocking units are arranged, when designs utilize arbitrary or naturally occurring blocking units, the magnitude and even polarity of the main effects are likely to vary substantially between the blocks. The preferred (non-additive or “Model 1”) approach to un-replicated factorial analysis of some bio-statisticians is to include the block by within subject effect interactions (e.g. &lt;span class=&#34;math inline&#34;&gt;\(\beta\alpha\)&lt;/span&gt;). Whilst these interaction effects cannot be formally tested, they can be used as the denominators in F-ratio calculations of their respective main effects tests. Proponents argue that since these blocking interactions cannot be formally tested, there is no sound inferential basis for using these error terms separately. Alternatively, models can be fitted additively (“Model 2”) whereby all the block by within subject effect interactions are pooled into a single residual term (&lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt;). Although the latter approach is simpler, each of the within subject effects tests do assume that there are no interactions involving the blocks and that perhaps even more restrictively, that sphericity holds across the entire design.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;As with other ANOVA designs, the reliability of hypothesis tests is dependent on the residuals being:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;independent of one another. Although the observations within a block may not strictly be independent, provided the treatments are applied or ordered randomly within each block or subject, within block proximity effects on the residuals should be random across all blocks and thus the residuals should still be independent of one another. Nevertheless, it is important that experimental units within blocks are adequately spaced in space and time so as to suppress contamination or carryover effects.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;simple-rcb&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simple RCB&lt;/h1&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Imagine we has designed an experiment in which we intend to measure a response (y) to one of treatments (three levels; “a1”, “a2” and “a3”). Unfortunately, the system that we intend to sample is spatially heterogeneous and thus will add a great deal of noise to the data that will make it difficult to detect a signal (impact of treatment). Thus in an attempt to constrain this variability you decide to apply a design (RCB) in which each of the treatments within each of 35 blocks dispersed randomly throughout the landscape. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(plyr)
&amp;gt; set.seed(123)
&amp;gt; nTreat &amp;lt;- 3
&amp;gt; nBlock &amp;lt;- 35
&amp;gt; sigma &amp;lt;- 5
&amp;gt; sigma.block &amp;lt;- 12
&amp;gt; n &amp;lt;- nBlock*nTreat
&amp;gt; Block &amp;lt;- gl(nBlock, k=1)
&amp;gt; A &amp;lt;- gl(nTreat,k=1)
&amp;gt; dt &amp;lt;- expand.grid(A=A,Block=Block)
&amp;gt; #Xmat &amp;lt;- model.matrix(~Block + A + Block:A, data=dt)
&amp;gt; Xmat &amp;lt;- model.matrix(~-1+Block + A, data=dt)
&amp;gt; block.effects &amp;lt;- rnorm(n = nBlock, mean = 40, sd = sigma.block)
&amp;gt; A.effects &amp;lt;- c(30,40)
&amp;gt; all.effects &amp;lt;- c(block.effects,A.effects)
&amp;gt; lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; # OR
&amp;gt; Xmat &amp;lt;- cbind(model.matrix(~-1+Block,data=dt),model.matrix(~-1+A,data=dt))
&amp;gt; ## Sum to zero block effects
&amp;gt; block.effects &amp;lt;- rnorm(n = nBlock, mean = 0, sd = sigma.block)
&amp;gt; A.effects &amp;lt;- c(40,70,80)
&amp;gt; all.effects &amp;lt;- c(block.effects,A.effects)
&amp;gt; lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; 
&amp;gt; 
&amp;gt; ## the quadrat observations (within sites) are drawn from
&amp;gt; ## normal distributions with means according to the site means
&amp;gt; ## and standard deviations of 5
&amp;gt; y &amp;lt;- rnorm(n,lin.pred,sigma)
&amp;gt; data.rcb &amp;lt;- data.frame(y=y, expand.grid(A=A, Block=Block))
&amp;gt; head(data.rcb)  #print out the first six rows of the data set
         y A Block
1 45.80853 1     1
2 66.71784 2     1
3 93.29238 3     1
4 43.10101 1     2
5 73.20697 2     2
6 91.77487 3     2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y~A, data.rcb)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/block-anova-stan/2020-02-01-block-anova-stan_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. . More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Block by within-Block interaction&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(car)
&amp;gt; with(data.rcb, interaction.plot(A,Block,y))
&amp;gt; 
&amp;gt; #OR with ggplot
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/block-anova-stan/2020-02-01-block-anova-stan_files/figure-html/exp2_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data.rcb, aes(y=y, x=A, group=Block,color=Block)) + geom_line() +
+   guides(color=guide_legend(ncol=3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/block-anova-stan/2020-02-01-block-anova-stan_files/figure-html/exp2_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; residualPlots(lm(y~Block+A, data.rcb))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/block-anova-stan/2020-02-01-block-anova-stan_files/figure-html/exp2_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;           Test stat Pr(&amp;gt;|Test stat|)
Block                                
A                                    
Tukey test   -1.4163           0.1567
&amp;gt; 
&amp;gt; # the Tukey&amp;#39;s non-additivity test by itself can be obtained via an internal function
&amp;gt; # within the car package
&amp;gt; car:::tukeyNonaddTest(lm(y~Block+A, data.rcb))
      Test     Pvalue 
-1.4163343  0.1566776 
&amp;gt; 
&amp;gt; # alternatively, there is also a Tukey&amp;#39;s non-additivity test within the
&amp;gt; # asbio package
&amp;gt; library(asbio)
&amp;gt; with(data.rcb,tukey.add.test(y,A,Block))

Tukey&amp;#39;s one df test for additivity 
F = 2.0060029   Denom df = 67    p-value = 0.1613102&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there is no visual or inferential evidence of any major interactions between Block and the within-Block effect (A). Any trends appear to be reasonably consistent between Blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Full parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\beta_0 + \beta_i + \gamma_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{ij)} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0, \beta_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The &lt;em&gt;full parameterisation&lt;/em&gt;, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\beta_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Matrix parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\boldsymbol \beta \boldsymbol X + \gamma_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{ij} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta \sim MVN(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The full parameterisation, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\beta_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;). The &lt;em&gt;matrix parameterisation&lt;/em&gt; is a compressed notation, In this parameterisation, there are three alpha parameters (one representing the mean of treatment a1, and the other two representing the treatment effects (differences between a2 and a1 and a3 and a1). In generating priors for each of these three alpha parameters, we could loop through each and define a non-informative normal prior to each (as in the Full parameterisation version). However, it turns out that it is more efficient (in terms of mixing and thus the number of necessary iterations) to define the priors from a multivariate normal distribution. This has as many means as there are parameters to estimate (&lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt;) and a &lt;span class=&#34;math inline&#34;&gt;\(3\times3\)&lt;/span&gt; matrix of zeros and &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; in the diagonals.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol \mu =
  \begin{bmatrix} 0  \\ 0  \\ 0 \end{bmatrix}, \;\;\; \sigma^2 \sim   
  \begin{bmatrix}
   1000000 &amp;amp; 0 &amp;amp; 0 \\
   0 &amp;amp; 1000000 &amp;amp; 0 \\
   0 &amp;amp; 0 &amp;amp; 1000000
   \end{bmatrix}. \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}= \beta_0 + \beta_i + \gamma_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{ij} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0, \beta_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Rather than assume a specific variance-covariance structure, just like &lt;code&gt;lme&lt;/code&gt; we can incorporate an appropriate structure to account for different dependency/correlation structures in our data. In RCB designs, it is prudent to capture the residuals to allow checks that there are no outstanding dependency issues following model fitting.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;full-means-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full means parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstanString=&amp;quot;
+ data{
+    int n;
+    int nA;
+    int nB;
+    vector [n] y;
+    int A[n];
+    int B[n];
+ }
+ 
+ parameters{
+   real alpha[nA];
+   real&amp;lt;lower=0&amp;gt; sigma;
+   vector [nB] beta;
+   real&amp;lt;lower=0&amp;gt; sigma_B;
+ }
+  
+ model{
+     real mu[n];
+ 
+     // Priors
+     alpha ~ normal( 0 , 100 );
+     beta ~ normal( 0 , sigma_B );
+     sigma_B ~ cauchy( 0 , 25 );
+     sigma ~ cauchy( 0 , 25 );
+     
+     for ( i in 1:n ) {
+         mu[i] = alpha[A[i]] + beta[B[i]];
+     }
+     y ~ normal( mu , sigma );
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstanString, con = &amp;quot;fullModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.list &amp;lt;- with(data.rcb, list(y=y, A=as.numeric(A), B=as.numeric(Block),
+   n=nrow(data.rcb), nB=length(levels(Block)),nA=length(levels(A))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma_B&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;STAN&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;rstan&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;STAN&lt;/code&gt; code via the &lt;code&gt;rstan&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.rstan.c &amp;lt;- stan(data = data.rcb.list, file = &amp;quot;fullModel.stan&amp;quot;, 
+                          chains = nChains, pars = params, iter = nIter, 
+                          warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;fullModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.406 seconds (Warm-up)
Chain 1:                0.218 seconds (Sampling)
Chain 1:                0.624 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;fullModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.347 seconds (Warm-up)
Chain 2:                0.187 seconds (Sampling)
Chain 2:                0.534 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.rcb.rstan.c, par = c(&amp;quot;alpha&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;sigma_B&amp;quot;))
Inference for Stan model: fullModel.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

          mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
alpha[1] 41.62    0.10 2.22 37.25 40.16 41.60 43.04 46.10   503    1
alpha[2] 69.56    0.10 2.23 65.09 68.08 69.55 71.00 74.06   501    1
alpha[3] 81.91    0.10 2.21 77.50 80.46 81.89 83.35 86.41   512    1
sigma     5.06    0.01 0.45  4.28  4.74  5.03  5.35  6.06  2235    1
sigma_B  11.71    0.03 1.53  9.19 10.60 11.57 12.67 15.17  3266    1

Samples were drawn using NUTS(diag_e) at Thu Feb 20 11:13:14 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; data.rcb.rstan.c.df &amp;lt;-as.data.frame(extract(data.rcb.rstan.c))
&amp;gt; head(data.rcb.rstan.c.df)
   alpha.1  alpha.2  alpha.3    sigma   sigma_B      lp__
1 39.79771 67.25749 80.02741 5.282417 12.242788 -322.0344
2 42.06012 69.10275 82.61692 5.337436 13.564846 -320.3613
3 44.78961 68.80971 82.67198 5.738811  9.592255 -330.7680
4 43.87492 71.52632 83.14572 5.623264 12.883006 -329.6773
5 41.66449 69.57592 82.74876 4.660046  9.676986 -315.6445
6 44.58965 71.16270 83.85940 5.243767 11.651670 -324.5751
&amp;gt; 
&amp;gt; data.rcb.mcmc.c&amp;lt;-rstan:::as.mcmc.list.stanfit(data.rcb.rstan.c)
&amp;gt; 
&amp;gt; library(coda)
&amp;gt; MCMCsum &amp;lt;- function(x) {
+    data.frame(Median=median(x, na.rm=TRUE), t(quantile(x,na.rm=TRUE)),
+               HPDinterval(as.mcmc(x)),HPDinterval(as.mcmc(x),p=0.5))
+ }
&amp;gt; 
&amp;gt; plyr:::adply(as.matrix(data.rcb.rstan.c.df),2,MCMCsum)
       X1      Median         X0.        X25.        X50.        X75.
1 alpha.1   41.597151   33.420664   40.156779   41.597151   43.039950
2 alpha.2   69.545338   62.734285   68.079657   69.545338   70.998104
3 alpha.3   81.886423   75.169984   80.457712   81.886423   83.351567
4   sigma    5.031927    3.809447    4.735465    5.031927    5.354484
5 sigma_B   11.567999    7.856574   10.598430   11.567999   12.672590
6    lp__ -321.445808 -348.603106 -325.384920 -321.445808 -317.997899
        X100.       lower       upper     lower.1     upper.1
1   50.023636   37.176909   46.004039   39.946809   42.769474
2   77.380653   65.407869   74.292016   68.088148   71.000258
3   89.460777   77.157802   86.028401   80.283264   83.159508
4    7.032198    4.266709    5.994735    4.675345    5.271463
5   17.627994    8.771093   14.580594   10.177722   12.169971
6 -307.471584 -332.225405 -311.436678 -323.628137 -316.377883&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;full-effect-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full effect parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstan2String=&amp;quot;
+ data{
+    int n;
+    int nB;
+    vector [n] y;
+    int A2[n];
+    int A3[n];
+    int B[n];
+ }
+ 
+ parameters{
+   real alpha0;
+   real alpha2;
+   real alpha3;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   vector [nB] beta;
+   real&amp;lt;lower=0&amp;gt; sigma_B;
+ }
+  
+ model{
+     real mu[n];
+ 
+     // Priors
+     alpha0 ~ normal( 0 , 1000 );
+     alpha2 ~ normal( 0 , 1000 );
+     alpha3 ~ normal( 0 , 1000 );
+     beta ~ normal( 0 , sigma_B );
+     sigma_B ~ cauchy( 0 , 25 );
+     sigma ~ cauchy( 0 , 25 );
+     
+     for ( i in 1:n ) {
+         mu[i] = alpha0 + alpha2*A2[i] + 
+                alpha3*A3[i] + beta[B[i]];
+     }
+     y ~ normal( mu , sigma );
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstan2String, con = &amp;quot;full2Model.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; A2 &amp;lt;- ifelse(data.rcb$A==&amp;#39;2&amp;#39;,1,0)
&amp;gt; A3 &amp;lt;- ifelse(data.rcb$A==&amp;#39;3&amp;#39;,1,0)
&amp;gt; data.rcb.list &amp;lt;- with(data.rcb, list(y=y, A2=A2, A3=A3, B=as.numeric(Block),
+    n=nrow(data.rcb), nB=length(levels(Block))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha0&amp;quot;,&amp;quot;alpha2&amp;quot;,&amp;quot;alpha3&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma_B&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;STAN&lt;/code&gt; code via the &lt;code&gt;rstan&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.rstan.f &amp;lt;- stan(data = data.rcb.list, file = &amp;quot;full2Model.stan&amp;quot;, 
+                          chains = nChains, pars = params, iter = nIter, 
+                          warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;full2Model&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.704 seconds (Warm-up)
Chain 1:                0.233 seconds (Sampling)
Chain 1:                0.937 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;full2Model&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.673 seconds (Warm-up)
Chain 2:                0.264 seconds (Sampling)
Chain 2:                0.937 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.rcb.rstan.f, par = c(&amp;quot;alpha0&amp;quot;, &amp;quot;alpha2&amp;quot;, &amp;quot;alpha3&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;sigma_B&amp;quot;))
Inference for Stan model: full2Model.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

         mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
alpha0  41.71    0.15 2.21 37.04 40.32 41.77 43.19 45.96   226    1
alpha2  27.97    0.03 1.20 25.68 27.16 27.97 28.77 30.41  2096    1
alpha3  40.29    0.03 1.20 37.88 39.52 40.27 41.07 42.73  2085    1
sigma    5.08    0.01 0.45  4.32  4.76  5.05  5.35  6.08  1585    1
sigma_B 11.73    0.03 1.58  9.10 10.62 11.58 12.73 15.13  2104    1

Samples were drawn using NUTS(diag_e) at Thu Feb 20 11:14:01 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; data.rcb.rstan.f.df &amp;lt;-as.data.frame(extract(data.rcb.rstan.f))
&amp;gt; head(data.rcb.rstan.f.df)
    alpha0   alpha2   alpha3    sigma  sigma_B      lp__
1 39.38308 27.48083 39.10102 5.742481 14.31952 -331.6050
2 38.29360 28.13918 41.58618 4.724267 11.67688 -315.5252
3 42.98642 26.90932 39.18832 6.013423 10.67375 -327.8293
4 43.84156 28.24367 38.43665 4.755819 11.80901 -318.5703
5 41.76138 30.59659 40.03245 5.299085 11.85943 -321.7613
6 42.46431 28.85686 39.76470 5.240906 10.37141 -317.9281
&amp;gt; 
&amp;gt; data.rcb.mcmc.f&amp;lt;-rstan:::as.mcmc.list.stanfit(data.rcb.rstan.f)
&amp;gt; 
&amp;gt; plyr:::adply(as.matrix(data.rcb.rstan.f.df),2,MCMCsum)
       X1      Median         X0.       X25.        X50.        X75.      X100.
1  alpha0   41.765430   32.584162   40.32217   41.765430   43.185446   48.91023
2  alpha2   27.970882   22.825642   27.16208   27.970882   28.768852   32.68851
3  alpha3   40.269416   35.484427   39.52038   40.269416   41.069445   44.40748
4   sigma    5.046204    3.830609    4.75756    5.046204    5.345414    6.99463
5 sigma_B   11.580959    7.573467   10.61634   11.580959   12.733706   20.27037
6    lp__ -321.442061 -344.215535 -325.37936 -321.442061 -317.729990 -306.64478
        lower       upper     lower.1     upper.1
1   37.196783   46.064222   40.350871   43.199889
2   25.626233   30.328589   27.296888   28.895397
3   37.695622   42.536499   39.488834   41.025024
4    4.216449    5.950882    4.696235    5.273486
5    8.894630   14.798288   10.336185   12.367167
6 -332.457780 -311.441309 -323.880049 -316.490939&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstanString2=&amp;quot;
+ data{
+    int n;
+    int nX;
+    int nB;
+    vector [n] y;
+    matrix [n,nX] X;
+    int B[n];
+ }
+ 
+ parameters{
+   vector [nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   vector [nB] gamma;
+   real&amp;lt;lower=0&amp;gt; sigma_B;
+ }
+ transformed parameters {
+   vector[n] mu;    
+   
+   mu = X*beta;
+   for (i in 1:n) {
+     mu[i] = mu[i] + gamma[B[i]];
+   }
+ } 
+ model{
+     // Priors
+     beta ~ normal( 0 , 100 );
+     gamma ~ normal( 0 , sigma_B );
+     sigma_B ~ cauchy( 0 , 25 );
+     sigma ~ cauchy( 0 , 25 );
+     
+     y ~ normal( mu , sigma );
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstanString2, con = &amp;quot;matrixModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~A, data=data.rcb)
&amp;gt; data.rcb.list &amp;lt;- with(data.rcb, list(y=y, X=Xmat, nX=ncol(Xmat),
+   B=as.numeric(Block),
+   n=nrow(data.rcb), nB=length(levels(Block))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma_B&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;STAN&lt;/code&gt; code via the &lt;code&gt;rstan&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rcb.rstan.d &amp;lt;- stan(data = data.rcb.list, file = &amp;quot;matrixModel.stan&amp;quot;, 
+                          chains = nChains, pars = params, iter = nIter, 
+                          warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;matrixModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.695 seconds (Warm-up)
Chain 1:                0.234 seconds (Sampling)
Chain 1:                0.929 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;matrixModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.704 seconds (Warm-up)
Chain 2:                0.234 seconds (Sampling)
Chain 2:                0.938 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.rcb.rstan.d, par = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;sigma_B&amp;quot;))
Inference for Stan model: matrixModel.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

         mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
beta[1] 41.74    0.13 2.08 37.63 40.40 41.71 43.09 46.01   268 1.01
beta[2] 27.89    0.03 1.21 25.50 27.09 27.89 28.71 30.26  2295 1.00
beta[3] 40.24    0.03 1.21 37.86 39.42 40.27 41.10 42.56  2342 1.00
sigma    5.07    0.01 0.45  4.29  4.75  5.03  5.34  6.06  1876 1.00
sigma_B 11.74    0.03 1.60  9.09 10.62 11.55 12.67 15.45  2908 1.00

Samples were drawn using NUTS(diag_e) at Thu Feb 20 11:14:50 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; data.rcb.rstan.d.df &amp;lt;-as.data.frame(extract(data.rcb.rstan.d))
&amp;gt; head(data.rcb.rstan.d.df)
    beta.1   beta.2   beta.3    sigma  sigma_B      lp__
1 42.18780 27.75495 38.97017 4.824826 12.43586 -313.5110
2 42.18060 29.00253 41.20811 5.640763 10.94287 -326.8560
3 36.71838 27.87852 39.66980 5.854247 10.78857 -328.5481
4 41.53933 30.06548 40.20779 5.555467 12.24461 -329.5007
5 41.43148 27.51720 38.67289 4.555229 10.14139 -327.1661
6 39.34493 28.41662 40.31444 4.276922 13.15484 -313.5802
&amp;gt; 
&amp;gt; data.rcb.mcmc.d&amp;lt;-rstan:::as.mcmc.list.stanfit(data.rcb.rstan.d)
&amp;gt; 
&amp;gt; plyr:::adply(as.matrix(data.rcb.rstan.d.df),2,MCMCsum)
       X1      Median         X0.        X25.        X50.       X75.
1  beta.1   41.710961   35.434490   40.398391   41.710961   43.09143
2  beta.2   27.887177   23.330526   27.087464   27.887177   28.71052
3  beta.3   40.274402   34.983236   39.423162   40.274402   41.10111
4   sigma    5.032048    3.678731    4.753538    5.032048    5.33909
5 sigma_B   11.549970    7.650390   10.624816   11.549970   12.66691
6    lp__ -321.017545 -353.249400 -324.914721 -321.017545 -317.55082
        X100.       lower      upper     lower.1     upper.1
1   48.927966   37.263192   45.52043   40.240435   42.908363
2   32.076745   25.707383   30.41474   27.175308   28.782407
3   45.619411   37.938149   42.59995   39.543821   41.185932
4    6.986504    4.251539    6.00204    4.714495    5.283777
5   19.896439    8.775183   14.90410   10.238108   12.186504
6 -306.873890 -332.837835 -311.51054 -323.070607 -315.824390&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;rcb-repeated-measures---continuous-within&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;RCB (repeated measures) - continuous within&lt;/h1&gt;
&lt;div id=&#34;data-generation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data generation&lt;/h2&gt;
&lt;p&gt;Imagine now that we has designed an experiment to investigate the effects of a continuous predictor (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, for example time) on a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;). Again, the system that we intend to sample is spatially heterogeneous and thus will add a great deal of noise to the data that will make it difficult to detect a signal (impact of treatment). Thus in an attempt to constrain this variability, we again decide to apply a design (RCB) in which each of the levels of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; (such as time) treatments within each of &lt;span class=&#34;math inline&#34;&gt;\(35\)&lt;/span&gt; blocks dispersed randomly throughout the landscape. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; slope &amp;lt;- 30
&amp;gt; intercept &amp;lt;- 200
&amp;gt; nBlock &amp;lt;- 35
&amp;gt; nTime &amp;lt;- 10
&amp;gt; sigma &amp;lt;- 50
&amp;gt; sigma.block &amp;lt;- 30
&amp;gt; n &amp;lt;- nBlock*nTime
&amp;gt; Block &amp;lt;- gl(nBlock, k=1)
&amp;gt; Time &amp;lt;- 1:10
&amp;gt; rho &amp;lt;- 0.8
&amp;gt; dt &amp;lt;- expand.grid(Time=Time,Block=Block)
&amp;gt; Xmat &amp;lt;- model.matrix(~-1+Block + Time, data=dt)
&amp;gt; block.effects &amp;lt;- rnorm(n = nBlock, mean = intercept, sd = sigma.block)
&amp;gt; #A.effects &amp;lt;- c(30,40)
&amp;gt; all.effects &amp;lt;- c(block.effects,slope)
&amp;gt; lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; # OR
&amp;gt; Xmat &amp;lt;- cbind(model.matrix(~-1+Block,data=dt),model.matrix(~Time,data=dt))
&amp;gt; ## Sum to zero block effects
&amp;gt; ##block.effects &amp;lt;- rnorm(n = nBlock, mean = 0, sd = sigma.block)
&amp;gt; ###A.effects &amp;lt;- c(40,70,80)
&amp;gt; ##all.effects &amp;lt;- c(block.effects,intercept,slope)
&amp;gt; ##lin.pred &amp;lt;- Xmat %*% all.effects
&amp;gt; 
&amp;gt; ## the quadrat observations (within sites) are drawn from
&amp;gt; ## normal distributions with means according to the site means
&amp;gt; ## and standard deviations of 5
&amp;gt; eps &amp;lt;- NULL
&amp;gt; eps[1] &amp;lt;- 0
&amp;gt; for (j in 2:n) {
+   eps[j] &amp;lt;- rho*eps[j-1] #residuals
+ }
&amp;gt; y &amp;lt;- rnorm(n,lin.pred,sigma)+eps
&amp;gt; 
&amp;gt; #OR
&amp;gt; eps &amp;lt;- NULL
&amp;gt; # first value cant be autocorrelated
&amp;gt; eps[1] &amp;lt;- rnorm(1,0,sigma)
&amp;gt; for (j in 2:n) {
+   eps[j] &amp;lt;- rho*eps[j-1] + rnorm(1, mean = 0, sd = sigma)  #residuals
+ }
&amp;gt; y &amp;lt;- lin.pred + eps
&amp;gt; data.rm &amp;lt;- data.frame(y=y, dt)
&amp;gt; head(data.rm)  #print out the first six rows of the data set
         y Time Block
1 282.1142    1     1
2 321.1404    2     1
3 278.7700    3     1
4 285.8709    4     1
5 336.6390    5     1
6 333.5961    6     1
&amp;gt; 
&amp;gt; ggplot(data.rm, aes(y=y, x=Time)) + geom_smooth(method=&amp;#39;lm&amp;#39;) + geom_point() + facet_wrap(~Block)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/block-anova-stan/2020-02-01-block-anova-stan_files/figure-html/generate_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y~Time, data.rm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/block-anova-stan/2020-02-01-block-anova-stan_files/figure-html/exp1_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data.rm, aes(y=y, x=factor(Time))) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/block-anova-stan/2020-02-01-block-anova-stan_files/figure-html/exp1_data_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Block by within-Block interaction&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; with(data.rm, interaction.plot(Time,Block,y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/block-anova-stan/2020-02-01-block-anova-stan_files/figure-html/exp2_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(data.rm, aes(y=y, x=Time, color=Block, group=Block)) + geom_line() +
+   guides(color=guide_legend(ncol=3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/block-anova-stan/2020-02-01-block-anova-stan_files/figure-html/exp2_data_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; residualPlots(lm(y~Block+Time, data.rm))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/block-anova-stan/2020-02-01-block-anova-stan_files/figure-html/exp2_data_ex2-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;           Test stat Pr(&amp;gt;|Test stat|)
Block                                
Time         -0.7274           0.4675
Tukey test   -0.9809           0.3267
&amp;gt; 
&amp;gt; # the Tukey&amp;#39;s non-additivity test by itself can be obtained via an internal function
&amp;gt; # within the car package
&amp;gt; car:::tukeyNonaddTest(lm(y~Block+Time, data.rm))
      Test     Pvalue 
-0.9808606  0.3266615 
&amp;gt; 
&amp;gt; # alternatively, there is also a Tukey&amp;#39;s non-additivity test within the
&amp;gt; # asbio package
&amp;gt; with(data.rm,tukey.add.test(y,Time,Block))

Tukey&amp;#39;s one df test for additivity 
F = 0.3997341   Denom df = 305    p-value = 0.5277003&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there is no visual or inferential evidence of any major interactions between Block and the within-Block effect (Time). Any trends appear to be reasonably consistent between Blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Sphericity&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Since the levels of Time cannot be randomly assigned, it is likely that sphericity is not met. We can explore whether there is an auto-correlation patterns in the residuals. Note, as there was only ten time periods, it does not make logical sense to explore lags above &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(nlme)
&amp;gt; data.rm.lme &amp;lt;- lme(y~Time, random=~1|Block, data=data.rm)
&amp;gt; acf(resid(data.rm.lme), lag=10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/block-anova-stan/2020-02-01-block-anova-stan_files/figure-html/exp3_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;The autocorrelation factor (ACF) at a range of lags up to &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;, indicate that there is a cyclical pattern of residual auto-correlation. We really should explore incorporating some form of correlation structure into our model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model fitting&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstanString2=&amp;quot;
+ data{
+    int n;
+    int nX;
+    int nB;
+    vector [n] y;
+    matrix [n,nX] X;
+    int B[n];
+ }
+ 
+ parameters{
+   vector [nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   vector [nB] gamma;
+   real&amp;lt;lower=0&amp;gt; sigma_B;
+ }
+ transformed parameters {
+   vector[n] mu;    
+   
+   mu = X*beta;
+   for (i in 1:n) {
+     mu[i] = mu[i] + gamma[B[i]];
+   }
+ } 
+ model{
+     // Priors
+     beta ~ normal( 0 , 100 );
+     gamma ~ normal( 0 , sigma_B );
+     sigma_B ~ cauchy( 0 , 25 );
+     sigma ~ cauchy( 0 , 25 );
+     
+     y ~ normal( mu , sigma );
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstanString2, con = &amp;quot;matrixModel2.stan&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~Time, data=data.rm)
&amp;gt; data.rm.list &amp;lt;- with(data.rm, list(y=y, X=Xmat, nX=ncol(Xmat),
+   B=as.numeric(Block),
+   n=nrow(data.rm), nB=length(levels(Block))))
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta&amp;#39;,&amp;#39;sigma&amp;#39;,&amp;#39;sigma_B&amp;#39;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.rm.rstan.d  &amp;lt;- stan(data = data.rm.list, file = &amp;quot;matrixModel2.stan&amp;quot;, 
+                             chains = nChains, pars = params, iter = nIter, 
+                             warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;matrixModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 2.027 seconds (Warm-up)
Chain 1:                0.657 seconds (Sampling)
Chain 1:                2.684 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;matrixModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 2.764 seconds (Warm-up)
Chain 2:                0.453 seconds (Sampling)
Chain 2:                3.217 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.rm.rstan.d , par = c(&amp;#39;beta&amp;#39;,&amp;#39;sigma&amp;#39;,&amp;#39;sigma_B&amp;#39;))
Inference for Stan model: matrixModel.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

          mean se_mean    sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1] 185.90    0.79 12.77 159.70 177.57 185.87 194.16 211.22   263 1.01
beta[2]  30.80    0.02  1.03  28.72  30.13  30.77  31.46  32.80  2854 1.00
sigma    55.86    0.04  2.20  51.68  54.34  55.75  57.29  60.43  2639 1.00
sigma_B  64.74    0.21  8.97  50.08  58.37  63.92  70.18  84.68  1816 1.00

Samples were drawn using NUTS(diag_e) at Thu Feb 20 11:15:03 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Given that Time cannot be randomized, there is likely to be a temporal dependency structure to the data. The above analyses assume no temporal dependency - actually, they assume that the variance-covariance matrix demonstrates a structure known as sphericity. Lets specifically model in a first order autoregressive correlation structure in an attempt to accommodate the expected temporal autocorrelation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstanString3=&amp;quot;
+ data{
+    int n;
+    int nX;
+    int nB;
+    vector [n] y;
+    matrix [n,nX] X;
+    int B[n];
+    vector [n] tgroup;
+ }
+ 
+ parameters{
+   vector [nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   vector [nB] gamma;
+   real&amp;lt;lower=0&amp;gt; sigma_B;
+   real ar;
+ }
+ transformed parameters {
+   vector[n] mu;    
+   vector[n] E;
+   vector[n] res;
+ 
+   mu = X*beta;
+   for (i in 1:n) {
+      E[i] = 0;
+   }
+   for (i in 1:n) {
+     mu[i] = mu[i] + gamma[B[i]];
+     res[i] = y[i] - mu[i];
+   if(i&amp;gt;0 &amp;amp;&amp;amp; i &amp;lt; n &amp;amp;&amp;amp; tgroup[i+1] == tgroup[i]) {
+     E[i+1] = res[i];
+     }
+     mu[i] = mu[i] + (E[i] * ar);
+   }
+ } 
+ model{
+     // Priors
+     beta ~ normal( 0 , 100 );
+     gamma ~ normal( 0 , sigma_B );
+     sigma_B ~ cauchy( 0 , 25 );
+     sigma ~ cauchy( 0 , 25 );
+     
+     y ~ normal( mu , sigma );
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstanString3, con = &amp;quot;matrixModel3.stan&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~Time, data=data.rm)
&amp;gt; data.rm.list &amp;lt;- with(data.rm, list(y=y, X=Xmat, nX=ncol(Xmat),
+   B=as.numeric(Block),
+   n=nrow(data.rm), nB=length(levels(Block)),
+   tgroup=as.numeric(Block)))
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;beta&amp;#39;,&amp;#39;sigma&amp;#39;,&amp;#39;sigma_B&amp;#39;,&amp;#39;ar&amp;#39;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.rm.rstan.d  &amp;lt;- stan(data = data.rm.list, file = &amp;quot;matrixModel3.stan&amp;quot;, 
+                             chains = nChains, pars = params, iter = nIter, 
+                             warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;matrixModel3&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 4.063 seconds (Warm-up)
Chain 1:                1.041 seconds (Sampling)
Chain 1:                5.104 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;matrixModel3&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 3.945 seconds (Warm-up)
Chain 2:                1.015 seconds (Sampling)
Chain 2:                4.96 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.rm.rstan.d , par = c(&amp;#39;beta&amp;#39;,&amp;#39;sigma&amp;#39;,&amp;#39;sigma_B&amp;#39;,&amp;#39;ar&amp;#39;))
Inference for Stan model: matrixModel3.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

          mean se_mean    sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1] 179.26    0.24 12.87 153.98 170.50 179.54 187.94 203.70  2981    1
beta[2]  31.25    0.02  1.64  28.05  30.14  31.22  32.32  34.54  5531    1
sigma    48.74    0.03  1.96  45.11  47.43  48.64  50.04  52.87  3537    1
sigma_B  50.33    0.30 10.54  31.10  43.06  49.68  56.96  72.38  1241    1
ar        0.78    0.00  0.05   0.68   0.75   0.78   0.82   0.87  2773    1

Samples were drawn using NUTS(diag_e) at Thu Feb 20 11:15:58 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-gelman2015stan&#34;&gt;
&lt;p&gt;Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt; 40 (5): 530–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanpackage&#34;&gt;
&lt;p&gt;Stan Development Team. 2018. “RStan: The R Interface to Stan.” &lt;a href=&#34;http://mc-stan.org/&#34;&gt;http://mc-stan.org/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nested Anova - JAGS</title>
      <link>/jags/nested-anova-jags/netsed-anova-jags/</link>
      <pubDate>Sun, 09 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/nested-anova-jags/netsed-anova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When single sampling units are selected amongst highly heterogeneous conditions, it is unlikely that these single units will adequately represent the populations and repeated sampling is likely to yield very different outcomes. For example, if we were investigating the impacts of fuel reduction burning across a highly heterogeneous landscape, our ability to replicate adequately might be limited by the number of burn sites available.&lt;/p&gt;
&lt;p&gt;Alternatively, sub-replicates within each of the sampling units (e.g. sites) can be collected (and averaged) so as to provided better representatives for each of the units and ultimately reduce the unexplained variability of the test of treatments. In essence, the sub-replicates are the replicates of an additional nested factor whose levels are nested within the main treatment factor. A nested factor refers to a factor whose levels are unique within each level of the factor it is nested within and each level is only represented once. For example, the fuel reduction burn study design could consist of three burnt sites and three un-burnt (control) sites each containing four quadrats (replicates of site and sub-replicates of the burn treatment). Each site represents a unique level of a random factor (any given site cannot be both burnt and un-burnt) that is nested within the fire treatment (burned or not).&lt;/p&gt;
&lt;p&gt;A nested design can be thought of as a hierarchical arrangement of factors (hence the alternative name hierarchical designs) whereby a treatment is progressively sub-replicated. As an additional example, imagine an experiment designed to comparing the leaf toughness of a number of tree species. Working down the hierarchy, five individual trees were randomly selected within (nested within) each species, three branches were randomly selected within each tree, two leaves were randomly selected within each branch and the force required to shear the leaf material in half (transversely) was measured in four random locations along the leaf. Clearly any given leaf can only be from a single branch, tree and species. Each level of sub-replication is introduced to further reduce the amount of unexplained variation and thereby increasing the power of the test for the main treatment effect. Additionally, it is possible to investigate which scale has the greatest (or least, etc) degree of variability - the level of the species, individual tree, branch, leaf, leaf region etc.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nested factors are typically random factors, of which the levels are randomly selected to represent all possible levels (e.g. sites). When the main treatment effect (often referred to as Factor A) is a fixed factor, such designs are referred to as a &lt;em&gt;mixed model nested ANOVA&lt;/em&gt;, whereas when Factor A is random, the design is referred to as a &lt;em&gt;Model II nested ANOVA&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fixed nested factors are also possible. For example, specific dates (corresponding to particular times during a season) could be nested within season. When all factors are fixed, the design is referred to as a &lt;em&gt;Model I mixed model&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fully nested designs (the topic of this chapter) differ from other multi-factor designs in that all factors within (below) the main treatment factor are nested and thus interactions are un-replicated and cannot be tested. Indeed, interaction effects (interaction between Factor A and site) are assumed to be zero.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models-frequentist&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models (frequentist)&lt;/h2&gt;
&lt;p&gt;The linear models for two and three factor nested design are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \alpha_i + \beta_{j(i)} + \epsilon_{ijk},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_{j(i)} + gamma_{k(j(i))}  + \epsilon_{ijkl},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the effect of Factor A, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of Factor B, &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the effect of Factor C and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models-bayesian&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models (Bayesian)&lt;/h2&gt;
&lt;p&gt;So called “random effects” are modelled differently from “fixed effects” in that rather than estimate their individual effects, we instead estimate the variability due to these “random effects”. Since technically all variables in a Bayesian framework are random, some prefer to use the terms ‘fixed effects’ and ‘varying effects’. As random factors typically represent “random” selections of levels (such as a set of randomly selected sites), incorporated in order to account for the dependency structure (observations within sites are more likely to be correlated to one another - not strickly independent) to the data, we are not overly interested in the individual differences between levels of the ‘varying’ (random) factor. Instead (in addition to imposing a separate correlation structure within each nest), we want to know how much variability is attributed to this level of the design. The linear models for two and three factor nested design are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \alpha_i + \beta_{j(i)} + \epsilon_{ijk}, \;\;\; \epsilon_{ijk} \sim N(0, \sigma^2), \;\;\; \beta_{j(i)} \sim N(0, \sigma^2_{B}) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_{j(i)} + \gamma_{k(j(i))} + \epsilon_{ijkl}, \;\;\; \epsilon_{ijkl} \sim N(0, \sigma^2), \;\;\; \beta_{j(i)} \sim N(0, \sigma^2_{B}) \;\;\; \gamma_{k(j(i))} \sim N(0, \sigma^2_C) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the effect of Factor A, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the variability of Factor B (nested within Factor A), &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the variability of Factor C (nested within Factor B) and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component that is assumed to be normally distributed with a mean of zero and a constant amount of standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;). The subscripts are iterators. For example, the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; represents the number of effects to be estimated for Factor A. Thus the first formula can be read as the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;-th observation of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is drawn from a normal distribution (with a specific level of variability) and mean proposed to be determined by a base mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; - mean of the first treatment across all nests) plus the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th treatment effect plus the variabilitythe model proposes that, given a base mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and knowing the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th treatment (factor A) and which of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th nests within the treatment the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;-th observation from Block &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; (factor B) within treatment effect.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypotheses&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypotheses&lt;/h2&gt;
&lt;p&gt;Separate null hypotheses are associated with each of the factors, however, nested factors are typically only added to absorb some of the unexplained variability and thus, specific hypotheses tests associated with nested factors are of lesser biological importance. Hence, rather than estimate the effects of random effects, we instead estimate how much variability they contribute.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor A: the main treatment effect (fixed)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A): \mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt; (the population group means are all equal). That is, that the mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to one another - no effect of the factor on the response. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the mean of the first group (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu_1\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A) : \alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt; (the effect of each group equals zero). If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), there is evidence that the null hypothesis is not true indicating that the factor does affect the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Factor A: the main treatment effect (random)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A) : \sigma^2_{\alpha}=0\)&lt;/span&gt; (population variance equals zero). There is no added variance due to all possible levels of A.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Factor B: the nested effect (random)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B) : \sigma^2_{\beta}=0\)&lt;/span&gt; (population variance equals zero). There is no added variance due to all possible levels of B within the (set or all possible) levels of A.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Factor B: the nested effect (fixed)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B): \mu_{1(1)}=\mu_{2(1)}=\ldots=\mu_{j(i)}=\mu\)&lt;/span&gt; (the population group means of B (within A) are all equal).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B): \beta_{1(1)}=\beta_{2(1)}=\ldots=\beta_{j(i)}=0\)&lt;/span&gt; (the effect of each chosen B group equals zero).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;Analysis of variance sequentially partitions the total variability in the response variable into components explained by each of the factors (starting with the factors lowest down in the hierarchy - the most deeply nested) and the components unexplained by each factor. Explained variability is calculated by subtracting the amount unexplained by the factor from the amount unexplained by a reduced model that does not contain the factor. When the null hypothesis for a factor is true (no effect or added variability), the ratio of explained and unexplained components for that factor (F-ratio) should follow a theoretical F-distribution with an expected value less than 1. The appropriate unexplained residuals and therefore the appropriate F-ratios for each factor differ according to the different null hypotheses associated with different combinations of fixed and random factors in a nested linear model (see Table below).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; fact_anova_table
      df        MS         F-ratio (B random)    Var comp (B random)        
A     &amp;quot;a-1&amp;quot;     &amp;quot;MS A&amp;quot;     &amp;quot;(MS A)/(MS B&amp;#39;(A))&amp;quot;   &amp;quot;((MS A) - (MS B&amp;#39;(A)))/nb&amp;quot; 
B&amp;#39;(A) &amp;quot;(b-1)a&amp;quot;  &amp;quot;MS B&amp;#39;(A)&amp;quot; &amp;quot;(MS B&amp;#39;(A))/(MS res)&amp;quot; &amp;quot;((MS B&amp;#39;(A)) - (MS res))/n&amp;quot;
Res   &amp;quot;(n-1)ba&amp;quot; &amp;quot;MS res&amp;quot;   &amp;quot;&amp;quot;                    &amp;quot;&amp;quot;                         
      F-ratio (B fixed)     Var comp (B fixed)         
A     &amp;quot;(MS A)/(MS res)&amp;quot;     &amp;quot;((MS A) - (MS res))/nb&amp;quot;   
B&amp;#39;(A) &amp;quot;(MS B&amp;#39;(A))/(MS res)&amp;quot; &amp;quot;((MS B&amp;#39;(A)) - (MS res))/n&amp;quot;
Res   &amp;quot;&amp;quot;                    &amp;quot;&amp;quot;                         &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The corresponding &lt;code&gt;R&lt;/code&gt; syntax is given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #A fixed/random, B random (balanced)
&amp;gt; summary(aov(y~A+Error(B), data))
&amp;gt; VarCorr(lme(y~A,random=1|B, data))
&amp;gt; 
&amp;gt; #A fixed/random, B random (unbalanced)
&amp;gt; anova(lme(y~A,random=1|B, data), type=&amp;#39;marginal&amp;#39;)
&amp;gt; 
&amp;gt; #A fixed/random, B fixed(balanced)
&amp;gt; summary(aov(y~A+B, data))
&amp;gt; 
&amp;gt; #A fixed/random, B fixed (unbalanced)
&amp;gt; contrasts(data$B) &amp;lt;- contr.sum
&amp;gt; Anova(aov(y~A/B, data), type=&amp;#39;III&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;variance-components&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Variance components&lt;/h2&gt;
&lt;p&gt;As previously alluded to, it can often be useful to determine the relative contribution (to explaining the unexplained variability) of each of the factors as this provides insights into the variability at each different scales. These contributions are known as &lt;strong&gt;Variance components&lt;/strong&gt; and are estimates of the added variances due to each of the factors. For consistency with leading texts on this topic, I have included estimated variance components for various balanced nested ANOVA designs in the above table. However, variance components based on a modified version of the maximum likelihood iterative model fitting procedure (&lt;em&gt;REML&lt;/em&gt;) is generally recommended as this accommodates both balanced and unbalanced designs. While there are no numerical differences in the calculations of variance components for fixed and random factors, fixed factors are interpreted very differently and arguably have little clinical meaning (other to infer relative contribution). For fixed factors, variance components estimate the variance between the means of the specific populations that are represented by the selected levels of the factor and therefore represent somewhat arbitrary and artificial populations. For random factors, variance components estimate the variance between means of all possible populations that could have been selected and thus represents the true population variance.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;An F-distribution represents the relative frequencies of all the possible F-ratio’s when a given null hypothesis is true and certain assumptions about the residuals (denominator in the F-ratio calculation) hold. Consequently, it is also important that diagnostics associated with a particular hypothesis test reflect the denominator for the appropriate F-ratio. For example, when testing the null hypothesis that there is no effect of Factor A (&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_i=0\)&lt;/span&gt;) in a mixed nested ANOVA, the means of each level of Factor B are used as the replicates of Factor A. As with single factor anova, hypothesis testing for nested ANOVA assumes the residuals are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;normally distributed. Factors higher up in the hierarchy of a nested model are based on means (or means of means) of lower factors and thus the &lt;em&gt;Central Limit Theory&lt;/em&gt; would predict that normality will usually be satisfied for the higher level factors. Nevertheless, boxplots using the appropriate scale of replication should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;independent of one another - this requires special consideration so as to ensure that the scale at which sub-replicates are measured is still great enough to enable observations to be independent.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;unbalanced-nested-designs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Unbalanced nested designs&lt;/h2&gt;
&lt;p&gt;Designs that incorporate fixed and random factors (either nested or factorial), involve F-ratio calculations in which the denominators are themselves random factors other than the overall residuals. Many statisticians argue that when such denominators are themselves not statistically significant (at the &lt;span class=&#34;math inline&#34;&gt;\(0.25\)&lt;/span&gt; level), there are substantial power benefits from pooling together successive non-significant denominator terms. Thus an F-ratio for a particular factor might be recalculated after pooling together its original denominator with its denominators denominator and so on. The conservative &lt;span class=&#34;math inline&#34;&gt;\(0.25\)&lt;/span&gt; is used instead of the usual 0.05 to reduce further the likelihood of Type II errors (falsely concluding an effect is non-significant - that might result from insufficient power).&lt;/p&gt;
&lt;p&gt;For a simple completely balanced nested ANOVA, it is possible to pool together (calculate their mean) each of the sub-replicates within each nest (site) and then perform single factor ANOVA on those aggregates. Indeed, for a &lt;em&gt;balanced design&lt;/em&gt;, the estimates and hypothesis for Factor A will be identical to that produced via nested ANOVA. However, if there are an unequal number of sub-replicates within each nest, then the single factor ANOVA will be less powerful that a proper nested ANOVA. &lt;em&gt;Unbalanced designs&lt;/em&gt; are those designs in which sample (subsample) sizes for each level of one or more factors differ. These situations are relatively common in biological research, however such imbalance has some important implications for nested designs.&lt;/p&gt;
&lt;p&gt;Firstly, hypothesis tests are more robust to the assumptions of normality and equal variance when the design is balanced. Secondly (and arguably, more importantly), the model contrasts are not orthogonal (independent) and the sums of squares component attributed to each of the model terms cannot be calculated by simple additive partitioning of the total sums of squares. In such situations, exact F-ratios cannot be constructed (at least in theory), variance components calculations are more complicated and significance tests cannot be computed. The denominator MS in an &lt;em&gt;F-ratio&lt;/em&gt; is determined by examining the expected value of the mean squares of each term in a model. Unequal sample sizes result in expected means squares for which there are no obvious logical comparators that enable the impact of an individual model term to be isolated. The severity of this issue depends on which scale of the sub-sampling hierarchy the unbalance(s) occurs as well whether the unbalance occurs in the replication of a fixed or random factor. For example, whilst unequal levels of the first nesting factor (e.g. unequal number of burn vs un-burnt sites) has no effect on F-ratio construction or hypothesis testing for the top level factor (irrespective of whether either of the factors are fixed or random), unequal sub-sampling (replication) at the level of a random (but not fixed) nesting factor will impact on the ability to construct F-ratios and variance components of all terms above it in the hierarchy. There are a number of alternative ways of dealing with unbalanced nested designs. All alternatives assume that the imbalance is not a direct result of the treatments themselves. Such outcomes are more appropriately analysed by modelling the counts of surviving observations via frequency analysis.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Split the analysis up into separate smaller simple ANOVA’s each using the means of the nesting factor to reflect the appropriate scale of replication. As the resulting sums of squares components are thereby based on an aggregated dataset the analyses then inherit the procedures and requirements of single ANOVA.&lt;/li&gt;
&lt;li&gt;Adopt mixed-modelling techniques.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We note that, in a Bayesian framework, issues of design balance essentially evaporate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-mixed-effects-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear mixed effects models&lt;/h2&gt;
&lt;p&gt;Although the term “mixed-effects” can be used to refer to any design that incorporates both fixed and random predictors, its use is more commonly restricted to designs in which factors are nested or grouped within other factors. Typical examples include nested, longitudinal (measurements repeated over time) data, repeated measures and blocking designs. Furthermore, rather than basing parameter estimations on observed and expected mean squares or error strata (as outline above), mixed-effects models estimate parameters via &lt;strong&gt;maximum likelihood&lt;/strong&gt; (ML) or &lt;strong&gt;residual maximum likelihood&lt;/strong&gt; (REML). In so doing, mixed-effects models more appropriately handle estimation of parameters, effects and variance components of unbalanced designs (particularly for random effects). Resulting fitted (or expected) values of each level of a factor (for example, the expected population site means) are referred to as &lt;em&gt;Best Linear Unbiased Predictors&lt;/em&gt; (BLUP’s). As an acknowledgement that most estimated site means will be more extreme than the underlying true population means they estimate (based on the principle that smaller sample sizes result in greater chances of more extreme observations and that nested sub-replicates are also likely to be highly intercorrelated), BLUP’s are less spread from the overall mean than are simple site means. In addition, mixed-effects models naturally model the “within-block” correlation structure that complicates many longitudinal designs.&lt;/p&gt;
&lt;p&gt;Whilst the basic concepts of mixed-effects models have been around for a long time, recent computing advances and adoptions have greatly boosted the popularity of these procedures. Linear mixed effects models are currently at the forefront of statistical development, and as such, are very much a work in progress - both in theory and in practice. Recent developments have seen a further shift away from the traditional practices associated with degrees of freedom, probability distribution and p-value calculations. The traditional approach to inference testing is to compare the fit of an alternative (full) model to a null (reduced) model (via an F-ratio). When assumptions of normality and homogeneity of variance apply, the degrees of freedom are easily computed and the F-ratio has an exact F-distribution to which it can be compared. However, this approach introduces two additional problematic assumptions when estimating fixed effects in a mixed effects model. Firstly, when estimating the effects of one factor, the parameter estimates associated with other factor(s) are assumed to be the true values of those parameters (not estimates). Whilst this assumption is reasonable when all factors are fixed, as random factors are selected such that they represent one possible set of levels drawn from an entire population of possible levels for the random factor, it is unlikely that the associated parameter estimates accurately reflect the true values. Consequently, there is not necessarily an appropriate F-distribution. Furthermore, determining the appropriate degrees of freedom (nominally, the number of independent observations on which estimates are based) for models that incorporate a hierarchical structure is only possible under very specific circumstances (such as completely balanced designs). Degrees of freedom is a somewhat arbitrary defined concept used primarily to select a theoretical probability distribution on which a statistic can be compared. Arguably, however, it is a concept that is overly simplistic for complex hierarchical designs. Most statistical applications continue to provide the “approximate” solutions (as did earlier versions within &lt;code&gt;R&lt;/code&gt;). However, &lt;code&gt;R&lt;/code&gt; linear mixed effects development leaders argue strenuously that given the above shortcomings, such approximations are variably inappropriate and are thus omitted.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Markov chain Monte Carlo&lt;/strong&gt; (MCMC) sampling methods provide a Bayesian-like alternative for inference testing. Markov chains use the mixed model parameter estimates to generate posterior probability distributions of each parameter from which Monte Carlo sampling methods draw a large set of parameter samples. These parameter samples can then be used to calculate &lt;em&gt;highest posterior density&lt;/em&gt; (HPD) intervals (also known as Bayesian credible intervals). Such intervals indicate the interval in which there is a specified probability (typically &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;%) that the true population parameter lies. Furthermore, whilst technically against the spirit of the Bayesian philosophy, it is also possible to generate P values on which to base inferences.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Imagine we has designed an experiment in which we intend to measure a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) to one of treatments (three levels; “a1”, “a2” and “a3”). The treatments occur at a spatial scale (over an area) that far exceeds the logistical scale of sampling units (it would take too long to sample at the scale at which the treatments were applied). The treatments occurred at the scale of hectares whereas it was only feasible to sample y using 1m quadrats. Given that the treatments were naturally occurring (such as soil type), it was not possible to have more than five sites of each treatment type, yet prior experience suggested that the sites in which you intended to sample were very uneven and patchy with respect to &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. In an attempt to account for this inter-site variability (and thus maximize the power of the test for the effect of treatment, you decided to employ a nested design in which 10 quadrats were randomly located within each of the five replicate sites per three treatments. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(plyr)
&amp;gt; set.seed(123)
&amp;gt; nTreat &amp;lt;- 3
&amp;gt; nSites &amp;lt;- 15
&amp;gt; nSitesPerTreat &amp;lt;- nSites/nTreat
&amp;gt; nQuads &amp;lt;- 10
&amp;gt; site.sigma &amp;lt;- 12
&amp;gt; sigma &amp;lt;- 5
&amp;gt; n &amp;lt;- nSites * nQuads
&amp;gt; sites &amp;lt;- gl(n=nSites,k=nQuads, lab=paste0(&amp;#39;S&amp;#39;,1:nSites))
&amp;gt; A &amp;lt;- gl(nTreat, nSitesPerTreat*nQuads, n, labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a.means &amp;lt;- c(40,70,80)
&amp;gt; ## the site means (treatment effects) are drawn from normal distributions
&amp;gt; ## with means of 40, 70 and 80 and standard deviations of 12
&amp;gt; A.effects &amp;lt;- rnorm(nSites, rep(a.means,each=nSitesPerTreat),site.sigma)
&amp;gt; #A.effects &amp;lt;- a.means %*% t(model.matrix(~A, data.frame(A=gl(nTreat,nSitesPerTreat,nSites))))+rnorm(nSites,0,site.sigma)
&amp;gt; Xmat &amp;lt;- model.matrix(~sites -1)
&amp;gt; lin.pred &amp;lt;- Xmat %*% c(A.effects)
&amp;gt; ## the quadrat observations (within sites) are drawn from
&amp;gt; ## normal distributions with means according to the site means
&amp;gt; ## and standard deviations of 5
&amp;gt; y &amp;lt;- rnorm(n,lin.pred,sigma)
&amp;gt; data.nest &amp;lt;- data.frame(y=y, A=A, Sites=sites,Quads=1:length(y))
&amp;gt; head(data.nest)  #print out the first six rows of the data set
         y  A Sites Quads
1 42.20886 a1    S1     1
2 35.76354 a1    S1     2
3 23.44121 a1    S1     3
4 36.78107 a1    S1     4
5 30.91034 a1    S1     5
6 27.93517 a1    S1     6
&amp;gt; 
&amp;gt; library(ggplot2)
&amp;gt; ggplot(data.nest, aes(y=y, x=1)) + geom_boxplot() + facet_grid(.~Sites)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/generate_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Effects of treatment
&amp;gt; boxplot(y~A, ddply(data.nest, ~A+Sites,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #Site effects
&amp;gt; boxplot(y~Sites, ddply(data.nest, ~A+Sites+Quads,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ## with ggplot2
&amp;gt; ggplot(ddply(data.nest, ~A+Sites,numcolwise(mean, na.rm=T)), aes(y=y, x=A)) +
+   geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the y-axis. Hence it there is no evidence of non-homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;For non-hierarchical linear models, uniform priors on variance (standard deviation) parameters seem to work reasonably well. &lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt; warns that the use of the inverse-gamma family of non-informative priors are very sensitive to ϵ particularly when variance is close to zero and this may lead to unintentionally informative priors. When the number of groups (treatments or varying/random effects) is large (more than &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;), &lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt; advocated the use of either uniform or half-cauchy priors. Yet when the number of groups is low, &lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt; indicates that uniform priors have a tendency to result in inflated variance estimates. Consequently, half-cauchy priors are generally recommended for variances.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Full parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\alpha_0 + \alpha_i + \beta_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_{ij)} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\alpha_0, \alpha_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The &lt;em&gt;full parameterisation&lt;/em&gt;, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Matrix parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\boldsymbol \alpha \boldsymbol X + \beta_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_{ij} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \alpha \sim MVN(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The full parameterisation, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;). The &lt;em&gt;matrix parameterisation&lt;/em&gt; is a compressed notation, In this parameterisation, there are three alpha parameters (one representing the mean of treatment a1, and the other two representing the treatment effects (differences between a2 and a1 and a3 and a1). In generating priors for each of these three alpha parameters, we could loop through each and define a non-informative normal prior to each (as in the Full parameterisation version). However, it turns out that it is more efficient (in terms of mixing and thus the number of necessary iterations) to define the priors from a multivariate normal distribution. This has as many means as there are parameters to estimate (&lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt;) and a &lt;span class=&#34;math inline&#34;&gt;\(3\times3\)&lt;/span&gt; matrix of zeros and &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; in the diagonals.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol \mu =
  \begin{bmatrix} 0  \\ 0  \\ 0 \end{bmatrix}, \;\;\; \sigma^2 \sim   
  \begin{bmatrix}
   1000000 &amp;amp; 0 &amp;amp; 0 \\
   0 &amp;amp; 1000000 &amp;amp; 0 \\
   0 &amp;amp; 0 &amp;amp; 1000000
   \end{bmatrix}. \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\beta_{i(j)}, \sigma^2), \;\;\; \beta_{i(j)}\sim N(\mu_i, \sigma^2_B), \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i = \boldsymbol \alpha \boldsymbol X\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. In the &lt;em&gt;heirarchical parameterisation&lt;/em&gt;, we are indicating two residual layers - one representing the variability in the observed data between individual observations (within sites) and the second representing the variability between site means (within the three treatments).&lt;/p&gt;
&lt;div id=&#34;full-effect-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full effect parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- alpha0 + alpha[A[i]] + beta[site[i]]
+    }
+    
+    #Priors
+    alpha0 ~ dnorm(0, 1.0E-6)
+    alpha[1] &amp;lt;- 0
+    for (i in 2:nA) {
+      alpha[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    for (i in 1:nSite) {
+      beta[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;-z/sqrt(chSq.B)
+    z.B ~ dnorm(0, .0016)I(0,)
+    chSq.B ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;fullModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.list &amp;lt;- with(data.nest,
+         list(y=y,
+                  site=as.numeric(Sites),
+          A=as.numeric(A),
+          n=nrow(data.nest),
+          nSite=length(levels(Sites)),
+                  nA = length(levels(A))
+          )
+ )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha0&amp;quot;,&amp;quot;alpha&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.r2jags.f &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;fullModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 22
   Total graph size: 502

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.f)
Inference for Bugs model at &amp;quot;fullModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
alpha[1]   0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000     1
alpha[2]  27.388   7.149  13.085  22.881  27.312  31.980  41.230 1.001  3000
alpha[3]  40.839   7.083  26.936  36.251  40.800  45.412  55.107 1.002  3000
alpha0    42.325   4.978  32.452  39.136  42.215  45.422  52.310 1.002  3000
sigma      5.069   0.307   4.530   4.851   5.051   5.265   5.722 1.002  3000
sigma.B   10.990   2.527   7.168   9.260  10.656  12.306  17.136 1.009   190
deviance 909.635   5.937 899.898 905.400 908.952 913.145 923.175 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 17.6 and DIC = 927.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- inprod(alpha[],X[i,]) + inprod(beta[], Z[i,])
+    } 
+    
+    #Priors
+    alpha ~ dmnorm(a0,A0)
+    for (i in 1:nZ) {
+      beta[i] ~ dnorm(0, tau.B) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;-z/sqrt(chSq.B)
+    z.B ~ dnorm(0, .0016)I(0,)
+    chSq.B ~ dgamma(0.5, 0.5)
+ 
+ }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;matrixModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; A.Xmat &amp;lt;- model.matrix(~A,data.nest)
&amp;gt; Zmat &amp;lt;- model.matrix(~-1+Sites, data.nest)
&amp;gt; data.nest.list &amp;lt;- with(data.nest,
+         list(y=y,
+          X=A.Xmat,
+          n=nrow(data.nest),
+          Z=Zmat, nZ=ncol(Zmat),
+          a0=rep(0,3), A0=diag(3)
+          )
+ )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.B&amp;quot;,&amp;#39;beta&amp;#39;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.r2jags.m &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;matrixModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 20
   Total graph size: 3231

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.m)
Inference for Bugs model at &amp;quot;matrixModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
alpha[1]   0.201   1.016  -1.750  -0.474   0.215   0.872   2.161 1.001  3000
alpha[2]   0.082   0.972  -1.835  -0.585   0.092   0.730   1.954 1.003  2000
alpha[3]   0.077   1.005  -1.867  -0.608   0.075   0.771   2.055 1.001  3000
beta[1]   31.532   1.871  27.942  30.237  31.536  32.794  35.248 1.001  3000
beta[2]   38.069   1.911  34.289  36.788  38.125  39.343  41.817 1.001  3000
beta[3]   59.346   1.872  55.692  58.089  59.346  60.579  63.088 1.001  3000
beta[4]   40.644   1.936  36.885  39.378  40.659  41.960  44.321 1.002  1400
beta[5]   40.506   1.855  36.802  39.248  40.492  41.750  44.199 1.001  3000
beta[6]   90.495   2.131  86.451  89.013  90.489  91.970  94.602 1.001  3000
beta[7]   75.252   2.114  71.007  73.850  75.238  76.681  79.322 1.002  1200
beta[8]   57.061   2.180  52.888  55.574  57.032  58.568  61.289 1.001  2400
beta[9]   61.336   2.171  57.214  59.855  61.372  62.822  65.415 1.001  3000
beta[10]  62.816   2.159  58.580  61.353  62.774  64.268  67.144 1.001  3000
beta[11]  93.379   2.134  89.192  91.945  93.374  94.750  97.533 1.001  3000
beta[12]  83.011   2.161  78.822  81.508  83.024  84.486  87.245 1.001  3000
beta[13]  82.765   2.202  78.398  81.292  82.774  84.252  87.054 1.001  3000
beta[14]  81.140   2.165  76.775  79.675  81.185  82.598  85.236 1.001  3000
beta[15]  74.041   2.119  70.008  72.616  74.027  75.493  78.245 1.001  3000
sigma      5.058   0.306   4.499   4.844   5.049   5.255   5.710 1.002  1200
sigma.B   68.791  13.133  48.825  59.338  66.869  75.995  98.963 1.002  3000
deviance 909.431   6.235 899.560 905.043 908.621 913.008 923.865 1.003   810

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 19.4 and DIC = 928.8
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;hierarchical-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hierarchical parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString3=&amp;quot;
+ model {
+    #Likelihood (esimating site means (gamma.site)
+    for (i in 1:n) {
+       y[i]~dnorm(quad.means[i],tau)
+       quad.means[i] &amp;lt;- gamma.site[site[i]]
+    }
+    for (i in 1:s) {
+       gamma.site[i] ~ dnorm(site.means[i], tau.site)
+       site.means[i] &amp;lt;- inprod(beta[],A.Xmat[i,])
+    }
+    #Priors
+    for (i in 1:a) {
+      beta[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.B &amp;lt;- pow(sigma.B,-2)
+    sigma.B &amp;lt;-z/sqrt(chSq.B)
+    z.B ~ dnorm(0, .0016)I(0,)
+    chSq.B ~ dgamma(0.5, 0.5)
+ 
+    tau.site &amp;lt;- pow(sigma.site,-2)
+    sigma.site &amp;lt;-z/sqrt(chSq.site)
+    z.site ~ dnorm(0, .0016)I(0,)
+    chSq.site ~ dgamma(0.5, 0.5)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString3, con = &amp;quot;hierarchicalModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; A.Xmat &amp;lt;- model.matrix(~A,ddply(data.nest,~Sites,catcolwise(unique)))
&amp;gt; data.nest.list &amp;lt;- with(data.nest,
+         list(y=y,
+                  site=Sites,
+          A.Xmat= A.Xmat,
+          n=nrow(data.nest),
+          s=length(levels(Sites)),
+                  a = ncol(A.Xmat)
+          )
+ )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.site&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.r2jags.h &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;hierarchicalModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 24
   Total graph size: 406

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.h)
Inference for Bugs model at &amp;quot;hierarchicalModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
           mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]     42.139   4.991  32.186  38.913  42.226  45.346  51.751 1.001  3000
beta[2]     27.611   6.859  13.692  23.437  27.617  31.993  41.118 1.001  3000
beta[3]     41.048   7.032  26.813  36.805  41.067  45.316  55.566 1.002  1200
sigma        5.058   0.315   4.483   4.841   5.036   5.257   5.763 1.001  3000
sigma.site  10.889   2.386   7.235   9.269  10.578  12.125  16.695 1.005  3000
deviance   909.557   6.168 899.915 905.154 908.708 913.153 923.686 1.001  1900

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 19.0 and DIC = 928.6
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to include finite-population standard deviations in the model you can use the following code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString4=&amp;quot;
+ model {
+    #Likelihood (esimating site means (gamma.site)
+    for (i in 1:n) {
+       y[i]~dnorm(quad.means[i],tau)
+       quad.means[i] &amp;lt;- gamma.site[site[i]]
+       y.err[i]&amp;lt;- quad.means[i]-y[i]
+    }
+    for (i in 1:s) {
+       gamma.site[i] ~ dnorm(site.means[i], tau.site)
+       site.means[i] &amp;lt;- inprod(beta[],A.Xmat[i,])
+       site.err[i] &amp;lt;- site.means[i] - gamma.site[i]
+    }
+    #Priors
+    for (i in 1:a) {
+      beta[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.site &amp;lt;- pow(sigma.site,-2)
+    sigma.site &amp;lt;-z/sqrt(chSq.site)
+    z.site ~ dnorm(0, .0016)I(0,)
+    chSq.site ~ dgamma(0.5, 0.5)
+    
+    sd.y &amp;lt;- sd(y.err)
+    sd.site &amp;lt;- sd(site.err)
+    sd.A &amp;lt;- sd(beta)
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString4, con = &amp;quot;SDModel.txt&amp;quot;)
&amp;gt; 
&amp;gt; #data list
&amp;gt; A.Xmat &amp;lt;- model.matrix(~A,ddply(data.nest,~Sites,catcolwise(unique)))
&amp;gt; data.nest.list &amp;lt;- with(data.nest,
+         list(y=y,
+                  site=Sites,
+          A.Xmat= A.Xmat,
+          n=nrow(data.nest),
+          s=length(levels(Sites)),
+                  a = ncol(A.Xmat)
+          )
+ )
&amp;gt; 
&amp;gt; #parameters and chain details
&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sd.y&amp;quot;,&amp;#39;sd.site&amp;#39;,&amp;#39;sd.A&amp;#39;,&amp;#39;sigma.site&amp;#39;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.nest.r2jags.SD &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;SDModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 22
   Total graph size: 571

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.SD)
Inference for Bugs model at &amp;quot;SDModel.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
           mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]     42.336   5.027  32.564  39.187  42.338  45.373  52.570 1.004   420
beta[2]     27.417   7.290  12.457  22.904  27.308  31.955  42.039 1.001  2100
beta[3]     40.862   7.164  26.163  36.386  40.920  45.444  55.173 1.007   770
sd.A        10.042   4.276   2.657   7.162   9.646  12.369  19.900 1.001  2200
sd.site     10.592   1.057   9.214   9.909  10.354  11.029  13.276 1.010   280
sd.y         4.999   0.095   4.852   4.929   4.987   5.058   5.219 1.003   770
sigma        5.047   0.309   4.489   4.830   5.029   5.257   5.705 1.005   310
sigma.site  11.003   2.465   7.419   9.295  10.610  12.282  16.704 1.004   480
deviance   909.411   6.011 899.576 904.938 908.750 913.034 922.925 1.003   630

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 18.0 and DIC = 927.5
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calculate &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; from the posterior of the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.mcmc.listSD &amp;lt;- as.mcmc(data.nest.r2jags.SD)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~A, data.nest)
&amp;gt; coefs &amp;lt;- data.nest.r2jags.SD$BUGSoutput$sims.list[[&amp;#39;beta&amp;#39;]]
&amp;gt; fitted &amp;lt;- coefs %*% t(Xmat)
&amp;gt; X.var &amp;lt;- aaply(fitted,1,function(x){var(x)})
&amp;gt; Z.var &amp;lt;- data.nest.r2jags.SD$BUGSoutput$sims.list[[&amp;#39;sd.site&amp;#39;]]^2
&amp;gt; R.var &amp;lt;- data.nest.r2jags.SD$BUGSoutput$sims.list[[&amp;#39;sd.y&amp;#39;]]^2
&amp;gt; R2.marginal &amp;lt;- (X.var)/(X.var+Z.var+R.var)
&amp;gt; R2.marginal &amp;lt;- data.frame(Mean=mean(R2.marginal), Median=median(R2.marginal), HPDinterval(as.mcmc(R2.marginal)))
&amp;gt; R2.conditional &amp;lt;- (X.var+Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.conditional &amp;lt;- data.frame(Mean=mean(R2.conditional),
+    Median=median(R2.conditional), HPDinterval(as.mcmc(R2.conditional)))
&amp;gt; R2.site &amp;lt;- (Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.site &amp;lt;- data.frame(Mean=mean(R2.site), Median=median(R2.site), HPDinterval(as.mcmc(R2.site)))
&amp;gt; R2.res&amp;lt;-(R.var)/(X.var+Z.var+R.var)
&amp;gt; R2.res &amp;lt;- data.frame(Mean=mean(R2.res), Median=median(R2.res), HPDinterval(as.mcmc(R2.res)))
&amp;gt; 
&amp;gt; rbind(R2.site=R2.site, R2.marginal=R2.marginal, R2.res=R2.res, R2.conditional=R2.conditional)
                     Mean    Median      lower      upper
R2.site        0.26437322 0.2428822 0.16881028 0.41958555
R2.marginal    0.67674004 0.6992418 0.49930501 0.78437310
R2.res         0.05888674 0.0584191 0.03459529 0.08514432
R2.conditional 0.94111326 0.9415809 0.91485568 0.96540471&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graphical summaries&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; newdata &amp;lt;- with(data.nest, data.frame(A=levels(A)))
&amp;gt; Xmat &amp;lt;- model.matrix(~A, newdata)
&amp;gt; coefs &amp;lt;- data.nest.r2jags.m$BUGSoutput$sims.list[[&amp;#39;alpha&amp;#39;]]
&amp;gt; fit &amp;lt;- coefs %*% t(Xmat)
&amp;gt; newdata &amp;lt;- cbind(newdata,
+    adply(fit, 2, function(x) {
+           data.frame(Mean=mean(x), Median=median(x), HPDinterval(as.mcmc(x)),
+              HPDinterval(as.mcmc(x), p=0.68))
+    })
+ )
&amp;gt; 
&amp;gt; 
&amp;gt; library(ggplot2)
&amp;gt; library(gridExtra)
&amp;gt; library(grid)
&amp;gt; p1 &amp;lt;- ggplot(newdata, aes(y=Median, x=A)) +
+   geom_errorbar(aes(ymin=lower, ymax=upper), width=0.01, size=1) +
+   geom_errorbar(aes(ymin=lower.1, ymax=upper.1), width=0, size=2) +
+   geom_point(size=4, shape=21, fill=&amp;#39;white&amp;#39;)+
+   scale_y_continuous(&amp;#39;Y&amp;#39;)+
+   scale_x_discrete(&amp;#39;X&amp;#39;)+
+   theme_classic()+
+   theme(axis.title.y=element_text(vjust=2, size=rel(1.25)),
+         axis.title.x=element_text(vjust=-2, size=rel(1.25)),
+         plot.margin=unit(c(0.5,0.5,2,2), &amp;#39;lines&amp;#39;)
+   )
&amp;gt; 
&amp;gt; p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/summaries_graph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation---second-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation - second example&lt;/h1&gt;
&lt;p&gt;Now imagine a similar experiment in which we intend to measure a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) to one of treatments (three levels; “a1”, “a2” and “a3”). As with the previous design, we decided to establish a nested design in which there are sub-replicate (&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;m Quadrats) within each Site. In the current design, we have decided to further sub-replicate. Within each of the &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; Quadrats, we are going to randomly place &lt;span class=&#34;math inline&#34;&gt;\(2\times10\)&lt;/span&gt;cm pit traps. Now we have Sites nested within Treatments, Quadrats nested within Sites AND, Pits nested within Sites. The latter of these (Pits nested within Sites) are the observations (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; nTreat &amp;lt;- 3
&amp;gt; nSites &amp;lt;- 15
&amp;gt; nSitesPerTreat &amp;lt;- nSites/nTreat
&amp;gt; nQuads &amp;lt;- 5
&amp;gt; nPits &amp;lt;- 2
&amp;gt; site.sigma &amp;lt;- 10 # sd within between sites within treatment
&amp;gt; quad.sigma &amp;lt;- 10
&amp;gt; sigma &amp;lt;- 7.5
&amp;gt; n &amp;lt;- nSites * nQuads * nPits
&amp;gt; sites &amp;lt;- gl(n=nSites,n/nSites,n, lab=paste(&amp;quot;site&amp;quot;,1:nSites))
&amp;gt; A &amp;lt;- gl(nTreat, n/nTreat, n, labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a.means &amp;lt;- c(40,70,80)
&amp;gt; 
&amp;gt; #A&amp;lt;-gl(nTreat,nSites/nTreat,nSites,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a&amp;lt;-gl(nTreat,1,nTreat,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a.X &amp;lt;- model.matrix(~a, expand.grid(a))
&amp;gt; a.eff &amp;lt;- as.vector(solve(a.X,a.means))
&amp;gt; site.means &amp;lt;- rnorm(nSites,a.X %*% a.eff,site.sigma)
&amp;gt; 
&amp;gt; A &amp;lt;- gl(nTreat,nSites/nTreat,nSites,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; A.X &amp;lt;- model.matrix(~A, expand.grid(A))
&amp;gt; #a.X &amp;lt;- model.matrix(~A, expand.grid(A=gl(nTreat,nSites/nTreat,nSites,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))))
&amp;gt; site.means &amp;lt;- rnorm(nSites,A.X %*% a.eff,site.sigma)
&amp;gt; 
&amp;gt; SITES &amp;lt;- gl(nSites,(nSites*nQuads)/nSites,nSites*nQuads,labels=paste(&amp;#39;site&amp;#39;,1:nSites))
&amp;gt; sites.X &amp;lt;- model.matrix(~SITES-1)
&amp;gt; quad.means &amp;lt;- rnorm(nSites*nQuads,sites.X %*% site.means,quad.sigma)
&amp;gt; 
&amp;gt; #SITES &amp;lt;- gl(nSites,1,nSites,labels=paste(&amp;#39;site&amp;#39;,1:nSites))
&amp;gt; #sites.X &amp;lt;- model.matrix(~SITES-1)
&amp;gt; #quad.means &amp;lt;- rnorm(nSites*nQuads,sites.X %*% site.means,quad.sigma)
&amp;gt; 
&amp;gt; QUADS &amp;lt;- gl(nSites*nQuads,n/(nSites*nQuads),n,labels=paste(&amp;#39;quad&amp;#39;,1:(nSites*nQuads)))
&amp;gt; quads.X &amp;lt;- model.matrix(~QUADS-1)
&amp;gt; #quads.eff &amp;lt;- as.vector(solve(quads.X,quad.means))
&amp;gt; #pit.means &amp;lt;- rnorm(n,quads.eff %*% t(quads.X),sigma)
&amp;gt; pit.means &amp;lt;- rnorm(n,quads.X %*% quad.means,sigma)
&amp;gt; 
&amp;gt; PITS &amp;lt;- gl(nPits*nSites*nQuads,1, n, labels=paste(&amp;#39;pit&amp;#39;,1:(nPits*nSites*nQuads)))
&amp;gt; data.nest1&amp;lt;-data.frame(Pits=PITS,Quads=QUADS,Sites=rep(SITES,each=2), A=rep(A,each=nQuads*nPits),y=pit.means)
&amp;gt; #data.nest1&amp;lt;-data.nest1[order(data.nest1$A,data.nest1$Sites,data.nest1$Quads),]
&amp;gt; head(data.nest1)  #print out the first six rows of the data set
   Pits  Quads  Sites  A        y
1 pit 1 quad 1 site 1 a1 61.79607
2 pit 2 quad 1 site 1 a1 56.24699
3 pit 3 quad 2 site 1 a1 42.40885
4 pit 4 quad 2 site 1 a1 52.06672
5 pit 5 quad 3 site 1 a1 73.71286
6 pit 6 quad 3 site 1 a1 62.50529
&amp;gt; 
&amp;gt; ggplot(data.nest1, aes(y=y, x=1)) + geom_boxplot() + facet_grid(.~Quads)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/generate_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Effects of treatment
&amp;gt; boxplot(y~A, ddply(data.nest1, ~A+Sites,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #Site effects
&amp;gt; boxplot(y~Sites, ddply(data.nest1, ~A+Sites+Quads,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #Quadrat effects
&amp;gt; boxplot(y~Quads, ddply(data.nest1, ~A+Sites+Quads+Pits,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/nested-anova-jags/2020-02-01-nested-anova-jags_files/figure-html/exp1_data_ex2-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;it is a little difficult to assess normality/homogeneity of variance of quadrats since there are only two pits per quadrat. Nevertheless, there is no suggestion that variance increases with increasing mean.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;div id=&#34;frequentist-for-comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Frequentist for comparison&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(nlme)
&amp;gt; d.lme &amp;lt;- lme(y ~ A, random=~1|Sites/Quads,data=data.nest1)
&amp;gt; summary(d.lme)
Linear mixed-effects model fit by REML
 Data: data.nest1 
       AIC      BIC   logLik
  1137.994 1155.937 -562.997

Random effects:
 Formula: ~1 | Sites
        (Intercept)
StdDev:    10.38248

 Formula: ~1 | Quads %in% Sites
        (Intercept) Residual
StdDev:    8.441615 7.161178

Fixed effects: y ~ A 
               Value Std.Error DF  t-value p-value
(Intercept) 41.38646   5.04334 75 8.206160  0.0000
Aa2         21.36271   7.13236 12 2.995181  0.0112
Aa3         39.14584   7.13236 12 5.488483  0.0001
 Correlation: 
    (Intr) Aa2   
Aa2 -0.707       
Aa3 -0.707  0.500

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-2.11852493 -0.54600763 -0.03428569  0.53382444  2.26256381 

Number of Observations: 150
Number of Groups: 
           Sites Quads %in% Sites 
              15               75 
&amp;gt; 
&amp;gt; anova(d.lme)
            numDF denDF  F-value p-value
(Intercept)     1    75 446.9152  &amp;lt;.0001
A               2    12  15.1037   5e-04&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;full-effect-parameterisation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full effect parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- alpha0 + alpha[A[i]] + beta.site[site[i]] + beta.quad[quad[i]]
+    }
+    
+    #Priors
+    alpha0 ~ dnorm(0, 1.0E-6)
+    alpha[1] &amp;lt;- 0
+    for (i in 2:nA) {
+      alpha[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    for (i in 1:nSite) {
+      beta.site[i] ~ dnorm(0, tau.Bs) #prior
+    }
+    for (i in 1:nQuad) {
+      beta.quad[i] ~ dnorm(0, tau.Bq) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.Bs &amp;lt;- pow(sigma.Bs,-2)
+    sigma.Bs &amp;lt;-z/sqrt(chSq.Bs)
+    z.Bs ~ dnorm(0, .0016)I(0,)
+    chSq.Bs ~ dgamma(0.5, 0.5)
+ 
+    tau.Bq &amp;lt;- pow(sigma.Bq,-2)
+    sigma.Bq &amp;lt;-z/sqrt(chSq.Bq)
+    z.Bq ~ dnorm(0, .0016)I(0,)
+    chSq.Bq ~ dgamma(0.5, 0.5)
+ 
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;fullModel2.txt&amp;quot;)
&amp;gt; 
&amp;gt; data.nest.list &amp;lt;- with(data.nest1,
+         list(y=y,
+                  site=as.numeric(Sites),
+          A=as.numeric(A),
+          n=nrow(data.nest1),
+          nSite=length(levels(Sites)),
+                  nA = length(levels(A)),
+          nQuad=length(levels(Quads)),
+                  quad = as.numeric(Quads)
+          )
+ )
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;quot;alpha0&amp;quot;,&amp;quot;alpha&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.Bs&amp;quot;,&amp;quot;sigma.Bq&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.nest.r2jags.f2 &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;fullModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 99
   Total graph size: 793

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.f2)
Inference for Bugs model at &amp;quot;fullModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
          mu.vect sd.vect    2.5%      25%      50%      75%    97.5%  Rhat
alpha[1]    0.000   0.000   0.000    0.000    0.000    0.000    0.000 1.000
alpha[2]   21.147   7.532   6.252   16.137   21.140   25.968   35.890 1.001
alpha[3]   38.985   7.635  23.341   34.130   39.120   43.879   53.757 1.001
alpha0     41.541   5.460  30.677   37.967   41.659   45.032   52.383 1.001
sigma       7.294   0.604   6.238    6.870    7.264    7.664    8.580 1.003
sigma.Bq    8.433   1.132   6.355    7.650    8.378    9.175   10.757 1.005
sigma.Bs   10.779   2.673   6.704    8.951   10.409   12.219   17.127 1.017
deviance 1020.495  17.724 988.898 1007.948 1019.500 1032.389 1056.708 1.005
         n.eff
alpha[1]     1
alpha[2]  3000
alpha[3]  3000
alpha0    3000
sigma      970
sigma.Bq   420
sigma.Bs   100
deviance   510

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 156.8 and DIC = 1177.3
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2=&amp;quot;
+ model {
+    #Likelihood
+    for (i in 1:n) {
+       y[i]~dnorm(mu[i],tau)
+       mu[i] &amp;lt;- inprod(alpha[], X[i,]) + inprod(beta.site[],Z.site[i,]) + inprod(beta.quad[],Z.quad[i,])
+       y.err[i] &amp;lt;- y[i]-mu[i]
+    }
+    
+    #Priors
+    for (i in 1:nX) {
+      alpha[i] ~ dnorm(0, 1.0E-6) #prior
+    }
+    for (i in 1:nSite) {
+      beta.site[i] ~ dnorm(0, tau.Bs) #prior
+    }
+    for (i in 1:nQuad) {
+      beta.quad[i] ~ dnorm(0, tau.Bq) #prior
+    }
+    tau &amp;lt;- pow(sigma,-2)
+    sigma &amp;lt;-z/sqrt(chSq)
+    z ~ dnorm(0, .0016)I(0,)
+    chSq ~ dgamma(0.5, 0.5)
+ 
+    tau.Bs &amp;lt;- pow(sigma.Bs,-2)
+    sigma.Bs &amp;lt;-z/sqrt(chSq.Bs)
+    z.Bs ~ dnorm(0, .0016)I(0,)
+    chSq.Bs ~ dgamma(0.5, 0.5)
+ 
+    tau.Bq &amp;lt;- pow(sigma.Bq,-2)
+    sigma.Bq &amp;lt;-z/sqrt(chSq.Bq)
+    z.Bq ~ dnorm(0, .0016)I(0,)
+    chSq.Bq ~ dgamma(0.5, 0.5)
+ 
+    sd.res &amp;lt;- sd(y.err[])
+    sd.site &amp;lt;- sd(beta.site[])
+    sd.quad &amp;lt;- sd(beta.quad[])   
+  }
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;matrixModel2.txt&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~A, data=data.nest1)
&amp;gt; Zsite &amp;lt;- model.matrix(~-1+Sites, data=data.nest1)
&amp;gt; Zquad &amp;lt;- model.matrix(~-1+Quads, data=data.nest1)
&amp;gt; 
&amp;gt; data.nest.list &amp;lt;- with(data.nest1,
+         list(y=y,
+          n=nrow(data.nest1),
+                  X=Xmat, nX=ncol(Xmat),
+          Z.site=Zsite, nSite=ncol(Zsite),
+                  Z.quad=Zquad, nQuad=ncol(Zquad)
+          )
+ )
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;quot;alpha&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma.Bs&amp;quot;,&amp;quot;sigma.Bq&amp;quot;,&amp;#39;sd.res&amp;#39;,&amp;#39;sd.site&amp;#39;,&amp;#39;sd.quad&amp;#39;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.nest.r2jags.m2 &amp;lt;- jags(data = data.nest.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;matrixModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 150
   Unobserved stochastic nodes: 99
   Total graph size: 14993

Initializing model
&amp;gt; 
&amp;gt; print(data.nest.r2jags.m2)
Inference for Bugs model at &amp;quot;matrixModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 4500 iterations (first 3000 discarded)
 n.sims = 3000 iterations saved
          mu.vect sd.vect    2.5%      25%      50%      75%    97.5%  Rhat
alpha[1]   41.247   5.438  30.494   37.721   41.227   44.692   52.262 1.002
alpha[2]   21.535   7.824   6.537   16.541   21.439   26.473   37.416 1.003
alpha[3]   39.276   7.723  24.165   34.357   39.319   44.191   54.637 1.001
sd.quad     8.427   0.828   6.866    7.889    8.420    8.956   10.131 1.001
sd.res      7.221   0.420   6.500    6.924    7.186    7.486    8.137 1.010
sd.site    10.263   1.703   7.202    9.180   10.187   11.240   13.917 1.002
sigma       7.261   0.598   6.189    6.845    7.209    7.631    8.540 1.010
sigma.Bq    8.514   1.064   6.557    7.776    8.454    9.189   10.801 1.001
sigma.Bs   10.703   2.802   6.379    8.805   10.283   12.108   17.304 1.001
deviance 1019.366  17.429 987.783 1007.166 1018.196 1030.618 1056.340 1.010
         n.eff
alpha[1]  3000
alpha[2]  3000
alpha[3]  2500
sd.quad   3000
sd.res     150
sd.site   3000
sigma      160
sigma.Bq  3000
sigma.Bs  3000
deviance   160

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 151.0 and DIC = 1170.4
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we use the &lt;code&gt;JAGS&lt;/code&gt; matrix parameterisation model from above, the &lt;code&gt;JAGS&lt;/code&gt; model is already complete (as we defined the sd components in that model already).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest1.mcmc.listSD &amp;lt;- as.mcmc(data.nest.r2jags.m2)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~A, data.nest1)
&amp;gt; coefs &amp;lt;- data.nest.r2jags.m2$BUGSoutput$sims.list[[&amp;#39;alpha&amp;#39;]]
&amp;gt; fitted &amp;lt;- coefs %*% t(Xmat)
&amp;gt; X.var &amp;lt;- aaply(fitted,1,function(x){var(x)})
&amp;gt; Z.var &amp;lt;- data.nest.r2jags.m2$BUGSoutput$sims.list[[&amp;#39;sd.site&amp;#39;]]^2
&amp;gt; R.var &amp;lt;- data.nest.r2jags.m2$BUGSoutput$sims.list[[&amp;#39;sd.res&amp;#39;]]^2
&amp;gt; R2.marginal &amp;lt;- (X.var)/(X.var+Z.var+R.var)
&amp;gt; R2.marginal &amp;lt;- data.frame(Mean=mean(R2.marginal), Median=median(R2.marginal), HPDinterval(as.mcmc(R2.marginal)))
&amp;gt; R2.conditional &amp;lt;- (X.var+Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.conditional &amp;lt;- data.frame(Mean=mean(R2.conditional),
+    Median=median(R2.conditional), HPDinterval(as.mcmc(R2.conditional)))
&amp;gt; R2.site &amp;lt;- (Z.var)/(X.var+Z.var+R.var)
&amp;gt; R2.site &amp;lt;- data.frame(Mean=mean(R2.site), Median=median(R2.site), HPDinterval(as.mcmc(R2.site)))
&amp;gt; R2.res&amp;lt;-(R.var)/(X.var+Z.var+R.var)
&amp;gt; R2.res &amp;lt;- data.frame(Mean=mean(R2.res), Median=median(R2.res), HPDinterval(as.mcmc(R2.res)))
&amp;gt; 
&amp;gt; rbind(R2.site=R2.site, R2.marginal=R2.marginal, R2.res=R2.res, R2.conditional=R2.conditional)
                    Mean    Median     lower     upper
R2.site        0.2537842 0.2373232 0.1145934 0.4450797
R2.marginal    0.6199972 0.6408875 0.4077973 0.7873383
R2.res         0.1262186 0.1233096 0.0646023 0.1907540
R2.conditional 0.8737814 0.8766904 0.8092460 0.9353977&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2006prior&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2006. “Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by Browne and Draper).” &lt;em&gt;Bayesian Analysis&lt;/em&gt; 1 (3): 515–34.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nested Anova - STAN</title>
      <link>/stan/nested-anova-stan/nested-anova-stan/</link>
      <pubDate>Sun, 09 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/stan/nested-anova-stan/nested-anova-stan/</guid>
      <description>


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;STAN&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman, Lee, and Guo (2015)&lt;/span&gt;) using the package &lt;code&gt;rstan&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Stan Development Team (2018)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;When single sampling units are selected amongst highly heterogeneous conditions, it is unlikely that these single units will adequately represent the populations and repeated sampling is likely to yield very different outcomes. For example, if we were investigating the impacts of fuel reduction burning across a highly heterogeneous landscape, our ability to replicate adequately might be limited by the number of burn sites available.&lt;/p&gt;
&lt;p&gt;Alternatively, sub-replicates within each of the sampling units (e.g. sites) can be collected (and averaged) so as to provided better representatives for each of the units and ultimately reduce the unexplained variability of the test of treatments. In essence, the sub-replicates are the replicates of an additional nested factor whose levels are nested within the main treatment factor. A nested factor refers to a factor whose levels are unique within each level of the factor it is nested within and each level is only represented once. For example, the fuel reduction burn study design could consist of three burnt sites and three un-burnt (control) sites each containing four quadrats (replicates of site and sub-replicates of the burn treatment). Each site represents a unique level of a random factor (any given site cannot be both burnt and un-burnt) that is nested within the fire treatment (burned or not).&lt;/p&gt;
&lt;p&gt;A nested design can be thought of as a hierarchical arrangement of factors (hence the alternative name hierarchical designs) whereby a treatment is progressively sub-replicated. As an additional example, imagine an experiment designed to comparing the leaf toughness of a number of tree species. Working down the hierarchy, five individual trees were randomly selected within (nested within) each species, three branches were randomly selected within each tree, two leaves were randomly selected within each branch and the force required to shear the leaf material in half (transversely) was measured in four random locations along the leaf. Clearly any given leaf can only be from a single branch, tree and species. Each level of sub-replication is introduced to further reduce the amount of unexplained variation and thereby increasing the power of the test for the main treatment effect. Additionally, it is possible to investigate which scale has the greatest (or least, etc) degree of variability - the level of the species, individual tree, branch, leaf, leaf region etc.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nested factors are typically random factors, of which the levels are randomly selected to represent all possible levels (e.g. sites). When the main treatment effect (often referred to as Factor A) is a fixed factor, such designs are referred to as a &lt;em&gt;mixed model nested ANOVA&lt;/em&gt;, whereas when Factor A is random, the design is referred to as a &lt;em&gt;Model II nested ANOVA&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fixed nested factors are also possible. For example, specific dates (corresponding to particular times during a season) could be nested within season. When all factors are fixed, the design is referred to as a &lt;em&gt;Model I mixed model&lt;/em&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fully nested designs (the topic of this chapter) differ from other multi-factor designs in that all factors within (below) the main treatment factor are nested and thus interactions are un-replicated and cannot be tested. Indeed, interaction effects (interaction between Factor A and site) are assumed to be zero.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models-frequentist&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models (frequentist)&lt;/h2&gt;
&lt;p&gt;The linear models for two and three factor nested design are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \alpha_i + \beta_{j(i)} + \epsilon_{ijk},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_{j(i)} + gamma_{k(j(i))}  + \epsilon_{ijkl},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the effect of Factor A, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of Factor B, &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the effect of Factor C and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models-bayesian&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear models (Bayesian)&lt;/h2&gt;
&lt;p&gt;So called “random effects” are modelled differently from “fixed effects” in that rather than estimate their individual effects, we instead estimate the variability due to these “random effects”. Since technically all variables in a Bayesian framework are random, some prefer to use the terms ‘fixed effects’ and ‘varying effects’. As random factors typically represent “random” selections of levels (such as a set of randomly selected sites), incorporated in order to account for the dependency structure (observations within sites are more likely to be correlated to one another - not strickly independent) to the data, we are not overly interested in the individual differences between levels of the ‘varying’ (random) factor. Instead (in addition to imposing a separate correlation structure within each nest), we want to know how much variability is attributed to this level of the design. The linear models for two and three factor nested design are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \alpha_i + \beta_{j(i)} + \epsilon_{ijk}, \;\;\; \epsilon_{ijk} \sim N(0, \sigma^2), \;\;\; \beta_{j(i)} \sim N(0, \sigma^2_{B}) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_{j(i)} + \gamma_{k(j(i))} + \epsilon_{ijkl}, \;\;\; \epsilon_{ijkl} \sim N(0, \sigma^2), \;\;\; \beta_{j(i)} \sim N(0, \sigma^2_{B}) \;\;\; \gamma_{k(j(i))} \sim N(0, \sigma^2_C) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the effect of Factor A, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the variability of Factor B (nested within Factor A), &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the variability of Factor C (nested within Factor B) and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component that is assumed to be normally distributed with a mean of zero and a constant amount of standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;). The subscripts are iterators. For example, the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; represents the number of effects to be estimated for Factor A. Thus the first formula can be read as the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;-th observation of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is drawn from a normal distribution (with a specific level of variability) and mean proposed to be determined by a base mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; - mean of the first treatment across all nests) plus the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th treatment effect plus the variabilitythe model proposes that, given a base mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and knowing the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th treatment (factor A) and which of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th nests within the treatment the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;-th observation from Block &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; (factor B) within treatment effect.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypotheses&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypotheses&lt;/h2&gt;
&lt;p&gt;Separate null hypotheses are associated with each of the factors, however, nested factors are typically only added to absorb some of the unexplained variability and thus, specific hypotheses tests associated with nested factors are of lesser biological importance. Hence, rather than estimate the effects of random effects, we instead estimate how much variability they contribute.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor A: the main treatment effect (fixed)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A): \mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt; (the population group means are all equal). That is, that the mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to one another - no effect of the factor on the response. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the mean of the first group (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu_1\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A) : \alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt; (the effect of each group equals zero). If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), there is evidence that the null hypothesis is not true indicating that the factor does affect the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Factor A: the main treatment effect (random)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A) : \sigma^2_{\alpha}=0\)&lt;/span&gt; (population variance equals zero). There is no added variance due to all possible levels of A.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Factor B: the nested effect (random)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B) : \sigma^2_{\beta}=0\)&lt;/span&gt; (population variance equals zero). There is no added variance due to all possible levels of B within the (set or all possible) levels of A.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Factor B: the nested effect (fixed)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B): \mu_{1(1)}=\mu_{2(1)}=\ldots=\mu_{j(i)}=\mu\)&lt;/span&gt; (the population group means of B (within A) are all equal).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B): \beta_{1(1)}=\beta_{2(1)}=\ldots=\beta_{j(i)}=0\)&lt;/span&gt; (the effect of each chosen B group equals zero).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;Analysis of variance sequentially partitions the total variability in the response variable into components explained by each of the factors (starting with the factors lowest down in the hierarchy - the most deeply nested) and the components unexplained by each factor. Explained variability is calculated by subtracting the amount unexplained by the factor from the amount unexplained by a reduced model that does not contain the factor. When the null hypothesis for a factor is true (no effect or added variability), the ratio of explained and unexplained components for that factor (F-ratio) should follow a theoretical F-distribution with an expected value less than 1. The appropriate unexplained residuals and therefore the appropriate F-ratios for each factor differ according to the different null hypotheses associated with different combinations of fixed and random factors in a nested linear model (see Table below).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; fact_anova_table
      df        MS         F-ratio (B random)    Var comp (B random)        
A     &amp;quot;a-1&amp;quot;     &amp;quot;MS A&amp;quot;     &amp;quot;(MS A)/(MS B&amp;#39;(A))&amp;quot;   &amp;quot;((MS A) - (MS B&amp;#39;(A)))/nb&amp;quot; 
B&amp;#39;(A) &amp;quot;(b-1)a&amp;quot;  &amp;quot;MS B&amp;#39;(A)&amp;quot; &amp;quot;(MS B&amp;#39;(A))/(MS res)&amp;quot; &amp;quot;((MS B&amp;#39;(A)) - (MS res))/n&amp;quot;
Res   &amp;quot;(n-1)ba&amp;quot; &amp;quot;MS res&amp;quot;   &amp;quot;&amp;quot;                    &amp;quot;&amp;quot;                         
      F-ratio (B fixed)     Var comp (B fixed)         
A     &amp;quot;(MS A)/(MS res)&amp;quot;     &amp;quot;((MS A) - (MS res))/nb&amp;quot;   
B&amp;#39;(A) &amp;quot;(MS B&amp;#39;(A))/(MS res)&amp;quot; &amp;quot;((MS B&amp;#39;(A)) - (MS res))/n&amp;quot;
Res   &amp;quot;&amp;quot;                    &amp;quot;&amp;quot;                         &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The corresponding &lt;code&gt;R&lt;/code&gt; syntax is given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #A fixed/random, B random (balanced)
&amp;gt; summary(aov(y~A+Error(B), data))
&amp;gt; VarCorr(lme(y~A,random=1|B, data))
&amp;gt; 
&amp;gt; #A fixed/random, B random (unbalanced)
&amp;gt; anova(lme(y~A,random=1|B, data), type=&amp;#39;marginal&amp;#39;)
&amp;gt; 
&amp;gt; #A fixed/random, B fixed(balanced)
&amp;gt; summary(aov(y~A+B, data))
&amp;gt; 
&amp;gt; #A fixed/random, B fixed (unbalanced)
&amp;gt; contrasts(data$B) &amp;lt;- contr.sum
&amp;gt; Anova(aov(y~A/B, data), type=&amp;#39;III&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;variance-components&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Variance components&lt;/h2&gt;
&lt;p&gt;As previously alluded to, it can often be useful to determine the relative contribution (to explaining the unexplained variability) of each of the factors as this provides insights into the variability at each different scales. These contributions are known as &lt;strong&gt;Variance components&lt;/strong&gt; and are estimates of the added variances due to each of the factors. For consistency with leading texts on this topic, I have included estimated variance components for various balanced nested ANOVA designs in the above table. However, variance components based on a modified version of the maximum likelihood iterative model fitting procedure (&lt;em&gt;REML&lt;/em&gt;) is generally recommended as this accommodates both balanced and unbalanced designs. While there are no numerical differences in the calculations of variance components for fixed and random factors, fixed factors are interpreted very differently and arguably have little clinical meaning (other to infer relative contribution). For fixed factors, variance components estimate the variance between the means of the specific populations that are represented by the selected levels of the factor and therefore represent somewhat arbitrary and artificial populations. For random factors, variance components estimate the variance between means of all possible populations that could have been selected and thus represents the true population variance.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;An F-distribution represents the relative frequencies of all the possible F-ratio’s when a given null hypothesis is true and certain assumptions about the residuals (denominator in the F-ratio calculation) hold. Consequently, it is also important that diagnostics associated with a particular hypothesis test reflect the denominator for the appropriate F-ratio. For example, when testing the null hypothesis that there is no effect of Factor A (&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_i=0\)&lt;/span&gt;) in a mixed nested ANOVA, the means of each level of Factor B are used as the replicates of Factor A. As with single factor anova, hypothesis testing for nested ANOVA assumes the residuals are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;normally distributed. Factors higher up in the hierarchy of a nested model are based on means (or means of means) of lower factors and thus the &lt;em&gt;Central Limit Theory&lt;/em&gt; would predict that normality will usually be satisfied for the higher level factors. Nevertheless, boxplots using the appropriate scale of replication should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;independent of one another - this requires special consideration so as to ensure that the scale at which sub-replicates are measured is still great enough to enable observations to be independent.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;unbalanced-nested-designs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Unbalanced nested designs&lt;/h2&gt;
&lt;p&gt;Designs that incorporate fixed and random factors (either nested or factorial), involve F-ratio calculations in which the denominators are themselves random factors other than the overall residuals. Many statisticians argue that when such denominators are themselves not statistically significant (at the &lt;span class=&#34;math inline&#34;&gt;\(0.25\)&lt;/span&gt; level), there are substantial power benefits from pooling together successive non-significant denominator terms. Thus an F-ratio for a particular factor might be recalculated after pooling together its original denominator with its denominators denominator and so on. The conservative &lt;span class=&#34;math inline&#34;&gt;\(0.25\)&lt;/span&gt; is used instead of the usual 0.05 to reduce further the likelihood of Type II errors (falsely concluding an effect is non-significant - that might result from insufficient power).&lt;/p&gt;
&lt;p&gt;For a simple completely balanced nested ANOVA, it is possible to pool together (calculate their mean) each of the sub-replicates within each nest (site) and then perform single factor ANOVA on those aggregates. Indeed, for a &lt;em&gt;balanced design&lt;/em&gt;, the estimates and hypothesis for Factor A will be identical to that produced via nested ANOVA. However, if there are an unequal number of sub-replicates within each nest, then the single factor ANOVA will be less powerful that a proper nested ANOVA. &lt;em&gt;Unbalanced designs&lt;/em&gt; are those designs in which sample (subsample) sizes for each level of one or more factors differ. These situations are relatively common in biological research, however such imbalance has some important implications for nested designs.&lt;/p&gt;
&lt;p&gt;Firstly, hypothesis tests are more robust to the assumptions of normality and equal variance when the design is balanced. Secondly (and arguably, more importantly), the model contrasts are not orthogonal (independent) and the sums of squares component attributed to each of the model terms cannot be calculated by simple additive partitioning of the total sums of squares. In such situations, exact F-ratios cannot be constructed (at least in theory), variance components calculations are more complicated and significance tests cannot be computed. The denominator MS in an &lt;em&gt;F-ratio&lt;/em&gt; is determined by examining the expected value of the mean squares of each term in a model. Unequal sample sizes result in expected means squares for which there are no obvious logical comparators that enable the impact of an individual model term to be isolated. The severity of this issue depends on which scale of the sub-sampling hierarchy the unbalance(s) occurs as well whether the unbalance occurs in the replication of a fixed or random factor. For example, whilst unequal levels of the first nesting factor (e.g. unequal number of burn vs un-burnt sites) has no effect on F-ratio construction or hypothesis testing for the top level factor (irrespective of whether either of the factors are fixed or random), unequal sub-sampling (replication) at the level of a random (but not fixed) nesting factor will impact on the ability to construct F-ratios and variance components of all terms above it in the hierarchy. There are a number of alternative ways of dealing with unbalanced nested designs. All alternatives assume that the imbalance is not a direct result of the treatments themselves. Such outcomes are more appropriately analysed by modelling the counts of surviving observations via frequency analysis.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Split the analysis up into separate smaller simple ANOVA’s each using the means of the nesting factor to reflect the appropriate scale of replication. As the resulting sums of squares components are thereby based on an aggregated dataset the analyses then inherit the procedures and requirements of single ANOVA.&lt;/li&gt;
&lt;li&gt;Adopt mixed-modelling techniques.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We note that, in a Bayesian framework, issues of design balance essentially evaporate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-mixed-effects-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear mixed effects models&lt;/h2&gt;
&lt;p&gt;Although the term “mixed-effects” can be used to refer to any design that incorporates both fixed and random predictors, its use is more commonly restricted to designs in which factors are nested or grouped within other factors. Typical examples include nested, longitudinal (measurements repeated over time) data, repeated measures and blocking designs. Furthermore, rather than basing parameter estimations on observed and expected mean squares or error strata (as outline above), mixed-effects models estimate parameters via &lt;strong&gt;maximum likelihood&lt;/strong&gt; (ML) or &lt;strong&gt;residual maximum likelihood&lt;/strong&gt; (REML). In so doing, mixed-effects models more appropriately handle estimation of parameters, effects and variance components of unbalanced designs (particularly for random effects). Resulting fitted (or expected) values of each level of a factor (for example, the expected population site means) are referred to as &lt;em&gt;Best Linear Unbiased Predictors&lt;/em&gt; (BLUP’s). As an acknowledgement that most estimated site means will be more extreme than the underlying true population means they estimate (based on the principle that smaller sample sizes result in greater chances of more extreme observations and that nested sub-replicates are also likely to be highly intercorrelated), BLUP’s are less spread from the overall mean than are simple site means. In addition, mixed-effects models naturally model the “within-block” correlation structure that complicates many longitudinal designs.&lt;/p&gt;
&lt;p&gt;Whilst the basic concepts of mixed-effects models have been around for a long time, recent computing advances and adoptions have greatly boosted the popularity of these procedures. Linear mixed effects models are currently at the forefront of statistical development, and as such, are very much a work in progress - both in theory and in practice. Recent developments have seen a further shift away from the traditional practices associated with degrees of freedom, probability distribution and p-value calculations. The traditional approach to inference testing is to compare the fit of an alternative (full) model to a null (reduced) model (via an F-ratio). When assumptions of normality and homogeneity of variance apply, the degrees of freedom are easily computed and the F-ratio has an exact F-distribution to which it can be compared. However, this approach introduces two additional problematic assumptions when estimating fixed effects in a mixed effects model. Firstly, when estimating the effects of one factor, the parameter estimates associated with other factor(s) are assumed to be the true values of those parameters (not estimates). Whilst this assumption is reasonable when all factors are fixed, as random factors are selected such that they represent one possible set of levels drawn from an entire population of possible levels for the random factor, it is unlikely that the associated parameter estimates accurately reflect the true values. Consequently, there is not necessarily an appropriate F-distribution. Furthermore, determining the appropriate degrees of freedom (nominally, the number of independent observations on which estimates are based) for models that incorporate a hierarchical structure is only possible under very specific circumstances (such as completely balanced designs). Degrees of freedom is a somewhat arbitrary defined concept used primarily to select a theoretical probability distribution on which a statistic can be compared. Arguably, however, it is a concept that is overly simplistic for complex hierarchical designs. Most statistical applications continue to provide the “approximate” solutions (as did earlier versions within &lt;code&gt;R&lt;/code&gt;). However, &lt;code&gt;R&lt;/code&gt; linear mixed effects development leaders argue strenuously that given the above shortcomings, such approximations are variably inappropriate and are thus omitted.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Markov chain Monte Carlo&lt;/strong&gt; (MCMC) sampling methods provide a Bayesian-like alternative for inference testing. Markov chains use the mixed model parameter estimates to generate posterior probability distributions of each parameter from which Monte Carlo sampling methods draw a large set of parameter samples. These parameter samples can then be used to calculate &lt;em&gt;highest posterior density&lt;/em&gt; (HPD) intervals (also known as Bayesian credible intervals). Such intervals indicate the interval in which there is a specified probability (typically &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;%) that the true population parameter lies. Furthermore, whilst technically against the spirit of the Bayesian philosophy, it is also possible to generate P values on which to base inferences.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Imagine we has designed an experiment in which we intend to measure a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) to one of treatments (three levels; “a1”, “a2” and “a3”). The treatments occur at a spatial scale (over an area) that far exceeds the logistical scale of sampling units (it would take too long to sample at the scale at which the treatments were applied). The treatments occurred at the scale of hectares whereas it was only feasible to sample y using 1m quadrats. Given that the treatments were naturally occurring (such as soil type), it was not possible to have more than five sites of each treatment type, yet prior experience suggested that the sites in which you intended to sample were very uneven and patchy with respect to &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. In an attempt to account for this inter-site variability (and thus maximize the power of the test for the effect of treatment, you decided to employ a nested design in which 10 quadrats were randomly located within each of the five replicate sites per three treatments. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(plyr)
&amp;gt; set.seed(123)
&amp;gt; nTreat &amp;lt;- 3
&amp;gt; nSites &amp;lt;- 15
&amp;gt; nSitesPerTreat &amp;lt;- nSites/nTreat
&amp;gt; nQuads &amp;lt;- 10
&amp;gt; site.sigma &amp;lt;- 12
&amp;gt; sigma &amp;lt;- 5
&amp;gt; n &amp;lt;- nSites * nQuads
&amp;gt; sites &amp;lt;- gl(n=nSites,k=nQuads, lab=paste0(&amp;#39;S&amp;#39;,1:nSites))
&amp;gt; A &amp;lt;- gl(nTreat, nSitesPerTreat*nQuads, n, labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a.means &amp;lt;- c(40,70,80)
&amp;gt; ## the site means (treatment effects) are drawn from normal distributions
&amp;gt; ## with means of 40, 70 and 80 and standard deviations of 12
&amp;gt; A.effects &amp;lt;- rnorm(nSites, rep(a.means,each=nSitesPerTreat),site.sigma)
&amp;gt; #A.effects &amp;lt;- a.means %*% t(model.matrix(~A, data.frame(A=gl(nTreat,nSitesPerTreat,nSites))))+rnorm(nSites,0,site.sigma)
&amp;gt; Xmat &amp;lt;- model.matrix(~sites -1)
&amp;gt; lin.pred &amp;lt;- Xmat %*% c(A.effects)
&amp;gt; ## the quadrat observations (within sites) are drawn from
&amp;gt; ## normal distributions with means according to the site means
&amp;gt; ## and standard deviations of 5
&amp;gt; y &amp;lt;- rnorm(n,lin.pred,sigma)
&amp;gt; data.nest &amp;lt;- data.frame(y=y, A=A, Sites=sites,Quads=1:length(y))
&amp;gt; head(data.nest)  #print out the first six rows of the data set
         y  A Sites Quads
1 42.20886 a1    S1     1
2 35.76354 a1    S1     2
3 23.44121 a1    S1     3
4 36.78107 a1    S1     4
5 30.91034 a1    S1     5
6 27.93517 a1    S1     6
&amp;gt; 
&amp;gt; library(ggplot2)
&amp;gt; ggplot(data.nest, aes(y=y, x=1)) + geom_boxplot() + facet_grid(.~Sites)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/nested-anova-stan/2020-02-01-nested-anova-stan_files/figure-html/generate_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Effects of treatment
&amp;gt; boxplot(y~A, ddply(data.nest, ~A+Sites,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/nested-anova-stan/2020-02-01-nested-anova-stan_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #Site effects
&amp;gt; boxplot(y~Sites, ddply(data.nest, ~A+Sites+Quads,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/nested-anova-stan/2020-02-01-nested-anova-stan_files/figure-html/exp1_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ## with ggplot2
&amp;gt; ggplot(ddply(data.nest, ~A+Sites,numcolwise(mean, na.rm=T)), aes(y=y, x=A)) +
+   geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/nested-anova-stan/2020-02-01-nested-anova-stan_files/figure-html/exp1_data-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the y-axis. Hence it there is no evidence of non-homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;For non-hierarchical linear models, uniform priors on variance (standard deviation) parameters seem to work reasonably well. &lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt; warns that the use of the inverse-gamma family of non-informative priors are very sensitive to ϵ particularly when variance is close to zero and this may lead to unintentionally informative priors. When the number of groups (treatments or varying/random effects) is large (more than &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;), &lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt; advocated the use of either uniform or half-cauchy priors. Yet when the number of groups is low, &lt;span class=&#34;citation&#34;&gt;Gelman and others (2006)&lt;/span&gt; indicates that uniform priors have a tendency to result in inflated variance estimates. Consequently, half-cauchy priors are generally recommended for variances.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Full parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\alpha_0 + \alpha_i + \beta_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_{ij)} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\alpha_0, \alpha_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The &lt;em&gt;full parameterisation&lt;/em&gt;, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Matrix parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\mu_{ij}, \sigma^2), \;\;\; \mu_{ij}=\boldsymbol \alpha \boldsymbol X + \beta_{j(i)}, \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_{ij} \sim N(0, \sigma^2_B)\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \alpha \sim MVN(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. The full parameterisation, shows the effects parameterisation in which there is an intercept (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt;) and two treatment effects (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(1,2\)&lt;/span&gt;). The &lt;em&gt;matrix parameterisation&lt;/em&gt; is a compressed notation, In this parameterisation, there are three alpha parameters (one representing the mean of treatment a1, and the other two representing the treatment effects (differences between a2 and a1 and a3 and a1). In generating priors for each of these three alpha parameters, we could loop through each and define a non-informative normal prior to each (as in the Full parameterisation version). However, it turns out that it is more efficient (in terms of mixing and thus the number of necessary iterations) to define the priors from a multivariate normal distribution. This has as many means as there are parameters to estimate (&lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt;) and a &lt;span class=&#34;math inline&#34;&gt;\(3\times3\)&lt;/span&gt; matrix of zeros and &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; in the diagonals.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \boldsymbol \mu =
  \begin{bmatrix} 0  \\ 0  \\ 0 \end{bmatrix}, \;\;\; \sigma^2 \sim   
  \begin{bmatrix}
   1000000 &amp;amp; 0 &amp;amp; 0 \\
   0 &amp;amp; 1000000 &amp;amp; 0 \\
   0 &amp;amp; 0 &amp;amp; 1000000
   \end{bmatrix}. \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical parameterisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} \sim N(\beta_{i(j)}, \sigma^2), \;\;\; \beta_{i(j)}\sim N(\mu_i, \sigma^2_B), \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i = \boldsymbol \alpha \boldsymbol X\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i \sim N(0, 1000000)\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2, \sigma^2_B \sim \text{Cauchy(0, 25)}\)&lt;/span&gt;. In the &lt;em&gt;heirarchical parameterisation&lt;/em&gt;, we are indicating two residual layers - one representing the variability in the observed data between individual observations (within sites) and the second representing the variability between site means (within the three treatments).&lt;/p&gt;
&lt;div id=&#34;full-means-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full means parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstanString=&amp;quot;
+ data{
+    int n;
+    int nA;
+    int nB;
+    vector [n] y;
+    int A[n];
+    int B[n];
+ }
+ 
+ parameters{
+   real alpha[nA];
+   real&amp;lt;lower=0&amp;gt; sigma;
+   vector [nB] beta;
+   real&amp;lt;lower=0&amp;gt; sigma_B;
+ }
+  
+ model{
+     real mu[n];
+ 
+     // Priors
+     alpha ~ normal( 0 , 100 );
+     beta ~ normal( 0 , sigma_B );
+     sigma_B ~ cauchy( 0 , 25 );
+     sigma ~ cauchy( 0 , 25 );
+     
+     for ( i in 1:n ) {
+         mu[i] = alpha[A[i]] + beta[B[i]];
+     }
+     y ~ normal( mu , sigma );
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstanString, con = &amp;quot;fullModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.list &amp;lt;- with(data.nest, list(y=y, A=as.numeric(A), B=as.numeric(Sites),
+   n=nrow(data.nest), nB=length(levels(Sites)),nA=length(levels(A))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma_B&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;STAN&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;rstan&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;STAN&lt;/code&gt; code via the &lt;code&gt;rstan&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.rstan.c &amp;lt;- stan(data = data.nest.list, file = &amp;quot;fullModel.stan&amp;quot;, chains = nChains, pars = params, iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;fullModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 1 seconds (Warm-up)
Chain 1:                0.532 seconds (Sampling)
Chain 1:                1.532 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;fullModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 1.046 seconds (Warm-up)
Chain 2:                0.515 seconds (Sampling)
Chain 2:                1.561 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.nest.rstan.c, par = c(&amp;quot;alpha&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;sigma_B&amp;quot;))
Inference for Stan model: fullModel.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

          mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
alpha[1] 42.13    0.17 5.42 31.72 38.59 42.04 45.54 52.73  1058    1
alpha[2] 69.78    0.16 5.18 58.88 66.67 70.02 73.13 79.77  1031    1
alpha[3] 83.44    0.16 5.32 73.39 80.08 83.32 86.79 93.71  1128    1
sigma     5.04    0.01 0.31  4.49  4.82  5.03  5.24  5.71  1681    1
sigma_B  11.53    0.07 2.64  7.64  9.65 11.05 13.00 17.73  1347    1

Samples were drawn using NUTS(diag_e) at Wed Feb 19 18:54:36 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; data.nest.rstan.c.df &amp;lt;-as.data.frame(extract(data.nest.rstan.c))
&amp;gt; head(data.nest.rstan.c.df)
   alpha.1  alpha.2  alpha.3    sigma   sigma_B      lp__
1 39.90783 67.92721 85.21329 5.001354 10.311217 -356.3867
2 43.82811 70.24443 84.04493 5.063975  8.728672 -355.7535
3 40.70837 86.85136 68.64037 5.418739 17.424519 -364.8486
4 44.81747 68.68533 81.60515 5.133029 11.324690 -356.2288
5 36.25821 69.65002 79.77226 5.401904 11.885382 -358.2225
6 39.98730 75.26225 83.81045 5.215396 10.654035 -355.1518&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;full-effect-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full effect parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstan2String=&amp;quot;
+ data{
+    int n;
+    int nB;
+    vector [n] y;
+    int A2[n];
+    int A3[n];
+    int B[n];
+ }
+ 
+ parameters{
+   real alpha0;
+   real alpha2;
+   real alpha3;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   vector [nB] beta;
+   real&amp;lt;lower=0&amp;gt; sigma_B;
+ }
+  
+ model{
+     real mu[n];
+ 
+     // Priors
+     alpha0 ~ normal( 0 , 100 );
+     alpha2 ~ normal( 0 , 100 );
+     alpha3 ~ normal( 0 , 100 );
+     beta ~ normal( 0 , sigma_B );
+     sigma_B ~ cauchy( 0 , 25 );
+     sigma ~ cauchy( 0 , 25 );
+     
+     for ( i in 1:n ) {
+         mu[i] = alpha0 + alpha2*A2[i] + 
+                alpha3*A3[i] + beta[B[i]];
+     }
+     y ~ normal( mu , sigma );
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstan2String, con = &amp;quot;full2Model.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; A2 &amp;lt;- ifelse(data.nest$A==&amp;#39;a2&amp;#39;,1,0)
&amp;gt; A3 &amp;lt;- ifelse(data.nest$A==&amp;#39;a3&amp;#39;,1,0)
&amp;gt; data.nest.list &amp;lt;- with(data.nest, list(y=y, A2=A2, A3=A3, B=as.numeric(Sites),
+    n=nrow(data.nest), nB=length(levels(Sites))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha0&amp;quot;,&amp;quot;alpha2&amp;quot;,&amp;quot;alpha3&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma_B&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;STAN&lt;/code&gt; code via the &lt;code&gt;rstan&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.rstan.c2 &amp;lt;- stan(data = data.nest.list, file = &amp;quot;full2Model.stan&amp;quot;, chains = nChains, pars = params, iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;full2Model&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 2.155 seconds (Warm-up)
Chain 1:                1.313 seconds (Sampling)
Chain 1:                3.468 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;full2Model&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 2.344 seconds (Warm-up)
Chain 2:                1.687 seconds (Sampling)
Chain 2:                4.031 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.nest.rstan.c2, par = c(&amp;quot;alpha0&amp;quot;, &amp;quot;alpha2&amp;quot;, &amp;quot;alpha3&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;sigma_B&amp;quot;))
Inference for Stan model: full2Model.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

         mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
alpha0  42.24    0.19 5.22 32.07 38.86 42.23 45.49 52.71   754    1
alpha2  27.74    0.24 7.22 12.83 23.19 27.95 32.39 41.86   930    1
alpha3  41.08    0.26 7.57 26.40 36.24 40.91 45.91 56.62   832    1
sigma    5.06    0.01 0.31  4.49  4.84  5.04  5.26  5.70  1614    1
sigma_B 11.50    0.07 2.62  7.48  9.61 11.18 12.87 17.56  1473    1

Samples were drawn using NUTS(diag_e) at Wed Feb 19 18:55:27 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; data.nest.rstan.c2.df &amp;lt;-as.data.frame(extract(data.nest.rstan.c2))
&amp;gt; head(data.nest.rstan.c2.df)
    alpha0   alpha2   alpha3    sigma   sigma_B      lp__
1 43.44920 25.05917 38.82597 4.987000  8.342916 -352.4477
2 37.88972 26.37229 52.49395 5.060172 14.993315 -359.3865
3 44.42550 31.08944 44.58649 4.560923 12.629643 -356.8136
4 44.91839 23.67947 47.86579 5.243758 11.344471 -360.4625
5 36.77499 30.43252 49.29206 4.755335 12.472457 -360.6371
6 41.89213 22.74346 43.71447 5.184679 10.054922 -356.3188&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstanString2=&amp;quot;
+ data{
+    int n;
+    int nB;
+    int nA;
+    vector [n] y;
+    matrix [n,nA] X;
+    int B[n];
+    vector [nA] a0;
+    matrix [nA,nA] A0;
+ }
+ 
+ parameters{
+   vector [nA] alpha;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   vector [nB] beta;
+   real&amp;lt;lower=0&amp;gt; sigma_B;
+ }
+  
+ model{
+     real mu[n];
+ 
+     // Priors
+     //alpha ~ normal( 0 , 100 );
+     alpha ~ multi_normal(a0,A0);
+     beta ~ normal( 0 , sigma_B );
+     sigma_B ~ cauchy( 0 , 25);
+     sigma ~ cauchy( 0 , 25 );
+     
+     for ( i in 1:n ) {
+         mu[i] = dot_product(X[i],alpha) + beta[B[i]];
+     }
+     y ~ normal( mu , sigma );
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstanString2, con = &amp;quot;matrixModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X &amp;lt;- model.matrix(~A, data.nest)
&amp;gt; nA &amp;lt;- ncol(X)
&amp;gt; data.nest.list &amp;lt;- with(data.nest, list(y=y, X=X, B=as.numeric(Sites),
+    n=nrow(data.nest), nB=length(levels(Sites)), nA=nA,
+    a0=rep(0,nA), A0=diag(100000,nA)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma_B&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;STAN&lt;/code&gt; code via the &lt;code&gt;rstan&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.rstan.m &amp;lt;- stan(data = data.nest.list, file = &amp;quot;matrixModel.stan&amp;quot;, chains = nChains, pars = params, iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;matrixModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 8.409 seconds (Warm-up)
Chain 1:                6.17 seconds (Sampling)
Chain 1:                14.579 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;matrixModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 9.595 seconds (Warm-up)
Chain 2:                6.436 seconds (Sampling)
Chain 2:                16.031 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.nest.rstan.m, par = c(&amp;quot;alpha&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;sigma_B&amp;quot;))
Inference for Stan model: matrixModel.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

          mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
alpha[1] 42.36    0.16 5.19 31.70 39.08 42.45 45.71 52.79  1069    1
alpha[2] 27.59    0.23 7.45 13.12 22.64 27.47 32.31 43.07  1037    1
alpha[3] 41.00    0.23 7.53 25.73 36.29 41.13 45.57 55.83  1083    1
sigma     5.04    0.01 0.31  4.48  4.83  5.02  5.22  5.69  2053    1
sigma_B  11.51    0.07 2.61  7.71  9.66 11.09 12.97 17.82  1545    1

Samples were drawn using NUTS(diag_e) at Wed Feb 19 18:56:43 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; data.nest.rstan.m.df &amp;lt;-as.data.frame(extract(data.nest.rstan.m))
&amp;gt; head(data.nest.rstan.m.df)
   alpha.1  alpha.2  alpha.3    sigma   sigma_B      lp__
1 41.40841 32.47143 57.93674 4.737729 11.199844 -364.6446
2 39.59351 24.92710 43.71482 5.359000  9.763771 -358.0532
3 51.54847 28.01489 31.29953 5.424494 10.611593 -357.9738
4 33.53023 43.54390 53.51006 4.879110 12.370616 -351.2236
5 41.44793 19.43188 41.36733 5.279320 10.059042 -360.4873
6 31.05092 29.80598 56.34603 4.882690 15.141476 -358.0164&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;hierarchical-parameterisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hierarchical parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstanString3=&amp;quot;
+ data{
+    int n;
+    int nA;
+    int nSites;
+    vector [n] y;
+    matrix [nSites,nA] X;
+    matrix [n,nSites] Z;
+ }
+ 
+ parameters{
+    vector[nA] beta;
+    vector[nSites] gamma;
+    real&amp;lt;lower=0&amp;gt; sigma;
+    real&amp;lt;lower=0&amp;gt; sigma_S;
+    
+ }
+  
+ model{
+     vector [n] mu_site;
+     vector [nSites] mu;
+ 
+     // Priors
+     beta ~ normal( 0 , 1000 );
+     gamma ~ normal( 0 , 1000 );
+     sigma ~ cauchy( 0 , 25 );
+     sigma_S~ cauchy( 0 , 25 );
+ 
+     mu_site = Z*gamma;
+     y ~ normal( mu_site , sigma );
+     mu = X*beta;
+     gamma ~ normal(mu, sigma_S);
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstanString3, con = &amp;quot;hierarchicalModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; dt.A &amp;lt;- ddply(data.nest,~Sites,catcolwise(unique))
&amp;gt; X&amp;lt;-model.matrix(~A, dt.A)
&amp;gt; Z&amp;lt;-model.matrix(~Sites-1, data.nest)
&amp;gt; data.nest.list &amp;lt;- list(y=data.nest$y, X=X, Z=Z, n=nrow(data.nest),
+   nSites=nrow(X),nA=ncol(X))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;,&amp;quot;sigma_S&amp;quot;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;STAN&lt;/code&gt; code via the &lt;code&gt;rstan&lt;/code&gt; interface.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.nest.rstan.h &amp;lt;- stan(data = data.nest.list, file = &amp;quot;hierarchicalModel.stan&amp;quot;, chains = nChains, pars = params, iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;hierarchicalModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.668 seconds (Warm-up)
Chain 1:                0.234 seconds (Sampling)
Chain 1:                0.902 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;hierarchicalModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.703 seconds (Warm-up)
Chain 2:                0.328 seconds (Sampling)
Chain 2:                1.031 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.nest.rstan.h, par = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;sigma_S&amp;quot;))
Inference for Stan model: hierarchicalModel.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

         mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
beta[1] 42.00    0.12 5.42 31.11 38.53 41.97 45.38 52.92  1950    1
beta[2] 27.78    0.16 7.78 12.51 22.96 27.60 32.61 43.48  2223    1
beta[3] 41.25    0.16 7.60 25.98 36.43 41.22 46.13 56.47  2297    1
sigma    5.05    0.01 0.31  4.51  4.83  5.03  5.24  5.69  3535    1
sigma_S 11.60    0.06 2.77  7.65  9.69 11.12 13.00 18.21  2293    1

Samples were drawn using NUTS(diag_e) at Wed Feb 19 18:57:31 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; data.nest.rstan.h.df &amp;lt;-as.data.frame(extract(data.nest.rstan.h))
&amp;gt; head(data.nest.rstan.h.df)
    beta.1   beta.2   beta.3    sigma   sigma_S      lp__
1 46.23354 28.84100 35.42376 5.036956 11.894690 -358.2262
2 45.88700 23.99846 40.07971 5.376392 10.841072 -354.2937
3 49.82263 21.87036 29.82862 5.212592 13.817988 -356.6391
4 52.75362 19.51831 26.12392 5.023215 11.063866 -357.1474
5 49.27716 26.58538 25.05783 5.633089 13.477152 -357.9141
6 46.81798 29.23605 31.25244 4.968886  8.497519 -353.4571&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to include finite-population standard deviations in the model you can use the following code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstanString4=&amp;quot;
+ data{
+    int n;
+    int nA;
+    int nSites;
+    vector [n] y;
+    matrix [nSites,nA] X;
+    matrix [n,nSites] Z;
+ }
+ 
+ parameters{
+    vector[nA] beta;
+    vector[nSites] gamma;
+    real&amp;lt;lower=0&amp;gt; sigma;
+    real&amp;lt;lower=0&amp;gt; sigma_S;
+    
+ }
+ 
+ model{
+     vector [n] mu_site;
+     vector [nSites] mu;
+ 
+     // Priors
+     beta ~ normal( 0 , 1000 );
+     gamma ~ normal( 0 , 1000 );
+     sigma ~ cauchy( 0 , 25 );
+     sigma_S~ cauchy( 0 , 25 );
+ 
+     mu_site = Z*gamma;
+     y ~ normal( mu_site , sigma );
+     mu = X*beta;
+     gamma ~ normal(mu, sigma_S);
+ }
+ 
+ generated quantities {
+     vector [n] mu_site;
+     vector [nSites] mu;
+     vector [n] y_err;
+     real sd_y;
+     vector [nSites] mu_site_err;
+     real sd_site;
+     real sd_A;
+     
+     mu_site = Z*gamma;
+     y_err = mu_site - y;
+     sd_y = sd(y_err);
+ 
+     mu = X*beta;
+     mu_site_err = mu - gamma;
+     sd_site = sd(mu_site_err);
+ 
+     sd_A = sd(beta);
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstanString4, con = &amp;quot;SDModel.stan&amp;quot;)
&amp;gt; 
&amp;gt; #data list
&amp;gt; dt.A &amp;lt;- ddply(data.nest,~Sites,catcolwise(unique))
&amp;gt; X&amp;lt;-model.matrix(~A, dt.A)
&amp;gt; Z&amp;lt;-model.matrix(~Sites-1, data.nest)
&amp;gt; data.nest.list &amp;lt;- list(y=data.nest$y, X=X, Z=Z, n=nrow(data.nest),
+    nSites=nrow(X),nA=ncol(X))
&amp;gt; 
&amp;gt; #parameters and chain details
&amp;gt; params &amp;lt;- c(&amp;#39;beta&amp;#39;,&amp;#39;sigma&amp;#39;,&amp;#39;sigma_S&amp;#39;,&amp;#39;sd_A&amp;#39;,&amp;#39;sd_site&amp;#39;,&amp;#39;sd_y&amp;#39;)
&amp;gt; adaptSteps = 1000
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.nest.rstan.SD &amp;lt;- stan(data = data.nest.list, file = &amp;quot;SDModel.stan&amp;quot;, chains = nChains, pars = params, iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;SDModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.853 seconds (Warm-up)
Chain 1:                0.344 seconds (Sampling)
Chain 1:                1.197 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;SDModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.703 seconds (Warm-up)
Chain 2:                0.433 seconds (Sampling)
Chain 2:                1.136 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.nest.rstan.SD, par = c(&amp;#39;beta&amp;#39;,&amp;#39;sigma&amp;#39;,&amp;#39;sigma_S&amp;#39;,&amp;#39;sd_A&amp;#39;,&amp;#39;sd_site&amp;#39;,&amp;#39;sd_y&amp;#39;))
Inference for Stan model: SDModel.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

         mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
beta[1] 42.04    0.13 5.72 29.86 38.36 42.12 45.76 53.10  2010    1
beta[2] 27.62    0.16 8.05 12.00 22.54 27.60 32.69 43.90  2627    1
beta[3] 41.07    0.17 8.06 25.43 36.00 41.02 46.12 57.14  2344    1
sigma    5.04    0.00 0.31  4.48  4.82  5.02  5.24  5.69  4394    1
sigma_S 11.70    0.06 2.81  7.63  9.75 11.25 13.12 18.91  2345    1
sd_A    10.44    0.10 4.59  2.83  7.28  9.90 13.05 21.10  1968    1
sd_site 10.77    0.03 1.22  9.20  9.99 10.50 11.24 13.94  1343    1
sd_y     5.00    0.00 0.10  4.85  4.93  4.98  5.05  5.21  1220    1

Samples were drawn using NUTS(diag_e) at Wed Feb 19 18:58:19 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; data.nest.rstan.SD.df &amp;lt;-as.data.frame(extract(data.nest.rstan.SD))
&amp;gt; head(data.nest.rstan.SD.df)
    beta.1   beta.2   beta.3    sigma   sigma_S      sd_A   sd_site     sd_y
1 36.80986 28.70439 51.46066 5.609824  7.880194 11.533954 10.530131 4.955827
2 43.21227 24.45470 36.88674 4.686372 12.168378  9.543014  9.421704 4.951786
3 44.79516 23.02770 33.81295 5.312964 13.073682 10.883877  9.541595 5.250076
4 37.08413 32.27076 52.57465 4.924647 13.462061 10.609527 10.778432 5.041660
5 47.78030 20.76704 31.80325 4.758630 11.249078 13.581725 11.035733 4.947235
6 47.58350 19.70850 37.81088 5.630886 12.222762 14.143406 10.171348 5.088340
       lp__
1 -356.9475
2 -354.0613
3 -361.8290
4 -357.0632
5 -353.8392
6 -360.0825&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation---second-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation - second example&lt;/h1&gt;
&lt;p&gt;Now imagine a similar experiment in which we intend to measure a response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) to one of treatments (three levels; “a1”, “a2” and “a3”). As with the previous design, we decided to establish a nested design in which there are sub-replicate (&lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;m Quadrats) within each Site. In the current design, we have decided to further sub-replicate. Within each of the &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; Quadrats, we are going to randomly place &lt;span class=&#34;math inline&#34;&gt;\(2\times10\)&lt;/span&gt;cm pit traps. Now we have Sites nested within Treatments, Quadrats nested within Sites AND, Pits nested within Sites. The latter of these (Pits nested within Sites) are the observations (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; nTreat &amp;lt;- 3
&amp;gt; nSites &amp;lt;- 15
&amp;gt; nSitesPerTreat &amp;lt;- nSites/nTreat
&amp;gt; nQuads &amp;lt;- 5
&amp;gt; nPits &amp;lt;- 2
&amp;gt; site.sigma &amp;lt;- 10 # sd within between sites within treatment
&amp;gt; quad.sigma &amp;lt;- 10
&amp;gt; sigma &amp;lt;- 7.5
&amp;gt; n &amp;lt;- nSites * nQuads * nPits
&amp;gt; sites &amp;lt;- gl(n=nSites,n/nSites,n, lab=paste(&amp;quot;site&amp;quot;,1:nSites))
&amp;gt; A &amp;lt;- gl(nTreat, n/nTreat, n, labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a.means &amp;lt;- c(40,70,80)
&amp;gt; 
&amp;gt; #A&amp;lt;-gl(nTreat,nSites/nTreat,nSites,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a&amp;lt;-gl(nTreat,1,nTreat,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; a.X &amp;lt;- model.matrix(~a, expand.grid(a))
&amp;gt; a.eff &amp;lt;- as.vector(solve(a.X,a.means))
&amp;gt; site.means &amp;lt;- rnorm(nSites,a.X %*% a.eff,site.sigma)
&amp;gt; 
&amp;gt; A &amp;lt;- gl(nTreat,nSites/nTreat,nSites,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))
&amp;gt; A.X &amp;lt;- model.matrix(~A, expand.grid(A))
&amp;gt; #a.X &amp;lt;- model.matrix(~A, expand.grid(A=gl(nTreat,nSites/nTreat,nSites,labels=c(&amp;#39;a1&amp;#39;,&amp;#39;a2&amp;#39;,&amp;#39;a3&amp;#39;))))
&amp;gt; site.means &amp;lt;- rnorm(nSites,A.X %*% a.eff,site.sigma)
&amp;gt; 
&amp;gt; SITES &amp;lt;- gl(nSites,(nSites*nQuads)/nSites,nSites*nQuads,labels=paste(&amp;#39;site&amp;#39;,1:nSites))
&amp;gt; sites.X &amp;lt;- model.matrix(~SITES-1)
&amp;gt; quad.means &amp;lt;- rnorm(nSites*nQuads,sites.X %*% site.means,quad.sigma)
&amp;gt; 
&amp;gt; #SITES &amp;lt;- gl(nSites,1,nSites,labels=paste(&amp;#39;site&amp;#39;,1:nSites))
&amp;gt; #sites.X &amp;lt;- model.matrix(~SITES-1)
&amp;gt; #quad.means &amp;lt;- rnorm(nSites*nQuads,sites.X %*% site.means,quad.sigma)
&amp;gt; 
&amp;gt; QUADS &amp;lt;- gl(nSites*nQuads,n/(nSites*nQuads),n,labels=paste(&amp;#39;quad&amp;#39;,1:(nSites*nQuads)))
&amp;gt; quads.X &amp;lt;- model.matrix(~QUADS-1)
&amp;gt; #quads.eff &amp;lt;- as.vector(solve(quads.X,quad.means))
&amp;gt; #pit.means &amp;lt;- rnorm(n,quads.eff %*% t(quads.X),sigma)
&amp;gt; pit.means &amp;lt;- rnorm(n,quads.X %*% quad.means,sigma)
&amp;gt; 
&amp;gt; PITS &amp;lt;- gl(nPits*nSites*nQuads,1, n, labels=paste(&amp;#39;pit&amp;#39;,1:(nPits*nSites*nQuads)))
&amp;gt; data.nest1&amp;lt;-data.frame(Pits=PITS,Quads=QUADS,Sites=rep(SITES,each=2), A=rep(A,each=nQuads*nPits),y=pit.means)
&amp;gt; #data.nest1&amp;lt;-data.nest1[order(data.nest1$A,data.nest1$Sites,data.nest1$Quads),]
&amp;gt; head(data.nest1)  #print out the first six rows of the data set
   Pits  Quads  Sites  A        y
1 pit 1 quad 1 site 1 a1 61.79607
2 pit 2 quad 1 site 1 a1 56.24699
3 pit 3 quad 2 site 1 a1 42.40885
4 pit 4 quad 2 site 1 a1 52.06672
5 pit 5 quad 3 site 1 a1 73.71286
6 pit 6 quad 3 site 1 a1 62.50529
&amp;gt; 
&amp;gt; ggplot(data.nest1, aes(y=y, x=1)) + geom_boxplot() + facet_grid(.~Quads)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/nested-anova-stan/2020-02-01-nested-anova-stan_files/figure-html/generate_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Effects of treatment
&amp;gt; boxplot(y~A, ddply(data.nest1, ~A+Sites,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/nested-anova-stan/2020-02-01-nested-anova-stan_files/figure-html/exp1_data_ex2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #Site effects
&amp;gt; boxplot(y~Sites, ddply(data.nest1, ~A+Sites+Quads,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/nested-anova-stan/2020-02-01-nested-anova-stan_files/figure-html/exp1_data_ex2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; #Quadrat effects
&amp;gt; boxplot(y~Quads, ddply(data.nest1, ~A+Sites+Quads+Pits,numcolwise(mean, na.rm=T)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/nested-anova-stan/2020-02-01-nested-anova-stan_files/figure-html/exp1_data_ex2-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;there is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;it is a little difficult to assess normality/homogeneity of variance of quadrats since there are only two pits per quadrat. Nevertheless, there is no suggestion that variance increases with increasing mean.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality, etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;div id=&#34;frequentist-for-comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Frequentist for comparison&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(nlme)
&amp;gt; d.lme &amp;lt;- lme(y ~ A, random=~1|Sites/Quads,data=data.nest1)
&amp;gt; summary(d.lme)
Linear mixed-effects model fit by REML
 Data: data.nest1 
       AIC      BIC   logLik
  1137.994 1155.937 -562.997

Random effects:
 Formula: ~1 | Sites
        (Intercept)
StdDev:    10.38248

 Formula: ~1 | Quads %in% Sites
        (Intercept) Residual
StdDev:    8.441615 7.161178

Fixed effects: y ~ A 
               Value Std.Error DF  t-value p-value
(Intercept) 41.38646   5.04334 75 8.206160  0.0000
Aa2         21.36271   7.13236 12 2.995181  0.0112
Aa3         39.14584   7.13236 12 5.488483  0.0001
 Correlation: 
    (Intr) Aa2   
Aa2 -0.707       
Aa3 -0.707  0.500

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-2.11852493 -0.54600763 -0.03428569  0.53382444  2.26256381 

Number of Observations: 150
Number of Groups: 
           Sites Quads %in% Sites 
              15               75 
&amp;gt; 
&amp;gt; anova(d.lme)
            numDF denDF  F-value p-value
(Intercept)     1    75 446.9152  &amp;lt;.0001
A               2    12  15.1037   5e-04&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;full-effect-parameterisation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Full effect parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstanString=&amp;quot;
+ data{
+    int n;
+    int nSite;
+    int nQuad;
+    vector [n] y;
+    int A2[n];
+    int A3[n];
+    int Site[n];
+    int Quad[n];
+ }
+ 
+ parameters{
+   real alpha0;
+   real alpha2;
+   real alpha3;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   vector [nSite] beta_Site;
+   real&amp;lt;lower=0&amp;gt; sigma_Site;
+   vector [nQuad] beta_Quad;
+   real&amp;lt;lower=0&amp;gt; sigma_Quad;
+ }
+  
+ model{
+     real mu[n];
+ 
+     // Priors
+     alpha0 ~ normal( 0 , 100 );
+     alpha2 ~ normal( 0 , 100 );
+     alpha3 ~ normal( 0 , 100 );
+     beta_Site~ normal( 0 , sigma_Site );
+     sigma_Site ~ cauchy( 0 , 25 );
+     beta_Quad~ normal( 0 , sigma_Quad );
+     sigma_Quad ~ cauchy( 0 , 25 );
+     sigma ~ cauchy( 0 , 25 );
+     
+     for ( i in 1:n ) {
+         mu[i] = alpha0 + alpha2*A2[i] + 
+                alpha3*A3[i] + beta_Site[Site[i]] + beta_Quad[Quad[i]];
+     }
+     y ~ normal( mu , sigma );
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstanString, con = &amp;quot;fullModel2.stan&amp;quot;)
&amp;gt; 
&amp;gt; A2 &amp;lt;- ifelse(data.nest1$A==&amp;#39;a2&amp;#39;,1,0)
&amp;gt; A3 &amp;lt;- ifelse(data.nest1$A==&amp;#39;a3&amp;#39;,1,0)
&amp;gt; data.nest.list &amp;lt;- with(data.nest1, list(y=y, A2=A2, A3=A3, Site=as.numeric(Sites),
+    n=nrow(data.nest1), nSite=length(levels(Sites)),
+    nQuad=length(levels(Quads)), Quad=as.numeric(Quads)))
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;alpha0&amp;#39;,&amp;#39;alpha2&amp;#39;,&amp;#39;alpha3&amp;#39;,&amp;#39;sigma&amp;#39;,&amp;#39;sigma_Site&amp;#39;, &amp;#39;sigma_Quad&amp;#39;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.nest1.rstan.f &amp;lt;- stan(data = data.nest.list, file = &amp;quot;fullModel2.stan&amp;quot;, chains = nChains, pars = params, iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;fullModel2&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 3.327 seconds (Warm-up)
Chain 1:                4.345 seconds (Sampling)
Chain 1:                7.672 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;fullModel2&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 4.045 seconds (Warm-up)
Chain 2:                4.161 seconds (Sampling)
Chain 2:                8.206 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.nest1.rstan.f, par = c(&amp;#39;alpha0&amp;#39;,&amp;#39;alpha2&amp;#39;,&amp;#39;alpha3&amp;#39;,&amp;#39;sigma&amp;#39;,&amp;#39;sigma_Site&amp;#39;, &amp;#39;sigma_Quad&amp;#39;))
Inference for Stan model: fullModel2.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

            mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
alpha0     41.21    0.12 5.53 30.40 37.59 41.13 44.76 52.32  2302    1
alpha2     21.55    0.17 7.92  5.66 16.63 21.47 26.71 37.38  2167    1
alpha3     38.98    0.16 7.60 23.46 34.19 39.32 43.83 53.42  2249    1
sigma       7.29    0.02 0.61  6.19  6.86  7.25  7.67  8.59  1527    1
sigma_Site 11.26    0.08 3.03  6.67  9.13 10.87 12.93 18.76  1571    1
sigma_Quad  8.58    0.03 1.14  6.51  7.81  8.53  9.32 11.04  1656    1

Samples were drawn using NUTS(diag_e) at Wed Feb 19 18:59:26 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; data.nest1.rstan.f.df &amp;lt;-as.data.frame(extract(data.nest1.rstan.f))
&amp;gt; head(data.nest1.rstan.f.df)
    alpha0     alpha2   alpha3    sigma sigma_Site sigma_Quad      lp__
1 40.99894 18.4408136 42.31045 7.968007   8.827050   8.460864 -613.2249
2 53.13787  0.7837646 25.07146 7.354129  20.331472   7.205399 -607.1231
3 37.57365 19.9305037 39.18817 7.851311   6.937956   9.572309 -607.2551
4 44.25290 26.5530610 41.77012 7.238055  11.726263  10.298161 -608.2911
5 43.04766 30.5539155 30.54624 7.949620   9.587351   9.579669 -615.0313
6 45.62270 15.5490676 23.57169 7.407616  15.972144   7.886300 -610.6864&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;matrix-parameterisation-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Matrix parameterisation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; rstanString2=&amp;quot;
+ data{
+    int n;
+    int nSite;
+    int nQuad;
+    int nA;
+    vector [n] y;
+    matrix [n,nA] X;
+    int Site[n];
+    int Quad[n];
+    vector [nA] a0;
+    matrix [nA,nA] A0;
+ }
+ 
+ parameters{
+   vector [nA] alpha;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   vector [nSite] beta_Site;
+   real&amp;lt;lower=0&amp;gt; sigma_Site;
+   vector [nQuad] beta_Quad;
+   real&amp;lt;lower=0&amp;gt; sigma_Quad;
+ }
+  
+ model{
+     real mu[n];
+ 
+     // Priors
+     //alpha ~ normal( 0 , 100 );
+     alpha ~ multi_normal(a0,A0);
+     beta_Site ~ normal( 0 , sigma_Site );
+     sigma_Site ~ cauchy( 0 , 25);
+   beta_Quad ~ normal( 0 , sigma_Quad );
+     sigma_Quad ~ cauchy( 0 , 25);
+     sigma ~ cauchy( 0 , 25 );
+     
+     for ( i in 1:n ) {
+         mu[i] = dot_product(X[i],alpha) + beta_Site[Site[i]] + beta_Quad[Quad[i]];
+     }
+     y ~ normal( mu , sigma );
+ }
+ 
+ &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(rstanString2, con = &amp;quot;matrixModel2.stan&amp;quot;)
&amp;gt; 
&amp;gt; X &amp;lt;- model.matrix(~A, data.nest)
&amp;gt; nA &amp;lt;- ncol(X)
&amp;gt; data.nest.list &amp;lt;- with(data.nest1, list(y=y, X=X, Site=as.numeric(Sites),
+    Quad=as.numeric(Quads),
+    n=nrow(data.nest1), nSite=length(levels(Sites)),
+    nQuad=length(levels(Quads)),
+    nA=nA,
+    a0=rep(0,nA), A0=diag(100000,nA)))
&amp;gt; 
&amp;gt; params &amp;lt;- c(&amp;#39;alpha&amp;#39;,&amp;#39;sigma&amp;#39;,&amp;#39;sigma_Site&amp;#39;, &amp;#39;sigma_Quad&amp;#39;)
&amp;gt; burnInSteps = 3000
&amp;gt; nChains = 2
&amp;gt; numSavedSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; nIter = burnInSteps+ceiling((numSavedSteps * thinSteps)/nChains)
&amp;gt; 
&amp;gt; data.nest1.rstan.m2 &amp;lt;- stan(data = data.nest.list, file = &amp;quot;matrixModel2.stan&amp;quot;, chains = nChains, pars = params, iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;matrixModel2&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 1: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 1: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 1: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 1: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 1: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 1: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 1: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 1: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 1: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 1: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 1: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 10.174 seconds (Warm-up)
Chain 1:                14.97 seconds (Sampling)
Chain 1:                25.144 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;matrixModel2&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4500 [  0%]  (Warmup)
Chain 2: Iteration:  450 / 4500 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 4500 [ 20%]  (Warmup)
Chain 2: Iteration: 1350 / 4500 [ 30%]  (Warmup)
Chain 2: Iteration: 1800 / 4500 [ 40%]  (Warmup)
Chain 2: Iteration: 2250 / 4500 [ 50%]  (Warmup)
Chain 2: Iteration: 2700 / 4500 [ 60%]  (Warmup)
Chain 2: Iteration: 3001 / 4500 [ 66%]  (Sampling)
Chain 2: Iteration: 3450 / 4500 [ 76%]  (Sampling)
Chain 2: Iteration: 3900 / 4500 [ 86%]  (Sampling)
Chain 2: Iteration: 4350 / 4500 [ 96%]  (Sampling)
Chain 2: Iteration: 4500 / 4500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 13.182 seconds (Warm-up)
Chain 2:                10.54 seconds (Sampling)
Chain 2:                23.722 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.nest1.rstan.m2, par = c(&amp;#39;alpha&amp;#39;,&amp;#39;sigma&amp;#39;,&amp;#39;sigma_Site&amp;#39;, &amp;#39;sigma_Quad&amp;#39;))
Inference for Stan model: matrixModel2.
2 chains, each with iter=4500; warmup=3000; thin=1; 
post-warmup draws per chain=1500, total post-warmup draws=3000.

            mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
alpha[1]   41.39    0.13 5.70 30.15 37.79 41.38 44.91 52.83  1882    1
alpha[2]   21.32    0.17 7.96  5.50 16.25 21.52 26.33 36.79  2123    1
alpha[3]   39.34    0.17 7.90 23.39 34.35 39.23 44.45 54.87  2103    1
sigma       7.31    0.01 0.61  6.23  6.87  7.27  7.70  8.60  1917    1
sigma_Site 11.43    0.07 3.03  6.65  9.35 11.01 13.05 18.81  1720    1
sigma_Quad  8.54    0.03 1.13  6.44  7.76  8.52  9.28 10.89  1786    1

Samples were drawn using NUTS(diag_e) at Wed Feb 19 19:01:01 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; data.nest1.rstan.m2.df &amp;lt;-as.data.frame(extract(data.nest1.rstan.m2))
&amp;gt; head(data.nest1.rstan.m2.df)
   alpha.1  alpha.2  alpha.3    sigma sigma_Site sigma_Quad      lp__
1 44.95385 11.48209 37.04594 7.045977  17.024677  10.216341 -616.7436
2 34.74513 32.79135 44.50707 7.688600   9.246435   8.342615 -604.2742
3 39.99199 21.01827 41.38576 7.014567  13.747544  10.353393 -606.2766
4 41.24520 30.12204 36.86309 6.652121  10.653882   8.080439 -588.9044
5 47.31591 14.78743 29.89851 6.686367   8.986245   9.646120 -610.5245
6 41.36124 16.08883 34.86754 6.258581  12.465772  10.688584 -606.7448&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-gelman2015stan&#34;&gt;
&lt;p&gt;Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt; 40 (5): 530–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2006prior&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2006. “Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by Browne and Draper).” &lt;em&gt;Bayesian Analysis&lt;/em&gt; 1 (3): 515–34.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanpackage&#34;&gt;
&lt;p&gt;Stan Development Team. 2018. “RStan: The R Interface to Stan.” &lt;a href=&#34;http://mc-stan.org/&#34;&gt;http://mc-stan.org/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Factorial Analysis of Variance - JAGS</title>
      <link>/jags/factorial-anova-jags/factorial-anova-jags/</link>
      <pubDate>Thu, 06 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/factorial-anova-jags/factorial-anova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Factorial designs are an extension of single factor ANOVA designs in which additional factors are added such that each level of one factor is applied to all levels of the other factor(s) and these combinations are replicated. For example, we might design an experiment in which the effects of temperature (high vs low) and fertiliser (added vs not added) on the growth rate of seedlings are investigated by growing seedlings under the different temperature and fertilizer combinations. In addition to investigating the impacts of the main factors, factorial designs allow us to investigate whether the effects of one factor are consistent across levels of another factor. For example, is the effect of temperature on growth rate the same for both fertilised and unfertilized seedlings and similarly, does the impact of fertiliser treatment depend on the temperature under which the seedlings are grown?&lt;/p&gt;
&lt;p&gt;Arguably, these interactions give more sophisticated insights into the dynamics of the system we are investigating. Hence, we could add additional main effects, such as soil pH, amount of water, etc, along with all the two way (temp:fert, temp:pH, temp:water, etc), three-way (temp:fert:pH, temp:pH:water), four-way (and so on) interactions in order to explore how these various factors interact with one another to effect the response. However, the more interactions, the more complex the model becomes to specify, compute and interpret - not to mention the rate at which the number of required observations increases. Factorial designs can consist:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;entirely of crossed fixed factors (&lt;strong&gt;Model I ANOVA&lt;/strong&gt; - most common) in which conclusions are restricted to the specific combinations of levels selected for the experiment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;entirely of crossed random factors (&lt;strong&gt;Model II ANOVA&lt;/strong&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;a mixture of crossed fixed and random factors (&lt;strong&gt;Model III ANOVA&lt;/strong&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The latter are useful for investigating the generality of a main treatment effect (fixed) over broad spatial, temporal or clinical levels of organisation. That is whether the observed effects of temperature and/or fertiliser (for example) are observed across the entire genera or country.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear model&lt;/h2&gt;
&lt;p&gt;As with single factor ANOVA, the linear model could be constructed as either effects or means parameterisation, although only effects parameterisation will be considered here. The linear models for two and three factor design are&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \epsilon_{ijk},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_j + \gamma_k + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \epsilon_{ijkl},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the effect of Factor A, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of Factor B, &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the effect of Factor C and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component. Note that although the linear models for Model I, Model II and Model III designs are identical, the interpretation of terms (and thus null hypothesis) differ. Recall from the tutorial on single factor ANOVA, that categorical variables in linear models are actually re-parameterised dummy codes - and thus the &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; term above, actually represents one or more dummy codes. Thus, if we actually had two levels of Factor A (A1 and A2) and three levels of Factor B (B1, B2, B3), then the fully parameterised linear model would be:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y=\beta_{A1B1}+\beta_{A2B1−A1B1}+\beta_{A1B2−A1B1}+\beta_{A1B3−A1B1}+\beta_{A2B2−A1B2−A2B1−A1B1}+\beta_{A2B3−A1B3−A2B1−A1B1}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thus, such a model would have six parameters to estimate (in addition to the variance).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis&lt;/h2&gt;
&lt;p&gt;There are separate null hypothesis associated with each of the main effects and the interaction terms.&lt;/p&gt;
&lt;div id=&#34;model-1---fixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 1 - fixed effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Factor A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to an overall mean. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the overall mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The effect of each group equals zero. If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), the null hypothesis is rejected indicating that the treatment has been found to affect the response variable. Note, as with multiple regression models, these “effects” represent &lt;em&gt;partial effects&lt;/em&gt;. In the above, the effect of Factor A is actually the effect of Factor A at the first level of the Factor(s).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal - at the first level of Factor A. Equivalent interpretation to Factor A above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\mu_{ij}=\mu_i+\mu_j-\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. For any given combination of factor levels, the population group mean will be equal to the difference between the overall population mean and the simple additive effects of the individual factor group means. That is, the effects of the main treatment factors are purely additive and independent of one another. This is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(H_0(AB): \alpha\beta_{ij}=0\)&lt;/span&gt;, no interaction between Factor A and Factor B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-2---random-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 2 - random effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Factor A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\sigma^2_{\alpha}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of A.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\sigma^2_{\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of B.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\sigma^2_{\alpha\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is no added variance due to all possible interactions between all possible levels of A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-3---mixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 3 - mixed effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Fixed factor - e.g. A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (pooled over all levels of the random factor) is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to an overall mean pooling over all possible levels of the random factor. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the overall mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;No effect of any level of this factor pooled over all possible levels of the random factor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Random factor - e.g. B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\sigma^2_{\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of B.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The interaction of a fixed and random factor is always considered a random factor.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\sigma^2_{\alpha\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible interactions between all possible levels of A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;When fixed factorial designs are balanced, the total variance in the response variable can be sequentially partitioned into what is explained by each of the model terms (factors and their interactions) and what is left unexplained. For each of the specific null hypotheses, the overall unexplained variability is used as the denominator in F-ratio calculations, and when a null hypothesis is true, an F-ratio should follow an F distribution with an expected value less than &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;. Random factors are added to provide greater generality of conclusions. That is, to enable us to make conclusions about the effect of one factor (such as whether or not fertiliser is added) over all possible levels (not just those sampled) of a random factor (such as all possible locations, seasons, varieties, etc). In order to expand our conclusions beyond the specific levels used in the design, the hypothesis tests (and thus F-ratios) must reflect this extra generality by being more conservative.&lt;/p&gt;
&lt;p&gt;The appropriate F-ratios for fixed, random and mixed factorial designs are presented below. Generally, once the terms (factors and interactions) have been ordered into a hierarchy (single factors at the top, highest level interactions at the bottom and terms of same order given equivalent positions in the hierarchy), the denominator for any term is selected as the next appropriate random term (an interaction that includes the term to be tested) encountered lower in the hierarchy. Interaction terms that contain one or more random factors are considered themselves to be random terms, as is the overall residual term (as all observations are assumed to be random representations of the entire population(s)). Note, when designs include a mixture of fixed and random crossed effects, exact denominator degrees of freedoms for certain F-ratios are undefined and traditional approaches adopt rather inexact estimated approximate or “Quasi” F-ratios. Pooling of non-significant F-ratio denominator terms, in which lower random terms are added to the denominator (provided &lt;span class=&#34;math inline&#34;&gt;\(\alpha &amp;gt; 0.25\)&lt;/span&gt;), may also be useful. For random factors within mixed models, selecting F-ratio denominators that are appropriate for the intended hypothesis tests is a particularly complex and controversial issue. Traditionally, there are two alternative approaches and whilst the statistical resumes of each are complicated, essentially they differ in whether or not the interaction term is constrained for the test of the random factor.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;constrained or restricted method&lt;/em&gt; (&lt;strong&gt;Model I&lt;/strong&gt;), stipulates that for the calculation of a random factor F-ratio (which investigates the added variance added due to the random factor), the overall effect of the interaction is treated as zero. Consequently, the random factor is tested against the residual term. The &lt;em&gt;unconstrained or unrestrained method&lt;/em&gt; (&lt;strong&gt;Model II&lt;/strong&gt;) however, does not set the interaction effect to zero and therefore the interaction term is used as the random factor F-ratio denominator. This method assumes that the interaction terms for each level of the random factor are completely independent (correlations between the fixed factor must be consistent across all levels of the random factor). Some statisticians maintain that the independence of the interaction term is difficult to assess for clinical data and therefore, the restricted approach is more appropriate. However, others have suggested that the restricted method is only appropriate for balanced designs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quasi-f-ratios&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quasi F-ratios&lt;/h2&gt;
&lt;p&gt;An additional complication for three or more factor models that contain two or more random factors, is that there may not be a single appropriate interaction term to use as the denominator for many of the main effects F-ratios. For example, if Factors A and B are random and C is fixed, then there are two random interaction terms of equivalent level under Factor C (&lt;span class=&#34;math inline&#34;&gt;\(A^\prime \times C\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B^\prime \times C\)&lt;/span&gt;). As a result, the value of the of the &lt;em&gt;Mean Squares&lt;/em&gt; (MS) expected when the null hypothesis is true cannot be easily defined. The solutions for dealing with such situations (&lt;em&gt;quasi F-ratios&lt;/em&gt;) involve adding (and subtracting) terms together to create approximate estimates of F-ratio denominators. Alternatively, for random factors, variance components with confidence intervals can be used. These solutions are sufficiently unsatisfying as to lead many statisticians to recommend that factorial designs with two or more random factors should avoided if possible. Arguably however, linear mixed effects models offer more appropriate solutions to the above issues as they are more robust for unbalanced designs, accommodate covariates and provide a more comprehensive treatment and overview of all the underlying data structures.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; fact_anova_table
    df           MS       A,B fixed          A,B random       
A   &amp;quot;a-1&amp;quot;        &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;  &amp;quot;(MS A)/(MS AB)&amp;quot; 
B   &amp;quot;b-1&amp;quot;        &amp;quot;MS B&amp;quot;   &amp;quot;(MS B)/(MS res)&amp;quot;  &amp;quot;(MS B)/(MS AB)&amp;quot; 
AB  &amp;quot;(b-1)(a-1)&amp;quot; &amp;quot;MS AB&amp;quot;  &amp;quot;(MS AB)/(MS res)&amp;quot; &amp;quot;(MS AB)/(MS AB)&amp;quot;
Res &amp;quot;(n-1)ba&amp;quot;    &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;                 &amp;quot;&amp;quot;               
    A fixed B random (model I) A fixed B random (model II)
A   &amp;quot;(MS A)/(MS AB)&amp;quot;           &amp;quot;(MS A)/(MS AB)&amp;quot;           
B   &amp;quot;(MS B)/(MS res)&amp;quot;          &amp;quot;(MS B)/(MS AB)&amp;quot;           
AB  &amp;quot;(MS AB)/(MS res)&amp;quot;         &amp;quot;(MS AB)/(MS res)&amp;quot;         
Res &amp;quot;&amp;quot;                         &amp;quot;&amp;quot;                         &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The corresponding &lt;code&gt;R&lt;/code&gt; syntax is given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Type I SS (Balanced)
&amp;gt; anova(lm(y ~ A * B, data))
&amp;gt; 
&amp;gt; #Type II SS (Unbalanced)
&amp;gt; Anova(lm(y ~ A * B, data), type = &amp;quot;II&amp;quot;)
&amp;gt; 
&amp;gt; #Type III SS (Unbalanced)
&amp;gt; Anova(lm(y ~ A * B, data), type = &amp;quot;III&amp;quot;)
&amp;gt; 
&amp;gt; #Variance components
&amp;gt; summary(lmer(y ~ 1 + (1 | A) + (1 | B) + (1 | A:B), data))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that for fixed factor models, when null hypotheses of interactions are rejected, the null hypothesis of the individual constituent factors are unlikely to represent the true nature of the effects and thus are of little value. The nature of such interactions are further explored by fitting simpler linear models (containing at least one less factor) separately for each of the levels of the other removed factor(s). Such &lt;em&gt;Main effects&lt;/em&gt; tests are based on a subset of the data, and therefore estimates of the overall residual (unexplained) variability are unlikely to be as precise as the estimates based on the global model. Consequently, F-ratios involving &lt;code&gt;MSResid&lt;/code&gt; should use the estimate of &lt;code&gt;MSResid&lt;/code&gt; from the global model rather than that based on the smaller, theoretically less precise subset of data. For random and mixed models, since the objective is to generalise the effect of one factor over and above any interactions with other factors, the main factor effects can be interpreted even in the presence of significant interactions. Nevertheless, it should be noted that when a significant interaction is present in a mixed model, the power of the main fixed effects will be reduced (since the amount of variability explained by the interaction term will be relatively high, and this term is used as the denominator for the F-ratio calculation).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;Hypothesis tests assume that the residuals are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator (see table above) should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;independent of one another.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Planned and unplanned comparisons&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As with single factor analysis of variance, planned and unplanned multiple comparisons (such as &lt;em&gt;Tukey&lt;/em&gt;’s test) can be incorporated into or follow the linear model respectively so as to further investigate any patterns or trends within the main factors and/or the interactions. As with single factor analysis of variance, the contrasts must be defined prior to fitting the linear model, and no more than &lt;span class=&#34;math inline&#34;&gt;\(p−1\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the number of levels of the factor) contrasts can be defined for a factor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Unbalanced designs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A factorial design can be thought of as a table made up of rows (representing the levels of one factor), columns (levels of another factor), and cells (the individual combinations of the set of factors). Whilst the middle left table does not have equal sample sizes in each cell, the sample sizes are in proportion and as such, does not present the issues discussed below for unbalanced designs.&lt;/p&gt;
&lt;p&gt;In addition to impacting on normality and homogeneity of variance, unequal sample sizes in factorial designs have major implications for the partitioning of the total sums of squares into each of the model components. For balanced designs, the total sums of squares (&lt;code&gt;SSTotal&lt;/code&gt;) is equal to the additive sums of squares of each of the components (including the residual). For example, in a two factor balanced design, &lt;code&gt;SSTotal=SSA+SSB+SSAB+SSResid&lt;/code&gt;. This can be represented diagrammatically by a &lt;em&gt;Venn Diagram&lt;/em&gt; in which each of the &lt;code&gt;SS&lt;/code&gt; for the term components butt against one another and are surrounded by the &lt;code&gt;SSResid&lt;/code&gt;. However, in unbalanced designs, the sums of squares will be non-orthogonal and the sum of the individual components does not add up to the total sums of squares. Diagrammatically, the &lt;code&gt;SS&lt;/code&gt; of the terms intersect or are separated.&lt;/p&gt;
&lt;p&gt;In regular &lt;em&gt;sequential sums of squares&lt;/em&gt; (&lt;strong&gt;Type I SS&lt;/strong&gt;), the sum of the individual sums of squares must be equal to the total sums of squares, the sums of squares of the last factor to be estimated will be calculated as the difference between the total sums of squares and what has already been accounted for by other components. Consequently, the order in which factors are specified in the model (and thus estimated) will alter their sums of squares and therefore their F-ratios. To overcome this problem, traditionally there are two other alternative methods of calculating sums of squares.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Type II (hierarchical) SS&lt;/strong&gt; estimate the sums of squares of each term as the improvement it contributes upon addition of that term to a model of greater complexity and lower in the hierarchy (recall that the hierarchical structure descends from the simplest model down to the fully populated model). The SS for the interaction as well as the first factor to be estimated are the same as for Type I SS. Type II SS estimate the contribution of a factor over and above the contributions of other factors of equal or lower complexity but not above the contributions of the interaction terms or terms nested within the factor. However, these sums of squares are weighted by the sample sizes of each level and therefore are biased towards the trends produced by the groups (levels) that have higher sample sizes. As a result of the weightings, Type II SS actually test hypotheses about really quite complex combinations of factor levels. Rather than test a hypothesis that &lt;span class=&#34;math inline&#34;&gt;\(\mu_{High}=\mu_{Medium}=\mu_{Low}\)&lt;/span&gt;, Type II SS might be testing that &lt;span class=&#34;math inline&#34;&gt;\(4\times\mu_{High}=1\times\mu_{Medium}=0.25\times\mu_{Low}\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Type III (marginal or orthogonal) SS&lt;/strong&gt; estimate the sums of squares of each term as the improvement based on a comparison of models with and without the term and are unweighted by sample sizes. Type III SS essentially measure just the unique contribution of each factor over and above the contributions of the other factors and interactions. For unbalanced designs,Type III SS essentially test equivalent hypotheses to balanced Type I SS and are therefore arguably more appropriate for unbalanced factorial designs than Type II SS. Importantly, Type III SS are only interpretable if they are based on orthogonal contrasts (such as sum or helmert contrasts and not treatment contrasts).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The choice between Type II and III SS clearly depends on the nature of the question. For example, if we had measured the growth rate of seedlings subjected to two factors (temperature and fertiliser), Type II SS could address whether there was an effect of temperature across the level of fertiliser treatment, whereas Type III SS could assess whether there was an effect of temperature within each level of the fertiliser treatment.&lt;/p&gt;
&lt;p&gt;When an entire combination, or cell, is missing (perhaps due to unforeseen circumstances) it is not possible to test all the main effects and/or interactions. The bottom right table above depicts such as situation. One solution is to fit a large single factor ANOVA with as many levels as there are cells (this is known as a cell means model) and investigate various factor and interaction effects via specific contrasts (see the following tables). Difficulties in establishing appropriate error terms, makes missing cells in random and mixed factor designs substantially more complex.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Imagine we has designed an experiment in which we had measured the response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) under a combination of two different potential influences (Factor A: levels a1 and a2; and Factor B: levels b1, b2 and b3), each combination replicated &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; times (&lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; nA &amp;lt;- 2  #number of levels of A
&amp;gt; nB &amp;lt;- 3  #number of levels of B
&amp;gt; nsample &amp;lt;- 10  #number of reps in each
&amp;gt; A &amp;lt;- gl(nA, 1, nA, lab = paste(&amp;quot;a&amp;quot;, 1:nA, sep = &amp;quot;&amp;quot;))
&amp;gt; B &amp;lt;- gl(nB, 1, nB, lab = paste(&amp;quot;b&amp;quot;, 1:nB, sep = &amp;quot;&amp;quot;))
&amp;gt; data &amp;lt;- expand.grid(A = A, B = B, n = 1:nsample)
&amp;gt; X &amp;lt;- model.matrix(~A * B, data = data)
&amp;gt; eff &amp;lt;- c(40, 15, 5, 0, -15, 10)
&amp;gt; sigma &amp;lt;- 3  #residual standard deviation
&amp;gt; n &amp;lt;- nrow(data)
&amp;gt; eps &amp;lt;- rnorm(n, 0, sigma)  #residuals
&amp;gt; data$y &amp;lt;- as.numeric(X %*% eff + eps)
&amp;gt; head(data)  #print out the first six rows of the data set
   A  B n        y
1 a1 b1 1 38.31857
2 a2 b1 1 54.30947
3 a1 b2 1 49.67612
4 a2 b2 1 45.21153
5 a1 b3 1 40.38786
6 a2 b3 1 70.14519
&amp;gt; 
&amp;gt; with(data, interaction.plot(A, B, y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/generate_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ## ALTERNATIVELY, we could supply the population means and get the effect parameters from these.  To
&amp;gt; ## correspond to the model matrix, enter the population means in the order of: a1b1, a2b1, a1b1,
&amp;gt; ## a2b2,a1b3,a2b3
&amp;gt; pop.means &amp;lt;- as.matrix(c(40, 55, 45, 45, 40, 65), byrow = F)
&amp;gt; ## Generate a minimum model matrix for the effects
&amp;gt; XX &amp;lt;- model.matrix(~A * B, expand.grid(A = factor(1:2), B = factor(1:3)))
&amp;gt; ## Use the solve() function to solve what are effectively simultaneous equations
&amp;gt; (eff &amp;lt;- as.vector(solve(XX, pop.means)))
[1]  40  15   5   0 -15  10
&amp;gt; 
&amp;gt; data$y &amp;lt;- as.numeric(X %*% eff + eps)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type. Does treatment type effect the response?.&lt;/p&gt;
&lt;div id=&#34;assumptions-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;The assumptions are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All of the observations are independent - this must be addressed at the design and collection stages. Importantly, to be considered independent replicates, the replicates must be made at the same scale at which the treatment is applied. For example, if the experiment involves subjecting organisms housed in tanks to different water temperatures, then the unit of replication is the individual tanks not the individual organisms in the tanks. The individuals in a tank are strictly not independent with respect to the treatment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (and thus the residuals) should be normally distributed for each sampled populations (combination of factors). Boxplots of each treatment combination are useful for diagnosing major issues with normality.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately) for each combination of treatments. Again, boxplots are useful.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ A * B, data)
&amp;gt; 
&amp;gt; # OR via ggplot2
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = y, x = A, fill = B)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/exp1_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity&lt;/p&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X \boldsymbol \beta\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; represents the intercept associated with the first combination of groups, as well as the (effects) differences between this intercept and each other group. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X\)&lt;/span&gt; is the model matrix. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. Exploratory data analysis suggests that the intercept and effects could be drawn from similar distributions (with mean in the &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;’s and variances in the &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;’s). Whilst we might therefore be tempted to provide different priors for the intercept, compared to the effects, for a simple model such as this, it is unlikely to be necessary. However, for more complex models, where prior specification becomes more critical, separate priors would probably be necessary.&lt;/p&gt;
&lt;p&gt;We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Note the following example as group means calculated as derived posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau)
+   mean[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   #Priors
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) 
+   }
+   sigma ~ dunif(0, 100)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;fact_anovaModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X &amp;lt;- model.matrix(~A * B, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = X, n = nrow(data), ngroups = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;fact_anovaModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 60
   Unobserved stochastic nodes: 7
   Total graph size: 502

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;fact_anovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.187   0.927  38.381  39.572  40.186  40.810  42.028 1.001 15000
beta[2]   14.739   1.297  12.177  13.875  14.741  15.611  17.281 1.001 15000
beta[3]    4.997   1.301   2.439   4.127   4.996   5.850   7.555 1.001  6200
beta[4]   -0.335   1.302  -2.922  -1.201  -0.323   0.523   2.182 1.001  9300
beta[5]  -14.551   1.831 -18.188 -15.752 -14.535 -13.331 -10.976 1.001 15000
beta[6]   11.081   1.823   7.514   9.859  11.073  12.288  14.680 1.001 15000
sigma      2.909   0.286   2.410   2.707   2.886   3.092   3.525 1.001  3100
deviance 296.719   4.003 290.996 293.788 296.037 298.923 306.334 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 8.0 and DIC = 304.7
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Trace plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters (such as &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;s).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3895  3746         1.040     
 beta[2]  2        3649  3746         0.974     
 beta[3]  2        3981  3746         1.060     
 beta[4]  2        3811  3746         1.020     
 beta[5]  2        3855  3746         1.030     
 beta[6]  2        3770  3746         1.010     
 deviance 2        3981  3746         1.060     
 sigma    4        5074  3746         1.350     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3729  3746         0.995     
 beta[2]  2        3853  3746         1.030     
 beta[3]  2        3649  3746         0.974     
 beta[4]  2        3770  3746         1.010     
 beta[5]  2        3853  3746         1.030     
 beta[6]  2        3770  3746         1.010     
 deviance 2        3649  3746         0.974     
 sigma    4        5366  3746         1.430     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
            beta[1]      beta[2]       beta[3]      beta[4]      beta[5]
Lag 0   1.000000000  1.000000000  1.0000000000  1.000000000  1.000000000
Lag 1  -0.002519333  0.009718890  0.0097211169  0.004831644  0.013455394
Lag 5  -0.004466196  0.013453425  0.0012166509 -0.009459535  0.010837730
Lag 10 -0.006418970 -0.004825081  0.0002148708 -0.003297864 -0.004528907
Lag 50  0.004241571  0.010613172 -0.0056258926 -0.002886136 -0.003130607
            beta[6]     deviance        sigma
Lag 0   1.000000000  1.000000000  1.000000000
Lag 1   0.004411377  0.194295905  0.335565370
Lag 5   0.004680461  0.011707557  0.003364317
Lag 10 -0.012377072  0.006873975  0.005557072
Lag 50  0.003484518 -0.008999031 -0.012155151&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.&lt;/p&gt;
&lt;p&gt;There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Standardised residuals&lt;/strong&gt;. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Studentised residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the residuals. Note that &lt;strong&gt;externally studentised residuals&lt;/strong&gt; are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pearson residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%) back thereby allowing us to train the model on &lt;span class=&#34;math inline&#34;&gt;\(75\)&lt;/span&gt;% of the data and then see how well the model can predict the withheld &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.&lt;/p&gt;
&lt;p&gt;Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within &lt;code&gt;JAGS&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; wch
[1] 1 2 3 4 5 6
&amp;gt; 
&amp;gt; head(mcmc)
      beta[1]  beta[2]  beta[3]     beta[4]   beta[5]  beta[6] deviance
[1,] 41.07993 14.73872 4.532543 -1.58279310 -14.91723 11.28780 292.8658
[2,] 40.30651 13.02455 4.475566 -0.86754574 -12.02942 13.36371 295.1239
[3,] 40.42144 14.71551 5.149725  0.09616707 -14.80497 10.82830 290.7322
[4,] 39.79269 16.35682 5.776724 -0.53251753 -17.64694 10.59484 295.1674
[5,] 39.40269 14.69470 5.237430 -0.29022676 -14.12951 12.81751 293.3136
[6,] 41.27115 12.58706 5.908648 -2.34899624 -13.31913 13.79862 302.0972
        sigma
[1,] 3.032059
[2,] 2.467221
[3,] 2.874167
[4,] 2.561227
[5,] 2.841503
[6,] 3.403891
&amp;gt; 
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; library(tidyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; print(coefs)
    beta[1]     beta[2]     beta[3]     beta[4]     beta[5]     beta[6] 
 40.1859804  14.7407405   4.9960673  -0.3233121 -14.5348136  11.0732139 
&amp;gt;  
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = B)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; #generate a model matrix
&amp;gt; Xmat = model.matrix(~A*B, data)
&amp;gt; ##get median parameter estimates
&amp;gt; coefs = mcmc[,wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,], mcmc[i, &amp;#39;sigma&amp;#39;]))
&amp;gt; newdata = data.frame(A=data$A, B=data$B, yRep) %&amp;gt;% gather(key=Sample, value=Value,-A,-B)
&amp;gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=A, fill=&amp;#39;Model&amp;#39;), alpha=0.5)+
+  geom_violin(data=data, aes(y=y,x=A,fill=&amp;#39;Obs&amp;#39;), alpha=0.5) +
+  geom_point(data=data, aes(y=y, x=A), position=position_jitter(width=0.1,height=0),
+             color=&amp;#39;black&amp;#39;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=B, fill=&amp;#39;Model&amp;#39;, group=B, color=A), alpha=0.5)+
+  geom_point(data=data, aes(y=y, x=B, group=B,color=A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;fact_anovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.187   0.927  38.381  39.572  40.186  40.810  42.028 1.001 15000
beta[2]   14.739   1.297  12.177  13.875  14.741  15.611  17.281 1.001 15000
beta[3]    4.997   1.301   2.439   4.127   4.996   5.850   7.555 1.001  6200
beta[4]   -0.335   1.302  -2.922  -1.201  -0.323   0.523   2.182 1.001  9300
beta[5]  -14.551   1.831 -18.188 -15.752 -14.535 -13.331 -10.976 1.001 15000
beta[6]   11.081   1.823   7.514   9.859  11.073  12.288  14.680 1.001 15000
sigma      2.909   0.286   2.410   2.707   2.886   3.092   3.525 1.001  3100
deviance 296.719   4.003 290.996 293.788 296.037 298.923 306.334 1.001  3000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 8.0 and DIC = 304.7
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 8 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    40.2       0.927    38.4      42.0 
2 beta[2]    14.7       1.30     12.2      17.3 
3 beta[3]     5.00      1.30      2.43      7.55
4 beta[4]    -0.335     1.30     -2.89      2.21
5 beta[5]   -14.6       1.83    -18.2     -11.0 
6 beta[6]    11.1       1.82      7.57     14.7 
7 deviance  297.        4.00    290.      304.  
8 sigma       2.91      0.286     2.37      3.47&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The intercept represents the mean of the first combination Aa1:Bb1 is &lt;span class=&#34;math inline&#34;&gt;\(40.2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb1 is &lt;span class=&#34;math inline&#34;&gt;\(14.7\)&lt;/span&gt; units greater than Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa1:Bb2 is &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; units greater Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa1:Bb3 is &lt;span class=&#34;math inline&#34;&gt;\(-0.335\)&lt;/span&gt; units greater Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb2 is &lt;span class=&#34;math inline&#34;&gt;\(-14.6\)&lt;/span&gt; units greater than the difference between (Aa1:Bb2 + Aa2:Bb1) and (2*Aa1:Bb1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb3 is &lt;span class=&#34;math inline&#34;&gt;\(11.1\)&lt;/span&gt; units greater than the difference between (Aa1:Bb3 + Aa2:Bb1) and (2*Aa1:Bb1)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility interval for both interactive effects (Aa2:Bb2 and Aa2:Bb3) do not contain &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, implying significant interactions between A and B. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])
[1] 0.0004666667
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[4]&amp;quot;])
[1] 0.7912667
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[5]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[6]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, c(&amp;quot;beta[5]&amp;quot;, &amp;quot;beta[6]&amp;quot;)])
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence of an interaction between A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = expand.grid(A=levels(data$A), B=levels(data$B))
&amp;gt; Xmat = model.matrix(~A*B,newdata)
&amp;gt; coefs = mcmc[,wch]
&amp;gt; fit=coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int=TRUE, conf.method=&amp;#39;HPDinterval&amp;#39;))
&amp;gt; newdata
   A  B estimate std.error conf.low conf.high
1 a1 b1 40.18727 0.9270982 38.38136  42.02744
2 a2 b1 54.92636 0.9160115 53.12047  56.67452
3 a1 b2 45.18473 0.9196740 43.37733  46.98224
4 a2 b2 45.37262 0.9197287 43.61538  47.19883
5 a1 b3 39.85206 0.9156380 38.11053  41.70144
6 a2 b3 65.67189 0.9209489 63.84038  67.47931
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y=estimate, x=B, fill=A)) +
+  geom_blank() +
+  geom_line(aes(x=as.numeric(B), linetype=A)) +
+  geom_linerange(aes(ymin=conf.low, ymax=conf.high))+
+  geom_point(aes(shape=A), size=3)+
+  scale_y_continuous(&amp;#39;Y&amp;#39;)+
+  scale_x_discrete(&amp;#39;B&amp;#39;)+
+  scale_shape_manual(&amp;#39;A&amp;#39;,values=c(21,16))+
+  scale_fill_manual(&amp;#39;A&amp;#39;,values=c(&amp;#39;white&amp;#39;,&amp;#39;black&amp;#39;))+
+  scale_linetype_manual(&amp;#39;A&amp;#39;,values=c(&amp;#39;solid&amp;#39;,&amp;#39;dashed&amp;#39;))+
+  theme_classic() +
+  theme(legend.justification=c(0,1), legend.position=c(0.05,1),
+   axis.title.y=element_text(vjust=2, size=rel(1.25)),
+   axis.title.x=element_text(vjust=-2, size=rel(1.25)),
+   plot.margin=unit(c(0.5,0.5,2,2), &amp;#39;lines&amp;#39;),
+   legend.key.size=unit(1,&amp;#39;cm&amp;#39;)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A        10.4     0.917      8.65     12.3 
2 sd.B         3.06    0.640      1.79      4.28
3 sd.AB       10.4     0.734      9.04     11.9 
4 sd.resid     2.84    0.0836     2.72      3.00
# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A         39.1     1.95     35.2       42.8
2 sd.B         11.4     1.90      7.60      15.0
3 sd.AB        39.0     0.947    37.0       40.8
4 sd.resid     10.6     0.822     9.30      12.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/factorial-anova-jags/2020-02-01-factorial-anova-jags_files/figure-html/eff_pop1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(39\)&lt;/span&gt;% of the total finite population standard deviation is due to the interaction between factor A and factor B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; Xmat = model.matrix(~A * B, data)
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.913   0.00817    0.897     0.925
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ A * B, data))

Call:
lm(formula = y ~ A * B, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5694 -1.8517 -0.0589  1.7120  6.5966 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.1940     0.8980  44.760  &amp;lt; 2e-16 ***
Aa2          14.7163     1.2700  11.588 2.88e-16 ***
Bb2           4.9823     1.2700   3.923 0.000249 ***
Bb3          -0.3464     1.2700  -0.273 0.786077    
Aa2:Bb2     -14.5093     1.7960  -8.079 7.37e-11 ***
Aa2:Bb3      11.1056     1.7960   6.184 8.65e-08 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 2.84 on 54 degrees of freedom
Multiple R-squared:   0.92, Adjusted R-squared:  0.9125 
F-statistic: 124.1 on 5 and 54 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dealing-with-interactions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dealing with interactions&lt;/h1&gt;
&lt;p&gt;In the presence of interations, conclusions about the main effects are overly simplistic at best and completely inaccurate at worst. Therefore, in the presense of interactions we should attempt to tease the analysis appart a little. In the current working example, we have identified that there is a significant interaction between Factor A and Factor B. Our exploration of the regression coefficients, indicated that the pattern between b1, b2 and b3 might differ between a1 and a2. Similarly, if we consider the coefficients from the perspective of Factor A, we can see that the patterns between a1 and a2 are similar for b1 and b3, yet very different for b2.&lt;/p&gt;
&lt;p&gt;At this point, we can then split the two-factor model up into a series of single-factor models, either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;examining the effects of Factor B separately for each level of Factor A (two single-factor models) or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;examining the effects of Factor A separately for each level of Factor B (three single-factor models)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, rather than subset the data and fit isolated smaller models, it is arguably better to treat these explorations as contrasts. As such we could either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;apply specific contrasts to the already fit model&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;define the specific contrasts and use them to refit the model&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will do the former of these options since we have already fit the global model. For this demonstration, we will explore the effect of factor A at each level of factor B. I will illustrate two ways to perform these contrasts on an already fit model:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&amp;gt; Xmat = model.matrix(~A * B, data = newdata)
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; head(fit)
            1        2        3        4        5        6
[1,] 41.07993 55.81865 45.61247 45.43397 39.49714 65.52366
[2,] 40.30651 53.33106 44.78207 45.77720 39.43896 65.82722
[3,] 40.42144 55.13695 45.57116 45.48170 40.51761 66.06142
[4,] 39.79269 56.14951 45.56942 44.27930 39.26017 66.21183
[5,] 39.40269 54.09738 44.64012 45.20530 39.11246 66.62467
[6,] 41.27115 53.85821 47.17980 46.44773 38.92215 65.30783
&amp;gt; 
&amp;gt; ## we want to compare columns 2-1, 4-3 and 6-5
&amp;gt; comps = fit[, c(2, 4, 6)] - fit[, c(1, 3, 5)]
&amp;gt; tidyMCMC(comps, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 3 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2       14.7        1.30    12.2      17.3 
2 4        0.188      1.30    -2.30      2.83
3 6       25.8        1.30    23.2      28.4 &lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&amp;gt; Xmat = model.matrix(~A * B, data = newdata)
&amp;gt; contr = attr(Xmat, &amp;quot;contrasts&amp;quot;)
&amp;gt; newdata.a1 = model.frame(~A * B, expand.grid(A = levels(data$A)[1], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&amp;gt; Xmat.a1 = model.matrix(~A * B, data = newdata.a1, contrasts = contr)
&amp;gt; newdata.a2 = model.frame(~A * B, expand.grid(A = levels(data$A)[2], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&amp;gt; Xmat.a2 = model.matrix(~A * B, data = newdata.a2, contrasts = contr)
&amp;gt; Xmat = Xmat.a2 - Xmat.a1
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 3 x 4
  estimate std.error conf.low conf.high
     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1   14.7        1.30    12.2      17.3 
2    0.188      1.30    -2.30      2.83
3   25.8        1.30    23.2      28.4 &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Factorial Analysis of Variance - STAN</title>
      <link>/stan/factorial-anova-stan/factorial-anova-stan/</link>
      <pubDate>Thu, 06 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/stan/factorial-anova-stan/factorial-anova-stan/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;STAN&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman, Lee, and Guo (2015)&lt;/span&gt;) using the package &lt;code&gt;rstan&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Stan Development Team (2018)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Factorial designs are an extension of single factor ANOVA designs in which additional factors are added such that each level of one factor is applied to all levels of the other factor(s) and these combinations are replicated. For example, we might design an experiment in which the effects of temperature (high vs low) and fertiliser (added vs not added) on the growth rate of seedlings are investigated by growing seedlings under the different temperature and fertilizer combinations. In addition to investigating the impacts of the main factors, factorial designs allow us to investigate whether the effects of one factor are consistent across levels of another factor. For example, is the effect of temperature on growth rate the same for both fertilised and unfertilized seedlings and similarly, does the impact of fertiliser treatment depend on the temperature under which the seedlings are grown?&lt;/p&gt;
&lt;p&gt;Arguably, these interactions give more sophisticated insights into the dynamics of the system we are investigating. Hence, we could add additional main effects, such as soil pH, amount of water, etc, along with all the two way (temp:fert, temp:pH, temp:water, etc), three-way (temp:fert:pH, temp:pH:water), four-way (and so on) interactions in order to explore how these various factors interact with one another to effect the response. However, the more interactions, the more complex the model becomes to specify, compute and interpret - not to mention the rate at which the number of required observations increases. Factorial designs can consist:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;entirely of crossed fixed factors (&lt;strong&gt;Model I ANOVA&lt;/strong&gt; - most common) in which conclusions are restricted to the specific combinations of levels selected for the experiment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;entirely of crossed random factors (&lt;strong&gt;Model II ANOVA&lt;/strong&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;a mixture of crossed fixed and random factors (&lt;strong&gt;Model III ANOVA&lt;/strong&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The latter are useful for investigating the generality of a main treatment effect (fixed) over broad spatial, temporal or clinical levels of organisation. That is whether the observed effects of temperature and/or fertiliser (for example) are observed across the entire genera or country.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear model&lt;/h2&gt;
&lt;p&gt;As with single factor ANOVA, the linear model could be constructed as either effects or means parameterisation, although only effects parameterisation will be considered here. The linear models for two and three factor design are&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \epsilon_{ijk},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ijkl} = \mu + \alpha_i + \beta_j + \gamma_k + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \epsilon_{ijkl},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the overall mean, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; is the effect of Factor A, &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is the effect of Factor B, &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the effect of Factor C and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random unexplained or residual component. Note that although the linear models for Model I, Model II and Model III designs are identical, the interpretation of terms (and thus null hypothesis) differ. Recall from the tutorial on single factor ANOVA, that categorical variables in linear models are actually re-parameterised dummy codes - and thus the &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; term above, actually represents one or more dummy codes. Thus, if we actually had two levels of Factor A (A1 and A2) and three levels of Factor B (B1, B2, B3), then the fully parameterised linear model would be:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y=\beta_{A1B1}+\beta_{A2B1−A1B1}+\beta_{A1B2−A1B1}+\beta_{A1B3−A1B1}+\beta_{A2B2−A1B2−A2B1−A1B1}+\beta_{A2B3−A1B3−A2B1−A1B1}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Thus, such a model would have six parameters to estimate (in addition to the variance).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis&lt;/h2&gt;
&lt;p&gt;There are separate null hypothesis associated with each of the main effects and the interaction terms.&lt;/p&gt;
&lt;div id=&#34;model-1---fixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 1 - fixed effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Factor A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to an overall mean. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the overall mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The effect of each group equals zero. If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), the null hypothesis is rejected indicating that the treatment has been found to affect the response variable. Note, as with multiple regression models, these “effects” represent &lt;em&gt;partial effects&lt;/em&gt;. In the above, the effect of Factor A is actually the effect of Factor A at the first level of the Factor(s).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal - at the first level of Factor A. Equivalent interpretation to Factor A above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\mu_{ij}=\mu_i+\mu_j-\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. For any given combination of factor levels, the population group mean will be equal to the difference between the overall population mean and the simple additive effects of the individual factor group means. That is, the effects of the main treatment factors are purely additive and independent of one another. This is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(H_0(AB): \alpha\beta_{ij}=0\)&lt;/span&gt;, no interaction between Factor A and Factor B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-2---random-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 2 - random effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Factor A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\sigma^2_{\alpha}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of A.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\sigma^2_{\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of B.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\sigma^2_{\alpha\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is no added variance due to all possible interactions between all possible levels of A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-3---mixed-effects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model 3 - mixed effects&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Fixed factor - e.g. A&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population group means are all equal. The mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; (pooled over all levels of the random factor) is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to an overall mean pooling over all possible levels of the random factor. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the overall mean (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;No effect of any level of this factor pooled over all possible levels of the random factor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Random factor - e.g. B&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(B):\sigma^2_{\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible levels of B.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Factor AB: interaction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The interaction of a fixed and random factor is always considered a random factor.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0(AB):\sigma^2_{\alpha\beta}=0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The population variance equals zero. There is no added variance due to all possible interactions between all possible levels of A and B.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;When fixed factorial designs are balanced, the total variance in the response variable can be sequentially partitioned into what is explained by each of the model terms (factors and their interactions) and what is left unexplained. For each of the specific null hypotheses, the overall unexplained variability is used as the denominator in F-ratio calculations, and when a null hypothesis is true, an F-ratio should follow an F distribution with an expected value less than &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;. Random factors are added to provide greater generality of conclusions. That is, to enable us to make conclusions about the effect of one factor (such as whether or not fertiliser is added) over all possible levels (not just those sampled) of a random factor (such as all possible locations, seasons, varieties, etc). In order to expand our conclusions beyond the specific levels used in the design, the hypothesis tests (and thus F-ratios) must reflect this extra generality by being more conservative.&lt;/p&gt;
&lt;p&gt;The appropriate F-ratios for fixed, random and mixed factorial designs are presented below. Generally, once the terms (factors and interactions) have been ordered into a hierarchy (single factors at the top, highest level interactions at the bottom and terms of same order given equivalent positions in the hierarchy), the denominator for any term is selected as the next appropriate random term (an interaction that includes the term to be tested) encountered lower in the hierarchy. Interaction terms that contain one or more random factors are considered themselves to be random terms, as is the overall residual term (as all observations are assumed to be random representations of the entire population(s)). Note, when designs include a mixture of fixed and random crossed effects, exact denominator degrees of freedoms for certain F-ratios are undefined and traditional approaches adopt rather inexact estimated approximate or “Quasi” F-ratios. Pooling of non-significant F-ratio denominator terms, in which lower random terms are added to the denominator (provided &lt;span class=&#34;math inline&#34;&gt;\(\alpha &amp;gt; 0.25\)&lt;/span&gt;), may also be useful. For random factors within mixed models, selecting F-ratio denominators that are appropriate for the intended hypothesis tests is a particularly complex and controversial issue. Traditionally, there are two alternative approaches and whilst the statistical resumes of each are complicated, essentially they differ in whether or not the interaction term is constrained for the test of the random factor.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;constrained or restricted method&lt;/em&gt; (&lt;strong&gt;Model I&lt;/strong&gt;), stipulates that for the calculation of a random factor F-ratio (which investigates the added variance added due to the random factor), the overall effect of the interaction is treated as zero. Consequently, the random factor is tested against the residual term. The &lt;em&gt;unconstrained or unrestrained method&lt;/em&gt; (&lt;strong&gt;Model II&lt;/strong&gt;) however, does not set the interaction effect to zero and therefore the interaction term is used as the random factor F-ratio denominator. This method assumes that the interaction terms for each level of the random factor are completely independent (correlations between the fixed factor must be consistent across all levels of the random factor). Some statisticians maintain that the independence of the interaction term is difficult to assess for clinical data and therefore, the restricted approach is more appropriate. However, others have suggested that the restricted method is only appropriate for balanced designs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quasi-f-ratios&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quasi F-ratios&lt;/h2&gt;
&lt;p&gt;An additional complication for three or more factor models that contain two or more random factors, is that there may not be a single appropriate interaction term to use as the denominator for many of the main effects F-ratios. For example, if Factors A and B are random and C is fixed, then there are two random interaction terms of equivalent level under Factor C (&lt;span class=&#34;math inline&#34;&gt;\(A^\prime \times C\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B^\prime \times C\)&lt;/span&gt;). As a result, the value of the of the &lt;em&gt;Mean Squares&lt;/em&gt; (MS) expected when the null hypothesis is true cannot be easily defined. The solutions for dealing with such situations (&lt;em&gt;quasi F-ratios&lt;/em&gt;) involve adding (and subtracting) terms together to create approximate estimates of F-ratio denominators. Alternatively, for random factors, variance components with confidence intervals can be used. These solutions are sufficiently unsatisfying as to lead many statisticians to recommend that factorial designs with two or more random factors should avoided if possible. Arguably however, linear mixed effects models offer more appropriate solutions to the above issues as they are more robust for unbalanced designs, accommodate covariates and provide a more comprehensive treatment and overview of all the underlying data structures.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; fact_anova_table
    df           MS       A,B fixed          A,B random       
A   &amp;quot;a-1&amp;quot;        &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;  &amp;quot;(MS A)/(MS AB)&amp;quot; 
B   &amp;quot;b-1&amp;quot;        &amp;quot;MS B&amp;quot;   &amp;quot;(MS B)/(MS res)&amp;quot;  &amp;quot;(MS B)/(MS AB)&amp;quot; 
AB  &amp;quot;(b-1)(a-1)&amp;quot; &amp;quot;MS AB&amp;quot;  &amp;quot;(MS AB)/(MS res)&amp;quot; &amp;quot;(MS AB)/(MS AB)&amp;quot;
Res &amp;quot;(n-1)ba&amp;quot;    &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;                 &amp;quot;&amp;quot;               
    A fixed B random (model I) A fixed B random (model II)
A   &amp;quot;(MS A)/(MS AB)&amp;quot;           &amp;quot;(MS A)/(MS AB)&amp;quot;           
B   &amp;quot;(MS B)/(MS res)&amp;quot;          &amp;quot;(MS B)/(MS AB)&amp;quot;           
AB  &amp;quot;(MS AB)/(MS res)&amp;quot;         &amp;quot;(MS AB)/(MS res)&amp;quot;         
Res &amp;quot;&amp;quot;                         &amp;quot;&amp;quot;                         &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The corresponding &lt;code&gt;R&lt;/code&gt; syntax is given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Type I SS (Balanced)
&amp;gt; anova(lm(y ~ A * B, data))
&amp;gt; 
&amp;gt; #Type II SS (Unbalanced)
&amp;gt; Anova(lm(y ~ A * B, data), type = &amp;quot;II&amp;quot;)
&amp;gt; 
&amp;gt; #Type III SS (Unbalanced)
&amp;gt; Anova(lm(y ~ A * B, data), type = &amp;quot;III&amp;quot;)
&amp;gt; 
&amp;gt; #Variance components
&amp;gt; summary(lmer(y ~ 1 + (1 | A) + (1 | B) + (1 | A:B), data))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that for fixed factor models, when null hypotheses of interactions are rejected, the null hypothesis of the individual constituent factors are unlikely to represent the true nature of the effects and thus are of little value. The nature of such interactions are further explored by fitting simpler linear models (containing at least one less factor) separately for each of the levels of the other removed factor(s). Such &lt;em&gt;Main effects&lt;/em&gt; tests are based on a subset of the data, and therefore estimates of the overall residual (unexplained) variability are unlikely to be as precise as the estimates based on the global model. Consequently, F-ratios involving &lt;code&gt;MSResid&lt;/code&gt; should use the estimate of &lt;code&gt;MSResid&lt;/code&gt; from the global model rather than that based on the smaller, theoretically less precise subset of data. For random and mixed models, since the objective is to generalise the effect of one factor over and above any interactions with other factors, the main factor effects can be interpreted even in the presence of significant interactions. Nevertheless, it should be noted that when a significant interaction is present in a mixed model, the power of the main fixed effects will be reduced (since the amount of variability explained by the interaction term will be relatively high, and this term is used as the denominator for the F-ratio calculation).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;Hypothesis tests assume that the residuals are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator (see table above) should be used to explore normality. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;independent of one another.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Planned and unplanned comparisons&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As with single factor analysis of variance, planned and unplanned multiple comparisons (such as &lt;em&gt;Tukey&lt;/em&gt;’s test) can be incorporated into or follow the linear model respectively so as to further investigate any patterns or trends within the main factors and/or the interactions. As with single factor analysis of variance, the contrasts must be defined prior to fitting the linear model, and no more than &lt;span class=&#34;math inline&#34;&gt;\(p−1\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the number of levels of the factor) contrasts can be defined for a factor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Unbalanced designs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A factorial design can be thought of as a table made up of rows (representing the levels of one factor), columns (levels of another factor), and cells (the individual combinations of the set of factors). Whilst the middle left table does not have equal sample sizes in each cell, the sample sizes are in proportion and as such, does not present the issues discussed below for unbalanced designs.&lt;/p&gt;
&lt;p&gt;In addition to impacting on normality and homogeneity of variance, unequal sample sizes in factorial designs have major implications for the partitioning of the total sums of squares into each of the model components. For balanced designs, the total sums of squares (&lt;code&gt;SSTotal&lt;/code&gt;) is equal to the additive sums of squares of each of the components (including the residual). For example, in a two factor balanced design, &lt;code&gt;SSTotal=SSA+SSB+SSAB+SSResid&lt;/code&gt;. This can be represented diagrammatically by a &lt;em&gt;Venn Diagram&lt;/em&gt; in which each of the &lt;code&gt;SS&lt;/code&gt; for the term components butt against one another and are surrounded by the &lt;code&gt;SSResid&lt;/code&gt;. However, in unbalanced designs, the sums of squares will be non-orthogonal and the sum of the individual components does not add up to the total sums of squares. Diagrammatically, the &lt;code&gt;SS&lt;/code&gt; of the terms intersect or are separated.&lt;/p&gt;
&lt;p&gt;In regular &lt;em&gt;sequential sums of squares&lt;/em&gt; (&lt;strong&gt;Type I SS&lt;/strong&gt;), the sum of the individual sums of squares must be equal to the total sums of squares, the sums of squares of the last factor to be estimated will be calculated as the difference between the total sums of squares and what has already been accounted for by other components. Consequently, the order in which factors are specified in the model (and thus estimated) will alter their sums of squares and therefore their F-ratios. To overcome this problem, traditionally there are two other alternative methods of calculating sums of squares.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Type II (hierarchical) SS&lt;/strong&gt; estimate the sums of squares of each term as the improvement it contributes upon addition of that term to a model of greater complexity and lower in the hierarchy (recall that the hierarchical structure descends from the simplest model down to the fully populated model). The SS for the interaction as well as the first factor to be estimated are the same as for Type I SS. Type II SS estimate the contribution of a factor over and above the contributions of other factors of equal or lower complexity but not above the contributions of the interaction terms or terms nested within the factor. However, these sums of squares are weighted by the sample sizes of each level and therefore are biased towards the trends produced by the groups (levels) that have higher sample sizes. As a result of the weightings, Type II SS actually test hypotheses about really quite complex combinations of factor levels. Rather than test a hypothesis that &lt;span class=&#34;math inline&#34;&gt;\(\mu_{High}=\mu_{Medium}=\mu_{Low}\)&lt;/span&gt;, Type II SS might be testing that &lt;span class=&#34;math inline&#34;&gt;\(4\times\mu_{High}=1\times\mu_{Medium}=0.25\times\mu_{Low}\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Type III (marginal or orthogonal) SS&lt;/strong&gt; estimate the sums of squares of each term as the improvement based on a comparison of models with and without the term and are unweighted by sample sizes. Type III SS essentially measure just the unique contribution of each factor over and above the contributions of the other factors and interactions. For unbalanced designs,Type III SS essentially test equivalent hypotheses to balanced Type I SS and are therefore arguably more appropriate for unbalanced factorial designs than Type II SS. Importantly, Type III SS are only interpretable if they are based on orthogonal contrasts (such as sum or helmert contrasts and not treatment contrasts).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The choice between Type II and III SS clearly depends on the nature of the question. For example, if we had measured the growth rate of seedlings subjected to two factors (temperature and fertiliser), Type II SS could address whether there was an effect of temperature across the level of fertiliser treatment, whereas Type III SS could assess whether there was an effect of temperature within each level of the fertiliser treatment.&lt;/p&gt;
&lt;p&gt;When an entire combination, or cell, is missing (perhaps due to unforeseen circumstances) it is not possible to test all the main effects and/or interactions. The bottom right table above depicts such as situation. One solution is to fit a large single factor ANOVA with as many levels as there are cells (this is known as a cell means model) and investigate various factor and interaction effects via specific contrasts (see the following tables). Difficulties in establishing appropriate error terms, makes missing cells in random and mixed factor designs substantially more complex.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Imagine we has designed an experiment in which we had measured the response (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) under a combination of two different potential influences (Factor A: levels a1 and a2; and Factor B: levels b1, b2 and b3), each combination replicated &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; times (&lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; nA &amp;lt;- 2  #number of levels of A
&amp;gt; nB &amp;lt;- 3  #number of levels of B
&amp;gt; nsample &amp;lt;- 10  #number of reps in each
&amp;gt; A &amp;lt;- gl(nA, 1, nA, lab = paste(&amp;quot;a&amp;quot;, 1:nA, sep = &amp;quot;&amp;quot;))
&amp;gt; B &amp;lt;- gl(nB, 1, nB, lab = paste(&amp;quot;b&amp;quot;, 1:nB, sep = &amp;quot;&amp;quot;))
&amp;gt; data &amp;lt;- expand.grid(A = A, B = B, n = 1:nsample)
&amp;gt; X &amp;lt;- model.matrix(~A * B, data = data)
&amp;gt; eff &amp;lt;- c(40, 15, 5, 0, -15, 10)
&amp;gt; sigma &amp;lt;- 3  #residual standard deviation
&amp;gt; n &amp;lt;- nrow(data)
&amp;gt; eps &amp;lt;- rnorm(n, 0, sigma)  #residuals
&amp;gt; data$y &amp;lt;- as.numeric(X %*% eff + eps)
&amp;gt; head(data)  #print out the first six rows of the data set
   A  B n        y
1 a1 b1 1 38.31857
2 a2 b1 1 54.30947
3 a1 b2 1 49.67612
4 a2 b2 1 45.21153
5 a1 b3 1 40.38786
6 a2 b3 1 70.14519
&amp;gt; 
&amp;gt; with(data, interaction.plot(A, B, y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/generate_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ## ALTERNATIVELY, we could supply the population means and get the effect parameters from these.  To
&amp;gt; ## correspond to the model matrix, enter the population means in the order of: a1b1, a2b1, a1b1,
&amp;gt; ## a2b2,a1b3,a2b3
&amp;gt; pop.means &amp;lt;- as.matrix(c(40, 55, 45, 45, 40, 65), byrow = F)
&amp;gt; ## Generate a minimum model matrix for the effects
&amp;gt; XX &amp;lt;- model.matrix(~A * B, expand.grid(A = factor(1:2), B = factor(1:3)))
&amp;gt; ## Use the solve() function to solve what are effectively simultaneous equations
&amp;gt; (eff &amp;lt;- as.vector(solve(XX, pop.means)))
[1]  40  15   5   0 -15  10
&amp;gt; 
&amp;gt; data$y &amp;lt;- as.numeric(X %*% eff + eps)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type. Does treatment type effect the response?.&lt;/p&gt;
&lt;div id=&#34;assumptions-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;The assumptions are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All of the observations are independent - this must be addressed at the design and collection stages. Importantly, to be considered independent replicates, the replicates must be made at the same scale at which the treatment is applied. For example, if the experiment involves subjecting organisms housed in tanks to different water temperatures, then the unit of replication is the individual tanks not the individual organisms in the tanks. The individuals in a tank are strictly not independent with respect to the treatment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable (and thus the residuals) should be normally distributed for each sampled populations (combination of factors). Boxplots of each treatment combination are useful for diagnosing major issues with normality.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately) for each combination of treatments. Again, boxplots are useful.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Normality and Homogeneity of variance&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ A * B, data)
&amp;gt; 
&amp;gt; # OR via ggplot2
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/exp1_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = y, x = A, fill = B)) + geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/exp1_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity&lt;/p&gt;
&lt;p&gt;Obvious violations could be addressed either by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;transform the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X \boldsymbol \beta\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt; represents the intercept associated with the first combination of groups, as well as the (effects) differences between this intercept and each other group. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol X\)&lt;/span&gt; is the model matrix. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. Exploratory data analysis suggests that the intercept and effects could be drawn from similar distributions (with mean in the &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;’s and variances in the &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;’s). Whilst we might therefore be tempted to provide different priors for the intercept, compared to the effects, for a simple model such as this, it is unlikely to be necessary. However, for more complex models, where prior specification becomes more critical, separate priors would probably be necessary. We proceed to code the model into &lt;code&gt;STAN&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   // Likelihood
+   y~normal(mu,sigma);
+   
+   // Priors
+   beta ~ normal(0,100);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString, con = &amp;quot;fact_anovaModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~A * B, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = Xmat, nX = ncol(Xmat), n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;log_lik&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 500
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 2000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 1500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now compile and run the Stan code via the &lt;code&gt;rstan&lt;/code&gt; interface. Note that the first time &lt;code&gt;stan&lt;/code&gt; is run after the &lt;code&gt;rstan&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;During the warmup stage, the No-U-Turn sampler (NUTS) attempts to determine the optimum stepsize - the stepsize that achieves the target acceptance rate (&lt;span class=&#34;math inline&#34;&gt;\(0.8\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(80\)&lt;/span&gt;% by default) without divergence (occurs when the stepsize is too large relative to the curvature of the log posterior and results in approximations that are likely to diverge and be biased) - and without hitting the maximum treedepth (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;). At each iteration of the NUTS algorithm, the number of leapfrog steps doubles (as it increases the treedepth) and only terminates when either the NUTS criterion are satisfied or the tree depth reaches the maximum (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; by default).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rstan &amp;lt;- stan(data = data.list, file = &amp;quot;fact_anovaModel.stan&amp;quot;, chains = nChains, pars = params,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;fact_anovaModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.064 seconds (Warm-up)
Chain 1:                0.085 seconds (Sampling)
Chain 1:                0.149 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;fact_anovaModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.07 seconds (Warm-up)
Chain 2:                0.087 seconds (Sampling)
Chain 2:                0.157 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.rstan, par = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: fact_anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]  40.19    0.03 0.90  38.43  39.57  40.17  40.81  41.99   710 1.00
beta[2]  14.71    0.05 1.33  12.05  13.83  14.71  15.56  17.39   655 1.01
beta[3]   4.99    0.04 1.29   2.42   4.11   5.03   5.88   7.35   845 1.00
beta[4]  -0.35    0.04 1.29  -2.80  -1.22  -0.37   0.53   2.15   907 1.00
beta[5] -14.51    0.07 1.86 -18.22 -15.78 -14.49 -13.21 -10.84   772 1.00
beta[6]  11.12    0.07 1.85   7.41   9.93  11.15  12.42  14.68   791 1.01
sigma     2.89    0.01 0.28   2.41   2.70   2.88   3.07   3.48  1521 1.00

Samples were drawn using NUTS(diag_e) at Tue Feb 18 14:32:34 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; s = as.array(data.rstan)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, dimnames(s)$parameters)
&amp;gt; s = s[, , wch]
&amp;gt; mcmc &amp;lt;- do.call(mcmc.list, plyr:::alply(s[, , -(length(s[1, 1, ]))], 2, as.mcmc))
&amp;gt; denplot(mcmc, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(mcmc, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(mcmc)
$`1`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

$`2`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; stan_ac(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_rhat(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_ess(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag4-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Rhat and effective sample size. In this instance, most of the parameters have reasonably high effective samples and thus there is likely to be a good range of values from which to estimate paramter properties.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model. Residuals are not computed directly within &lt;code&gt;rstan&lt;/code&gt; However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; library(tidyr)
&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; print(coefs)
    beta[1]     beta[2]     beta[3]     beta[4]     beta[5]     beta[6] 
 40.1693379  14.7128347   5.0341367  -0.3693605 -14.4877785  11.1514524 
&amp;gt; 
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = B)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~A * B, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, wch], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentized residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;beta\\[&amp;quot;, colnames(mcmc))
&amp;gt; #generate a model matrix
&amp;gt; Xmat = model.matrix(~A*B, data)
&amp;gt; ##get median parameter estimates
&amp;gt; coefs = mcmc[,wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,], mcmc[i, &amp;#39;sigma&amp;#39;]))
&amp;gt; newdata = data.frame(A=data$A, B=data$B, yRep) %&amp;gt;% gather(key=Sample, value=Value,-A,-B)
&amp;gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=A, fill=&amp;#39;Model&amp;#39;), alpha=0.5)+
+  geom_violin(data=data, aes(y=y,x=A,fill=&amp;#39;Obs&amp;#39;), alpha=0.5) +
+  geom_point(data=data, aes(y=y, x=A), position=position_jitter(width=0.1,height=0),
+             color=&amp;#39;black&amp;#39;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=B, fill=&amp;#39;Model&amp;#39;, group=B, color=A), alpha=0.5)+
+  geom_point(data=data, aes(y=y, x=B, group=B,color=A)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(as.matrix(data.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(as.matrix(data.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.rstan, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: fact_anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]  40.19    0.03 0.90  38.43  39.57  40.17  40.81  41.99   710 1.00
beta[2]  14.71    0.05 1.33  12.05  13.83  14.71  15.56  17.39   655 1.01
beta[3]   4.99    0.04 1.29   2.42   4.11   5.03   5.88   7.35   845 1.00
beta[4]  -0.35    0.04 1.29  -2.80  -1.22  -0.37   0.53   2.15   907 1.00
beta[5] -14.51    0.07 1.86 -18.22 -15.78 -14.49 -13.21 -10.84   772 1.00
beta[6]  11.12    0.07 1.85   7.41   9.93  11.15  12.42  14.68   791 1.01
sigma     2.89    0.01 0.28   2.41   2.70   2.88   3.07   3.48  1521 1.00

Samples were drawn using NUTS(diag_e) at Tue Feb 18 14:32:34 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(data.rstan, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
# A tibble: 7 x 5
  term    estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]   40.2       0.905    38.5      42.0 
2 beta[2]   14.7       1.33     12.2      17.5 
3 beta[3]    4.99      1.29      2.35      7.29
4 beta[4]   -0.349     1.29     -2.78      2.16
5 beta[5]  -14.5       1.86    -18.4     -11.1 
6 beta[6]   11.1       1.85      7.40     14.7 
7 sigma      2.89      0.279     2.38      3.43&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The intercept represents the mean of the first combination Aa1:Bb1 is &lt;span class=&#34;math inline&#34;&gt;\(40.2\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb1 is &lt;span class=&#34;math inline&#34;&gt;\(14.7\)&lt;/span&gt; units greater than Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa1:Bb2 is &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; units greater Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa1:Bb3 is &lt;span class=&#34;math inline&#34;&gt;\(-0.335\)&lt;/span&gt; units greater Aa1:Bb1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb2 is &lt;span class=&#34;math inline&#34;&gt;\(-14.6\)&lt;/span&gt; units greater than the difference between (Aa1:Bb2 + Aa2:Bb1) and (2*Aa1:Bb1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aa2:Bb3 is &lt;span class=&#34;math inline&#34;&gt;\(11.1\)&lt;/span&gt; units greater than the difference between (Aa1:Bb3 + Aa2:Bb1) and (2*Aa1:Bb1)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility interval for both interactive effects (Aa2:Bb2 and Aa2:Bb3) do not contain &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, implying significant interactions between A and B. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[2]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[3]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[4]&amp;quot;])
[1] 0.777
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[5]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[6]&amp;quot;])
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, c(&amp;quot;beta[5]&amp;quot;, &amp;quot;beta[6]&amp;quot;)])
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence of an interaction between A and B. In a Bayesian context, we can compare models using the &lt;strong&gt;leave-one-out cross-validation&lt;/strong&gt; statistics. Leave-one-out (LOO) cross-validation explores how well a series of models can predict withheld values &lt;span class=&#34;citation&#34;&gt;Vehtari, Gelman, and Gabry (2017)&lt;/span&gt;. The LOO Information Criterion (LOOIC) is analogous to the AIC except that the LOOIC takes priors into consideration, does not assume that the posterior distribution is drawn from a multivariate normal and integrates over parameter uncertainty so as to yield a distribution of looic rather than just a point estimate. The LOOIC does however assume that all observations are equally influential (it does not matter which observations are left out). This assumption can be examined via the Pareto &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; estimate (values greater than &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt; or more conservatively &lt;span class=&#34;math inline&#34;&gt;\(0.75\)&lt;/span&gt; are considered overly influential). We can compute LOOIC if we store the loglikelihood from our &lt;code&gt;STAN&lt;/code&gt; model, which can then be extracted to compute the information criterion using the package &lt;code&gt;loo&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(loo)
&amp;gt; (full = loo(extract_log_lik(data.rstan)))

Computed from 2000 by 60 log-likelihood matrix

         Estimate   SE
elpd_loo   -151.8  5.2
p_loo         6.3  1.1
looic       303.5 10.5
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k &amp;lt; 0.5).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; # now fit a model without main factor
&amp;gt; modelString2 = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   // Likelihood
+   y~normal(mu,sigma);
+   
+   // Priors
+   beta ~ normal(0,1000);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString2, con = &amp;quot;fact_anovaModel2.stan&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~A + B, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = Xmat, n = nrow(data), nX = ncol(Xmat)))
&amp;gt; data.rstan.red &amp;lt;- stan(data = data.list, file = &amp;quot;fact_anovaModel2.stan&amp;quot;, chains = nChains,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;fact_anovaModel2&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.061 seconds (Warm-up)
Chain 1:                0.068 seconds (Sampling)
Chain 1:                0.129 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;fact_anovaModel2&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.064 seconds (Warm-up)
Chain 2:                0.062 seconds (Sampling)
Chain 2:                0.126 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; (reduced = loo(extract_log_lik(data.rstan.red)))

Computed from 2000 by 60 log-likelihood matrix

         Estimate  SE
elpd_loo   -196.6 3.9
p_loo         4.4 0.5
looic       393.2 7.7
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k &amp;lt; 0.5).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; par(mfrow = 1:2, mar = c(5, 3.8, 1, 0) + 0.1, las = 3)
&amp;gt; plot(full, label_points = TRUE)
&amp;gt; plot(reduced, label_points = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_looic-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;the expected out-of-sample predictive accuracy is substantially lower for the model that includes the interaction (full model).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = expand.grid(A=levels(data$A), B=levels(data$B))
&amp;gt; Xmat = model.matrix(~A*B,newdata)
&amp;gt; coefs = mcmc[,wch]
&amp;gt; fit=coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int=TRUE, conf.method=&amp;#39;HPDinterval&amp;#39;))
&amp;gt; newdata
   A  B estimate std.error conf.low conf.high
1 a1 b1 40.18899 0.9047706 38.49347  42.01653
2 a2 b1 54.89674 0.9051450 53.09543  56.61192
3 a1 b2 45.17758 0.9211897 43.52976  47.13596
4 a2 b2 45.37979 0.8898798 43.70321  47.20260
5 a1 b3 39.84017 0.9091679 38.15775  41.68992
6 a2 b3 65.67259 0.9105872 63.89731  67.49493
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y=estimate, x=B, fill=A)) +
+  geom_blank() +
+  geom_line(aes(x=as.numeric(B), linetype=A)) +
+  geom_linerange(aes(ymin=conf.low, ymax=conf.high))+
+  geom_point(aes(shape=A), size=3)+
+  scale_y_continuous(&amp;#39;Y&amp;#39;)+
+  scale_x_discrete(&amp;#39;B&amp;#39;)+
+  scale_shape_manual(&amp;#39;A&amp;#39;,values=c(21,16))+
+  scale_fill_manual(&amp;#39;A&amp;#39;,values=c(&amp;#39;white&amp;#39;,&amp;#39;black&amp;#39;))+
+  scale_linetype_manual(&amp;#39;A&amp;#39;,values=c(&amp;#39;solid&amp;#39;,&amp;#39;dashed&amp;#39;))+
+  theme_classic() +
+  theme(legend.justification=c(0,1), legend.position=c(0.05,1),
+   axis.title.y=element_text(vjust=2, size=rel(1.25)),
+   axis.title.x=element_text(vjust=-2, size=rel(1.25)),
+   plot.margin=unit(c(0.5,0.5,2,2), &amp;#39;lines&amp;#39;),
+   legend.key.size=unit(1,&amp;#39;cm&amp;#39;)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A        10.4     0.942      8.64     12.4 
2 sd.B         3.06    0.634      1.81      4.25
3 sd.AB       10.4     0.734      9.02     11.9 
4 sd.resid     2.84    0.0811     2.72      3.00
# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.A         39.1     1.94     35.0       42.6
2 sd.B         11.5     1.90      7.70      15.1
3 sd.AB        39.0     0.946    37.2       41.0
4 sd.resid     10.6     0.862     9.37      12.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/effects_modelv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(39\)&lt;/span&gt;% of the total finite population standard deviation is due to the interaction between factor A and factor B.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- as.matrix(data.rstan)
&amp;gt; Xmat = model.matrix(~A * B, data)
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.913   0.00814    0.898     0.925
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ A * B, data))

Call:
lm(formula = y ~ A * B, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5694 -1.8517 -0.0589  1.7120  6.5966 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.1940     0.8980  44.760  &amp;lt; 2e-16 ***
Aa2          14.7163     1.2700  11.588 2.88e-16 ***
Bb2           4.9823     1.2700   3.923 0.000249 ***
Bb3          -0.3464     1.2700  -0.273 0.786077    
Aa2:Bb2     -14.5093     1.7960  -8.079 7.37e-11 ***
Aa2:Bb3      11.1056     1.7960   6.184 8.65e-08 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 2.84 on 54 degrees of freedom
Multiple R-squared:   0.92, Adjusted R-squared:  0.9125 
F-statistic: 124.1 on 5 and 54 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dealing-with-interactions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dealing with interactions&lt;/h1&gt;
&lt;p&gt;In the presence of interations, conclusions about the main effects are overly simplistic at best and completely inaccurate at worst. Therefore, in the presense of interactions we should attempt to tease the analysis appart a little. In the current working example, we have identified that there is a significant interaction between Factor A and Factor B. Our exploration of the regression coefficients, indicated that the pattern between b1, b2 and b3 might differ between a1 and a2. Similarly, if we consider the coefficients from the perspective of Factor A, we can see that the patterns between a1 and a2 are similar for b1 and b3, yet very different for b2.&lt;/p&gt;
&lt;p&gt;At this point, we can then split the two-factor model up into a series of single-factor models, either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;examining the effects of Factor B separately for each level of Factor A (two single-factor models) or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;examining the effects of Factor A separately for each level of Factor B (three single-factor models)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, rather than subset the data and fit isolated smaller models, it is arguably better to treat these explorations as contrasts. As such we could either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;apply specific contrasts to the already fit model&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;define the specific contrasts and use them to refit the model&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will do the former of these options since we have already fit the global model. For this demonstration, we will explore the effect of factor A at each level of factor B. I will illustrate two ways to perform these contrasts on an already fit model:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&amp;gt; Xmat = model.matrix(~A * B, data = newdata)
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; head(fit)
          
iterations        1        2        3        4        5        6
      [1,] 39.69752 55.00221 44.75174 45.00506 40.68290 66.39012
      [2,] 38.09011 54.98489 46.07381 45.40083 40.12613 65.72993
      [3,] 38.43453 55.88735 45.44974 44.95014 39.88235 65.69477
      [4,] 40.62015 55.15234 45.25819 45.63459 39.89825 65.41017
      [5,] 41.36307 54.24942 45.07712 46.12218 39.55757 64.96870
      [6,] 41.36075 54.50463 45.34008 44.16493 38.64767 66.31968
&amp;gt; 
&amp;gt; ## we want to compare columns 2-1, 4-3 and 6-5
&amp;gt; comps = fit[, c(2, 4, 6)] - fit[, c(1, 3, 5)]
&amp;gt; tidyMCMC(comps, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 3 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 2       14.7        1.33    12.2      17.5 
2 4        0.202      1.29    -2.37      2.74
3 6       25.8        1.26    23.4      28.3 &lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- as.matrix(data.rstan)
&amp;gt; wch = grep(&amp;quot;^beta&amp;quot;, colnames(mcmc))
&amp;gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&amp;gt; Xmat = model.matrix(~A * B, data = newdata)
&amp;gt; contr = attr(Xmat, &amp;quot;contrasts&amp;quot;)
&amp;gt; newdata.a1 = model.frame(~A * B, expand.grid(A = levels(data$A)[1], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&amp;gt; Xmat.a1 = model.matrix(~A * B, data = newdata.a1, contrasts = contr)
&amp;gt; newdata.a2 = model.frame(~A * B, expand.grid(A = levels(data$A)[2], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&amp;gt; Xmat.a2 = model.matrix(~A * B, data = newdata.a2, contrasts = contr)
&amp;gt; Xmat = Xmat.a2 - Xmat.a1
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 3 x 4
  estimate std.error conf.low conf.high
     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1   14.7        1.33    12.2      17.5 
2    0.202      1.29    -2.37      2.74
3   25.8        1.26    23.4      28.3 &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2015stan&#34;&gt;
&lt;p&gt;Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt; 40 (5): 530–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanpackage&#34;&gt;
&lt;p&gt;Stan Development Team. 2018. “RStan: The R Interface to Stan.” &lt;a href=&#34;http://mc-stan.org/&#34;&gt;http://mc-stan.org/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vehtari2017practical&#34;&gt;
&lt;p&gt;Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and Waic.” &lt;em&gt;Statistics and Computing&lt;/em&gt; 27 (5): 1413–32.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Single Factor Anova - JAGS</title>
      <link>/jags/single-factor-anova-jags/single-factor-anova-jags/</link>
      <pubDate>Tue, 04 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/jags/single-factor-anova-jags/single-factor-anova-jags/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;JAGS&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Plummer (2004)&lt;/span&gt;) using the package &lt;code&gt;R2jags&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Su et al. (2015)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Single factor Analysis of Variance&lt;/em&gt; (ANOVA), also known as single factor classification, is used to investigate the effect of a single factor comprising two or more groups (treatment levels) from a completely randomised design. Completely randomised refers to the absence of restrictions on the random allocation of experimental or sampling units to factor levels.&lt;/p&gt;
&lt;p&gt;For example, consider a situation in which three types of treatments (A, B and C) are applied to replicate sampling units across the sampling domain. Importantly, the treatments are applied at the scale of the sampling units and the treatments applied to each sampling unit do not extend to any other neighbouring sampling units. Another possible situation is where the scale of a treatment is far larger than that of a sampling unit. This design features two treatments, each replicated three times. Note that additional sampling units within each Site (the scale at which the treatment occurs) would NOT constitute additional replication. Rather, these would be sub-replicates. That is, they would be replicates of the Sites, not the treatments (since the treatments occur at the level of whole sites). In order to genuinely increase the number of replicates, it is necessary to have more Sites. The random allocation of sampling units within the sampling domain (such as population) is appropriate provided either the underlying response is reasonably homogenous throughout the domain, or else, there is a large number of sampling units. If the conditions are relatively hetrogenous, then the exact location of the sampling units is likely to be highly influential and may mask any detectable effects of treatments.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fixed-and-random-effects&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fixed and random effects&lt;/h2&gt;
&lt;p&gt;From a frequentist perspective, &lt;em&gt;fixed factors&lt;/em&gt; are factors whose levels represent the specific populations of interest. For example, a factor that comprises “high”, “medium” and “low” temperature treatments is a fixed factor - we are only interested in comparing those three populations. Conclusions about the effects of a fixed factor are restricted to the specific treatment levels investigated and for any subsequent experiments to be comparable, the same specific treatments of the factor would need to be used. By contrast, &lt;em&gt;random factors&lt;/em&gt; are factors whose levels are randomly chosen from all the possible levels of populations and are used as random representatives of the populations. For example, five random temperature treatments could be used to represent a full spectrum of temperature treatments. In this case, conclusions are extrapolated to all the possible treatment (temperature) levels and for subsequent experiments, a new random set of treatments of the factor would be selected.&lt;/p&gt;
&lt;p&gt;Other common examples of random factors include sites and subjects - factors for which we are attempting to generalise over. Furthermore, the nature of random factors means that we have no indication of how a new level of that factor (such as another subject or site) are likely to respond and thus it is not possible to predict new observations from random factors. These differences between fixed and random factors are reflected in the way their respective null hypotheses are formulated and interpreted. Whilst fixed factors contrast the effects of the different levels of the factor, random factors are modelled as the amount of additional variability they introduce. Random factors are modelled with a mean of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and their variance is estimated as the effect coefficient.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear model&lt;/h2&gt;
&lt;p&gt;The linear model for single factor classification is similar to that of multiple linear regression. The linear model can thus be represented by either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Means parameterisation&lt;/strong&gt; - in which the regression slopes represent the means of each treatment group and the intercept is removed (to prevent over-parameterisation).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \beta_1(\text{level}_1)_{ij} + \beta_2(\text{level}_2)_{ij} + \ldots + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; respectively represent the means response of treatment level &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;. This is often simplified to &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\alpha_i + \epsilon_{ij}\)&lt;/span&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Effects parameterisation&lt;/strong&gt; - the intercept represents a property such as the mean of one of the treatment groups (treatment contrasts) or the overall mean (sum contrasts), and the slope parameters represent effects (differences between each other group and the reference mean for example).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \mu + \beta_2(\text{level}_2)_{ij} + \beta_3(\text{level}_3)_{ij} + \ldots + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the mean of the first treatment group, &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_3\)&lt;/span&gt; respectively represent the effects (change from level &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;) of level &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; on the mean response. This is often simplified to: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \epsilon_{ij}\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1=0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since we are traditionally interested in investigating effects (differences) rather than treatment means, effects parameterisation is far more common (particularly when coupled with hypothesis testing). In a Bayesian framework, it does not really matter whether models are fit with means or effects parameterisation since the posterior likelihood can be querried in any way and repeatedly - thus enabling us to explore any specific effects after the model has been fit. Nevertheless, to ease comparisons with frequentist approaches, we will stick with effects paramterisation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis-fixed-factor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis: fixed factor&lt;/h2&gt;
&lt;p&gt;We can associate a null hypothesis test with each estimated parameter. For example, in a cell for each estimated mean in a means model we could test a null hypothesis that the population mean is equal to zero (e.g. &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\alpha_2=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\ldots\)&lt;/span&gt;). However, this rarely would be of much interest. By contrast, individual null hypotheses associated with each parameter of the effects model can be used to investigate the differences between each group and a reference group (for example). In addition to the individual null hypothesis tests, a single fixed factor ANOVA tests the collective &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; that there are no differences between the population group means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt; (the population group means are all equal). That is, that the mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to one another - no effect of the factor on the response. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the mean of the first group (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu_1\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0 : \alpha_2=\alpha_3=\ldots=\alpha_i=0\)&lt;/span&gt; (the effect of each group equals zero). If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), there is evidence that the null hypothesis is not true indicating that the factor does affect the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis-random-factor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis: random factor&lt;/h2&gt;
&lt;p&gt;The collective &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; for a random factor is that the variance between all possible treatment groups equals zero:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0 : \sigma^2_{\alpha}=0\)&lt;/span&gt; (added variance due to this factor equals zero).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that whilst the null hypotheses for fixed and random factors are different (fixed: population group means all equal, random: variances between populations all equal zero), the linear model fitted for fixed and random factors in single factor ANOVA models is identical. For more complex multi-factor ANOVA models however, the distinction between fixed and random factors has important consequences for building and interpreting statistical models and null hypotheses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;When the null hypothesis is true (and the populations are identical), the amount of variation among observations within groups should be similar to the amount of variation in observations between groups. However, when the null hypothesis is false (and some means are different from other means), the amount of variation among observations might be expected to be less than the amount of variation within groups. Analysis of variance, or ANOVA, partitions the total variance in the response (dependent) variable into a component of the variance that is explained by combinations of one or more categorical predictor variables (called factors) and a component of the variance that cannot be explained (residual). The variance ratio (F-ratio) from this partitioning can then be used to test the null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;) that the population group or treatment means are all equal. Ttotal variation can be decomposed into components explained by the groups (&lt;span class=&#34;math inline&#34;&gt;\(MS_{groups}\)&lt;/span&gt;) and and unexplained (&lt;span class=&#34;math inline&#34;&gt;\(MS_{residual}\)&lt;/span&gt;) by the groups. The gray arrows in b) depict the relative amounts explained by the groups. The proposed groupings generally explain why the first few points are higher on the y-axis than the last three points. The probability of collecting our sample, and thus generating the sample ratio of explained to unexplained variation (or one more extreme), when the null hypothesis is true (and population means are equal) is the area under the F-distribution beyond our sample ratio (&lt;span class=&#34;math inline&#34;&gt;\(\text{F-ratio}=\frac{MS_{groups}}{MS_{residual}}\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;When the null hypothesis is true (and the test assumptions have not been violated), the ratio (F-ratio) of explained to unexplained variance follows a theoretical probability distribution (F-distribution). When the null hypothesis is true, and there is no effect of the treatment on the response variable, the ratio of explained variability to unexplained variability is expected to be &lt;span class=&#34;math inline&#34;&gt;\(\leq 1\)&lt;/span&gt;. Since the denominator should represent the expected numerator in the absence of an effect. Importantly, the denominator in an F-ratio calculation essentially represents what we would expect the numerator to be in the absence of a treatment effect. For simple analyses, identifying what these expected values are is relatively straightforward (equivalent to the degree of within group variability). However, in more complex designs (particularly involving random factors and hierarchical treatment levels), the logical “groups” can be more difficult (and in some cases impossible) to identify. In such cases, nominating the appropriate F-ratio denominator for estimating an specific effect requires careful consideration. The following table depicts the anatomy of the single factor ANOVA table&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova_table
         df       MS       F-ratio          
Factor A &amp;quot;a-1&amp;quot;    &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;
Residual &amp;quot;(n-1)a&amp;quot; &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;               &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and corresponding &lt;code&gt;R&lt;/code&gt; syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(DV ~ A, dataset))
&amp;gt; # OR
&amp;gt; anova(aov(DV ~ A, dataset))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An F-ratio substantially greater than &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; suggests that the model relating the response variable to the categorical variable explains substantially more variability than is left unexplained. In turn, this implies that the linear model does represent the data well and that differences between observations can be explained largely by differences in treatment levels rather than purely the result of random variation. If the probability of getting the observed (sample) F-ratio or one more extreme is less than some predefined critical value (typically &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% or &lt;span class=&#34;math inline&#34;&gt;\(0.05\)&lt;/span&gt;), we conclude that it is highly unlikely that the observed samples could have been collected from populations in which the treatment has no effect and therefore we would reject the null hypothesis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;An F-ratio from real data can only reliably relate to a theoretical F-distribution when the data conform to certain assumptions. Hypothesis testing for a single factor ANOVA model assumes that the residuals (and therefore the response variable for each of the treatment levels) are all:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;normally distributed&lt;/strong&gt; - although ANOVA is robust to non-normality provided sample sizes and variances are equal. Boxplots should be used to explore normality, skewness, bimodality and outliers. In the event of homogeneity of variance issues (see below), a Q-Q normal plot can also be useful for exploring normality (as this might be the cause of non-homogeneity). Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;equally varied&lt;/strong&gt; - provided sample sizes are equal and the largest to smallest variance ratio does not exceed 3:1 (9:1 for sd), ANOVA is reasonably robust to this assumption, however, relationships between variance and mean and/or sample size are of particular concern as they elevate the Type I error rate. Boxplots and plots of means against variance should be used to explore the spread of values. Residual plots should reveal no patterns. Since unequal variances are often the result of non-normality, transformations that improve normality will also improve variance homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;independent of one another&lt;/strong&gt; - this assumption must be addressed at the design and collection stages and cannot be compensated for later (unless a model is used that specifically accounts for particular types of non-independent data, such as that introduced with hierarchical designs or autocorrelation)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Violations of these assumptions reduce the reliability of the analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Lets say we had set up a natural experiment in which we measured a response from &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; sampling units (replicates) from each of &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; treatments. Hence, we have a single categorical factor with &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; levels - we might have five different locations, or five different habitat types or substrates etc. In statistical speak, we have sampled from &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; different populations. We have then randomly selected &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; independent and random (representative) units of each population to sample. That is, we have &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; samples (replicates) of each population. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; ngroups &amp;lt;- 5  #number of populations
&amp;gt; nsample &amp;lt;- 10  #number of reps in each
&amp;gt; pop.means &amp;lt;- c(40, 45, 55, 40, 30)  #population mean length
&amp;gt; sigma &amp;lt;- 3  #residual standard deviation
&amp;gt; n &amp;lt;- ngroups * nsample  #total sample size
&amp;gt; eps &amp;lt;- rnorm(n, 0, sigma)  #residuals
&amp;gt; x &amp;lt;- gl(ngroups, nsample, n, lab = LETTERS[1:5])  #factor
&amp;gt; means &amp;lt;- rep(pop.means, rep(nsample, ngroups))
&amp;gt; X &amp;lt;- model.matrix(~x - 1)  #create a design matrix
&amp;gt; y &amp;lt;- as.numeric(X %*% pop.means + eps)
&amp;gt; data &amp;lt;- data.frame(y, x)
&amp;gt; head(data)  #print out the first six rows of the data set
         y x
1 38.31857 A
2 39.30947 A
3 44.67612 A
4 40.21153 A
5 40.38786 A
6 45.14519 A
&amp;gt; 
&amp;gt; write.csv(data, &amp;quot;simpleAnova.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type.&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Normality and Homogeneity of variance&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ x, data)
&amp;gt; 
&amp;gt; # OR via ggplot2
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/exp_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = y, x = x)) + geom_boxplot() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/exp_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity. Obvious violations could be addressed either by, for example, transforming the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0+\boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the mean of the first group and the set of &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;’s represent the differences between each other group and the first group. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. We proceed to code the model into &lt;code&gt;JAGS&lt;/code&gt; (remember that in this software normal distribution are parameterised in terms of precisions &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; rather than variances, where &lt;span class=&#34;math inline&#34;&gt;\(\tau=\frac{1}{\sigma^2}\)&lt;/span&gt;). Note the following example as group means calculated as derived posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau.res)
+   mean[i] &amp;lt;- alpha+beta[x[i]]
+   }
+ 
+   #Priors and derivatives
+   alpha ~ dnorm(0,1.0E-6)
+   beta[1] &amp;lt;- 0
+   for (i in 2:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) #prior
+   }
+   sigma.res ~ dunif(0, 100)
+   tau.res &amp;lt;- 1 / (sigma.res * sigma.res)
+   sigma.group &amp;lt;- sd(beta[])
+ 
+   #Group mean posteriors (derivatives)
+   for (i in 1:ngroups) {
+   Group.means[i] &amp;lt;- beta[i]+alpha
+   }
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString, con = &amp;quot;anovaModel.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;JAGS&lt;/code&gt;). As input, &lt;code&gt;JAGS&lt;/code&gt; will need to be supplied with: the response variable, the predictor matrix, the number of predictors, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.list &amp;lt;- with(data, list(y = y, x = as.numeric(x), n = nrow(data),
+     ngroups = length(levels(data$x))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;alpha&amp;quot;, &amp;quot;beta&amp;quot;, &amp;quot;sigma.res&amp;quot;, &amp;quot;Group.means&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Load the &lt;code&gt;R2jags&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(R2jags)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;anovaModel.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 50
   Unobserved stochastic nodes: 6
   Total graph size: 126

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;anovaModel.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
               mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat
Group.means[1]  40.232   0.908  38.424  39.631  40.237  40.837  41.991 1.001
Group.means[2]  45.632   0.902  43.858  45.022  45.626  46.231  47.432 1.002
Group.means[3]  53.730   0.913  51.947  53.113  53.722  54.334  55.543 1.001
Group.means[4]  40.962   0.906  39.188  40.350  40.968  41.563  42.734 1.001
Group.means[5]  29.974   0.915  28.173  29.367  29.974  30.586  31.746 1.001
alpha           40.232   0.908  38.424  39.631  40.237  40.837  41.991 1.001
beta[1]          0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000
beta[2]          5.400   1.278   2.889   4.551   5.395   6.244   7.896 1.001
beta[3]         13.498   1.286  11.017  12.639  13.485  14.354  16.049 1.001
beta[4]          0.730   1.283  -1.768  -0.122   0.722   1.582   3.261 1.001
beta[5]        -10.258   1.294 -12.820 -11.110 -10.253  -9.412  -7.721 1.001
sigma.res        2.864   0.320   2.313   2.638   2.832   3.056   3.578 1.001
deviance       245.540   3.787 240.323 242.761 244.832 247.511 254.843 1.001
               n.eff
Group.means[1] 15000
Group.means[2]  2200
Group.means[3]  3800
Group.means[4] 15000
Group.means[5] 15000
alpha          15000
beta[1]            1
beta[2]         2900
beta[3]        15000
beta[4]        15000
beta[5]        15000
sigma.res      15000
deviance       15000

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;model-matrix-formulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model matrix formulation&lt;/h2&gt;
&lt;p&gt;For very simple models such as this example, we can write the models as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString2 = &amp;quot;
+   model {
+   #Likelihood
+   for (i in 1:n) {
+   y[i]~dnorm(mean[i],tau)
+   mean[i] &amp;lt;- inprod(beta[],X[i,])
+   }
+   #Priors
+   for (i in 1:ngroups) {
+   beta[i] ~ dnorm(0, 1.0E-6) 
+   }
+   sigma ~ dunif(0, 100)
+   tau &amp;lt;- 1 / (sigma * sigma)
+   }
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a text file
&amp;gt; writeLines(modelString2, con = &amp;quot;anovaModel2.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the data to pass to &lt;code&gt;R2jags&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; X &amp;lt;- model.matrix(~x, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = X, n = nrow(data), ngroups = ncol(X)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and the chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 3000
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 15000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 10500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;JAGS&lt;/code&gt; model (check the model, load data into the model, specify the number of chains and compile the model). Run the &lt;code&gt;JAGS&lt;/code&gt; code via the &lt;code&gt;R2jags&lt;/code&gt; interface. Note that the first time jags is run after the &lt;code&gt;R2jags&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.r2jags &amp;lt;- jags(data = data.list, inits = NULL, parameters.to.save = params,
+     model.file = &amp;quot;anovaModel2.txt&amp;quot;, n.chains = nChains, n.iter = nIter,
+     n.burnin = burnInSteps, n.thin = thinSteps)
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 50
   Unobserved stochastic nodes: 6
   Total graph size: 370

Initializing model
&amp;gt; 
&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;anovaModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.226   0.901  38.475  39.624  40.222  40.824  41.999 1.001  4800
beta[2]    5.401   1.272   2.906   4.552   5.397   6.242   7.900 1.001 15000
beta[3]   13.492   1.296  10.969  12.634  13.484  14.355  16.038 1.001  5100
beta[4]    0.734   1.279  -1.793  -0.114   0.740   1.582   3.263 1.001 15000
beta[5]  -10.248   1.283 -12.785 -11.108 -10.242  -9.380  -7.731 1.001  9800
sigma      2.863   0.315   2.321   2.642   2.838   3.053   3.558 1.001  6200
deviance 245.551   3.785 240.353 242.765 244.844 247.603 254.815 1.002  1800

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example. When there are a lot of parameters, this can result in a very large number of traceplots. To focus on just certain parameters, e.g. &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; denplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(data.r2jags, parms = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.mcmc = as.mcmc(data.r2jags)
&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(data.mcmc)
[[1]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3895  3746         1.040     
 beta[2]  2        3729  3746         0.995     
 beta[3]  2        3811  3746         1.020     
 beta[4]  3        4115  3746         1.100     
 beta[5]  2        3853  3746         1.030     
 deviance 2        3729  3746         0.995     
 sigma    5        5834  3746         1.560     


[[2]]

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 
                                                
          Burn-in  Total Lower bound  Dependence
          (M)      (N)   (Nmin)       factor (I)
 beta[1]  2        3853  3746         1.03      
 beta[2]  2        3918  3746         1.05      
 beta[3]  2        3811  3746         1.02      
 beta[4]  2        3853  3746         1.03      
 beta[5]  2        3853  3746         1.03      
 deviance 2        3981  3746         1.06      
 sigma    4        5306  3746         1.42      &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; autocorr.diag(data.mcmc)
             beta[1]     beta[2]       beta[3]       beta[4]      beta[5]
Lag 0   1.0000000000 1.000000000  1.0000000000  1.0000000000  1.000000000
Lag 1   0.0015561854 0.001902670 -0.0023462263  0.0063854498 -0.008928813
Lag 5  -0.0006487164 0.003556616 -0.0008267107 -0.0003892349  0.004087306
Lag 10  0.0141414517 0.012308363  0.0064688638 -0.0029210457  0.009117446
Lag 50 -0.0019115790 0.005069522  0.0072096979 -0.0030858504  0.002938152
           deviance        sigma
Lag 0   1.000000000  1.000000000
Lag 1   0.198317688  0.334172270
Lag 5  -0.001425768  0.005514213
Lag 10 -0.000422188 -0.001600486
Lag 50 -0.008805916  0.007414425&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. For more complex models (those that contain multiple effects), it is also advisable to plot the residuals against each of the individual predictors. For sampling designs that involve sample collection over space or time, it is also a good idea to explore whether there are any temporal or spatial patterns in the residuals.&lt;/p&gt;
&lt;p&gt;There are numerous situations (e.g. when applying specific variance-covariance structures to a model) where raw residuals do not reflect the interior workings of the model. Typically, this is because they do not take into account the variance-covariance matrix or assume a very simple variance-covariance matrix. Since the purpose of exploring residuals is to evaluate the model, for these cases, it is arguably better to draw conclusions based on standardized (or studentised) residuals. Unfortunately the definitions of standardised and studentised residuals appears to vary and the two terms get used interchangeably. I will adopt the following definitions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Standardised residuals&lt;/strong&gt;. The raw residuals divided by the true standard deviation of the residuals (which of course is rarely known).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Studentised residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the residuals. Note that &lt;strong&gt;externally studentised residuals&lt;/strong&gt; are calculated by dividing the raw residuals by a unique standard deviation for each observation that is calculated from regressions having left each successive observation out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pearson residuals&lt;/strong&gt;. The raw residuals divided by the standard deviation of the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;he mark of a good model is being able to predict well. In an ideal world, we would have sufficiently large sample size as to permit us to hold a fraction (such as &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%) back thereby allowing us to train the model on &lt;span class=&#34;math inline&#34;&gt;\(75\)&lt;/span&gt;% of the data and then see how well the model can predict the withheld &lt;span class=&#34;math inline&#34;&gt;\(25\)&lt;/span&gt;%. Unfortunately, such a luxury is still rare. The next best option is to see how well the model can predict the observed data. Models tend to struggle most with the extremes of trends and have particular issues when the extremes approach logical boundaries (such as zero for count data and standard deviations). We can use the fitted model to generate random predicted observations and then explore some properties of these compared to the actual observed data.&lt;/p&gt;
&lt;p&gt;Rather than dublicate this for both additive and multiplicative models, we will only explore the multiplicative model. Residuals are not computed directly within &lt;code&gt;JAGS&lt;/code&gt;. However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(tidyr)
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = x)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentised residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix %&amp;gt;% as.data.frame %&amp;gt;%
+     dplyr:::select(contains(&amp;quot;beta&amp;quot;), sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:5]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; newdata = data.frame(x = data$x, yRep) %&amp;gt;% gather(key = Sample,
+     value = Value, -x)
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = x, fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_violin(data = data, aes(y = y, x = x,
+     fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) + geom_point(data = data, aes(y = y,
+     x = x), position = position_jitter(width = 0.1, height = 0),
+     color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(data.r2jags$BUGSoutput$sims.matrix, regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.r2jags)
Inference for Bugs model at &amp;quot;anovaModel2.txt&amp;quot;, fit using jags,
 2 chains, each with 10500 iterations (first 3000 discarded)
 n.sims = 15000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
beta[1]   40.226   0.901  38.475  39.624  40.222  40.824  41.999 1.001  4800
beta[2]    5.401   1.272   2.906   4.552   5.397   6.242   7.900 1.001 15000
beta[3]   13.492   1.296  10.969  12.634  13.484  14.355  16.038 1.001  5100
beta[4]    0.734   1.279  -1.793  -0.114   0.740   1.582   3.263 1.001 15000
beta[5]  -10.248   1.283 -12.785 -11.108 -10.242  -9.380  -7.731 1.001  9800
sigma      2.863   0.315   2.321   2.642   2.838   3.053   3.558 1.001  6200
deviance 245.551   3.785 240.353 242.765 244.844 247.603 254.815 1.002  1800

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 7.2 and DIC = 252.7
DIC is an estimate of expected predictive error (lower deviance is better).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(as.mcmc(data.r2jags), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 7 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]    40.2       0.901    38.5      42.0 
2 beta[2]     5.40      1.27      2.90      7.89
3 beta[3]    13.5       1.30     11.0      16.1 
4 beta[4]     0.734     1.28     -1.82      3.21
5 beta[5]   -10.2       1.28    -12.7      -7.68
6 deviance  246.        3.79    240.      253.  
7 sigma       2.86      0.315     2.26      3.48&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the mean of the first group (A) is &lt;span class=&#34;math inline&#34;&gt;\(40.2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the mean of the second group (B) is &lt;span class=&#34;math inline&#34;&gt;\(5.4\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the third group (C) is &lt;span class=&#34;math inline&#34;&gt;\(13.5\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the forth group (D) is &lt;span class=&#34;math inline&#34;&gt;\(0.74\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the fifth group (E) is &lt;span class=&#34;math inline&#34;&gt;\(-10.2\)&lt;/span&gt; units greater (i.e. less) than (A)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of B, C and E do not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between group A and groups B, C and E. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[2]&amp;quot;])  # effect of (B-A)
[1] 6.666667e-05
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[3]&amp;quot;])  # effect of (C-A)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[4]&amp;quot;])  # effect of (D-A)
[1] 0.5576
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, &amp;quot;beta[5]&amp;quot;])  # effect of (E-A)
[1] 0
&amp;gt; mcmcpvalue(data.r2jags$BUGSoutput$sims.matrix[, 2:5])  # effect of (all groups)
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence that the reponse differs between the groups. There is evidence suggesting that the response of group D differs from that of group A.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = rbind(data.frame(x = levels(data$x)))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;, &amp;quot;beta[4]&amp;quot;, &amp;quot;beta[5]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_linerange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_point() + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = as.numeric(x) - 0.1)) + geom_blank(aes(x = x)) +
+     geom_point(data = rdata, aes(y = partial.resid, x = as.numeric(x) +
+         0.1), color = &amp;quot;gray&amp;quot;) + geom_linerange(aes(ymin = conf.low, ymax = conf.high)) +
+     geom_point() + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posteriors&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Posteriors&lt;/h1&gt;
&lt;p&gt;In frequentist statistics, when we have more than two groups, we are typically not only interested in whether there is evidence for an overall “effect” of a factor - we are also interested in how various groups compare to one another. To explore these trends, we either compare each group to each other in a pairwise manner (controlling for family-wise Type I error rates) or we explore an independent subset of the possible comparisons. Although these alternate approaches can adequately address a specific research agenda, often they impose severe limitations and compromises on the scope and breadth of questions that can be asked of your data. The reason for these limitations is that in a frequentist framework, any single hypothesis carries with it a (nominally) &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% chance of a false rejection (since it is based on long-run frequency). Thus, performing multiple tests are likely to compound this error rate. The point is, that each comparison is compared to its own probability distribution (and each carries a &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% error rate). By contrast, in Bayesian statistics, all comparisons (contrasts) are drawn from the one (hopefully stable and convergent) posterior distribution and this posterior is invariant to the type and number of comparisons drawn. Hence, the theory clearly indicates that having generated our posterior distribution, we can then query this distribution in any way that we wish thereby allowing us to explore all of our research questions simultaneously.&lt;/p&gt;
&lt;p&gt;Bayesian “contrasts” can be performed either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;within the Bayesian sampling model or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;construct them from the returned MCMC samples (they are drawn from the posteriors)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Only the latter will be demonstrated as it povides a consistent approach across all routines. In order to allow direct comparison to the frequentist equivalents, I will explore the same set of planned and &lt;em&gt;Tukey&lt;/em&gt;’s test comparisons described here. For the “planned comparison” we defined two contrasts: 1) group 3 vs group 5; and 2) the average of groups 1 and 2 vs the average of groups 3, 4 and 5.&lt;/p&gt;
&lt;p&gt;Lets start by comparing each group to each other group in a pairwise manner. Arguably the most elegant way to do this is to generate a Tukey’s contrast matrix. This is a model matrix specific to comparing each group to each other group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:5]
&amp;gt; newdata &amp;lt;- data.frame(x = levels(data$x))
&amp;gt; # A Tukeys contrast matrix
&amp;gt; library(multcomp)
&amp;gt; # table(newdata$x) - gets the number of replicates of each level
&amp;gt; tuk.mat &amp;lt;- contrMat(n = table(newdata$x), type = &amp;quot;Tukey&amp;quot;)
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data = newdata)
&amp;gt; pairwise.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; pairwise.mat
      (Intercept) xB xC xD xE
B - A           0  1  0  0  0
C - A           0  0  1  0  0
D - A           0  0  0  1  0
E - A           0  0  0  0  1
C - B           0 -1  1  0  0
D - B           0 -1  0  1  0
E - B           0 -1  0  0  1
D - C           0  0 -1  1  0
E - C           0  0 -1  0  1
E - D           0  0  0 -1  1
&amp;gt; 
&amp;gt; mcmc_areas(coefs %*% t(pairwise.mat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; (comps = tidyMCMC(coefs %*% t(pairwise.mat), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 B - A    5.40       1.27     2.90      7.89
 2 C - A   13.5        1.30    11.0      16.1 
 3 D - A    0.734      1.28    -1.82      3.21
 4 E - A  -10.2        1.28   -12.7      -7.68
 5 C - B    8.09       1.29     5.58     10.7 
 6 D - B   -4.67       1.30    -7.19     -2.02
 7 E - B  -15.6        1.28   -18.1     -13.1 
 8 D - C  -12.8        1.31   -15.3     -10.2 
 9 E - C  -23.7        1.29   -26.2     -21.2 
10 E - D  -11.0        1.29   -13.5      -8.46
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With a couple of modifications, we could also express this as percentage changes. A percentage change represents the change (difference between groups) divided by one of the groups (determined by which group you want to express the percentage change to). Hence, we generate an additional mcmc matrix that represents the cell means for the divisor group (group we want to express change relative to). Since the &lt;code&gt;tuk.mat&lt;/code&gt; defines comparisons as &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; pairs, if we simply replace all the &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, the eventual matrix multiplication will result in estimates of the divisor cell means instread of the difference. We can then divide the original mcmc matrix above with this new divisor mcmc matrix to yeild a mcmc matrix of percentage change.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # Modify the tuk.mat to replace -1 with 0.  This will allow us to get a
&amp;gt; # mcmc matrix of ..
&amp;gt; tuk.mat[tuk.mat == -1] = 0
&amp;gt; comp.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; comp.mat
      (Intercept) xB xC xD xE
B - A           1  1  0  0  0
C - A           1  0  1  0  0
D - A           1  0  0  1  0
E - A           1  0  0  0  1
C - B           1  0  1  0  0
D - B           1  0  0  1  0
E - B           1  0  0  0  1
D - C           1  0  0  1  0
E - C           1  0  0  0  1
E - D           1  0  0  0  1
&amp;gt; 
&amp;gt; comp.mcmc = 100 * (coefs %*% t(pairwise.mat))/coefs %*% t(comp.mat)
&amp;gt; (comps = tidyMCMC(comp.mcmc, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 B - A    11.8       2.63     6.52     16.8 
 2 C - A    25.1       2.13    21.0      29.4 
 3 D - A     1.74      3.10    -4.30      7.88
 4 E - A   -34.3       5.09   -44.3     -24.4 
 5 C - B    15.0       2.24    10.4      19.2 
 6 D - B   -11.5       3.38   -18.1      -4.70
 7 E - B   -52.3       5.53   -63.2     -41.6 
 8 D - C   -31.2       3.73   -38.5     -23.9 
 9 E - C   -79.4       6.26   -91.9     -67.5 
10 E - D   -36.8       5.15   -47.1     -27.0 
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size (%)&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/posterior2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for the specific planned comparisons (Group 3 vs Group 5 and the average of Groups 1 and 2 vs the average of Groups 3, 4 and 5). This is achieved by generating our own contrast matrix (defining the contributions of each group to each contrast).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; c.mat = rbind(c(0, 0, -1, 0, 1), c(-1/2, -1/2, 1/3, 1/3, 1/3))
&amp;gt; c.mat
     [,1] [,2]       [,3]      [,4]      [,5]
[1,]  0.0  0.0 -1.0000000 0.0000000 1.0000000
[2,] -0.5 -0.5  0.3333333 0.3333333 0.3333333
&amp;gt; 
&amp;gt; mcmc = data.r2jags$BUGSoutput$sims.matrix
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:5]
&amp;gt; newdata &amp;lt;- data.frame(x = levels(data$x))
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data = newdata)
&amp;gt; c.mat = c.mat %*% Xmat
&amp;gt; c.mat
       (Intercept)   xB         xC        xD        xE
[1,]  0.000000e+00  0.0 -1.0000000 0.0000000 1.0000000
[2,] -1.110223e-16 -0.5  0.3333333 0.3333333 0.3333333
&amp;gt; 
&amp;gt; (comps = tidyMCMC(as.mcmc(coefs %*% t(c.mat)), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 2 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1    -23.7      1.29    -26.2    -21.2  
2 var2     -1.37     0.836    -3.01     0.273&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;      beta[1]  beta[2]  beta[3]    beta[4]    beta[5] deviance    sigma
[1,] 41.14988 5.425974 13.10634  0.5423808 -12.004913 245.9651 2.374957
[2,] 41.77436 3.165155 12.08478 -2.5284367 -11.070257 251.2837 3.546706
[3,] 39.87873 5.074910 13.46806  0.7805140  -7.932663 245.7947 3.020465
[4,] 41.15168 3.079048 10.80976 -0.5505218 -10.396170 249.3934 2.547300
[5,] 39.93263 4.548017 13.82126  1.2192389  -9.549601 242.2442 2.449639
[6,] 40.41198 4.705732 12.87972  2.3548628  -8.868949 250.1582 2.432338
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         9.94    0.528      8.86     10.9 
2 sd.resid     2.79    0.0903     2.67      2.96
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         78.3      1.07     76.0      79.7
2 sd.resid     21.7      1.07     20.3      24.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/JAGS/single-factor-anova-jags/2020-02-01-single-factor-anova-jags_files/figure-html/eff_pop1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(78.3\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- data.r2jags$BUGSoutput$sims.matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.887    0.0127    0.862     0.905
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ x, data))

Call:
lm(formula = y ~ x, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5257 -1.9000 -0.2589  1.4935  6.5330 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.2239     0.8801  45.702  &amp;lt; 2e-16 ***
xB            5.4020     1.2447   4.340 7.97e-05 ***
xC           13.5024     1.2447  10.848 3.82e-14 ***
xD            0.7423     1.2447   0.596    0.554    
xE          -10.2500     1.2447  -8.235 1.57e-10 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 2.783 on 45 degrees of freedom
Multiple R-squared:  0.8957,    Adjusted R-squared:  0.8865 
F-statistic: 96.64 on 4 and 45 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-model-selection&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bayesian model selection&lt;/h1&gt;
&lt;p&gt;A statistical model is by definition a low-dimensional (over simplification) representation of what is really likely to be a very complex system. As a result, no model is right. Some models however can provide useful insights into some of the processes operating on the system. Frequentist statistics have various methods (model selection, dredging, lasso, cross validation) for selecting parsimonious models. These are models that provide a good comprimise between minimizing unexplained patterns and minimizing model complexity. The basic premise is that since no model can hope to capture the full complexity of a system with all its subtleties, only the very major patterns can be estimated. Overly complex models are likely to be representing artificial complexity present only in the specific observed data (not the general population). The Bayesian approach is to apply priors to the non-variance parameters such that parameters close to zero are further shrunk towards zero whilst priors on parameters further away from zero are less effected. The most popular form of prior for sparsity is the &lt;em&gt;horseshoe prior&lt;/em&gt;, so called because the shape of a component of this prior resembles a horseshoe (with most of the mass either close to &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; or close to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Rather than apply weakly informative Gaussian priors on parameters as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\sigma^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the horseshoe prior is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2\lambda_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tau \sim \text{Cauchy}(0,1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j \sim \text{Cauchy}(0,1)\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(j=1,\ldots,D\)&lt;/span&gt;. Using this prior, &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is the number of (non-intercept or variance) parameters, &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; represents the global scale that weights or shrinks all parameters towards zero and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_j\)&lt;/span&gt; are thick tailed local scales that allow some of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; parameters to escape shrinkage. More recently, &lt;span class=&#34;citation&#34;&gt;Piironen, Vehtari, and others (2017)&lt;/span&gt; have argued that whilst the above horseshoe priors do guarantee that strong effects (parameters) will not be over-shrunk, there is the potential for weekly identified effects (those based on relatively little data) to be misrepresented in the posteriors. As an alternative they advocated the use of regularised horseshoe priors in which the amount of shrinkage applied to the largest effects can be controlled. The prior is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta_j \sim N(0,\tau^2 \tilde{\lambda}_j^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\tilde{\lambda}_j^2 = \frac{c^2\lambda^2_j}{c^2+\tau^2 \lambda^2_j}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is (slab width, actually variance) is a constant. For small effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;lt; c^2\)&lt;/span&gt;) the prior approaches a regular prior. However, for large effects (when &lt;span class=&#34;math inline&#34;&gt;\(\tau^2 \lambda^2_j &amp;gt; c^2\)&lt;/span&gt;) the prior approaches &lt;span class=&#34;math inline&#34;&gt;\(N(0,c^2)\)&lt;/span&gt;. Finally, they recommend applying a inverse-gamma prior on &lt;span class=&#34;math inline&#34;&gt;\(c^2\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ c^2 \sim \text{Inv-Gamma}(\alpha,\beta),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\alpha=v/2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta=vs^2/2\)&lt;/span&gt;, which translates to a &lt;span class=&#34;math inline&#34;&gt;\(\text{Student-t}_ν(0, s^2)\)&lt;/span&gt; slab for the coefficients far from zero and is typically a good default choice for a weakly informative prior.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-piironen2017sparsity&#34;&gt;
&lt;p&gt;Piironen, Juho, Aki Vehtari, and others. 2017. “Sparsity Information and Regularization in the Horseshoe and Other Shrinkage Priors.” &lt;em&gt;Electronic Journal of Statistics&lt;/em&gt; 11 (2): 5018–51.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-plummer2004jags&#34;&gt;
&lt;p&gt;Plummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2015package&#34;&gt;
&lt;p&gt;Su, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” &lt;em&gt;R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Single Factor Anova - STAN</title>
      <link>/stan/single-factor-anova-stan/single-factor-anova-stan/</link>
      <pubDate>Tue, 04 Feb 2020 21:13:14 -0500</pubDate>
      
      <guid>/stan/single-factor-anova-stan/single-factor-anova-stan/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. &lt;code&gt;BUGS&lt;/code&gt; (Bayesian inference Using &lt;em&gt;Gibbs Sampling&lt;/em&gt;) is an algorithm and supporting language (resembling &lt;code&gt;R&lt;/code&gt;) dedicated to performing the Gibbs sampling implementation of &lt;em&gt;Markov Chain Monte Carlo&lt;/em&gt; (MCMC) method. Dialects of the &lt;code&gt;BUGS&lt;/code&gt; language are implemented within three main projects:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OpenBUGS&lt;/strong&gt; - written in component pascal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;JAGS&lt;/strong&gt; - (Just Another Gibbs Sampler) - written in &lt;code&gt;C++&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STAN&lt;/strong&gt; - a dedicated Bayesian modelling framework written in &lt;code&gt;C++&lt;/code&gt; and implementing &lt;em&gt;Hamiltonian&lt;/em&gt; MCMC samplers.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of &lt;code&gt;R&lt;/code&gt;, and thus, they are best accessed from within &lt;code&gt;R&lt;/code&gt; itself. As such there are multiple packages devoted to interfacing with the various software implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2OpenBUGS&lt;/em&gt; - interfaces with &lt;code&gt;OpenBUGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;R2jags&lt;/em&gt; - interfaces with &lt;code&gt;JAGS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;rstan&lt;/em&gt; - interfaces with &lt;code&gt;STAN&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial will demonstrate how to fit models in &lt;code&gt;STAN&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Gelman, Lee, and Guo (2015)&lt;/span&gt;) using the package &lt;code&gt;rstan&lt;/code&gt; (&lt;span class=&#34;citation&#34;&gt;Stan Development Team (2018)&lt;/span&gt;) as interface, which also requires to load some other packages.&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Single factor Analysis of Variance&lt;/em&gt; (ANOVA), also known as single factor classification, is used to investigate the effect of a single factor comprising two or more groups (treatment levels) from a completely randomised design. Completely randomised refers to the absence of restrictions on the random allocation of experimental or sampling units to factor levels.&lt;/p&gt;
&lt;p&gt;For example, consider a situation in which three types of treatments (A, B and C) are applied to replicate sampling units across the sampling domain. Importantly, the treatments are applied at the scale of the sampling units and the treatments applied to each sampling unit do not extend to any other neighbouring sampling units. Another possible situation is where the scale of a treatment is far larger than that of a sampling unit. This design features two treatments, each replicated three times. Note that additional sampling units within each Site (the scale at which the treatment occurs) would NOT constitute additional replication. Rather, these would be sub-replicates. That is, they would be replicates of the Sites, not the treatments (since the treatments occur at the level of whole sites). In order to genuinely increase the number of replicates, it is necessary to have more Sites. The random allocation of sampling units within the sampling domain (such as population) is appropriate provided either the underlying response is reasonably homogenous throughout the domain, or else, there is a large number of sampling units. If the conditions are relatively hetrogenous, then the exact location of the sampling units is likely to be highly influential and may mask any detectable effects of treatments.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fixed-and-random-effects&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fixed and random effects&lt;/h2&gt;
&lt;p&gt;From a frequentist perspective, &lt;em&gt;fixed factors&lt;/em&gt; are factors whose levels represent the specific populations of interest. For example, a factor that comprises “high”, “medium” and “low” temperature treatments is a fixed factor - we are only interested in comparing those three populations. Conclusions about the effects of a fixed factor are restricted to the specific treatment levels investigated and for any subsequent experiments to be comparable, the same specific treatments of the factor would need to be used. By contrast, &lt;em&gt;random factors&lt;/em&gt; are factors whose levels are randomly chosen from all the possible levels of populations and are used as random representatives of the populations. For example, five random temperature treatments could be used to represent a full spectrum of temperature treatments. In this case, conclusions are extrapolated to all the possible treatment (temperature) levels and for subsequent experiments, a new random set of treatments of the factor would be selected.&lt;/p&gt;
&lt;p&gt;Other common examples of random factors include sites and subjects - factors for which we are attempting to generalise over. Furthermore, the nature of random factors means that we have no indication of how a new level of that factor (such as another subject or site) are likely to respond and thus it is not possible to predict new observations from random factors. These differences between fixed and random factors are reflected in the way their respective null hypotheses are formulated and interpreted. Whilst fixed factors contrast the effects of the different levels of the factor, random factors are modelled as the amount of additional variability they introduce. Random factors are modelled with a mean of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and their variance is estimated as the effect coefficient.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear model&lt;/h2&gt;
&lt;p&gt;The linear model for single factor classification is similar to that of multiple linear regression. The linear model can thus be represented by either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Means parameterisation&lt;/strong&gt; - in which the regression slopes represent the means of each treatment group and the intercept is removed (to prevent over-parameterisation).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \beta_1(\text{level}_1)_{ij} + \beta_2(\text{level}_2)_{ij} + \ldots + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; respectively represent the means response of treatment level &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt;. This is often simplified to &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\alpha_i + \epsilon_{ij}\)&lt;/span&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Effects parameterisation&lt;/strong&gt; - the intercept represents a property such as the mean of one of the treatment groups (treatment contrasts) or the overall mean (sum contrasts), and the slope parameters represent effects (differences between each other group and the reference mean for example).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_{ij} = \mu + \beta_2(\text{level}_2)_{ij} + \beta_3(\text{level}_3)_{ij} + \ldots + \epsilon_{ij},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the mean of the first treatment group, &lt;span class=&#34;math inline&#34;&gt;\(\beta_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_3\)&lt;/span&gt; respectively represent the effects (change from level &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;) of level &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; on the mean response. This is often simplified to: &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}=\mu + \alpha_i + \epsilon_{ij}\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1=0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since we are traditionally interested in investigating effects (differences) rather than treatment means, effects parameterisation is far more common (particularly when coupled with hypothesis testing). In a Bayesian framework, it does not really matter whether models are fit with means or effects parameterisation since the posterior likelihood can be querried in any way and repeatedly - thus enabling us to explore any specific effects after the model has been fit. Nevertheless, to ease comparisons with frequentist approaches, we will stick with effects paramterisation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis-fixed-factor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis: fixed factor&lt;/h2&gt;
&lt;p&gt;We can associate a null hypothesis test with each estimated parameter. For example, in a cell for each estimated mean in a means model we could test a null hypothesis that the population mean is equal to zero (e.g. &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\alpha_1=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\alpha_2=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\ldots\)&lt;/span&gt;). However, this rarely would be of much interest. By contrast, individual null hypotheses associated with each parameter of the effects model can be used to investigate the differences between each group and a reference group (for example). In addition to the individual null hypothesis tests, a single fixed factor ANOVA tests the collective &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; that there are no differences between the population group means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu_1=\mu_2=\ldots=\mu_i=\mu\)&lt;/span&gt; (the population group means are all equal). That is, that the mean of population &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; is equal to that of population &lt;span class=&#34;math inline&#34;&gt;\(2\)&lt;/span&gt; and so on, and thus all population means are equal to one another - no effect of the factor on the response. If the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group is the difference between the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th group mean and the mean of the first group (&lt;span class=&#34;math inline&#34;&gt;\(\alpha_i=\mu_i-\mu_1\)&lt;/span&gt;) then the &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; can alternatively be written as:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0 : \alpha_2=\alpha_3=\ldots=\alpha_i=0\)&lt;/span&gt; (the effect of each group equals zero). If one or more of the &lt;span class=&#34;math inline&#34;&gt;\(\alpha_i\)&lt;/span&gt; are different from zero (the response mean for this treatment differs from the overall response mean), there is evidence that the null hypothesis is not true indicating that the factor does affect the response variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;null-hypothesis-random-factor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null hypothesis: random factor&lt;/h2&gt;
&lt;p&gt;The collective &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; for a random factor is that the variance between all possible treatment groups equals zero:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0 : \sigma^2_{\alpha}=0\)&lt;/span&gt; (added variance due to this factor equals zero).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that whilst the null hypotheses for fixed and random factors are different (fixed: population group means all equal, random: variances between populations all equal zero), the linear model fitted for fixed and random factors in single factor ANOVA models is identical. For more complex multi-factor ANOVA models however, the distinction between fixed and random factors has important consequences for building and interpreting statistical models and null hypotheses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Analysis of variance&lt;/h2&gt;
&lt;p&gt;When the null hypothesis is true (and the populations are identical), the amount of variation among observations within groups should be similar to the amount of variation in observations between groups. However, when the null hypothesis is false (and some means are different from other means), the amount of variation among observations might be expected to be less than the amount of variation within groups. Analysis of variance, or ANOVA, partitions the total variance in the response (dependent) variable into a component of the variance that is explained by combinations of one or more categorical predictor variables (called factors) and a component of the variance that cannot be explained (residual). The variance ratio (F-ratio) from this partitioning can then be used to test the null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;) that the population group or treatment means are all equal. Ttotal variation can be decomposed into components explained by the groups (&lt;span class=&#34;math inline&#34;&gt;\(MS_{groups}\)&lt;/span&gt;) and and unexplained (&lt;span class=&#34;math inline&#34;&gt;\(MS_{residual}\)&lt;/span&gt;) by the groups. The gray arrows in b) depict the relative amounts explained by the groups. The proposed groupings generally explain why the first few points are higher on the y-axis than the last three points. The probability of collecting our sample, and thus generating the sample ratio of explained to unexplained variation (or one more extreme), when the null hypothesis is true (and population means are equal) is the area under the F-distribution beyond our sample ratio (&lt;span class=&#34;math inline&#34;&gt;\(\text{F-ratio}=\frac{MS_{groups}}{MS_{residual}}\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;When the null hypothesis is true (and the test assumptions have not been violated), the ratio (F-ratio) of explained to unexplained variance follows a theoretical probability distribution (F-distribution). When the null hypothesis is true, and there is no effect of the treatment on the response variable, the ratio of explained variability to unexplained variability is expected to be &lt;span class=&#34;math inline&#34;&gt;\(\leq 1\)&lt;/span&gt;. Since the denominator should represent the expected numerator in the absence of an effect. Importantly, the denominator in an F-ratio calculation essentially represents what we would expect the numerator to be in the absence of a treatment effect. For simple analyses, identifying what these expected values are is relatively straightforward (equivalent to the degree of within group variability). However, in more complex designs (particularly involving random factors and hierarchical treatment levels), the logical “groups” can be more difficult (and in some cases impossible) to identify. In such cases, nominating the appropriate F-ratio denominator for estimating an specific effect requires careful consideration. The following table depicts the anatomy of the single factor ANOVA table&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova_table
         df       MS       F-ratio          
Factor A &amp;quot;a-1&amp;quot;    &amp;quot;MS A&amp;quot;   &amp;quot;(MS A)/(MS res)&amp;quot;
Residual &amp;quot;(n-1)a&amp;quot; &amp;quot;MS res&amp;quot; &amp;quot;&amp;quot;               &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and corresponding &lt;code&gt;R&lt;/code&gt; syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; anova(lm(DV ~ A, dataset))
&amp;gt; # OR
&amp;gt; anova(aov(DV ~ A, dataset))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An F-ratio substantially greater than &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; suggests that the model relating the response variable to the categorical variable explains substantially more variability than is left unexplained. In turn, this implies that the linear model does represent the data well and that differences between observations can be explained largely by differences in treatment levels rather than purely the result of random variation. If the probability of getting the observed (sample) F-ratio or one more extreme is less than some predefined critical value (typically &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% or &lt;span class=&#34;math inline&#34;&gt;\(0.05\)&lt;/span&gt;), we conclude that it is highly unlikely that the observed samples could have been collected from populations in which the treatment has no effect and therefore we would reject the null hypothesis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;An F-ratio from real data can only reliably relate to a theoretical F-distribution when the data conform to certain assumptions. Hypothesis testing for a single factor ANOVA model assumes that the residuals (and therefore the response variable for each of the treatment levels) are all:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;normally distributed&lt;/strong&gt; - although ANOVA is robust to non-normality provided sample sizes and variances are equal. Boxplots should be used to explore normality, skewness, bimodality and outliers. In the event of homogeneity of variance issues (see below), a Q-Q normal plot can also be useful for exploring normality (as this might be the cause of non-homogeneity). Scale transformations are often useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;equally varied&lt;/strong&gt; - provided sample sizes are equal and the largest to smallest variance ratio does not exceed 3:1 (9:1 for sd), ANOVA is reasonably robust to this assumption, however, relationships between variance and mean and/or sample size are of particular concern as they elevate the Type I error rate. Boxplots and plots of means against variance should be used to explore the spread of values. Residual plots should reveal no patterns. Since unequal variances are often the result of non-normality, transformations that improve normality will also improve variance homogeneity.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;independent of one another&lt;/strong&gt; - this assumption must be addressed at the design and collection stages and cannot be compensated for later (unless a model is used that specifically accounts for particular types of non-independent data, such as that introduced with hierarchical designs or autocorrelation)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Violations of these assumptions reduce the reliability of the analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-generation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data generation&lt;/h1&gt;
&lt;p&gt;Lets say we had set up a natural experiment in which we measured a response from &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; sampling units (replicates) from each of &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; treatments. Hence, we have a single categorical factor with &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; levels - we might have five different locations, or five different habitat types or substrates etc. In statistical speak, we have sampled from &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt; different populations. We have then randomly selected &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; independent and random (representative) units of each population to sample. That is, we have &lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; samples (replicates) of each population. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; set.seed(123)
&amp;gt; ngroups &amp;lt;- 5  #number of populations
&amp;gt; nsample &amp;lt;- 10  #number of reps in each
&amp;gt; pop.means &amp;lt;- c(40, 45, 55, 40, 30)  #population mean length
&amp;gt; sigma &amp;lt;- 3  #residual standard deviation
&amp;gt; n &amp;lt;- ngroups * nsample  #total sample size
&amp;gt; eps &amp;lt;- rnorm(n, 0, sigma)  #residuals
&amp;gt; x &amp;lt;- gl(ngroups, nsample, n, lab = LETTERS[1:5])  #factor
&amp;gt; means &amp;lt;- rep(pop.means, rep(nsample, ngroups))
&amp;gt; X &amp;lt;- model.matrix(~x - 1)  #create a design matrix
&amp;gt; y &amp;lt;- as.numeric(X %*% pop.means + eps)
&amp;gt; data &amp;lt;- data.frame(y, x)
&amp;gt; head(data)  #print out the first six rows of the data set
         y x
1 38.31857 A
2 39.30947 A
3 44.67612 A
4 40.21153 A
5 40.38786 A
6 45.14519 A
&amp;gt; 
&amp;gt; write.csv(data, &amp;quot;simpleAnova.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type.&lt;/p&gt;
&lt;div id=&#34;exploratory-data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploratory data analysis&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Normality and Homogeneity of variance&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; boxplot(y ~ x, data)
&amp;gt; 
&amp;gt; # OR via ggplot2
&amp;gt; library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/exp_data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ggplot(data, aes(y = y, x = x)) + geom_boxplot() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/exp_data-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Hence it there is no evidence of non-homogeneity. Obvious violations could be addressed either by, for example, transforming the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The observed response (&lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;) are assumed to be drawn from a normal distribution with a given mean (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and standard deviation (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;). The expected values (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) are themselves determined by the linear predictor (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0+\boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;). In this case, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; represents the mean of the first group and the set of &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol \beta\)&lt;/span&gt;’s represent the differences between each other group and the first group. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;) for both the intercept and the treatment effect and a wide half-cauchy (&lt;span class=&#34;math inline&#34;&gt;\(\text{scale}=5\)&lt;/span&gt;) for the standard deviation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim N(\mu_i,\sigma),  \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X_i\)&lt;/span&gt;. The assumed priors are: &lt;span class=&#34;math inline&#34;&gt;\(\beta \sim N(0,100)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma \sim \text{Cauchy}(0,5)\)&lt;/span&gt;. We proceed to code the model into &lt;code&gt;STAN&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; modelString = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   //Likelihood
+   y~normal(mu,sigma);
+   
+   //Priors
+   beta ~ normal(0,1000);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString, con = &amp;quot;anovaModel.stan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Arrange the data as a list (as required by &lt;code&gt;STAN&lt;/code&gt;). As input, &lt;code&gt;STAN&lt;/code&gt; will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Xmat &amp;lt;- model.matrix(~x, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = Xmat, nX = ncol(Xmat), n = nrow(data)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the nodes (parameters and derivatives) to monitor and chain parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; params &amp;lt;- c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;, &amp;quot;log_lik&amp;quot;)
&amp;gt; nChains = 2
&amp;gt; burnInSteps = 500
&amp;gt; thinSteps = 1
&amp;gt; numSavedSteps = 2000  #across all chains
&amp;gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&amp;gt; nIter
[1] 1500&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now compile and run the Stan code via the &lt;code&gt;rstan&lt;/code&gt; interface. Note that the first time &lt;code&gt;stan&lt;/code&gt; is run after the &lt;code&gt;rstan&lt;/code&gt; package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(rstan)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;During the warmup stage, the No-U-Turn sampler (NUTS) attempts to determine the optimum stepsize - the stepsize that achieves the target acceptance rate (&lt;span class=&#34;math inline&#34;&gt;\(0.8\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(80\)&lt;/span&gt;% by default) without divergence (occurs when the stepsize is too large relative to the curvature of the log posterior and results in approximations that are likely to diverge and be biased) - and without hitting the maximum treedepth (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt;). At each iteration of the NUTS algorithm, the number of leapfrog steps doubles (as it increases the treedepth) and only terminates when either the NUTS criterion are satisfied or the tree depth reaches the maximum (&lt;span class=&#34;math inline&#34;&gt;\(10\)&lt;/span&gt; by default).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; data.rstan &amp;lt;- stan(data = data.list, file = &amp;quot;anovaModel.stan&amp;quot;, chains = nChains, pars = params,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;anovaModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.05 seconds (Warm-up)
Chain 1:                0.055 seconds (Sampling)
Chain 1:                0.105 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;anovaModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.049 seconds (Warm-up)
Chain 2:                0.063 seconds (Sampling)
Chain 2:                0.112 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; print(data.rstan, par = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%   75% 97.5% n_eff Rhat
beta[1]  40.24    0.04 0.89  38.45  39.69  40.24 40.87 41.93   634 1.01
beta[2]   5.38    0.04 1.25   2.97   4.54   5.36  6.18  7.86   833 1.00
beta[3]  13.48    0.04 1.29  10.89  12.64  13.41 14.34 15.97   888 1.00
beta[4]   0.70    0.04 1.25  -1.81  -0.13   0.69  1.56  3.06   949 1.01
beta[5] -10.27    0.04 1.25 -12.57 -11.13 -10.30 -9.40 -7.85   817 1.00
sigma     2.85    0.01 0.31   2.34   2.64   2.83  3.04  3.53  1108 1.00

Samples were drawn using NUTS(diag_e) at Mon Feb 17 11:28:36 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mcmc-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;MCMC diagnostics&lt;/h1&gt;
&lt;p&gt;In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Traceplots&lt;/em&gt; for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Autocorrelation&lt;/em&gt; plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;). A lag of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Potential scale reduction factor&lt;/em&gt; (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt;. If there are values of &lt;span class=&#34;math inline&#34;&gt;\(1.05\)&lt;/span&gt; or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package &lt;code&gt;mcmcplots&lt;/code&gt; to obtain density and trace plots for the effects model as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(mcmcplots)
&amp;gt; s = as.array(data.rstan)
&amp;gt; mcmc &amp;lt;- do.call(mcmc.list, plyr:::alply(s[, , -(length(s[1, 1, ]))], 2, as.mcmc))
&amp;gt; denplot(mcmc, parms = c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; traplot(mcmc, parms = c(&amp;quot;beta&amp;quot;,&amp;quot;sigma&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Raftery diagnostic
&amp;gt; raftery.diag(mcmc)
$`1`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

$`2`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Raftery diagnostics for each chain estimate that we would require no more than &lt;span class=&#34;math inline&#34;&gt;\(5000\)&lt;/span&gt; samples to reach the specified level of confidence in convergence. As we have &lt;span class=&#34;math inline&#34;&gt;\(10500\)&lt;/span&gt; samples, we can be confidence that convergence has occurred.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; #Autocorrelation diagnostic
&amp;gt; stan_ac(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_rhat(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; stan_ess(data.rstan, pars = c(&amp;quot;beta&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag4-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Rhat and effective sample size. In this instance, most of the parameters have reasonably high effective samples and thus there is likely to be a good range of values from which to estimate paramter properties.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-validation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model validation&lt;/h1&gt;
&lt;p&gt;Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model. Residuals are not computed directly within &lt;code&gt;rstan&lt;/code&gt; However, we can calculate them manually form the posteriors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(dplyr)
&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_residuals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Residuals against predictors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(tidyr)
&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = newdata
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; newdata = newdata %&amp;gt;% cbind(fit, resid)
&amp;gt; ggplot(newdata) + geom_point(aes(y = resid, x = x)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_residuals2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for studentised residuals&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; newdata = data
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = apply(mcmc[, 1:5], 2, median)
&amp;gt; fit = as.vector(coefs %*% t(Xmat))
&amp;gt; resid = data$y - fit
&amp;gt; sresid = resid/sd(resid)
&amp;gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_residuals3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this simple model, the studentized residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.data.frame(data.rstan) %&amp;gt;% dplyr:::select(contains(&amp;quot;beta&amp;quot;),
+     sigma) %&amp;gt;% as.matrix
&amp;gt; # generate a model matrix
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; ## get median parameter estimates
&amp;gt; coefs = mcmc[, 1:5]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; ## draw samples from this model
&amp;gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &amp;quot;sigma&amp;quot;]))
&amp;gt; newdata = data.frame(x = data$x, yRep) %&amp;gt;% gather(key = Sample,
+     value = Value, -x)
&amp;gt; ggplot(newdata) + geom_violin(aes(y = Value, x = x, fill = &amp;quot;Model&amp;quot;),
+     alpha = 0.5) + geom_violin(data = data, aes(y = y, x = x,
+     fill = &amp;quot;Obs&amp;quot;), alpha = 0.5) + geom_point(data = data, aes(y = y,
+     x = x), position = position_jitter(width = 0.1, height = 0),
+     color = &amp;quot;black&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_rep-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(bayesplot)
&amp;gt; mcmc_intervals(as.matrix(data.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_rep2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc_areas(as.matrix(data.rstan), regex_pars = &amp;quot;beta|sigma&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_rep2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parameter-estimates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Parameter estimates&lt;/h1&gt;
&lt;p&gt;Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% credibility intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmcpvalue &amp;lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/length(samp)
+     } else {
+         std &amp;lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &amp;lt;- colSums(std * std)
+         sum(sqdist[-1] &amp;gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we look at the results from the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; print(data.rstan, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
Inference for Stan model: anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%   75% 97.5% n_eff Rhat
beta[1]  40.24    0.04 0.89  38.45  39.69  40.24 40.87 41.93   634 1.01
beta[2]   5.38    0.04 1.25   2.97   4.54   5.36  6.18  7.86   833 1.00
beta[3]  13.48    0.04 1.29  10.89  12.64  13.41 14.34 15.97   888 1.00
beta[4]   0.70    0.04 1.25  -1.81  -0.13   0.69  1.56  3.06   949 1.01
beta[5] -10.27    0.04 1.25 -12.57 -11.13 -10.30 -9.40 -7.85   817 1.00
sigma     2.85    0.01 0.31   2.34   2.64   2.83  3.04  3.53  1108 1.00

Samples were drawn using NUTS(diag_e) at Mon Feb 17 11:28:36 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&amp;gt; 
&amp;gt; # OR
&amp;gt; library(broom)
&amp;gt; tidyMCMC(data.rstan, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;, pars = c(&amp;quot;beta&amp;quot;, &amp;quot;sigma&amp;quot;))
# A tibble: 6 x 5
  term    estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 beta[1]   40.2       0.895    38.4      41.9 
2 beta[2]    5.38      1.25      3.09      7.96
3 beta[3]   13.5       1.29     11.0      16.1 
4 beta[4]    0.703     1.25     -1.94      2.90
5 beta[5]  -10.3       1.25    -12.6      -7.85
6 sigma      2.85      0.306     2.33      3.50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the mean of the first group (A) is &lt;span class=&#34;math inline&#34;&gt;\(40.2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;the mean of the second group (B) is &lt;span class=&#34;math inline&#34;&gt;\(5.4\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the third group (C) is &lt;span class=&#34;math inline&#34;&gt;\(13.5\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the forth group (D) is &lt;span class=&#34;math inline&#34;&gt;\(0.74\)&lt;/span&gt; units greater than (A)&lt;/li&gt;
&lt;li&gt;the mean of the fifth group (E) is &lt;span class=&#34;math inline&#34;&gt;\(-10.2\)&lt;/span&gt; units greater (i.e. less) than (A)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(95\)&lt;/span&gt;% confidence interval for the effects of B, C and E do not overlap with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implying a significant difference between group A and groups B, C and E. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## since values are less than zero
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[2]&amp;quot;])  # effect of (B-A)
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[3]&amp;quot;])  # effect of (C-A)
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[4]&amp;quot;])  # effect of (D-A)
[1] 0.5805
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, &amp;quot;beta[5]&amp;quot;])  # effect of (E-A)
[1] 0
&amp;gt; mcmcpvalue(as.matrix(data.rstan)[, 2:5])  # effect of (all groups)
[1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is evidence that the reponse differs between the groups. There is evidence suggesting that the response of group D differs from that of group A. In a Bayesian context, we can compare models using the &lt;strong&gt;leave-one-out cross-validation&lt;/strong&gt; statistics. Leave-one-out (LOO) cross-validation explores how well a series of models can predict withheld values &lt;span class=&#34;citation&#34;&gt;Vehtari, Gelman, and Gabry (2017)&lt;/span&gt;. The LOO Information Criterion (LOOIC) is analogous to the AIC except that the LOOIC takes priors into consideration, does not assume that the posterior distribution is drawn from a multivariate normal and integrates over parameter uncertainty so as to yield a distribution of looic rather than just a point estimate. The LOOIC does however assume that all observations are equally influential (it does not matter which observations are left out). This assumption can be examined via the Pareto &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; estimate (values greater than &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt; or more conservatively &lt;span class=&#34;math inline&#34;&gt;\(0.75\)&lt;/span&gt; are considered overly influential). We can compute LOOIC if we store the loglikelihood from our &lt;code&gt;STAN&lt;/code&gt; model, which can then be extracted to compute the information criterion using the package &lt;code&gt;loo&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; library(loo)
&amp;gt; (full = loo(extract_log_lik(data.rstan)))

Computed from 2000 by 50 log-likelihood matrix

         Estimate   SE
elpd_loo   -125.8  5.1
p_loo         5.6  1.1
looic       251.6 10.2
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k &amp;lt; 0.5).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; # now fit a model without main factor
&amp;gt; modelString2 = &amp;quot;
+   data {
+   int&amp;lt;lower=1&amp;gt; n;
+   int&amp;lt;lower=1&amp;gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&amp;lt;lower=0&amp;gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   //Likelihood
+   y~normal(mu,sigma);
+   
+   //Priors
+   beta ~ normal(0,1000);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &amp;quot;
&amp;gt; 
&amp;gt; ## write the model to a stan file 
&amp;gt; writeLines(modelString2, con = &amp;quot;anovaModel2.stan&amp;quot;)
&amp;gt; 
&amp;gt; Xmat &amp;lt;- model.matrix(~1, data)
&amp;gt; data.list &amp;lt;- with(data, list(y = y, X = Xmat, n = nrow(data), nX = ncol(Xmat)))
&amp;gt; data.rstan.red &amp;lt;- stan(data = data.list, file = &amp;quot;anovaModel2.stan&amp;quot;, chains = nChains,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &amp;#39;anovaModel&amp;#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.019 seconds (Warm-up)
Chain 1:                0.042 seconds (Sampling)
Chain 1:                0.061 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &amp;#39;anovaModel&amp;#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.021 seconds (Warm-up)
Chain 2:                0.094 seconds (Sampling)
Chain 2:                0.115 seconds (Total)
Chain 2: 
&amp;gt; 
&amp;gt; (reduced = loo(extract_log_lik(data.rstan.red)))

Computed from 2000 by 50 log-likelihood matrix

         Estimate  SE
elpd_loo   -177.8 4.4
p_loo         1.6 0.3
looic       355.6 8.7
------
Monte Carlo SE of elpd_loo is 0.0.

All Pareto k estimates are good (k &amp;lt; 0.5).
See help(&amp;#39;pareto-k-diagnostic&amp;#39;) for details.
&amp;gt; 
&amp;gt; par(mfrow = 1:2, mar = c(5, 3.8, 1, 0) + 0.1, las = 3)
&amp;gt; plot(full, label_points = TRUE)
&amp;gt; plot(reduced, label_points = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_looic-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The expected out-of-sample predictive accuracy is substantially lower for the model that includes &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. This might be used to suggest that the inferential evidence for a general effect of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphical-summaries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Graphical summaries&lt;/h1&gt;
&lt;p&gt;With appropriate use of model matrices and data wrangling, it is possible to produce a single prediction data set along with &lt;code&gt;ggplot&lt;/code&gt; syntax to produce a multi-panel figure. First we look at the additive model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = as.matrix(data.rstan)
&amp;gt; ## Calculate the fitted values
&amp;gt; newdata = rbind(data.frame(x = levels(data$x)))
&amp;gt; Xmat = model.matrix(~x, newdata)
&amp;gt; coefs = mcmc[, c(&amp;quot;beta[1]&amp;quot;, &amp;quot;beta[2]&amp;quot;, &amp;quot;beta[3]&amp;quot;, &amp;quot;beta[4]&amp;quot;, &amp;quot;beta[5]&amp;quot;)]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; newdata = newdata %&amp;gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_linerange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_point() + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;X&amp;quot;) +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_post1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; ## Calculate partial residuals fitted values
&amp;gt; fdata = rdata = data
&amp;gt; fMat = rMat = model.matrix(~x, fdata)
&amp;gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&amp;gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&amp;gt; rdata = rdata %&amp;gt;% mutate(partial.resid = resid + fit)
&amp;gt; 
&amp;gt; ggplot(newdata, aes(y = estimate, x = as.numeric(x) - 0.1)) + geom_blank(aes(x = x)) +
+     geom_point(data = rdata, aes(y = partial.resid, x = as.numeric(x) +
+         0.1), color = &amp;quot;gray&amp;quot;) + geom_linerange(aes(ymin = conf.low, ymax = conf.high)) +
+     geom_point() + scale_y_continuous(&amp;quot;Y&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_post2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posteriors&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Posteriors&lt;/h1&gt;
&lt;p&gt;In frequentist statistics, when we have more than two groups, we are typically not only interested in whether there is evidence for an overall “effect” of a factor - we are also interested in how various groups compare to one another. To explore these trends, we either compare each group to each other in a pairwise manner (controlling for family-wise Type I error rates) or we explore an independent subset of the possible comparisons. Although these alternate approaches can adequately address a specific research agenda, often they impose severe limitations and compromises on the scope and breadth of questions that can be asked of your data. The reason for these limitations is that in a frequentist framework, any single hypothesis carries with it a (nominally) &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% chance of a false rejection (since it is based on long-run frequency). Thus, performing multiple tests are likely to compound this error rate. The point is, that each comparison is compared to its own probability distribution (and each carries a &lt;span class=&#34;math inline&#34;&gt;\(5\)&lt;/span&gt;% error rate). By contrast, in Bayesian statistics, all comparisons (contrasts) are drawn from the one (hopefully stable and convergent) posterior distribution and this posterior is invariant to the type and number of comparisons drawn. Hence, the theory clearly indicates that having generated our posterior distribution, we can then query this distribution in any way that we wish thereby allowing us to explore all of our research questions simultaneously.&lt;/p&gt;
&lt;p&gt;Bayesian “contrasts” can be performed either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;within the Bayesian sampling model or&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;construct them from the returned MCMC samples (they are drawn from the posteriors)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Only the latter will be demonstrated as it povides a consistent approach across all routines. In order to allow direct comparison to the frequentist equivalents, I will explore the same set of planned and &lt;em&gt;Tukey&lt;/em&gt;’s test comparisons described here. For the “planned comparison” we defined two contrasts: 1) group 3 vs group 5; and 2) the average of groups 1 and 2 vs the average of groups 3, 4 and 5.&lt;/p&gt;
&lt;p&gt;Lets start by comparing each group to each other group in a pairwise manner. Arguably the most elegant way to do this is to generate a Tukey’s contrast matrix. This is a model matrix specific to comparing each group to each other group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc = data.rstan
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:5]
&amp;gt; newdata &amp;lt;- data.frame(x = levels(data$x))
&amp;gt; # A Tukeys contrast matrix
&amp;gt; library(multcomp)
&amp;gt; # table(newdata$x) - gets the number of replicates of each level
&amp;gt; tuk.mat &amp;lt;- contrMat(n = table(newdata$x), type = &amp;quot;Tukey&amp;quot;)
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data = newdata)
&amp;gt; pairwise.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; pairwise.mat
      (Intercept) xB xC xD xE
B - A           0  1  0  0  0
C - A           0  0  1  0  0
D - A           0  0  0  1  0
E - A           0  0  0  0  1
C - B           0 -1  1  0  0
D - B           0 -1  0  1  0
E - B           0 -1  0  0  1
D - C           0  0 -1  1  0
E - C           0  0 -1  0  1
E - D           0  0  0 -1  1
&amp;gt; 
&amp;gt; mcmc_areas(coefs %*% t(pairwise.mat))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/posterior1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; 
&amp;gt; (comps = tidyMCMC(coefs %*% t(pairwise.mat), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 B - A    5.38       1.25     3.09      7.96
 2 C - A   13.5        1.29    11.0      16.1 
 3 D - A    0.703      1.25    -1.94      2.90
 4 E - A  -10.3        1.25   -12.6      -7.85
 5 C - B    8.10       1.28     5.71     10.8 
 6 D - B   -4.68       1.26    -7.06     -2.21
 7 E - B  -15.6        1.25   -18.3     -13.4 
 8 D - C  -12.8        1.29   -15.3     -10.1 
 9 E - C  -23.7        1.31   -26.2     -21.0 
10 E - D  -11.0        1.27   -13.5      -8.63
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/posterior1-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With a couple of modifications, we could also express this as percentage changes. A percentage change represents the change (difference between groups) divided by one of the groups (determined by which group you want to express the percentage change to). Hence, we generate an additional mcmc matrix that represents the cell means for the divisor group (group we want to express change relative to). Since the &lt;code&gt;tuk.mat&lt;/code&gt; defines comparisons as &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; pairs, if we simply replace all the &lt;span class=&#34;math inline&#34;&gt;\(-1\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;, the eventual matrix multiplication will result in estimates of the divisor cell means instread of the difference. We can then divide the original mcmc matrix above with this new divisor mcmc matrix to yeild a mcmc matrix of percentage change.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; # Modify the tuk.mat to replace -1 with 0.  This will allow us to get a
&amp;gt; # mcmc matrix of ..
&amp;gt; tuk.mat[tuk.mat == -1] = 0
&amp;gt; comp.mat &amp;lt;- tuk.mat %*% Xmat
&amp;gt; comp.mat
      (Intercept) xB xC xD xE
B - A           1  1  0  0  0
C - A           1  0  1  0  0
D - A           1  0  0  1  0
E - A           1  0  0  0  1
C - B           1  0  1  0  0
D - B           1  0  0  1  0
E - B           1  0  0  0  1
D - C           1  0  0  1  0
E - C           1  0  0  0  1
E - D           1  0  0  0  1
&amp;gt; 
&amp;gt; comp.mcmc = 100 * (coefs %*% t(pairwise.mat))/coefs %*% t(comp.mat)
&amp;gt; (comps = tidyMCMC(comp.mcmc, conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 B - A    11.8       2.59     6.40     16.5 
 2 C - A    25.1       2.11    20.9      29.1 
 3 D - A     1.67      3.02    -4.53      7.24
 4 E - A   -34.4       4.95   -43.7     -24.9 
 5 C - B    15.1       2.20    10.9      19.6 
 6 D - B   -11.5       3.27   -17.7      -5.09
 7 E - B   -52.3       5.36   -62.5     -41.7 
 8 D - C   -31.3       3.64   -38.4     -23.7 
 9 E - C   -79.4       6.27   -90.6     -66.2 
10 E - D   -36.7       5.06   -46.9     -27.4 
&amp;gt; 
&amp;gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
+     scale_y_continuous(&amp;quot;Effect size (%)&amp;quot;) + scale_x_discrete(&amp;quot;&amp;quot;) + coord_flip() +
+     theme_classic()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/posterior2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And now for the specific planned comparisons (Group 3 vs Group 5 and the average of Groups 1 and 2 vs the average of Groups 3, 4 and 5). This is achieved by generating our own contrast matrix (defining the contributions of each group to each contrast).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; c.mat = rbind(c(0, 0, -1, 0, 1), c(-1/2, -1/2, 1/3, 1/3, 1/3))
&amp;gt; c.mat
     [,1] [,2]       [,3]      [,4]      [,5]
[1,]  0.0  0.0 -1.0000000 0.0000000 1.0000000
[2,] -0.5 -0.5  0.3333333 0.3333333 0.3333333
&amp;gt; 
&amp;gt; mcmc = data.rstan
&amp;gt; coefs &amp;lt;- as.matrix(mcmc)[, 1:5]
&amp;gt; newdata &amp;lt;- data.frame(x = levels(data$x))
&amp;gt; Xmat &amp;lt;- model.matrix(~x, data = newdata)
&amp;gt; c.mat = c.mat %*% Xmat
&amp;gt; c.mat
       (Intercept)   xB         xC        xD        xE
[1,]  0.000000e+00  0.0 -1.0000000 0.0000000 1.0000000
[2,] -1.110223e-16 -0.5  0.3333333 0.3333333 0.3333333
&amp;gt; 
&amp;gt; (comps = tidyMCMC(as.mcmc(coefs %*% t(c.mat)), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;))
# A tibble: 2 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1    -23.7      1.31    -26.2    -21.0  
2 var2     -1.38     0.806    -2.92     0.186&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;finite-population-standard-deviations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finite population standard deviations&lt;/h1&gt;
&lt;p&gt;Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).&lt;/p&gt;
&lt;p&gt;Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (&lt;span class=&#34;citation&#34;&gt;Gelman and others (2005)&lt;/span&gt;). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         9.94    0.532      8.89     11.0 
2 sd.resid     2.79    0.0888     2.67      2.96
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 sd.x         78.3      1.06     76.0      79.7
2 sd.resid     21.7      1.06     20.3      24.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/effects_modelv4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Approximately &lt;span class=&#34;math inline&#34;&gt;\(78.3\)&lt;/span&gt;% of the total finite population standard deviation is due to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-squared&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R squared&lt;/h1&gt;
&lt;p&gt;In a frequentist context, the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; greater than &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt;%. &lt;span class=&#34;citation&#34;&gt;Gelman et al. (2019)&lt;/span&gt; proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.&lt;/p&gt;
&lt;p&gt;So in the standard regression model notation of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; could be formulated as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;, and for normal models &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; mcmc &amp;lt;- as.matrix(data.rstan)
&amp;gt; Xmat = model.matrix(~x, data)
&amp;gt; wch = grep(&amp;quot;beta&amp;quot;, colnames(mcmc))
&amp;gt; coefs = mcmc[, wch]
&amp;gt; fit = coefs %*% t(Xmat)
&amp;gt; resid = sweep(fit, 2, data$y, &amp;quot;-&amp;quot;)
&amp;gt; var_f = apply(fit, 1, var)
&amp;gt; var_e = apply(resid, 1, var)
&amp;gt; R2 = var_f/(var_f + var_e)
&amp;gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &amp;quot;HPDinterval&amp;quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 var1     0.887    0.0126    0.863     0.905
&amp;gt; 
&amp;gt; # for comparison with frequentist
&amp;gt; summary(lm(y ~ x, data))

Call:
lm(formula = y ~ x, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5257 -1.9000 -0.2589  1.4935  6.5330 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)  40.2239     0.8801  45.702  &amp;lt; 2e-16 ***
xB            5.4020     1.2447   4.340 7.97e-05 ***
xC           13.5024     1.2447  10.848 3.82e-14 ***
xD            0.7423     1.2447   0.596    0.554    
xE          -10.2500     1.2447  -8.235 1.57e-10 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 2.783 on 45 degrees of freedom
Multiple R-squared:  0.8957,    Adjusted R-squared:  0.8865 
F-statistic: 96.64 on 4 and 45 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-gelman2019r&#34;&gt;
&lt;p&gt;Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” &lt;em&gt;The American Statistician&lt;/em&gt; 73 (3): 307–9.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2015stan&#34;&gt;
&lt;p&gt;Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” &lt;em&gt;Journal of Educational and Behavioral Statistics&lt;/em&gt; 40 (5): 530–43.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelman2005analysis&#34;&gt;
&lt;p&gt;Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” &lt;em&gt;The Annals of Statistics&lt;/em&gt; 33 (1): 1–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rstanpackage&#34;&gt;
&lt;p&gt;Stan Development Team. 2018. “RStan: The R Interface to Stan.” &lt;a href=&#34;http://mc-stan.org/&#34;&gt;http://mc-stan.org/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vehtari2017practical&#34;&gt;
&lt;p&gt;Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and Waic.” &lt;em&gt;Statistics and Computing&lt;/em&gt; 27 (5): 1413–32.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
