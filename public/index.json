[{"authors":["agabrio"],"categories":null,"content":"I am a Research Fellow in Statistics and Health Economics in the Department of Statistical Science \u0026amp; in the Department of Primary Care and Population Health at University College London (UK). I graduated in Applied Economics from the University of Pavia (Italy) and in Statistics and Econometrics from the University of Essex (UK). I then completed a PhD programme in Statistics at University College London, after a short visiting period in the Department of Statistics at University of Florida (USA).\nMy main interests are in Bayesian statistical modelling for cost-effectiveness analysis and decision-making problems in the health systems. During my PhD I have specifically focused on the study and adoption of Bayesian methods to handle missing data in health economic evaluations and to assess the impact of their uncertainty on the output of the decision-making process. My research area involves different topics: from systematic literature reviews, case study applications, survival analysis, meta-analytic methods, multilevel models and trial-based clinical and economic analyses. I am very interested in the analysis of longitudinal data, with a focus on different types of statistical methods to deal with missingness.\nI am a member of the Statistics for Health Economic Evaluation research group in the Department of Statistical Science at UCL, which is mainly focused on the development and application of Bayesian methods for health economic evaluations. The group works in collaboration with academics from different institutions and its activities are aimed at providing advice to statisticians, health economists and clinicians working in economic evaluations.\nI am also a member of the Health Economics Analysis and Research methodology Team in the Institute for Clinical Trials and Methodology at UCL, working primarily with the members of the Priment Clinical Trials Unit. The group focuses on the development of methodological tools for the analysis of the economic components in randomised control trials across a wide range of clinical areas and is formed by a group of interdisciplinary and varied experience.\n","date":1517788800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1517788800,"objectID":"a4a58741d21f71aab0e211bcb1160621","permalink":"/authors/agabrio/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/agabrio/","section":"authors","summary":"I am a Research Fellow in Statistics and Health Economics in the Department of Statistical Science \u0026amp; in the Department of Primary Care and Population Health at University College London (UK). I graduated in Applied Economics from the University of Pavia (Italy) and in Statistics and Econometrics from the University of Essex (UK). I then completed a PhD programme in Statistics at University College London, after a short visiting period in the Department of Statistics at University of Florida (USA).","tags":null,"title":"Andrea Gabrio","type":"authors"},{"authors":[],"categories":null,"content":"","date":1562256000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562256000,"objectID":"83ff58a85903f76d2402e728102afadf","permalink":"/talk/hesg2019/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/talk/hesg2019/","section":"talk","summary":"Contibuted presentation","tags":["Economic Evaluations","Missing Data"],"title":"Adjusting for partially-observed utilities and costs in trial-based cost-effectiveness analysis: a comparison of different methods and their performance","type":"talk"},{"authors":["Andrea Gabrio"],"categories":["courses"],"content":"As member of the Health Economics Analysis and Research Methods Team (HEART), together with my colleagues, on Tuesday 2 July I took part in a 1-day introductory short course entitled “Understanding health economics in clinical trials”, which was designed and delivered by the team. HEART is a new group of health economists who are based in UCL’s Institute of Clinical Trials and Methodology (ICTM), led by Rachael Hunter, and is involved at different levels in the economic components of clinical trials in different trial units at UCL. This short course was aimed at ICTM staff who are not health economists (e.g. trial managers, CIs/PIs, statisticians, data managers, research assistants, etc.) and was designed in response to the need we have identified over the last few years in working on trials as well as in response to colleagues across ICTM. This course was unique as it was intended specifically for non health economists working in trials, who wish to better understand the health economics in their study, and/or the health economist on their study. The course used a mix of lectures, group discussions and practical exercises to help participants consolidate their learning and see how to apply information from the sessions to real studies. No prior knowledge of health economics was assumed.\nI believe the course was a success both in terms of the quality/quantity of the material covered during the six sessions throughout the day, as well as in terms of the positive feedback we received from the participants (almost entirely women, with the exception of two men). Many key and typically not well understood economic topics were discussed during the day, e.g. what are and how QALYs and costs are caclulated, the potential limitations and issues of an economic analysis within a trial, or the role played by the protocol and analysis plan in the economic evaluation. My session was related to reporting and interpreting health economic results and I realised that most people who do not routinely deal with health economics may find difficult to grasp certain concepts or tools used in the economic analysis (e.g. what is a cost-effectiveness acceptability curve and how it can be computed). Nevertheless, I must admit that I was surprised by how many people were very motivated to learn these concepts and these \u0026ldquo;difficult\u0026rdquo; methods, often asking questions and making good comments (despite the fact that my session was the last of the course at the end of the day).\nWe ran this course as a trial as we did not have clear ideas of what an optimal design should be or the number of topics that should be covered for this type of course. We are now confident that the course has a solid structure and that there is a clear demand to learn the basic concepts of health economics, at least among people involved in trial analyses. Following the successful delivery of the course, we are planning to replicate the experience in the future, improving certain aspects of the sessions based on the feedback we received and also considering to open the course to meet the demand of a wider audience.\nI have to say that this was an extremely positive experience for me as it was the first time I was involved in this type of projects. Me and my colleagues worked hard to design and prepare the different sessions of the course over the last few months, find the best way to link the arguments across the sessions, provide interesting group activities and materials for the practicals, etc. I have to thank all my colleagues who contributed to the promotion and realisation of this project, with a special mention for Caroline Clarke, who spent a lot of time and effort to organise the course and who personally contributed in giving one of the session of the course. Finally, I would also like to thank my colleague and health economist Ekaterina, with whom I had the pleasure to share the presentation and practical of my session in the course.\nPerhaps the only true negative aspect of the course was the absence of a Bayesian perspective, especially related to the interpretation of the results and the statistical methods that can be used to perform the analysis. Given the generally low familiarity of the people attending the course with statistics, I believe it was reasonable not to further confuse them with another new element into the picture. However, I truly hope that people will become more and more familiar with the importance of using tailored statistical methods in economic evaluations to avoid biased results, and from that point to justify a Bayesian approach, well, at least for me, the step is straightforward!.\n","date":1562112000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562153643,"objectID":"32751f66aea8e2316ec4874bd6c1d290","permalink":"/post/introduction-to-health-economics/understanding-health-economics-in-clinical-trials/","publishdate":"2019-07-03T00:00:00Z","relpermalink":"/post/introduction-to-health-economics/understanding-health-economics-in-clinical-trials/","section":"post","summary":"As member of the Health Economics Analysis and Research Methods Team (HEART), together with my colleagues, on Tuesday 2 July I took part in a 1-day introductory short course entitled “Understanding health economics in clinical trials”, which was designed and delivered by the team. HEART is a new group of health economists who are based in UCL’s Institute of Clinical Trials and Methodology (ICTM), led by Rachael Hunter, and is involved at different levels in the economic components of clinical trials in different trial units at UCL.","tags":["Academic","Clinical Trials","Health economics","introduction"],"title":"Understanding health economics in clinical trials","type":"post"},{"authors":[],"categories":null,"content":"","date":1562058000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562058000,"objectID":"cd757bbca2053fdc8ded948ff62c2cc3","permalink":"/talk/heartcourse2019/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/talk/heartcourse2019/","section":"talk","summary":"One day short course","tags":["Economic Evaluations","Clinical Trials"],"title":"Understanding Health Economics in Clinical Trials","type":"talk"},{"authors":[],"categories":null,"content":"","date":1560247200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560247200,"objectID":"56bfdbfa104cbed858b670d8954cd275","permalink":"/talk/albacete2019/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/talk/albacete2019/","section":"talk","summary":"Pre-conference workshop","tags":["Bayesian Statistics","Economic Evaluations","Missing Data"],"title":"Bayesian methods for addressing missing data in health economic evaluations","type":"talk"},{"authors":["A Gabrio","MJ Daniels","G Baio"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"6069360c460078f6e7c2128b47e6d1d2","permalink":"/publication/gabrio2019c/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/publication/gabrio2019c/","section":"publication","summary":"Trial-based economic evaluations are typically performed on cross-sectional variables, derived from the responses for only the completers in the study, using methods that ignore the complexities of utility and cost data (e.g. skewness and spikes). We present an alternative and more efficient Bayesian parametric approach to handle missing longitudinal outcomes in economic evaluations, while accounting for the complexities of the data. We specify a flexible parametric model for the observed data and partially identify the distribution of the missing data with partial identifying restrictions and sensitivity parameters. We explore alternative nonignorable scenarios through different priors for the sensitivity parameters, calibrated on the observed data. Our approach is motivated by, and applied to, data from a trial assessing the cost-effectiveness of a new treatment for intellectual disability and challenging behaviour.","tags":["Missing Data","Bayesian Statistics","Economic Evaluations"],"title":"A Bayesian Parametric Approach to Handle Missing Longitudinal Outcome Data in Trial-Based Health Economic Evaluations","type":"publication"},{"authors":["A Gabrio","G Baio","A Manca"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"58b637ad9c4945c334e3dbfbf3a955fe","permalink":"/publication/gabrio2019b/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/publication/gabrio2019b/","section":"publication","summary":"The evidence produced by healthcare economic evaluation studies is a key component of any health technology assessment (HTA) process designed to inform resource allocation decisions in a budget limited context. To improve the quality (and harmonize the generation process) of such evidence, many HTA agencies have established methodological guidelines describing the normative framework inspiring their decision-making process. The information requirements that economic evaluation analyses for HTA must satisfy typically involve the use of complex quantitative syntheses of multiple available datasets, handling mixtures of aggregate and patient-level information, and the use of sophisticated statistical models for the analysis of non-Normal data (e.g. time-to-event, quality of life and costs). Much of the recent methodological research in economic evaluation for healthcare has developed in response to these needs, in terms of sound statistical decision-theoretic foundations, and is increasingly being formulated within a Bayesian paradigm. The rationale for this preference lies in the fact that by taking a probabilistic approach, based on decision rules and available information, a Bayesian economic evaluation study can explicitly account for relevant sources of uncertainty in the decision process and produce information to identify an optimal course of actions.  Moreover, the Bayesian approach naturally allows the incorporation of an element of judgement or evidence from different sources (e.g.~expert opinion or multiple studies) into the analysis. This is particularly important when, as often occurs in economic evaluation for HTA, the evidence base is sparse and requires some inevitable mathematical modelling to bridge the gaps in the available data. The availability of free and open source software in the last two decades has greatly reduced the computational costs and facilitated the application of Bayesian methods and has the potential to improve the work of modellers and regulators alike, thus advancing the fields of economic evaluation of health care interventions. This chapter provides an overview of the areas where Bayesian methods have contributed to the address the methodological needs that stem from the normative framework adopted by a number of HTA agencies.","tags":["Economic Evaluations","Bayesian Statistics"],"title":"Bayesian Statistical Economic Evaluation Methods for Health Technology Assessment","type":"publication"},{"authors":["A Gabrio","R Hunter","AJ Mason","G Baio"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"59de577875bb81ae76f7296d27d711a0","permalink":"/publication/gabrio2019d/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/publication/gabrio2019d/","section":"publication","summary":"Failure to account for baseline utilities/costs imbalance between treatment groups in cost-effectiveness analyses can result in biased estimates and mislead the decision making process. The currently recommended adjustment approach is linear regression, with estimates that are typically evaluated at the mean of the baseline utilities/costs. However, a problem arises whenever there are some missing follow-up values and the evaluation is restricted to the complete cases. Should the mean of the complete cases or the available cases baseline utilities/costs be used in generating the adjusted estimates? To our knowledge there is no current guideline about this choice in the literature, with standard software implementations often implicitly selecting one of the methods. We use two trials as motivating examples to show that the two approaches can lead to substantially different conclusions for healthcare decision making and that standard approaches which automatically resort to complete case analysis are potentially dangerous and biased. Analysts should therefore consider methods that can explicitly incorporate missing data assumptions and assess the robustness of the results to a range of plausible alternatives.","tags":["Missing Data","Economic Evaluations"],"title":"Pitfalls of adjusting for mean baseline utilities/costs in trial-based cost-effectiveness analysis with missing data","type":"publication"},{"authors":["A Gabrio","AJ Mason","G Baio"],"categories":null,"content":"","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554076800,"objectID":"e4282ca40728b2e297a1792c11cd58b6","permalink":"/publication/gabrio2019a/","publishdate":"2019-04-01T00:00:00Z","relpermalink":"/publication/gabrio2019a/","section":"publication","summary":"Economic evaluations from individual?level data are an important component of the process of technology appraisal, with a view to informing resource allocation decisions. A critical problem in these analyses is that both effectiveness and cost data typically present some complexity (eg, nonnormality, spikes, and missingness) that should be addressed using appropriate methods. However, in routine analyses, standardised approaches are typically used, possibly leading to biassed inferences. We present a general Bayesian framework that can handle the complexity. We show the benefits of using our approach with a motivating example, the MenSS trial, for which there are spikes at one in the effectiveness and missingness in both outcomes. We contrast a set of increasingly complex models and perform sensitivity analysis to assess the robustness of the conclusions to a range of plausible missingness assumptions. We demonstrate the flexibility of our approach with a second example, the PBS trial, and extend the framework to accommodate the characteristics of the data in this study. This paper highlights the importance of adopting a comprehensive modelling approach to economic evaluations and the strategic advantages of building these complex models within a Bayesian framework. ","tags":["Missing Data","Economic Evaluations","Bayesian Statistics"],"title":"A Full Bayesian Model to Handle Structural Ones and Missingness in Economic Evaluations from Individual-Level Data","type":"publication"},{"authors":["Andrea Gabrio"],"categories":["R"],"content":"\rThe focus of this simple tutorial is to provide a brief introduction and overview about how to fit Bayesian models using JAGS via R.\nPrerequisites:\n\rThe latest version of R, which can be downloaded and installed for Windows, Mac or Linux OS from the CRAN website\rI also strongly recommend to download and install Rstudio, an integrated development environment which provides an “user-friendly” interaction with R (e.g. many drop-down menus, tabs, customisation options)\r\rPreliminaries\rWhat is JAGS?\rJAGS or Just Another Gibbs Sampler is a program for analysis of Bayesian models using Markov Chain Monte Carlo (MCMC) methods (Plummer (2004)). JAGS is a free software based on the Bayesian inference Using Gibbs Sampling (informally BUGS) language at the base of WinBUGS/OpenBUGS but, unlike these programs, it is written in C++ and is platform independent. The latest version of JAGS can be dowloaded from Martyn Plummer’s repository and is available for different OS. There are different R packages which function as frontends for JAGS. These packages make it easy to process the output of Bayesian models and present it in publication-ready form. In this brief introduction, I will specifically focus on the R2jags package (Su et al. (2015)) and show how to fit JAGS models using this package.\n\rInstalling JAGS and R2jags\rInstall the latest version of JAGS for your OS. Next, install the package R2jags from within R or Rstudio, via the package installer or by typing in the command line\n\u0026gt; install.packages(\u0026quot;R2jags\u0026quot;, dependencies = TRUE)\rThe dependencies = TRUE option will automatically install all the packages on which the functions in the R2jags package rely.\n\r\rBasic model\rSimulate data\rFor an example dataset, I simulate my own data in R. I create a continuous outcome variable \\(y\\) as a function of one predictor \\(x\\) and a disturbance term \\(\\epsilon\\). I simulate a dataset with 100 observations. Create the error term, the predictor and the outcome using a linear form with an intercept \\(\\beta_0\\) and slope \\(\\beta_1\\) coefficients, i.e.\n\\[y = \\beta_0 + \\beta_1 x + \\epsilon \\]\nThe R commands which I use to simulate the data are the following:\n\u0026gt; n.sim=100; set.seed(123)\r\u0026gt; x=rnorm(n.sim, mean = 5, sd = 2)\r\u0026gt; epsilon=rnorm(n.sim, mean = 0, sd = 1)\r\u0026gt; beta0=1.5\r\u0026gt; beta1=1.2\r\u0026gt; y=beta0 + beta1 * x + epsilon\rThen, I define all the data for JAGS in a list object\n\u0026gt; datalist=list(\u0026quot;y\u0026quot;,\u0026quot;x\u0026quot;,\u0026quot;n.sim\u0026quot;)\r\rModel file\rNow, I write the model for JAGS and save it as a text file named \"basic.mod.txt\" in the current working directory\n\u0026gt; basic.mod= \u0026quot;\r+ model {\r+ #model\r+ for(i in 1:n.sim){\r+ y[i] ~ dnorm(mu[i], tau)\r+ mu[i] = beta0 + beta1 * x[i]\r+ }\r+ #priors\r+ beta0 ~ dnorm(0, 0.01)\r+ beta1 ~ dnorm(0, 0.01)\r+ tau ~ dgamma(0.01,0.01)\r+ }\r+ \u0026quot;\rThe part of the model inside the for loop denotes the likelihood, which is evaluated for each individual in the sample using a Normal distribution parameterised by some mean mu and precision tau (where, precision = 1/variance). The covariate x is included at the mean level using a linear regression, which is indexed by the intercept beta0 and slope beta1 terms. The second part defines the prior distributions for all parameters of the model, namely the regression coefficients and the precision. Weakly informative priors are used since I assume that I do not have any prior knowledge about these parameters.\nTo write and save the model as the text file “basic.mod.txt” in the current working directory, I use the writeLines function\n\u0026gt; writeLines(basic.mod, \u0026quot;basic.mod.txt\u0026quot;)\r\rPre-processing\rDefine the parameters whose posterior distribtuions we are interested in summarising later and set up the initial values for the MCMC sampler in JAGS\n\u0026gt; params=c(\u0026quot;beta0\u0026quot;,\u0026quot;beta1\u0026quot;)\r\u0026gt; inits=function(){list(\u0026quot;beta0\u0026quot;=rnorm(1), \u0026quot;beta1\u0026quot;=rnorm(1))}\rThe function creates a list that contains one element for each parameter, which gets assigned a random draw from a normal distribution as a strating value for each chain in the model. For simple models like this, it is generally easy to define the intial values for all parameters. However, for more complex models, this may not be immediate and a lot of trial and error may be required. However, JAGS can automatically select the initial values for all parameters in an efficient way even for relatively complex models. This can be achieved by setting inits=NULL, which is then passed to the jags function in R2jags.\nBefore using R2jags for the first time, you need to load the package, and you may want to set a random seed number for making your estimates replicable\n\u0026gt; library(R2jags)\r\u0026gt; set.seed(123)\r\rFit the model\rNow, we can fit the model in JAGS using the jags function in the R2jags package and save it in the object basic.mod\n\u0026gt; basic.mod=jags(data = datalist, inits = inits,\r+ parameters.to.save = params, n.chains = 2, n.iter = 2000, + n.burnin = 1000, model.file = \u0026quot;basic.mod.txt\u0026quot;)\rCompiling model graph\rResolving undeclared variables\rAllocating nodes\rGraph information:\rObserved stochastic nodes: 100\rUnobserved stochastic nodes: 3\rTotal graph size: 406\rInitializing model\rWhile the model is running, the function prints out some information related to the Bayesian graph (corresponding to the specification used for the model) underneath JAGS, such as number of observed and unobserved nodes and graph size.\n\rPost-processing\rOnce the model has finished running, a summary of the posteiror estimates and convergence diagnostics for all parameters specified can be seen by typing print(basic.mod) or, alternatively,\n\u0026gt; print(basic.mod$BUGSoutput$summary)\r mean sd 2.5% 25% 50% 75% 97.5% Rhat n.eff\rbeta0 1.5 0.294 0.95 1.3 1.5 1.7 2.1 1 2000\rbeta1 1.2 0.054 1.07 1.1 1.2 1.2 1.3 1 2000\rdeviance 278.8 2.475 276.03 277.1 278.2 279.9 285.1 1 2000\rThe posterior distribution of each parameter is summarised in terms of:\n\rThe mean, sd and some percentiles\rPotential scale reduction factor Rhat and effective sample size n.eff (Gelman (2013)). The first is a measure to assess issues in convergence of the MCMC algorithm (typically a value below \\(1.05\\) for all parameters is considered ok). The second is a measure which assesses the adequacy of the posterior sample (typically values close to the total number of iterations are desirable for all parameters).\r\rThe deviance is a goodness of fit statistic and is used in the construction of the “Deviance Information Criterion” or DIC (Spiegelhalter et al. (2014)), which is a relative measure of model comparison. The DIC of the model can be accessed by typing\n\u0026gt; basic.mod$BUGSoutput$DIC\r[1] 282\r\rDiagnostics\rMore diagnostics are available when we convert the model output into an MCMC object using the command\n\u0026gt; basic.mod.mcmc=as.mcmc(basic.mod)\rDifferent packages are available to perform diagnostic checks for Bayesian models. Here, I install and load the mcmcplots package (Curtis (2015)) to obtain graphical diagnostics and results.\n\u0026gt; install.packages(\u0026quot;mcmcplots\u0026quot;)\r\u0026gt; library(mcmcplots)\rFor example, density and trace plots can be obtained by typing\n\u0026gt; denplot(basic.mod.mcmc, parms = c(\u0026quot;beta0\u0026quot;,\u0026quot;beta1\u0026quot;))\r\u0026gt; traplot(basic.mod.mcmc, parms = c(\u0026quot;beta0\u0026quot;,\u0026quot;beta1\u0026quot;))\rBoth types of graphs suggest that there are not issues in the convergence of the algorithm (smooth normal densities and hairy caterpillar graphs for both MCMC chains).\n\r\rConclusions\rThis tutorial was simply a brief introduction on how simple linear regression models can be fitted using the Bayesian software JAGS via the R2jags package. Although this may seem a complex procedure compared with simply fitting a linear model under the frequentist framework, however, the real advantages of Bayesian methods become evident when the complexity of the analysis is increased (which is often the case in real applications). Indeed, the flexibility in Bayesian modelling allows to account for increasingly complex models in a relatively easy way. In addition, Bayesian methods are ideal when the interest is in taking into account the potential impact that different sources of uncertainty may have on the final results, as they allow the natural propagation of uncertainty throughout each quantity in the model.\n\rReferences\rCurtis, SM. 2015. “Mcmcplots: Create Plots from Mcmc Output.” R Package Version 0.4 2.\n\rGelman, Andrew. 2013. Bayesian Data Analysis. Chapman; Hall/CRC.\n\rPlummer, Martyn. 2004. “JAGS: Just Another Gibbs Sampler.”\n\rSpiegelhalter, David J, Nicola G Best, Bradley P Carlin, and Angelika Van Der Linde. 2014. “The Deviance Information Criterion: 12 Years on.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 76 (3): 485–93.\n\rSu, Yu-Sung, Masanao Yajima, Maintainer Yu-Sung Su, and JAGS SystemRequirements. 2015. “Package ‘R2jags’.” R Package Version 0.03-08, URL Http://CRAN. R-Project. Org/Package= R2jags.\n\r\r\r","date":1535076794,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535076794,"objectID":"3e17280ebd0c2f5fb338cae0d6c210e8","permalink":"/jags/basic-introduction-to-jags/super-basic-introduction-to-jags/","publishdate":"2018-08-23T21:13:14-05:00","relpermalink":"/jags/basic-introduction-to-jags/super-basic-introduction-to-jags/","section":"JAGS","summary":"The focus of this simple tutorial is to provide a brief introduction and overview about how to fit Bayesian models using JAGS via R.\nPrerequisites:\n\rThe latest version of R, which can be downloaded and installed for Windows, Mac or Linux OS from the CRAN website\rI also strongly recommend to download and install Rstudio, an integrated development environment which provides an “user-friendly” interaction with R (e.g. many drop-down menus, tabs, customisation options)\r\rPreliminaries\rWhat is JAGS?","tags":["linear regression","JAGS","introduction"],"title":"Super basic introduction to JAGS","type":"JAGS"},{"authors":["Andrea Gabrio"],"categories":["R"],"content":"\rThe focus of this simple tutorial is to provide a brief introduction and overview about how to fit Bayesian models using STAN via R.\nPrerequisites:\n\rThe latest version of R, which can be downloaded and installed for Windows, Mac or Linux OS from the CRAN website\rI also strongly recommend to download and install Rstudio, an integrated development environment which provides an “user-friendly” interaction with R (e.g. many drop-down menus, tabs, customisation options)\r\rPreliminaries\rWhat is STAN?\rStan provides full Bayesian inference for continuous-variable models through Markov Chain Monte Carlo methods such as the No-U-Turn sampler, an adaptive form of Hamiltonian Monte Carlo sampling\nSTAN is a program for analysis of Bayesian models using Markov Chain Monte Carlo (MCMC) methods (Gelman, Lee, and Guo (2015)). STAN is a free software and a probabilistic programming language for specifying statistical models using a specific class of MCMC algorithms known as Hamiltonian Monte Carlo methods (HMC). The latest version of STAN can be dowloaded from the web repository and is available for different OS. There are different R packages which function as frontends for STAN. These packages make it easy to process the output of Bayesian models and present it in publication-ready form. In this brief introduction, I will specifically focus on the rstan package (Stan Development Team (2018)) and show how to fit STAN models using this package.\n\rInstalling STAN and rstan\rUnlike other Bayesian software, such as JAGS or OpenBUGS, it is not required to separately install the program and the corresponding frontend R package. Indeed, installing the R package rstan will automatically install STAN on your machine. However, you will also need to make sure to having installed on your pc a C++ compiler which is used by rstan to fit the models. Under a Windows OS, for example, this can be done by installing Rtools, a collection of resources for building packages for R, which is freely available from the web repository.\nNext, install the package rstan from within R or Rstudio, via the package installer or by typing in the command line\n\u0026gt; install.packages(\u0026quot;rstan\u0026quot;, dependencies = TRUE)\rThe dependencies = TRUE option will automatically install all the packages on which the functions in the rstan package rely.\n\r\rBasic model\rSimulate data\rFor an example dataset, I simulate my own data in R. I create a continuous outcome variable \\(y\\) as a function of one predictor \\(x\\) and a disturbance term \\(\\epsilon\\). I simulate a dataset with 100 observations. Create the error term, the predictor and the outcome using a linear form with an intercept \\(\\beta_0\\) and slope \\(\\beta_1\\) coefficients, i.e.\n\\[y = \\beta_0 + \\beta_1 x + \\epsilon \\]\nThe R commands which I use to simulate the data are the following:\n\u0026gt; n.sim=100; set.seed(123)\r\u0026gt; x=rnorm(n.sim, mean = 5, sd = 2)\r\u0026gt; epsilon=rnorm(n.sim, mean = 0, sd = 1)\r\u0026gt; beta0=1.5\r\u0026gt; beta1=1.2\r\u0026gt; y=beta0 + beta1 * x + epsilon\rThen, I define all the data for STAN in a list object\n\u0026gt; datalist=list(\u0026quot;y\u0026quot;,\u0026quot;x\u0026quot;,\u0026quot;n.sim\u0026quot;)\r\rModel file\rNow, I write the model for STAN and save it as a stan file named \"basic.mod.stan\" in the current working directory\n\u0026gt; basic.mod= \u0026quot;\r+ data {\r+ int\u0026lt;lower=0\u0026gt; N;\r+ vector[N] y;\r+ vector[N] x;\r+ }\r+ parameters {\r+ real beta0;\r+ real beta1;\r+ real\u0026lt;lower=0\u0026gt; sigma;\r+ }\r+ transformed parameters {\r+ vector[N] mu;\r+ mu=beta0 + beta1*x;\r+ } + model {\r+ sigma~uniform(0,100);\r+ beta0~normal(0,1000);\r+ beta1~normal(0,1000);\r+ y~normal(mu,sigma);\r+ }\r+ + \u0026quot;\rSTAN models are written using an imperative programming language, which means that the order in which you write the elements in your model file matters, i.e. you first need to define your variables (e.g. integers, vectors, matrices, etc.), the constraints which define the range of values your variable can take (e.g. only positive values for standard deviations), and finally define the relationship among the variables (e.g. one is a liner function of another).\nA Stan model is defined by six program blocks:\n\rData (required). The data block reads external information – e.g. data vectors, matrices, integers, etc.\rTransformed data (optional). The transformed data block allows for preprocessing of the data – e.g. transformation or rescaling of the data.\rParameters (required). The parameters block defines the sampling space – e.g. parameters to which prior distributions must be assigned.\rTransformed parameters (optional). The transformed parameters block allows for parameter processing before the posterior is computed – e.g. tranformation or rescaling of the parameters.\rModel (required). In the model block we define our posterior distributions – e.g. choice of distributions for all variables.\rGenerated quantities (optional). The generated quantities block allows for postprocessing – e.g. backtranformation of the parameters using the posterior samples.\r\rFor this introduction I consider a very simple model which only requires the specification of four blocks in the STAN model. In the data block, I first define the size of the sample N as a positive integer number using the expression int\u0026lt;lower=0\u0026gt; N; then I declare the two variables y and x as reals (or vectors) with length equal to N. In the parameters block, I define the coefficients for the linear regression beta0 and beta1 (as two real numbers) and the standard deviation parameter sigma (as a positive real number). In the transformed parameters block, I define the conditional mean mu (a real vector of length N) as a linear function of the intercept beta0, the slope beta1, and the covariate x. Finally, in the model block, I assign weakly informative priors to the regression coefficients and the standard deviation parameters, and I model the outcome data y using a normal distribution indexed by the conditional mean mu and the standard deviation sigma parameters. In many cases, STAN uses sampling statements which can be vectorised, i.e. you do not need to use for loop statements.\nTo write and save the model as the text file “basic.mod.stan” in the current working directory, I use the writeLines function\n\u0026gt; writeLines(basic.mod, \u0026quot;basic.mod.stan\u0026quot;)\r\rPre-processing\rDefine the parameters whose posterior distribtuions we are interested in summarising later and set up the initial values for the MCMC sampler in STAN\n\u0026gt; params=c(\u0026quot;beta0\u0026quot;,\u0026quot;beta1\u0026quot;)\r\u0026gt; inits=function(){list(\u0026quot;beta0\u0026quot;=rnorm(1), \u0026quot;beta1\u0026quot;=rnorm(1))}\rThe function creates a list that contains one element for each parameter, which gets assigned a random draw from a normal distribution as a strating value for each chain in the model. For simple models like this, it is generally easy to define the intial values for all parameters in the object inits which is then passed to the stan function in rstan. However, for more complex models, this may not be immediate and a lot of trial and error may be required. However, STAN can automatically select the initial values for all parameters randomly. This can be achieved by setting inits=\"random\", which is then passed to the stan function in rstan.\nBefore using rstan for the first time, you need to load the package, and you may want to set a random seed number for making your estimates replicable\n\u0026gt; library(rstan)\r\u0026gt; set.seed(123)\r\rFit the model\rNow, we can fit the model in STAN using the stan function in the rstan package and save it in the object basic.mod\n\u0026gt; #basic.mod\u0026lt;-stan(data = datalist, pars = params, \u0026gt; # iter = 9000, warmup = 1000, chains = 2, file = \u0026quot;basic.mod.stan\u0026quot;)\rGelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” Journal of Educational and Behavioral Statistics 40 (5): 530–43.\n\rStan Development Team. 2018. “RStan: The R Interface to Stan.” http://mc-stan.org/.\n\r\r\r\r","date":1532398394,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532398394,"objectID":"16a77cc23dd55d8ba6afba62a396f822","permalink":"/stan/basic-introduction-to-stan/super-basic-introduction-to-stan/","publishdate":"2018-07-23T21:13:14-05:00","relpermalink":"/stan/basic-introduction-to-stan/super-basic-introduction-to-stan/","section":"STAN","summary":"The focus of this simple tutorial is to provide a brief introduction and overview about how to fit Bayesian models using STAN via R.\nPrerequisites:\n\rThe latest version of R, which can be downloaded and installed for Windows, Mac or Linux OS from the CRAN website\rI also strongly recommend to download and install Rstudio, an integrated development environment which provides an “user-friendly” interaction with R (e.g. many drop-down menus, tabs, customisation options)\r\rPreliminaries\rWhat is STAN?","tags":["linear regression","STAN","introduction"],"title":"Super basic introduction to STAN","type":"STAN"},{"authors":["Andrea Gabrio"],"categories":["R"],"content":"\rThe focus of this simple tutorial is to provide a brief introduction and overview about how to fit Bayesian models using OpenBUGS via R.\nPrerequisites:\n\rThe latest version of R, which can be downloaded and installed for Windows, Mac or Linux OS from the CRAN website\rI also strongly recommend to download and install Rstudio, an integrated development environment which provides an “user-friendly” interaction with R (e.g. many drop-down menus, tabs, customisation options)\r\rPreliminaries\rWhat is OpenBUGS?\rOpenBUGS is a program for analysis of Bayesian models using Markov Chain Monte Carlo (MCMC) methods (Spiegelhalter et al. (2007)). OpenBUGS is a free software based on the Bayesian inference Using Gibbs Sampling (informally BUGS) language at the base of WinBUGS but, unlike this program, is platform independent. The latest version of OpenBUGS can be dowloaded from the web repository and is available for different OS. There are different R packages which function as frontends for OpenBUGS. These packages make it easy to process the output of Bayesian models and present it in publication-ready form. In this brief introduction, I will specifically focus on the R2OpenBUGS package (Sturtz, Ligges, and Gelman (2010)) and show how to fit OpenBUGS models using this package.\n\rInstalling OpenBUGS and R2OpenBUGS\rInstall the latest version of OpenBUGS for your OS. Next, install the package R2OpenBUGS from within R or Rstudio, via the package installer or by typing in the command line\n\u0026gt; install.packages(\u0026quot;R2OpenBUGS\u0026quot;, dependencies = TRUE)\rThe dependencies = TRUE option will automatically install all the packages on which the functions in the R2OpenBUGS package rely.\n\r\rBasic model\rSimulate data\rFor an example dataset, I simulate my own data in R. I create a continuous outcome variable \\(y\\) as a function of one predictor \\(x\\) and a disturbance term \\(\\epsilon\\). I simulate a dataset with 100 observations. Create the error term, the predictor and the outcome using a linear form with an intercept \\(\\beta_0\\) and slope \\(\\beta_1\\) coefficients, i.e.\n\\[y = \\beta_0 + \\beta_1 x + \\epsilon \\]\nThe R commands which I use to simulate the data are the following:\n\u0026gt; n.sim=100; set.seed(123)\r\u0026gt; x=rnorm(n.sim, mean = 5, sd = 2)\r\u0026gt; epsilon=rnorm(n.sim, mean = 0, sd = 1)\r\u0026gt; beta0=1.5\r\u0026gt; beta1=1.2\r\u0026gt; y=beta0 + beta1 * x + epsilon\rThen, I define all the data for JAGS in a list object\n\u0026gt; datalist=list(\u0026quot;y\u0026quot;,\u0026quot;x\u0026quot;,\u0026quot;n.sim\u0026quot;)\r\rModel file\rNow, I write the model for OpenBUGS and save it as a text file named \"basicmodbugs.txt\" in the current working directory\n\u0026gt; basic.mod= \u0026quot;\r+ model {\r+ #model\r+ for(i in 1:n.sim){\r+ y[i] ~ dnorm(mu[i], tau)\r+ mu[i] \u0026lt;- beta0 + beta1 * x[i]\r+ }\r+ #priors\r+ beta0 ~ dnorm(0, 0.01)\r+ beta1 ~ dnorm(0, 0.01)\r+ tau ~ dgamma(0.01,0.01)\r+ }\r+ \u0026quot;\rThe part of the model inside the for loop denotes the likelihood, which is evaluated for each individual in the sample using a Normal distribution parameterised by some mean mu and precision tau (where, precision = 1/variance). The covariate x is included at the mean level using a linear regression, which is indexed by the intercept beta0 and slope beta1 terms. The second part defines the prior distributions for all parameters of the model, namely the regression coefficients and the precision. Weakly informative priors are used since I assume that I do not have any prior knowledge about these parameters.\nTo write and save the model as the text file “basicmodbugs.txt” in the current working directory, I use the writeLines function\n\u0026gt; writeLines(basic.mod, \u0026quot;basicmodbugs.txt\u0026quot;)\r\rPre-processing\rDefine the parameters whose posterior distribtuions we are interested in summarising later and set up the initial values for the MCMC sampler in OpenBUGS\n\u0026gt; params=c(\u0026quot;beta0\u0026quot;,\u0026quot;beta1\u0026quot;)\r\u0026gt; inits=function(){list(\u0026quot;beta0\u0026quot;=rnorm(1), \u0026quot;beta1\u0026quot;=rnorm(1), \u0026quot;tau\u0026quot;=rgamma(1,1,1))}\rThe function creates a list that contains one element for each parameter, which gets assigned a random draw from a normal distribution as a strating value for each chain in the model. For simple models like this, it is generally easy to define the intial values for all parameters in the object inits which is then passed to the bugs function in R2OpenBUGS. However, for more complex models, this may not be immediate and a lot of trial and error may be required.\nBefore using R2OpenBUGS for the first time, you need to load the package, and you may want to set a random seed number for making your estimates replicable\n\u0026gt; library(R2OpenBUGS)\r\u0026gt; set.seed(123)\r\rFit the model\rNow, we can fit the model in OpenBUGS using the bugs function in the R2openBUGS package and save it in the object basic.mod\n\u0026gt; basic.mod.bugs=bugs(data = datalist, inits = inits, + parameters.to.save = params, n.chains = 2, n.iter = 2000,\r+ n.burnin = 1000, model.file = \u0026quot;basicmodbugs.txt\u0026quot;)\rWhile the model is running, the function prints out some information related to the Bayesian graph (corresponding to the specification used for the model) underneath OpenBUGS, such as number of observed and unobserved nodes and graph size.\n\rPost-processing\rOnce the model has finished running, a summary of the posteiror estimates and convergence diagnostics for all parameters specified can be seen by typing print(basic.mod) or, alternatively,\n\u0026gt; print(basic.mod.bugs$summary)\r mean sd 2.5% 25% 50% 75% 97.5% Rhat n.eff\rbeta0 1.5 0.293 0.99 1.3 1.5 1.7 2.1 1 1700\rbeta1 1.2 0.053 1.06 1.1 1.2 1.2 1.3 1 2000\rdeviance 278.8 2.439 276.00 277.1 278.2 280.0 285.2 1 2000\rThe posterior distribution of each parameter is summarised in terms of:\n\rThe mean, sd and some percentiles\rPotential scale reduction factor Rhat and effective sample size n.eff (Gelman (2013)). The first is a measure to assess issues in convergence of the MCMC algorithm (typically a value below \\(1.05\\) for all parameters is considered ok). The second is a measure which assesses the adequacy of the posterior sample (typically values close to the total number of iterations are desirable for all parameters).\r\rThe deviance is a goodness of fit statistic and is used in the construction of the “Deviance Information Criterion” or DIC (Spiegelhalter et al. (2014)), which is a relative measure of model comparison. The DIC of the model can be accessed by typing\n\u0026gt; basic.mod.bugs$DIC\r[1] 282\r\rDiagnostics\rMore diagnostics are available when we convert the model output into an MCMC object using the command\n\u0026gt; install.packages(\u0026quot;coda\u0026quot;)\r\u0026gt; library(coda)\r\u0026gt; basic.mod.mcmc.bugs=as.mcmc.list(basic.mod.bugs)\rDifferent packages are available to perform diagnostic checks for Bayesian models. Here, I install and load the mcmcplots package (Curtis (2015)) to obtain graphical diagnostics and results.\n\u0026gt; install.packages(\u0026quot;mcmcplots\u0026quot;)\r\u0026gt; library(mcmcplots)\rFor example, density and trace plots can be obtained by typing\n\u0026gt; denplot(basic.mod.mcmc.bugs, parms = c(\u0026quot;beta0\u0026quot;,\u0026quot;beta1\u0026quot;))\r\u0026gt; traplot(basic.mod.mcmc.bugs, parms = c(\u0026quot;beta0\u0026quot;,\u0026quot;beta1\u0026quot;))\rBoth types of graphs suggest that there are not issues in the convergence of the algorithm (smooth normal densities and hairy caterpillar graphs for both MCMC chains).\n\r\rConclusions\rThis tutorial was simply a brief introduction on how simple linear regression models can be fitted using the Bayesian software OpenBUGS via the R2OpenBUGS package. Although this may seem a complex procedure compared with simply fitting a linear model under the frequentist framework, however, the real advantages of Bayesian methods become evident when the complexity of the analysis is increased (which is often the case in real applications). Indeed, the flexibility in Bayesian modelling allows to account for increasingly complex models in a relatively easy way. In addition, Bayesian methods are ideal when the interest is in taking into account the potential impact that different sources of uncertainty may have on the final results, as they allow the natural propagation of uncertainty throughout each quantity in the model.\n\rReferences\rCurtis, SM. 2015. “Mcmcplots: Create Plots from Mcmc Output.” R Package Version 0.4 2.\n\rGelman, Andrew. 2013. Bayesian Data Analysis. Chapman; Hall/CRC.\n\rSpiegelhalter, David J, Nicola G Best, Bradley P Carlin, and Angelika Van Der Linde. 2014. “The Deviance Information Criterion: 12 Years on.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 76 (3): 485–93.\n\rSpiegelhalter, David, Andrew Thomas, Nicky Best, and Dave Lunn. 2007. “OpenBUGS User Manual, Version 3.0. 2.” MRC Biostatistics Unit, Cambridge.\n\rSturtz, Sibylle, Uwe Ligges, and Andrew Gelman. 2010. “R2OpenBUGS: A Package for Running Openbugs from R.” URL Http://Cran. Rproject. Org/Web/Packages/R2OpenBUGS/Vignettes/R2OpenBUGS. Pdf.\n\r\r\r","date":1532398274,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532398274,"objectID":"dd38afcc7412084a4fc897a7e681d0f6","permalink":"/openbugs/basic-introduction-to-openbugs/super-basic-introduction-to-openbugs/","publishdate":"2018-07-23T21:11:14-05:00","relpermalink":"/openbugs/basic-introduction-to-openbugs/super-basic-introduction-to-openbugs/","section":"OpenBUGS","summary":"The focus of this simple tutorial is to provide a brief introduction and overview about how to fit Bayesian models using OpenBUGS via R.\nPrerequisites:\n\rThe latest version of R, which can be downloaded and installed for Windows, Mac or Linux OS from the CRAN website\rI also strongly recommend to download and install Rstudio, an integrated development environment which provides an “user-friendly” interaction with R (e.g. many drop-down menus, tabs, customisation options)\r\rPreliminaries\rWhat is OpenBUGS?","tags":["linear regression","OpenBUGS","introduction"],"title":"Super basic introduction to OpenBUGS","type":"OpenBUGS"},{"authors":[],"categories":null,"content":"","date":1527858000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527858000,"objectID":"ea9f4848b6ad6d57bd35e16b751992b0","permalink":"/talk/priment2018/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/talk/priment2018/","section":"talk","summary":"Invited presentation","tags":["Economic Evaluations","Missing Data"],"title":"A Bayesian Parametric Approach to Handle Nonignorable Missingness in Economic Evaluations","type":"talk"},{"authors":[],"categories":null,"content":"","date":1517824800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517824800,"objectID":"6595e4086447a19af1feb033b3a8201a","permalink":"/talk/hesymposium2018/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/talk/hesymposium2018/","section":"talk","summary":"Invited presentation","tags":["Bayesian Statistics","Economic Evaluations","Missing Data"],"title":"A Full Bayesian Model to Handle Structural Ones and Missingness in Health Economic Evaluations from Individual-Level Data","type":"talk"},{"authors":["A Gabrio","AJ Mason","G Baio"],"categories":null,"content":"","date":1496275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496275200,"objectID":"bbef5e786cc53704ee1f92102539d5e4","permalink":"/publication/gabrio2017/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/publication/gabrio2017/","section":"publication","summary":"Cost-effectiveness analyses (CEAs) alongside randomised controlled trials (RCTs) are increasingly designed to collect resource use and preference-based health status data for the purpose of healthcare technology assessment. However, because of the way these measures are collected, they are prone to missing data, which can ultimately affect the decision of whether an intervention is good value for money. We examine how missing cost and effect outcome data are handled in RCT-based CEAs, complementing a previous review (covering 2003-2009, 88 articles) with a new systematic review (2009-2015, 81 articles) focussing on two different perspectives. First, we provide guidelines on how the information about missingness and related methods should be presented to improve the reporting and handling of missing data. We propose to address this issue by means of a quality evaluation scheme, providing a structured approach that can be used to guide the collection of information, elicitation of the assumptions, choice of methods and considerations of possible limitations of the given missingness problem. Second, we review the description of the missing data, the statistical methods used to deal with them and the quality of the judgement underpinning the choice of these methods. Our review shows that missing data in within-RCT CEAs are still often inadequately handled and the overall level of information provided to support the chosen methods is rarely satisfactory. ","tags":["Missing Data","Economic Evaluations","Literature Review"],"title":"Handling Missing Data in Within-Trial Cost-Effectiveness Analysis: A Review with Future Recommendations","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1496275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496275200,"objectID":"264b6a73ec81e06fc20279d323edf442","permalink":"/project/missing-data-review/","publishdate":"2017-06-01T00:00:00Z","relpermalink":"/project/missing-data-review/","section":"project","summary":"With [Alexina Mason](https://www.lshtm.ac.uk/aboutus/people/mason.alexina) and [Gianluca Baio](https://www.ucl.ac.uk/statistics/people/gianlucabaio)","tags":["Missing Data"],"title":"Missingness Methods in trial-based CEA","type":"project"},{"authors":[],"categories":null,"content":"","date":1473346800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473346800,"objectID":"a177d4c811e51520cedd357bee093b9f","permalink":"/talk/euhea2016/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/talk/euhea2016/","section":"talk","summary":"Contributed presentation","tags":["Economic Evaluations","Missing Data"],"title":"Handling Missing Data in Within-Trial Cost-Effectiveness Analysis: a Review with Future Recommendations","type":"talk"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"971bed50bf7791bf6b8581ec7b3373d8","permalink":"/project/health-economics/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/health-economics/","section":"project","summary":"With [Andrea Manca](https://www.york.ac.uk/che/staff/research/andrea-manca/) and [Gianluca Baio](https://www.ucl.ac.uk/statistics/people/gianlucabaio)","tags":["Health Economics","Bayesian Modelling"],"title":"Bayesian Methods for Health Technology Assessment","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"159ff484bc950a41748df648cbd474ee","permalink":"/project/bayesian-modelling/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/bayesian-modelling/","section":"project","summary":"With [Alexina Mason](https://www.lshtm.ac.uk/aboutus/people/mason.alexina) and [Gianluca Baio](https://www.ucl.ac.uk/statistics/people/gianlucabaio)","tags":["Bayesian Modelling","Health Economics"],"title":"Bayesian Modelling for Health Economic Evaluations","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"64ed545a4c3df615031db54dc419fefc","permalink":"/project/missing-data/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/missing-data/","section":"project","summary":"With [Michael Daniels](http://users.stat.ufl.edu/~daniels/) and [Gianluca Baio](https://www.ucl.ac.uk/statistics/people/gianlucabaio)","tags":["Missing Data"],"title":"Nonignorable Missingness Models in HTA","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"/research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"","tags":null,"title":"Research","type":"widget_page"}]