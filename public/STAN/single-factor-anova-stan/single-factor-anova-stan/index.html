<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.3.1">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Andrea Gabrio">

  
  
  
    
  
  <meta name="description" content="This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. BUGS (Bayesian inference Using Gibbs Sampling) is an algorithm and supporting language (resembling R) dedicated to performing the Gibbs sampling implementation of Markov Chain Monte Carlo (MCMC) method. Dialects of the BUGS language are implemented within three main projects:
OpenBUGS - written in component pascal.
JAGS - (Just Another Gibbs Sampler) - written in C&#43;&#43;.">

  
  <link rel="alternate" hreflang="en-us" href="/stan/single-factor-anova-stan/single-factor-anova-stan/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:450,700|Oswald+Sans:600,700|Roboto+Mono:550,700">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.a71200610c21759266bff163bb521d95.css">

  
    
    
    
    
      
    
    
    
    <link rel="stylesheet" href="/css/academic.3f1befffb0882d6c3372ec9dda375740.css">
  

  
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/stan/single-factor-anova-stan/single-factor-anova-stan/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Andrea Gabrio">
  <meta property="og:url" content="/stan/single-factor-anova-stan/single-factor-anova-stan/">
  <meta property="og:title" content="Single Factor Anova - STAN | Andrea Gabrio">
  <meta property="og:description" content="This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. BUGS (Bayesian inference Using Gibbs Sampling) is an algorithm and supporting language (resembling R) dedicated to performing the Gibbs sampling implementation of Markov Chain Monte Carlo (MCMC) method. Dialects of the BUGS language are implemented within three main projects:
OpenBUGS - written in component pascal.
JAGS - (Just Another Gibbs Sampler) - written in C&#43;&#43;."><meta property="og:image" content="/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2020-02-04T21:13:14-05:00">
  
  <meta property="article:modified_time" content="2020-02-04T21:13:14-05:00">
  

  


  





  <title>Single Factor Anova - STAN | Andrea Gabrio</title>

</head>


<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Andrea Gabrio</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/post/"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/research/"><span>Research</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/publication/"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/talk/"><span>Talks</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Software</span><span class="caret"></span>
          </a>
          <ul class="dropdown-menu">
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/missingHE/"><span>missingHE</span></a>
            </li>
            
          </ul>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Tutorials</span><span class="caret"></span>
          </a>
          <ul class="dropdown-menu">
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/JAGS/"><span>JAGS</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/OpenBUGS/"><span>OpenBUGS</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/STAN/"><span>STAN</span></a>
            </li>
            
          </ul>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/missingdata/"><span>Missing Data</span></a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        

      </ul>

    </div>
  </div>
</nav>


  <article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Single Factor Anova - STAN</h1>

  

  
    



<meta content="2020-02-04 21:13:14 -0500 -0500" itemprop="datePublished">
<meta content="2020-02-04 21:13:14 -0500 -0500" itemprop="dateModified">

<div class="article-metadata">

  
  
  
  
  <div>
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a>Andrea Gabrio</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    <time>Feb 4, 2020</time>
  </span>
  

  

  

  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder"></i>
    <a href="/categories/r/">R</a>, <a href="/categories/anova/">anova</a>, <a href="/categories/stan/">STAN</a>, <a href="/categories/facor-analysis/">facor analysis</a></span>
  

  
    

  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. <code>BUGS</code> (Bayesian inference Using <em>Gibbs Sampling</em>) is an algorithm and supporting language (resembling <code>R</code>) dedicated to performing the Gibbs sampling implementation of <em>Markov Chain Monte Carlo</em> (MCMC) method. Dialects of the <code>BUGS</code> language are implemented within three main projects:</p>
<ol style="list-style-type: decimal">
<li><p><strong>OpenBUGS</strong> - written in component pascal.</p></li>
<li><p><strong>JAGS</strong> - (Just Another Gibbs Sampler) - written in <code>C++</code>.</p></li>
<li><p><strong>STAN</strong> - a dedicated Bayesian modelling framework written in <code>C++</code> and implementing <em>Hamiltonian</em> MCMC samplers.</p></li>
</ol>
<p>Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of <code>R</code>, and thus, they are best accessed from within <code>R</code> itself. As such there are multiple packages devoted to interfacing with the various software implementations:</p>
<ul>
<li><p><em>R2OpenBUGS</em> - interfaces with <code>OpenBUGS</code></p></li>
<li><p><em>R2jags</em> - interfaces with <code>JAGS</code></p></li>
<li><p><em>rstan</em> - interfaces with <code>STAN</code></p></li>
</ul>
<p>This tutorial will demonstrate how to fit models in <code>STAN</code> (<span class="citation">Gelman, Lee, and Guo (2015)</span>) using the package <code>rstan</code> (<span class="citation">Stan Development Team (2018)</span>) as interface, which also requires to load some other packages.</p>
<div id="overview" class="section level1">
<h1>Overview</h1>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p><em>Single factor Analysis of Variance</em> (ANOVA), also known as single factor classification, is used to investigate the effect of a single factor comprising two or more groups (treatment levels) from a completely randomised design. Completely randomised refers to the absence of restrictions on the random allocation of experimental or sampling units to factor levels.</p>
<p>For example, consider a situation in which three types of treatments (A, B and C) are applied to replicate sampling units across the sampling domain. Importantly, the treatments are applied at the scale of the sampling units and the treatments applied to each sampling unit do not extend to any other neighbouring sampling units. Another possible situation is where the scale of a treatment is far larger than that of a sampling unit. This design features two treatments, each replicated three times. Note that additional sampling units within each Site (the scale at which the treatment occurs) would NOT constitute additional replication. Rather, these would be sub-replicates. That is, they would be replicates of the Sites, not the treatments (since the treatments occur at the level of whole sites). In order to genuinely increase the number of replicates, it is necessary to have more Sites. The random allocation of sampling units within the sampling domain (such as population) is appropriate provided either the underlying response is reasonably homogenous throughout the domain, or else, there is a large number of sampling units. If the conditions are relatively hetrogenous, then the exact location of the sampling units is likely to be highly influential and may mask any detectable effects of treatments.</p>
</div>
<div id="fixed-and-random-effects" class="section level2">
<h2>Fixed and random effects</h2>
<p>From a frequentist perspective, <em>fixed factors</em> are factors whose levels represent the specific populations of interest. For example, a factor that comprises “high”, “medium” and “low” temperature treatments is a fixed factor - we are only interested in comparing those three populations. Conclusions about the effects of a fixed factor are restricted to the specific treatment levels investigated and for any subsequent experiments to be comparable, the same specific treatments of the factor would need to be used. By contrast, <em>random factors</em> are factors whose levels are randomly chosen from all the possible levels of populations and are used as random representatives of the populations. For example, five random temperature treatments could be used to represent a full spectrum of temperature treatments. In this case, conclusions are extrapolated to all the possible treatment (temperature) levels and for subsequent experiments, a new random set of treatments of the factor would be selected.</p>
<p>Other common examples of random factors include sites and subjects - factors for which we are attempting to generalise over. Furthermore, the nature of random factors means that we have no indication of how a new level of that factor (such as another subject or site) are likely to respond and thus it is not possible to predict new observations from random factors. These differences between fixed and random factors are reflected in the way their respective null hypotheses are formulated and interpreted. Whilst fixed factors contrast the effects of the different levels of the factor, random factors are modelled as the amount of additional variability they introduce. Random factors are modelled with a mean of <span class="math inline">\(0\)</span> and their variance is estimated as the effect coefficient.</p>
</div>
<div id="linear-model" class="section level2">
<h2>Linear model</h2>
<p>The linear model for single factor classification is similar to that of multiple linear regression. The linear model can thus be represented by either:</p>
<ul>
<li><strong>Means parameterisation</strong> - in which the regression slopes represent the means of each treatment group and the intercept is removed (to prevent over-parameterisation).</li>
</ul>
<p><span class="math display">\[ y_{ij} = \beta_1(\text{level}_1)_{ij} + \beta_2(\text{level}_2)_{ij} + \ldots + \epsilon_{ij},\]</span></p>
<p>where <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> respectively represent the means response of treatment level <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span>. This is often simplified to <span class="math inline">\(y_{ij}=\alpha_i + \epsilon_{ij}\)</span>.</p>
<ul>
<li><strong>Effects parameterisation</strong> - the intercept represents a property such as the mean of one of the treatment groups (treatment contrasts) or the overall mean (sum contrasts), and the slope parameters represent effects (differences between each other group and the reference mean for example).</li>
</ul>
<p><span class="math display">\[ y_{ij} = \mu + \beta_2(\text{level}_2)_{ij} + \beta_3(\text{level}_3)_{ij} + \ldots + \epsilon_{ij},\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the mean of the first treatment group, <span class="math inline">\(\beta_2\)</span> and <span class="math inline">\(\beta_3\)</span> respectively represent the effects (change from level <span class="math inline">\(1\)</span>) of level <span class="math inline">\(2\)</span> and <span class="math inline">\(3\)</span> on the mean response. This is often simplified to: <span class="math inline">\(y_{ij}=\mu + \alpha_i + \epsilon_{ij}\)</span>, with <span class="math inline">\(\alpha_1=0\)</span>.</p>
<p>Since we are traditionally interested in investigating effects (differences) rather than treatment means, effects parameterisation is far more common (particularly when coupled with hypothesis testing). In a Bayesian framework, it does not really matter whether models are fit with means or effects parameterisation since the posterior likelihood can be querried in any way and repeatedly - thus enabling us to explore any specific effects after the model has been fit. Nevertheless, to ease comparisons with frequentist approaches, we will stick with effects paramterisation.</p>
</div>
<div id="null-hypothesis-fixed-factor" class="section level2">
<h2>Null hypothesis: fixed factor</h2>
<p>We can associate a null hypothesis test with each estimated parameter. For example, in a cell for each estimated mean in a means model we could test a null hypothesis that the population mean is equal to zero (e.g. <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\alpha_1=0\)</span>, <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\alpha_2=0\)</span>, <span class="math inline">\(\ldots\)</span>). However, this rarely would be of much interest. By contrast, individual null hypotheses associated with each parameter of the effects model can be used to investigate the differences between each group and a reference group (for example). In addition to the individual null hypothesis tests, a single fixed factor ANOVA tests the collective <span class="math inline">\(H_0\)</span> that there are no differences between the population group means:</p>
<ul>
<li><p><span class="math inline">\(H_0: \mu_1=\mu_2=\ldots=\mu_i=\mu\)</span> (the population group means are all equal). That is, that the mean of population <span class="math inline">\(1\)</span> is equal to that of population <span class="math inline">\(2\)</span> and so on, and thus all population means are equal to one another - no effect of the factor on the response. If the effect of the <span class="math inline">\(i\)</span>-th group is the difference between the <span class="math inline">\(i\)</span>-th group mean and the mean of the first group (<span class="math inline">\(\alpha_i=\mu_i-\mu_1\)</span>) then the <span class="math inline">\(H_0\)</span> can alternatively be written as:</p></li>
<li><p><span class="math inline">\(H_0 : \alpha_2=\alpha_3=\ldots=\alpha_i=0\)</span> (the effect of each group equals zero). If one or more of the <span class="math inline">\(\alpha_i\)</span> are different from zero (the response mean for this treatment differs from the overall response mean), there is evidence that the null hypothesis is not true indicating that the factor does affect the response variable.</p></li>
</ul>
</div>
<div id="null-hypothesis-random-factor" class="section level2">
<h2>Null hypothesis: random factor</h2>
<p>The collective <span class="math inline">\(H_0\)</span> for a random factor is that the variance between all possible treatment groups equals zero:</p>
<ul>
<li><span class="math inline">\(H_0 : \sigma^2_{\alpha}=0\)</span> (added variance due to this factor equals zero).</li>
</ul>
<p>Note that whilst the null hypotheses for fixed and random factors are different (fixed: population group means all equal, random: variances between populations all equal zero), the linear model fitted for fixed and random factors in single factor ANOVA models is identical. For more complex multi-factor ANOVA models however, the distinction between fixed and random factors has important consequences for building and interpreting statistical models and null hypotheses.</p>
</div>
<div id="analysis-of-variance" class="section level2">
<h2>Analysis of variance</h2>
<p>When the null hypothesis is true (and the populations are identical), the amount of variation among observations within groups should be similar to the amount of variation in observations between groups. However, when the null hypothesis is false (and some means are different from other means), the amount of variation among observations might be expected to be less than the amount of variation within groups. Analysis of variance, or ANOVA, partitions the total variance in the response (dependent) variable into a component of the variance that is explained by combinations of one or more categorical predictor variables (called factors) and a component of the variance that cannot be explained (residual). The variance ratio (F-ratio) from this partitioning can then be used to test the null hypothesis (<span class="math inline">\(H_0\)</span>) that the population group or treatment means are all equal. Ttotal variation can be decomposed into components explained by the groups (<span class="math inline">\(MS_{groups}\)</span>) and and unexplained (<span class="math inline">\(MS_{residual}\)</span>) by the groups. The gray arrows in b) depict the relative amounts explained by the groups. The proposed groupings generally explain why the first few points are higher on the y-axis than the last three points. The probability of collecting our sample, and thus generating the sample ratio of explained to unexplained variation (or one more extreme), when the null hypothesis is true (and population means are equal) is the area under the F-distribution beyond our sample ratio (<span class="math inline">\(\text{F-ratio}=\frac{MS_{groups}}{MS_{residual}}\)</span>).</p>
<p>When the null hypothesis is true (and the test assumptions have not been violated), the ratio (F-ratio) of explained to unexplained variance follows a theoretical probability distribution (F-distribution). When the null hypothesis is true, and there is no effect of the treatment on the response variable, the ratio of explained variability to unexplained variability is expected to be <span class="math inline">\(\leq 1\)</span>. Since the denominator should represent the expected numerator in the absence of an effect. Importantly, the denominator in an F-ratio calculation essentially represents what we would expect the numerator to be in the absence of a treatment effect. For simple analyses, identifying what these expected values are is relatively straightforward (equivalent to the degree of within group variability). However, in more complex designs (particularly involving random factors and hierarchical treatment levels), the logical “groups” can be more difficult (and in some cases impossible) to identify. In such cases, nominating the appropriate F-ratio denominator for estimating an specific effect requires careful consideration. The following table depicts the anatomy of the single factor ANOVA table</p>
<pre class="r"><code>&gt; anova_table
         df       MS       F-ratio          
Factor A &quot;a-1&quot;    &quot;MS A&quot;   &quot;(MS A)/(MS res)&quot;
Residual &quot;(n-1)a&quot; &quot;MS res&quot; &quot;&quot;               </code></pre>
<p>and corresponding <code>R</code> syntax.</p>
<pre class="r"><code>&gt; anova(lm(DV ~ A, dataset))
&gt; # OR
&gt; anova(aov(DV ~ A, dataset))</code></pre>
<p>An F-ratio substantially greater than <span class="math inline">\(1\)</span> suggests that the model relating the response variable to the categorical variable explains substantially more variability than is left unexplained. In turn, this implies that the linear model does represent the data well and that differences between observations can be explained largely by differences in treatment levels rather than purely the result of random variation. If the probability of getting the observed (sample) F-ratio or one more extreme is less than some predefined critical value (typically <span class="math inline">\(5\)</span>% or <span class="math inline">\(0.05\)</span>), we conclude that it is highly unlikely that the observed samples could have been collected from populations in which the treatment has no effect and therefore we would reject the null hypothesis.</p>
</div>
<div id="assumptions" class="section level2">
<h2>Assumptions</h2>
<p>An F-ratio from real data can only reliably relate to a theoretical F-distribution when the data conform to certain assumptions. Hypothesis testing for a single factor ANOVA model assumes that the residuals (and therefore the response variable for each of the treatment levels) are all:</p>
<ul>
<li><p><strong>normally distributed</strong> - although ANOVA is robust to non-normality provided sample sizes and variances are equal. Boxplots should be used to explore normality, skewness, bimodality and outliers. In the event of homogeneity of variance issues (see below), a Q-Q normal plot can also be useful for exploring normality (as this might be the cause of non-homogeneity). Scale transformations are often useful.</p></li>
<li><p><strong>equally varied</strong> - provided sample sizes are equal and the largest to smallest variance ratio does not exceed 3:1 (9:1 for sd), ANOVA is reasonably robust to this assumption, however, relationships between variance and mean and/or sample size are of particular concern as they elevate the Type I error rate. Boxplots and plots of means against variance should be used to explore the spread of values. Residual plots should reveal no patterns. Since unequal variances are often the result of non-normality, transformations that improve normality will also improve variance homogeneity.</p></li>
<li><p><strong>independent of one another</strong> - this assumption must be addressed at the design and collection stages and cannot be compensated for later (unless a model is used that specifically accounts for particular types of non-independent data, such as that introduced with hierarchical designs or autocorrelation)</p></li>
</ul>
<p>Violations of these assumptions reduce the reliability of the analysis.</p>
</div>
</div>
<div id="data-generation" class="section level1">
<h1>Data generation</h1>
<p>Lets say we had set up a natural experiment in which we measured a response from <span class="math inline">\(10\)</span> sampling units (replicates) from each of <span class="math inline">\(5\)</span> treatments. Hence, we have a single categorical factor with <span class="math inline">\(5\)</span> levels - we might have five different locations, or five different habitat types or substrates etc. In statistical speak, we have sampled from <span class="math inline">\(5\)</span> different populations. We have then randomly selected <span class="math inline">\(10\)</span> independent and random (representative) units of each population to sample. That is, we have <span class="math inline">\(10\)</span> samples (replicates) of each population. As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.</p>
<pre class="r"><code>&gt; set.seed(123)
&gt; ngroups &lt;- 5  #number of populations
&gt; nsample &lt;- 10  #number of reps in each
&gt; pop.means &lt;- c(40, 45, 55, 40, 30)  #population mean length
&gt; sigma &lt;- 3  #residual standard deviation
&gt; n &lt;- ngroups * nsample  #total sample size
&gt; eps &lt;- rnorm(n, 0, sigma)  #residuals
&gt; x &lt;- gl(ngroups, nsample, n, lab = LETTERS[1:5])  #factor
&gt; means &lt;- rep(pop.means, rep(nsample, ngroups))
&gt; X &lt;- model.matrix(~x - 1)  #create a design matrix
&gt; y &lt;- as.numeric(X %*% pop.means + eps)
&gt; data &lt;- data.frame(y, x)
&gt; head(data)  #print out the first six rows of the data set
         y x
1 38.31857 A
2 39.30947 A
3 44.67612 A
4 40.21153 A
5 40.38786 A
6 45.14519 A
&gt; 
&gt; write.csv(data, &quot;simpleAnova.csv&quot;)</code></pre>
<p>With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type.</p>
<div id="exploratory-data-analysis" class="section level2">
<h2>Exploratory data analysis</h2>
<ul>
<li><em>Normality and Homogeneity of variance</em></li>
</ul>
<pre class="r"><code>&gt; boxplot(y ~ x, data)
&gt; 
&gt; # OR via ggplot2
&gt; library(ggplot2)</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/exp_data-1.png" width="672" /></p>
<pre class="r"><code>&gt; ggplot(data, aes(y = y, x = x)) + geom_boxplot() +
+     theme_classic()</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/exp_data-2.png" width="672" /></p>
<p><strong>Conclusions</strong></p>
<p>There is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the <span class="math inline">\(y\)</span>-axis. Hence it there is no evidence of non-homogeneity. Obvious violations could be addressed either by, for example, transforming the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).</p>
</div>
</div>
<div id="model-fitting" class="section level1">
<h1>Model fitting</h1>
<p>The observed response (<span class="math inline">\(y_i\)</span>) are assumed to be drawn from a normal distribution with a given mean (<span class="math inline">\(\mu\)</span>) and standard deviation (<span class="math inline">\(\sigma\)</span>). The expected values (<span class="math inline">\(\mu\)</span>) are themselves determined by the linear predictor (<span class="math inline">\(\beta_0+\boldsymbol \beta \boldsymbol X_i\)</span>). In this case, <span class="math inline">\(\beta_0\)</span> represents the mean of the first group and the set of <span class="math inline">\(\boldsymbol \beta\)</span>’s represent the differences between each other group and the first group. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (<span class="math inline">\(100\)</span>) for both the intercept and the treatment effect and a wide half-cauchy (<span class="math inline">\(\text{scale}=5\)</span>) for the standard deviation.</p>
<p><span class="math display">\[y_i \sim N(\mu_i,\sigma),  \]</span></p>
<p>where <span class="math inline">\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X_i\)</span>. The assumed priors are: <span class="math inline">\(\beta \sim N(0,100)\)</span> and <span class="math inline">\(\sigma \sim \text{Cauchy}(0,5)\)</span>. We proceed to code the model into <code>STAN</code>.</p>
<pre class="r"><code>&gt; modelString = &quot;
+   data {
+   int&lt;lower=1&gt; n;
+   int&lt;lower=1&gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&lt;lower=0&gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   //Likelihood
+   y~normal(mu,sigma);
+   
+   //Priors
+   beta ~ normal(0,1000);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &quot;
&gt; ## write the model to a stan file 
&gt; writeLines(modelString, con = &quot;anovaModel.stan&quot;)</code></pre>
<p>Arrange the data as a list (as required by <code>STAN</code>). As input, <code>STAN</code> will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.</p>
<pre class="r"><code>&gt; Xmat &lt;- model.matrix(~x, data)
&gt; data.list &lt;- with(data, list(y = y, X = Xmat, nX = ncol(Xmat), n = nrow(data)))</code></pre>
<p>Define the nodes (parameters and derivatives) to monitor and chain parameters.</p>
<pre class="r"><code>&gt; params &lt;- c(&quot;beta&quot;, &quot;sigma&quot;, &quot;log_lik&quot;)
&gt; nChains = 2
&gt; burnInSteps = 500
&gt; thinSteps = 1
&gt; numSavedSteps = 2000  #across all chains
&gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&gt; nIter
[1] 1500</code></pre>
<p>Now compile and run the Stan code via the <code>rstan</code> interface. Note that the first time <code>stan</code> is run after the <code>rstan</code> package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.</p>
<pre class="r"><code>&gt; library(rstan)</code></pre>
<p>During the warmup stage, the No-U-Turn sampler (NUTS) attempts to determine the optimum stepsize - the stepsize that achieves the target acceptance rate (<span class="math inline">\(0.8\)</span> or <span class="math inline">\(80\)</span>% by default) without divergence (occurs when the stepsize is too large relative to the curvature of the log posterior and results in approximations that are likely to diverge and be biased) - and without hitting the maximum treedepth (<span class="math inline">\(10\)</span>). At each iteration of the NUTS algorithm, the number of leapfrog steps doubles (as it increases the treedepth) and only terminates when either the NUTS criterion are satisfied or the tree depth reaches the maximum (<span class="math inline">\(10\)</span> by default).</p>
<pre class="r"><code>&gt; data.rstan &lt;- stan(data = data.list, file = &quot;anovaModel.stan&quot;, chains = nChains, pars = params,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &#39;anovaModel&#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.001 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 10 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.049 seconds (Warm-up)
Chain 1:                0.053 seconds (Sampling)
Chain 1:                0.102 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &#39;anovaModel&#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.046 seconds (Warm-up)
Chain 2:                0.061 seconds (Sampling)
Chain 2:                0.107 seconds (Total)
Chain 2: 
&gt; 
&gt; print(data.rstan, par = c(&quot;beta&quot;, &quot;sigma&quot;))
Inference for Stan model: anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%   75% 97.5% n_eff Rhat
beta[1]  40.24    0.04 0.89  38.45  39.69  40.24 40.87 41.93   634 1.01
beta[2]   5.38    0.04 1.25   2.97   4.54   5.36  6.18  7.86   833 1.00
beta[3]  13.48    0.04 1.29  10.89  12.64  13.41 14.34 15.97   888 1.00
beta[4]   0.70    0.04 1.25  -1.81  -0.13   0.69  1.56  3.06   949 1.01
beta[5] -10.27    0.04 1.25 -12.57 -11.13 -10.30 -9.40 -7.85   817 1.00
sigma     2.85    0.01 0.31   2.34   2.64   2.83  3.04  3.53  1108 1.00

Samples were drawn using NUTS(diag_e) at Fri Feb 14 15:53:48 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).</code></pre>
</div>
<div id="mcmc-diagnostics" class="section level1">
<h1>MCMC diagnostics</h1>
<p>In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.</p>
<ul>
<li><p><em>Traceplots</em> for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.</p></li>
<li><p><em>Autocorrelation</em> plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of <span class="math inline">\(0\)</span> represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of <span class="math inline">\(1\)</span>). A lag of <span class="math inline">\(1\)</span> represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).</p></li>
<li><p><em>Potential scale reduction factor</em> (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than <span class="math inline">\(1.05\)</span>. If there are values of <span class="math inline">\(1.05\)</span> or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.</p></li>
</ul>
<p>Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package <code>mcmcplots</code> to obtain density and trace plots for the effects model as an example.</p>
<pre class="r"><code>&gt; library(mcmcplots)
&gt; s = as.array(data.rstan)
&gt; mcmc &lt;- do.call(mcmc.list, plyr:::alply(s[, , -(length(s[1, 1, ]))], 2, as.mcmc))
&gt; denplot(mcmc, parms = c(&quot;beta&quot;,&quot;sigma&quot;))</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag-1.png" width="672" /></p>
<pre class="r"><code>&gt; traplot(mcmc, parms = c(&quot;beta&quot;,&quot;sigma&quot;))</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag-2.png" width="672" /></p>
<p>These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.</p>
<pre class="r"><code>&gt; #Raftery diagnostic
&gt; raftery.diag(mcmc)
$`1`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

$`2`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s</code></pre>
<p>The Raftery diagnostics for each chain estimate that we would require no more than <span class="math inline">\(5000\)</span> samples to reach the specified level of confidence in convergence. As we have <span class="math inline">\(10500\)</span> samples, we can be confidence that convergence has occurred.</p>
<pre class="r"><code>&gt; #Autocorrelation diagnostic
&gt; stan_ac(data.rstan, pars = c(&quot;beta&quot;))</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag3-1.png" width="672" /></p>
<p>A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).</p>
<pre class="r"><code>&gt; stan_rhat(data.rstan, pars = c(&quot;beta&quot;))</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag4-1.png" width="672" /></p>
<pre class="r"><code>&gt; stan_ess(data.rstan, pars = c(&quot;beta&quot;))</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_diag4-2.png" width="672" /></p>
<p>Rhat and effective sample size. In this instance, most of the parameters have reasonably high effective samples and thus there is likely to be a good range of values from which to estimate paramter properties.</p>
</div>
<div id="model-validation" class="section level1">
<h1>Model validation</h1>
<p>Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model. Residuals are not computed directly within <code>rstan</code> However, we can calculate them manually form the posteriors.</p>
<pre class="r"><code>&gt; library(dplyr)
&gt; mcmc = as.data.frame(data.rstan) %&gt;% dplyr:::select(contains(&quot;beta&quot;),
+     sigma) %&gt;% as.matrix
&gt; # generate a model matrix
&gt; newdata = data
&gt; Xmat = model.matrix(~x, newdata)
&gt; ## get median parameter estimates
&gt; coefs = apply(mcmc[, 1:5], 2, median)
&gt; fit = as.vector(coefs %*% t(Xmat))
&gt; resid = data$y - fit
&gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_residuals-1.png" width="672" /></p>
<p>Residuals against predictors</p>
<pre class="r"><code>&gt; library(tidyr)
&gt; mcmc = as.data.frame(data.rstan) %&gt;% dplyr:::select(contains(&quot;beta&quot;),
+     sigma) %&gt;% as.matrix
&gt; # generate a model matrix
&gt; newdata = newdata
&gt; Xmat = model.matrix(~x, newdata)
&gt; ## get median parameter estimates
&gt; coefs = apply(mcmc[, 1:5], 2, median)
&gt; fit = as.vector(coefs %*% t(Xmat))
&gt; resid = data$y - fit
&gt; newdata = newdata %&gt;% cbind(fit, resid)
&gt; ggplot(newdata) + geom_point(aes(y = resid, x = x)) + theme_classic()</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_residuals2-1.png" width="672" /></p>
<p>And now for studentised residuals</p>
<pre class="r"><code>&gt; mcmc = as.data.frame(data.rstan) %&gt;% dplyr:::select(contains(&quot;beta&quot;),
+     sigma) %&gt;% as.matrix
&gt; # generate a model matrix
&gt; newdata = data
&gt; Xmat = model.matrix(~x, newdata)
&gt; ## get median parameter estimates
&gt; coefs = apply(mcmc[, 1:5], 2, median)
&gt; fit = as.vector(coefs %*% t(Xmat))
&gt; resid = data$y - fit
&gt; sresid = resid/sd(resid)
&gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_residuals3-1.png" width="672" /></p>
<p>For this simple model, the studentized residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.</p>
<pre class="r"><code>&gt; mcmc = as.data.frame(data.rstan) %&gt;% dplyr:::select(contains(&quot;beta&quot;),
+     sigma) %&gt;% as.matrix
&gt; # generate a model matrix
&gt; Xmat = model.matrix(~x, data)
&gt; ## get median parameter estimates
&gt; coefs = mcmc[, 1:5]
&gt; fit = coefs %*% t(Xmat)
&gt; ## draw samples from this model
&gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,
+     ], mcmc[i, &quot;sigma&quot;]))
&gt; newdata = data.frame(x = data$x, yRep) %&gt;% gather(key = Sample,
+     value = Value, -x)
&gt; ggplot(newdata) + geom_violin(aes(y = Value, x = x, fill = &quot;Model&quot;),
+     alpha = 0.5) + geom_violin(data = data, aes(y = y, x = x,
+     fill = &quot;Obs&quot;), alpha = 0.5) + geom_point(data = data, aes(y = y,
+     x = x), position = position_jitter(width = 0.1, height = 0),
+     color = &quot;black&quot;) + theme_classic()</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_rep-1.png" width="672" /></p>
<p>The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.</p>
<pre class="r"><code>&gt; library(bayesplot)
&gt; mcmc_intervals(as.matrix(data.rstan), regex_pars = &quot;beta|sigma&quot;)</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_rep2-1.png" width="672" /></p>
<pre class="r"><code>&gt; mcmc_areas(as.matrix(data.rstan), regex_pars = &quot;beta|sigma&quot;)</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_rep2-2.png" width="672" /></p>
</div>
<div id="parameter-estimates" class="section level1">
<h1>Parameter estimates</h1>
<p>Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and <span class="math inline">\(95\)</span>% credibility intervals.</p>
<pre class="r"><code>&gt; mcmcpvalue &lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &lt;- colSums(std * std)
+         sum(sqdist[-1] &gt; sqdist[1])/length(samp)
+     } else {
+         std &lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &lt;- colSums(std * std)
+         sum(sqdist[-1] &gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }</code></pre>
<p>First, we look at the results from the additive model.</p>
<pre class="r"><code>&gt; print(data.rstan, pars = c(&quot;beta&quot;, &quot;sigma&quot;))
Inference for Stan model: anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%   75% 97.5% n_eff Rhat
beta[1]  40.24    0.04 0.89  38.45  39.69  40.24 40.87 41.93   634 1.01
beta[2]   5.38    0.04 1.25   2.97   4.54   5.36  6.18  7.86   833 1.00
beta[3]  13.48    0.04 1.29  10.89  12.64  13.41 14.34 15.97   888 1.00
beta[4]   0.70    0.04 1.25  -1.81  -0.13   0.69  1.56  3.06   949 1.01
beta[5] -10.27    0.04 1.25 -12.57 -11.13 -10.30 -9.40 -7.85   817 1.00
sigma     2.85    0.01 0.31   2.34   2.64   2.83  3.04  3.53  1108 1.00

Samples were drawn using NUTS(diag_e) at Fri Feb 14 15:53:48 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&gt; 
&gt; # OR
&gt; library(broom)
&gt; tidyMCMC(data.rstan, conf.int = TRUE, conf.method = &quot;HPDinterval&quot;, pars = c(&quot;beta&quot;, &quot;sigma&quot;))
# A tibble: 6 x 5
  term    estimate std.error conf.low conf.high
  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 beta[1]   40.2       0.895    38.4      41.9 
2 beta[2]    5.38      1.25      3.09      7.96
3 beta[3]   13.5       1.29     11.0      16.1 
4 beta[4]    0.703     1.25     -1.94      2.90
5 beta[5]  -10.3       1.25    -12.6      -7.85
6 sigma      2.85      0.306     2.33      3.50</code></pre>
<p><strong>Conclusions</strong></p>
<ul>
<li>the mean of the first group (A) is <span class="math inline">\(40.2\)</span></li>
<li>the mean of the second group (B) is <span class="math inline">\(5.4\)</span> units greater than (A)</li>
<li>the mean of the third group (C) is <span class="math inline">\(13.5\)</span> units greater than (A)</li>
<li>the mean of the forth group (D) is <span class="math inline">\(0.74\)</span> units greater than (A)</li>
<li>the mean of the fifth group (E) is <span class="math inline">\(-10.2\)</span> units greater (i.e. less) than (A)</li>
</ul>
<p>The <span class="math inline">\(95\)</span>% confidence interval for the effects of B, C and E do not overlap with <span class="math inline">\(0\)</span> implying a significant difference between group A and groups B, C and E. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.</p>
<pre class="r"><code>&gt; ## since values are less than zero
&gt; mcmcpvalue(as.matrix(data.rstan)[, &quot;beta[2]&quot;])  # effect of (B-A)
[1] 0
&gt; mcmcpvalue(as.matrix(data.rstan)[, &quot;beta[3]&quot;])  # effect of (C-A)
[1] 0
&gt; mcmcpvalue(as.matrix(data.rstan)[, &quot;beta[4]&quot;])  # effect of (D-A)
[1] 0.5805
&gt; mcmcpvalue(as.matrix(data.rstan)[, &quot;beta[5]&quot;])  # effect of (E-A)
[1] 0
&gt; mcmcpvalue(as.matrix(data.rstan)[, 2:5])  # effect of (all groups)
[1] 0</code></pre>
<p>There is evidence that the reponse differs between the groups. There is evidence suggesting that the response of group D differs from that of group A. In a Bayesian context, we can compare models using the <strong>leave-one-out cross-validation</strong> statistics. Leave-one-out (LOO) cross-validation explores how well a series of models can predict withheld values <span class="citation">Vehtari, Gelman, and Gabry (2017)</span>. The LOO Information Criterion (LOOIC) is analogous to the AIC except that the LOOIC takes priors into consideration, does not assume that the posterior distribution is drawn from a multivariate normal and integrates over parameter uncertainty so as to yield a distribution of looic rather than just a point estimate. The LOOIC does however assume that all observations are equally influential (it does not matter which observations are left out). This assumption can be examined via the Pareto <span class="math inline">\(k\)</span> estimate (values greater than <span class="math inline">\(0.5\)</span> or more conservatively <span class="math inline">\(0.75\)</span> are considered overly influential). We can compute LOOIC if we store the loglikelihood from our <code>STAN</code> model, which can then be extracted to compute the information criterion using the package <code>loo</code>.</p>
<pre class="r"><code>&gt; library(loo)
&gt; (full = loo(extract_log_lik(data.rstan)))

Computed from 2000 by 50 log-likelihood matrix

         Estimate   SE
elpd_loo   -125.8  5.1
p_loo         5.6  1.1
looic       251.6 10.2
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k &lt; 0.5).
See help(&#39;pareto-k-diagnostic&#39;) for details.
&gt; 
&gt; # now fit a model without main factor
&gt; modelString2 = &quot;
+   data {
+   int&lt;lower=1&gt; n;
+   int&lt;lower=1&gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&lt;lower=0&gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   //Likelihood
+   y~normal(mu,sigma);
+   
+   //Priors
+   beta ~ normal(0,1000);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &quot;
&gt; 
&gt; ## write the model to a stan file 
&gt; writeLines(modelString2, con = &quot;anovaModel2.stan&quot;)
&gt; 
&gt; Xmat &lt;- model.matrix(~1, data)
&gt; data.list &lt;- with(data, list(y = y, X = Xmat, n = nrow(data), nX = ncol(Xmat)))
&gt; data.rstan.red &lt;- stan(data = data.list, file = &quot;anovaModel2.stan&quot;, chains = nChains,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &#39;anovaModel&#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.001 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 10 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.018 seconds (Warm-up)
Chain 1:                0.038 seconds (Sampling)
Chain 1:                0.056 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &#39;anovaModel&#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.023 seconds (Warm-up)
Chain 2:                0.087 seconds (Sampling)
Chain 2:                0.11 seconds (Total)
Chain 2: 
&gt; 
&gt; (reduced = loo(extract_log_lik(data.rstan.red)))

Computed from 2000 by 50 log-likelihood matrix

         Estimate  SE
elpd_loo   -177.8 4.4
p_loo         1.6 0.3
looic       355.6 8.7
------
Monte Carlo SE of elpd_loo is 0.0.

All Pareto k estimates are good (k &lt; 0.5).
See help(&#39;pareto-k-diagnostic&#39;) for details.
&gt; 
&gt; par(mfrow = 1:2, mar = c(5, 3.8, 1, 0) + 0.1, las = 3)
&gt; plot(full, label_points = TRUE)
&gt; plot(reduced, label_points = TRUE)</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_looic-1.png" width="672" /></p>
<p>The expected out-of-sample predictive accuracy is substantially lower for the model that includes <span class="math inline">\(x\)</span>. This might be used to suggest that the inferential evidence for a general effect of <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span>.</p>
</div>
<div id="graphical-summaries" class="section level1">
<h1>Graphical summaries</h1>
<p>With appropriate use of model matrices and data wrangling, it is possible to produce a single prediction data set along with <code>ggplot</code> syntax to produce a multi-panel figure. First we look at the additive model.</p>
<pre class="r"><code>&gt; mcmc = as.matrix(data.rstan)
&gt; ## Calculate the fitted values
&gt; newdata = rbind(data.frame(x = levels(data$x)))
&gt; Xmat = model.matrix(~x, newdata)
&gt; coefs = mcmc[, c(&quot;beta[1]&quot;, &quot;beta[2]&quot;, &quot;beta[3]&quot;, &quot;beta[4]&quot;, &quot;beta[5]&quot;)]
&gt; fit = coefs %*% t(Xmat)
&gt; newdata = newdata %&gt;% cbind(tidyMCMC(fit, conf.int = TRUE, conf.method = &quot;HPDinterval&quot;))
&gt; 
&gt; ggplot(newdata, aes(y = estimate, x = x)) + geom_linerange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_point() + scale_y_continuous(&quot;Y&quot;) + scale_x_discrete(&quot;X&quot;) +
+     theme_classic()</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_post1-1.png" width="672" /></p>
<p>As this is simple single factor ANOVA, we can simple add the raw data to this figure. For more complex designs with additional predictors, it is necessary to plot partial residuals.</p>
<pre class="r"><code>&gt; ## Calculate partial residuals fitted values
&gt; fdata = rdata = data
&gt; fMat = rMat = model.matrix(~x, fdata)
&gt; fit = as.vector(apply(coefs, 2, median) %*% t(fMat))
&gt; resid = as.vector(data$y - apply(coefs, 2, median) %*% t(rMat))
&gt; rdata = rdata %&gt;% mutate(partial.resid = resid + fit)
&gt; 
&gt; ggplot(newdata, aes(y = estimate, x = as.numeric(x) - 0.1)) + geom_blank(aes(x = x)) +
+     geom_point(data = rdata, aes(y = partial.resid, x = as.numeric(x) +
+         0.1), color = &quot;gray&quot;) + geom_linerange(aes(ymin = conf.low, ymax = conf.high)) +
+     geom_point() + scale_y_continuous(&quot;Y&quot;) + scale_x_discrete(&quot;&quot;) + theme_classic()</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/mcmc_post2-1.png" width="672" /></p>
</div>
<div id="posteriors" class="section level1">
<h1>Posteriors</h1>
<p>In frequentist statistics, when we have more than two groups, we are typically not only interested in whether there is evidence for an overall “effect” of a factor - we are also interested in how various groups compare to one another. To explore these trends, we either compare each group to each other in a pairwise manner (controlling for family-wise Type I error rates) or we explore an independent subset of the possible comparisons. Although these alternate approaches can adequately address a specific research agenda, often they impose severe limitations and compromises on the scope and breadth of questions that can be asked of your data. The reason for these limitations is that in a frequentist framework, any single hypothesis carries with it a (nominally) <span class="math inline">\(5\)</span>% chance of a false rejection (since it is based on long-run frequency). Thus, performing multiple tests are likely to compound this error rate. The point is, that each comparison is compared to its own probability distribution (and each carries a <span class="math inline">\(5\)</span>% error rate). By contrast, in Bayesian statistics, all comparisons (contrasts) are drawn from the one (hopefully stable and convergent) posterior distribution and this posterior is invariant to the type and number of comparisons drawn. Hence, the theory clearly indicates that having generated our posterior distribution, we can then query this distribution in any way that we wish thereby allowing us to explore all of our research questions simultaneously.</p>
<p>Bayesian “contrasts” can be performed either:</p>
<ul>
<li><p>within the Bayesian sampling model or</p></li>
<li><p>construct them from the returned MCMC samples (they are drawn from the posteriors)</p></li>
</ul>
<p>Only the latter will be demonstrated as it povides a consistent approach across all routines. In order to allow direct comparison to the frequentist equivalents, I will explore the same set of planned and <em>Tukey</em>’s test comparisons described here. For the “planned comparison” we defined two contrasts: 1) group 3 vs group 5; and 2) the average of groups 1 and 2 vs the average of groups 3, 4 and 5.</p>
<p>Lets start by comparing each group to each other group in a pairwise manner. Arguably the most elegant way to do this is to generate a Tukey’s contrast matrix. This is a model matrix specific to comparing each group to each other group.</p>
<pre class="r"><code>&gt; mcmc = data.rstan
&gt; coefs &lt;- as.matrix(mcmc)[, 1:5]
&gt; newdata &lt;- data.frame(x = levels(data$x))
&gt; # A Tukeys contrast matrix
&gt; library(multcomp)
&gt; # table(newdata$x) - gets the number of replicates of each level
&gt; tuk.mat &lt;- contrMat(n = table(newdata$x), type = &quot;Tukey&quot;)
&gt; Xmat &lt;- model.matrix(~x, data = newdata)
&gt; pairwise.mat &lt;- tuk.mat %*% Xmat
&gt; pairwise.mat
      (Intercept) xB xC xD xE
B - A           0  1  0  0  0
C - A           0  0  1  0  0
D - A           0  0  0  1  0
E - A           0  0  0  0  1
C - B           0 -1  1  0  0
D - B           0 -1  0  1  0
E - B           0 -1  0  0  1
D - C           0  0 -1  1  0
E - C           0  0 -1  0  1
E - D           0  0  0 -1  1
&gt; 
&gt; mcmc_areas(coefs %*% t(pairwise.mat))</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/posterior1-1.png" width="672" /></p>
<pre class="r"><code>&gt; 
&gt; (comps = tidyMCMC(coefs %*% t(pairwise.mat), conf.int = TRUE, conf.method = &quot;HPDinterval&quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
 1 B - A    5.38       1.25     3.09      7.96
 2 C - A   13.5        1.29    11.0      16.1 
 3 D - A    0.703      1.25    -1.94      2.90
 4 E - A  -10.3        1.25   -12.6      -7.85
 5 C - B    8.10       1.28     5.71     10.8 
 6 D - B   -4.68       1.26    -7.06     -2.21
 7 E - B  -15.6        1.25   -18.3     -13.4 
 8 D - C  -12.8        1.29   -15.3     -10.1 
 9 E - C  -23.7        1.31   -26.2     -21.0 
10 E - D  -11.0        1.27   -13.5      -8.63
&gt; 
&gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) +
+     scale_y_continuous(&quot;Effect size&quot;) + scale_x_discrete(&quot;&quot;) + coord_flip() +
+     theme_classic()</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/posterior1-2.png" width="672" /></p>
<p>With a couple of modifications, we could also express this as percentage changes. A percentage change represents the change (difference between groups) divided by one of the groups (determined by which group you want to express the percentage change to). Hence, we generate an additional mcmc matrix that represents the cell means for the divisor group (group we want to express change relative to). Since the <code>tuk.mat</code> defines comparisons as <span class="math inline">\(-1\)</span> and <span class="math inline">\(1\)</span> pairs, if we simply replace all the <span class="math inline">\(-1\)</span> with <span class="math inline">\(0\)</span>, the eventual matrix multiplication will result in estimates of the divisor cell means instread of the difference. We can then divide the original mcmc matrix above with this new divisor mcmc matrix to yeild a mcmc matrix of percentage change.</p>
<pre class="r"><code>&gt; # Modify the tuk.mat to replace -1 with 0.  This will allow us to get a
&gt; # mcmc matrix of ..
&gt; tuk.mat[tuk.mat == -1] = 0
&gt; comp.mat &lt;- tuk.mat %*% Xmat
&gt; comp.mat
      (Intercept) xB xC xD xE
B - A           1  1  0  0  0
C - A           1  0  1  0  0
D - A           1  0  0  1  0
E - A           1  0  0  0  1
C - B           1  0  1  0  0
D - B           1  0  0  1  0
E - B           1  0  0  0  1
D - C           1  0  0  1  0
E - C           1  0  0  0  1
E - D           1  0  0  0  1
&gt; 
&gt; comp.mcmc = 100 * (coefs %*% t(pairwise.mat))/coefs %*% t(comp.mat)
&gt; (comps = tidyMCMC(comp.mcmc, conf.int = TRUE, conf.method = &quot;HPDinterval&quot;))
# A tibble: 10 x 5
   term  estimate std.error conf.low conf.high
   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
 1 B - A    11.8       2.59     6.40     16.5 
 2 C - A    25.1       2.11    20.9      29.1 
 3 D - A     1.67      3.02    -4.53      7.24
 4 E - A   -34.4       4.95   -43.7     -24.9 
 5 C - B    15.1       2.20    10.9      19.6 
 6 D - B   -11.5       3.27   -17.7      -5.09
 7 E - B   -52.3       5.36   -62.5     -41.7 
 8 D - C   -31.3       3.64   -38.4     -23.7 
 9 E - C   -79.4       6.27   -90.6     -66.2 
10 E - D   -36.7       5.06   -46.9     -27.4 
&gt; 
&gt; ggplot(comps, aes(y = estimate, x = term)) + geom_pointrange(aes(ymin = conf.low,
+     ymax = conf.high)) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) +
+     scale_y_continuous(&quot;Effect size (%)&quot;) + scale_x_discrete(&quot;&quot;) + coord_flip() +
+     theme_classic()</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/posterior2-1.png" width="672" /></p>
<p>And now for the specific planned comparisons (Group 3 vs Group 5 and the average of Groups 1 and 2 vs the average of Groups 3, 4 and 5). This is achieved by generating our own contrast matrix (defining the contributions of each group to each contrast).</p>
<pre class="r"><code>&gt; c.mat = rbind(c(0, 0, -1, 0, 1), c(-1/2, -1/2, 1/3, 1/3, 1/3))
&gt; c.mat
     [,1] [,2]       [,3]      [,4]      [,5]
[1,]  0.0  0.0 -1.0000000 0.0000000 1.0000000
[2,] -0.5 -0.5  0.3333333 0.3333333 0.3333333
&gt; 
&gt; mcmc = data.rstan
&gt; coefs &lt;- as.matrix(mcmc)[, 1:5]
&gt; newdata &lt;- data.frame(x = levels(data$x))
&gt; Xmat &lt;- model.matrix(~x, data = newdata)
&gt; c.mat = c.mat %*% Xmat
&gt; c.mat
       (Intercept)   xB         xC        xD        xE
[1,]  0.000000e+00  0.0 -1.0000000 0.0000000 1.0000000
[2,] -1.110223e-16 -0.5  0.3333333 0.3333333 0.3333333
&gt; 
&gt; (comps = tidyMCMC(as.mcmc(coefs %*% t(c.mat)), conf.int = TRUE, conf.method = &quot;HPDinterval&quot;))
# A tibble: 2 x 5
  term  estimate std.error conf.low conf.high
  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 var1    -23.7      1.31    -26.2    -21.0  
2 var2     -1.38     0.806    -2.92     0.186</code></pre>
</div>
<div id="finite-population-standard-deviations" class="section level1">
<h1>Finite population standard deviations</h1>
<p>Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).</p>
<p>Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (<span class="citation">Gelman and others (2005)</span>). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.</p>
<pre><code># A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 sd.x         9.94    0.532      8.89     11.0 
2 sd.resid     2.79    0.0888     2.67      2.96
# A tibble: 2 x 5
  term     estimate std.error conf.low conf.high
  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 sd.x         78.3      1.06     76.0      79.7
2 sd.resid     21.7      1.06     20.3      24.0</code></pre>
<p><img src="/STAN/single-factor-anova-stan/2020-02-01-single-factor-anova-stan_files/figure-html/effects_modelv4-1.png" width="672" /></p>
<p>Approximately <span class="math inline">\(78.3\)</span>% of the total finite population standard deviation is due to <span class="math inline">\(x\)</span>.</p>
</div>
<div id="r-squared" class="section level1">
<h1>R squared</h1>
<p>In a frequentist context, the <span class="math inline">\(R^2\)</span> value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, <span class="math inline">\(R^2\)</span> is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an <span class="math inline">\(R^2\)</span> greater than <span class="math inline">\(100\)</span>%. <span class="citation">Gelman et al. (2019)</span> proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.</p>
<p>So in the standard regression model notation of:</p>
<p><span class="math display">\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]</span></p>
<p>the <span class="math inline">\(R^2\)</span> could be formulated as</p>
<p><span class="math display">\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]</span></p>
<p>where <span class="math inline">\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)</span>, and for normal models <span class="math inline">\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)</span></p>
<pre class="r"><code>&gt; mcmc &lt;- as.matrix(data.rstan)
&gt; Xmat = model.matrix(~x, data)
&gt; wch = grep(&quot;beta&quot;, colnames(mcmc))
&gt; coefs = mcmc[, wch]
&gt; fit = coefs %*% t(Xmat)
&gt; resid = sweep(fit, 2, data$y, &quot;-&quot;)
&gt; var_f = apply(fit, 1, var)
&gt; var_e = apply(resid, 1, var)
&gt; R2 = var_f/(var_f + var_e)
&gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &quot;HPDinterval&quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 var1     0.887    0.0126    0.863     0.905
&gt; 
&gt; # for comparison with frequentist
&gt; summary(lm(y ~ x, data))

Call:
lm(formula = y ~ x, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5257 -1.9000 -0.2589  1.4935  6.5330 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  40.2239     0.8801  45.702  &lt; 2e-16 ***
xB            5.4020     1.2447   4.340 7.97e-05 ***
xC           13.5024     1.2447  10.848 3.82e-14 ***
xD            0.7423     1.2447   0.596    0.554    
xE          -10.2500     1.2447  -8.235 1.57e-10 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.783 on 45 degrees of freedom
Multiple R-squared:  0.8957,    Adjusted R-squared:  0.8865 
F-statistic: 96.64 on 4 and 45 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references hanging-indent">
<div id="ref-gelman2019r">
<p>Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” <em>The American Statistician</em> 73 (3): 307–9.</p>
</div>
<div id="ref-gelman2015stan">
<p>Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” <em>Journal of Educational and Behavioral Statistics</em> 40 (5): 530–43.</p>
</div>
<div id="ref-gelman2005analysis">
<p>Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” <em>The Annals of Statistics</em> 33 (1): 1–53.</p>
</div>
<div id="ref-rstanpackage">
<p>Stan Development Team. 2018. “RStan: The R Interface to Stan.” <a href="http://mc-stan.org/">http://mc-stan.org/</a>.</p>
</div>
<div id="ref-vehtari2017practical">
<p>Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and Waic.” <em>Statistics and Computing</em> 27 (5): 1413–32.</p>
</div>
</div>
</div>

    </div>

    

<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/tutorials/">tutorials</a>
  
  <a class="badge badge-light" href="/tags/stan/">STAN</a>
  
  <a class="badge badge-light" href="/tags/anova/">anova</a>
  
  <a class="badge badge-light" href="/tags/facor-analysis/">facor analysis</a>
  
</div>



    
      








  
  
    
  
  





  
  
  
  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="/authors/andrea-gabrio/"></a></h5>
      
      
      <ul class="network-icon" aria-hidden="true">
        
      </ul>
    </div>
  </div>



      
      
      <div class="article-widget">
        <div class="hr-light"></div>
        <h3>Related</h3>
        <ul>
          
          <li><a href="/jags/sin-factor-anova-jags/single-factor-anova-jags/">Single Factor Anova - JAGS</a></li>
          
          <li><a href="/stan/multiple-linear-regression-stan/multiple-linear-regression-stan/">Multiple Linear Regression - STAN</a></li>
          
          <li><a href="/stan/simple-linear-regression-stan/simple-linear-regression-stan/">Simple Linear Regression - STAN</a></li>
          
          <li><a href="/stan/comparing-two-populations-stan/comparing-two-populations-stan/">Comparing Two Populations - STAN</a></li>
          
          <li><a href="/jags/multiple-linear-regression-jags/multiple-linear-regression-jags/">Multiple Linear Regression - JAGS</a></li>
          
        </ul>
      </div>
      
    

    

    


  </div>
</article>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script async defer src="//maps.googleapis.com/maps/api/js?key=AIzaSyAYShZdrjjE_TojzlN30gOZCZjvTBD3b3c"></script>
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/gmaps.js/0.4.25/gmaps.min.js" integrity="sha256-7vjlAeb8OaTrCXZkCNun9djzuB2owUsaO72kXaFDBJs=" crossorigin="anonymous"></script>
      
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.3394a224b26ce58ff36f44c54743e0ab.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">

  <p class="powered-by">
    

    &#169; Andrea Gabrio 2019. Based on the 
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
