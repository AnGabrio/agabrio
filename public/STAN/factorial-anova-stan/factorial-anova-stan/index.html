<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.3.1">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Andrea Gabrio">

  
  
  
    
  
  <meta name="description" content="This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. BUGS (Bayesian inference Using Gibbs Sampling) is an algorithm and supporting language (resembling R) dedicated to performing the Gibbs sampling implementation of Markov Chain Monte Carlo (MCMC) method. Dialects of the BUGS language are implemented within three main projects:
OpenBUGS - written in component pascal.
JAGS - (Just Another Gibbs Sampler) - written in C&#43;&#43;.">

  
  <link rel="alternate" hreflang="en-us" href="/stan/factorial-anova-stan/factorial-anova-stan/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:450,700|Oswald+Sans:600,700|Roboto+Mono:550,700">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.548c5488bf2acb3767aba941aacbd58f.css">

  
    
    
    
    
      
    
    
    
    <link rel="stylesheet" href="/css/academic.4fe06d02a41da8ea4cf58ceef0b5213f.css">
  

  
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/stan/factorial-anova-stan/factorial-anova-stan/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Andrea Gabrio">
  <meta property="og:url" content="/stan/factorial-anova-stan/factorial-anova-stan/">
  <meta property="og:title" content="Factorial Analysis of Variance - STAN | Andrea Gabrio">
  <meta property="og:description" content="This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. BUGS (Bayesian inference Using Gibbs Sampling) is an algorithm and supporting language (resembling R) dedicated to performing the Gibbs sampling implementation of Markov Chain Monte Carlo (MCMC) method. Dialects of the BUGS language are implemented within three main projects:
OpenBUGS - written in component pascal.
JAGS - (Just Another Gibbs Sampler) - written in C&#43;&#43;."><meta property="og:image" content="/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2020-02-06T21:13:14-05:00">
  
  <meta property="article:modified_time" content="2020-02-06T21:13:14-05:00">
  

  


  





  <title>Factorial Analysis of Variance - STAN | Andrea Gabrio</title>

</head>


<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Andrea Gabrio</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/post/"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/research/"><span>Research</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/publication/"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/talk/"><span>Talks</span></a>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Software</span><span class="caret"></span>
          </a>
          <ul class="dropdown-menu">
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/missingHE/"><span>missingHE</span></a>
            </li>
            
          </ul>
        </li>

        
        

        
        <li class="nav-item dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>Tutorials</span><span class="caret"></span>
          </a>
          <ul class="dropdown-menu">
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/JAGS/"><span>JAGS</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/OpenBUGS/"><span>OpenBUGS</span></a>
            </li>
            
            <li class="dropdown-item my-0 py-0 mx-0 px-0">
              <a href="/STAN/"><span>STAN</span></a>
            </li>
            
          </ul>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/missingdata/"><span>Missing Data</span></a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        

      </ul>

    </div>
  </div>
</nav>


  <article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Factorial Analysis of Variance - STAN</h1>

  

  
    



<meta content="2020-02-06 21:13:14 -0500 -0500" itemprop="datePublished">
<meta content="2020-02-06 21:13:14 -0500 -0500" itemprop="dateModified">

<div class="article-metadata">

  
  
  
  
  <div>
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a>Andrea Gabrio</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    <time>Feb 6, 2020</time>
  </span>
  

  

  

  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder"></i>
    <a href="/categories/r/">R</a>, <a href="/categories/anova/">anova</a>, <a href="/categories/stan/">STAN</a>, <a href="/categories/factor-analysis/">factor analysis</a>, <a href="/categories/factorial-designs/">factorial designs</a></span>
  

  
    

  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. <code>BUGS</code> (Bayesian inference Using <em>Gibbs Sampling</em>) is an algorithm and supporting language (resembling <code>R</code>) dedicated to performing the Gibbs sampling implementation of <em>Markov Chain Monte Carlo</em> (MCMC) method. Dialects of the <code>BUGS</code> language are implemented within three main projects:</p>
<ol style="list-style-type: decimal">
<li><p><strong>OpenBUGS</strong> - written in component pascal.</p></li>
<li><p><strong>JAGS</strong> - (Just Another Gibbs Sampler) - written in <code>C++</code>.</p></li>
<li><p><strong>STAN</strong> - a dedicated Bayesian modelling framework written in <code>C++</code> and implementing <em>Hamiltonian</em> MCMC samplers.</p></li>
</ol>
<p>Whilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of <code>R</code>, and thus, they are best accessed from within <code>R</code> itself. As such there are multiple packages devoted to interfacing with the various software implementations:</p>
<ul>
<li><p><em>R2OpenBUGS</em> - interfaces with <code>OpenBUGS</code></p></li>
<li><p><em>R2jags</em> - interfaces with <code>JAGS</code></p></li>
<li><p><em>rstan</em> - interfaces with <code>STAN</code></p></li>
</ul>
<p>This tutorial will demonstrate how to fit models in <code>STAN</code> (<span class="citation">Gelman, Lee, and Guo (2015)</span>) using the package <code>rstan</code> (<span class="citation">Stan Development Team (2018)</span>) as interface, which also requires to load some other packages.</p>
<div id="overview" class="section level1">
<h1>Overview</h1>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Factorial designs are an extension of single factor ANOVA designs in which additional factors are added such that each level of one factor is applied to all levels of the other factor(s) and these combinations are replicated. For example, we might design an experiment in which the effects of temperature (high vs low) and fertiliser (added vs not added) on the growth rate of seedlings are investigated by growing seedlings under the different temperature and fertilizer combinations. In addition to investigating the impacts of the main factors, factorial designs allow us to investigate whether the effects of one factor are consistent across levels of another factor. For example, is the effect of temperature on growth rate the same for both fertilised and unfertilized seedlings and similarly, does the impact of fertiliser treatment depend on the temperature under which the seedlings are grown?</p>
<p>Arguably, these interactions give more sophisticated insights into the dynamics of the system we are investigating. Hence, we could add additional main effects, such as soil pH, amount of water, etc, along with all the two way (temp:fert, temp:pH, temp:water, etc), three-way (temp:fert:pH, temp:pH:water), four-way (and so on) interactions in order to explore how these various factors interact with one another to effect the response. However, the more interactions, the more complex the model becomes to specify, compute and interpret - not to mention the rate at which the number of required observations increases. Factorial designs can consist:</p>
<ul>
<li><p>entirely of crossed fixed factors (<strong>Model I ANOVA</strong> - most common) in which conclusions are restricted to the specific combinations of levels selected for the experiment.</p></li>
<li><p>entirely of crossed random factors (<strong>Model II ANOVA</strong>).</p></li>
<li><p>a mixture of crossed fixed and random factors (<strong>Model III ANOVA</strong>).</p></li>
</ul>
<p>The latter are useful for investigating the generality of a main treatment effect (fixed) over broad spatial, temporal or clinical levels of organisation. That is whether the observed effects of temperature and/or fertiliser (for example) are observed across the entire genera or country.</p>
</div>
<div id="linear-model" class="section level2">
<h2>Linear model</h2>
<p>As with single factor ANOVA, the linear model could be constructed as either effects or means parameterisation, although only effects parameterisation will be considered here. The linear models for two and three factor design are</p>
<p><span class="math display">\[ y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \epsilon_{ijk},\]</span></p>
<p>and</p>
<p><span class="math display">\[ y_{ijkl} = \mu + \alpha_i + \beta_j + \gamma_k + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\beta\gamma)_{ijk} + \epsilon_{ijkl},\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the overall mean, <span class="math inline">\(\alpha\)</span> is the effect of Factor A, <span class="math inline">\(\beta\)</span> is the effect of Factor B, <span class="math inline">\(\gamma\)</span> is the effect of Factor C and <span class="math inline">\(\epsilon\)</span> is the random unexplained or residual component. Note that although the linear models for Model I, Model II and Model III designs are identical, the interpretation of terms (and thus null hypothesis) differ. Recall from the tutorial on single factor ANOVA, that categorical variables in linear models are actually re-parameterised dummy codes - and thus the <span class="math inline">\(\alpha\)</span> term above, actually represents one or more dummy codes. Thus, if we actually had two levels of Factor A (A1 and A2) and three levels of Factor B (B1, B2, B3), then the fully parameterised linear model would be:</p>
<p><span class="math display">\[ y=\beta_{A1B1}+\beta_{A2B1−A1B1}+\beta_{A1B2−A1B1}+\beta_{A1B3−A1B1}+\beta_{A2B2−A1B2−A2B1−A1B1}+\beta_{A2B3−A1B3−A2B1−A1B1}.\]</span></p>
<p>Thus, such a model would have six parameters to estimate (in addition to the variance).</p>
</div>
<div id="null-hypothesis" class="section level2">
<h2>Null hypothesis</h2>
<p>There are separate null hypothesis associated with each of the main effects and the interaction terms.</p>
<div id="model-1---fixed-effects" class="section level3">
<h3>Model 1 - fixed effects</h3>
<p><strong>Factor A</strong></p>
<ul>
<li><span class="math inline">\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)</span></li>
</ul>
<p>The population group means are all equal. The mean of population <span class="math inline">\(1\)</span> is equal to that of population <span class="math inline">\(2\)</span> and so on, and thus all population means are equal to an overall mean. If the effect of the <span class="math inline">\(i\)</span>-th group is the difference between the <span class="math inline">\(i\)</span>-th group mean and the overall mean (<span class="math inline">\(\alpha_i=\mu_i-\mu\)</span>) then the <span class="math inline">\(H_0\)</span> can alternatively be written as:</p>
<ul>
<li><span class="math inline">\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)</span></li>
</ul>
<p>The effect of each group equals zero. If one or more of the <span class="math inline">\(\alpha_i\)</span> are different from zero (the response mean for this treatment differs from the overall response mean), the null hypothesis is rejected indicating that the treatment has been found to affect the response variable. Note, as with multiple regression models, these “effects” represent <em>partial effects</em>. In the above, the effect of Factor A is actually the effect of Factor A at the first level of the Factor(s).</p>
<p><strong>Factor B</strong></p>
<ul>
<li><span class="math inline">\(H_0(B):\mu_1=\mu_2=\ldots=\mu_i=\mu\)</span></li>
</ul>
<p>The population group means are all equal - at the first level of Factor A. Equivalent interpretation to Factor A above.</p>
<p><strong>Factor AB: interaction</strong></p>
<ul>
<li><span class="math inline">\(H_0(AB):\mu_{ij}=\mu_i+\mu_j-\mu\)</span></li>
</ul>
<p>The population group means are all equal. For any given combination of factor levels, the population group mean will be equal to the difference between the overall population mean and the simple additive effects of the individual factor group means. That is, the effects of the main treatment factors are purely additive and independent of one another. This is equivalent to <span class="math inline">\(H_0(AB): \alpha\beta_{ij}=0\)</span>, no interaction between Factor A and Factor B.</p>
</div>
<div id="model-2---random-effects" class="section level3">
<h3>Model 2 - random effects</h3>
<p><strong>Factor A</strong></p>
<ul>
<li><span class="math inline">\(H_0(A):\sigma^2_{\alpha}=0\)</span></li>
</ul>
<p>The population variance equals zero. There is no added variance due to all possible levels of A.</p>
<p><strong>Factor B</strong></p>
<ul>
<li><span class="math inline">\(H_0(B):\sigma^2_{\beta}=0\)</span></li>
</ul>
<p>The population variance equals zero. There is no added variance due to all possible levels of B.</p>
<p><strong>Factor AB: interaction</strong></p>
<ul>
<li><span class="math inline">\(H_0(AB):\sigma^2_{\alpha\beta}=0\)</span></li>
</ul>
<p>There is no added variance due to all possible interactions between all possible levels of A and B.</p>
</div>
<div id="model-3---mixed-effects" class="section level3">
<h3>Model 3 - mixed effects</h3>
<p><strong>Fixed factor - e.g. A</strong></p>
<ul>
<li><span class="math inline">\(H_0(A):\mu_1=\mu_2=\ldots=\mu_i=\mu\)</span></li>
</ul>
<p>The population group means are all equal. The mean of population <span class="math inline">\(1\)</span> (pooled over all levels of the random factor) is equal to that of population <span class="math inline">\(2\)</span> and so on, and thus all population means are equal to an overall mean pooling over all possible levels of the random factor. If the effect of the <span class="math inline">\(i\)</span>-th group is the difference between the <span class="math inline">\(i\)</span>-th group mean and the overall mean (<span class="math inline">\(\alpha_i=\mu_i-\mu\)</span>) then the <span class="math inline">\(H_0\)</span> can alternatively be written as:</p>
<ul>
<li><span class="math inline">\(H_0(A):\alpha_1=\alpha_2=\ldots=\alpha_i=0\)</span></li>
</ul>
<p>No effect of any level of this factor pooled over all possible levels of the random factor.</p>
<p><strong>Random factor - e.g. B</strong></p>
<ul>
<li><span class="math inline">\(H_0(B):\sigma^2_{\beta}=0\)</span></li>
</ul>
<p>The population variance equals zero. There is no added variance due to all possible levels of B.</p>
<p><strong>Factor AB: interaction</strong></p>
<p>The interaction of a fixed and random factor is always considered a random factor.</p>
<ul>
<li><span class="math inline">\(H_0(AB):\sigma^2_{\alpha\beta}=0\)</span></li>
</ul>
<p>The population variance equals zero. There is no added variance due to all possible interactions between all possible levels of A and B.</p>
</div>
</div>
<div id="analysis-of-variance" class="section level2">
<h2>Analysis of variance</h2>
<p>When fixed factorial designs are balanced, the total variance in the response variable can be sequentially partitioned into what is explained by each of the model terms (factors and their interactions) and what is left unexplained. For each of the specific null hypotheses, the overall unexplained variability is used as the denominator in F-ratio calculations, and when a null hypothesis is true, an F-ratio should follow an F distribution with an expected value less than <span class="math inline">\(1\)</span>. Random factors are added to provide greater generality of conclusions. That is, to enable us to make conclusions about the effect of one factor (such as whether or not fertiliser is added) over all possible levels (not just those sampled) of a random factor (such as all possible locations, seasons, varieties, etc). In order to expand our conclusions beyond the specific levels used in the design, the hypothesis tests (and thus F-ratios) must reflect this extra generality by being more conservative.</p>
<p>The appropriate F-ratios for fixed, random and mixed factorial designs are presented below. Generally, once the terms (factors and interactions) have been ordered into a hierarchy (single factors at the top, highest level interactions at the bottom and terms of same order given equivalent positions in the hierarchy), the denominator for any term is selected as the next appropriate random term (an interaction that includes the term to be tested) encountered lower in the hierarchy. Interaction terms that contain one or more random factors are considered themselves to be random terms, as is the overall residual term (as all observations are assumed to be random representations of the entire population(s)). Note, when designs include a mixture of fixed and random crossed effects, exact denominator degrees of freedoms for certain F-ratios are undefined and traditional approaches adopt rather inexact estimated approximate or “Quasi” F-ratios. Pooling of non-significant F-ratio denominator terms, in which lower random terms are added to the denominator (provided <span class="math inline">\(\alpha &gt; 0.25\)</span>), may also be useful. For random factors within mixed models, selecting F-ratio denominators that are appropriate for the intended hypothesis tests is a particularly complex and controversial issue. Traditionally, there are two alternative approaches and whilst the statistical resumes of each are complicated, essentially they differ in whether or not the interaction term is constrained for the test of the random factor.</p>
<p>The <em>constrained or restricted method</em> (<strong>Model I</strong>), stipulates that for the calculation of a random factor F-ratio (which investigates the added variance added due to the random factor), the overall effect of the interaction is treated as zero. Consequently, the random factor is tested against the residual term. The <em>unconstrained or unrestrained method</em> (<strong>Model II</strong>) however, does not set the interaction effect to zero and therefore the interaction term is used as the random factor F-ratio denominator. This method assumes that the interaction terms for each level of the random factor are completely independent (correlations between the fixed factor must be consistent across all levels of the random factor). Some statisticians maintain that the independence of the interaction term is difficult to assess for clinical data and therefore, the restricted approach is more appropriate. However, others have suggested that the restricted method is only appropriate for balanced designs.</p>
</div>
<div id="quasi-f-ratios" class="section level2">
<h2>Quasi F-ratios</h2>
<p>An additional complication for three or more factor models that contain two or more random factors, is that there may not be a single appropriate interaction term to use as the denominator for many of the main effects F-ratios. For example, if Factors A and B are random and C is fixed, then there are two random interaction terms of equivalent level under Factor C (<span class="math inline">\(A^\prime \times C\)</span> and <span class="math inline">\(B^\prime \times C\)</span>). As a result, the value of the of the <em>Mean Squares</em> (MS) expected when the null hypothesis is true cannot be easily defined. The solutions for dealing with such situations (<em>quasi F-ratios</em>) involve adding (and subtracting) terms together to create approximate estimates of F-ratio denominators. Alternatively, for random factors, variance components with confidence intervals can be used. These solutions are sufficiently unsatisfying as to lead many statisticians to recommend that factorial designs with two or more random factors should avoided if possible. Arguably however, linear mixed effects models offer more appropriate solutions to the above issues as they are more robust for unbalanced designs, accommodate covariates and provide a more comprehensive treatment and overview of all the underlying data structures.</p>
<pre class="r"><code>&gt; fact_anova_table
    df           MS       A,B fixed          A,B random       
A   &quot;a-1&quot;        &quot;MS A&quot;   &quot;(MS A)/(MS res)&quot;  &quot;(MS A)/(MS AB)&quot; 
B   &quot;b-1&quot;        &quot;MS B&quot;   &quot;(MS B)/(MS res)&quot;  &quot;(MS B)/(MS AB)&quot; 
AB  &quot;(b-1)(a-1)&quot; &quot;MS AB&quot;  &quot;(MS AB)/(MS res)&quot; &quot;(MS AB)/(MS AB)&quot;
Res &quot;(n-1)ba&quot;    &quot;MS res&quot; &quot;&quot;                 &quot;&quot;               
    A fixed B random (model I) A fixed B random (model II)
A   &quot;(MS A)/(MS AB)&quot;           &quot;(MS A)/(MS AB)&quot;           
B   &quot;(MS B)/(MS res)&quot;          &quot;(MS B)/(MS AB)&quot;           
AB  &quot;(MS AB)/(MS res)&quot;         &quot;(MS AB)/(MS res)&quot;         
Res &quot;&quot;                         &quot;&quot;                         </code></pre>
<p>The corresponding <code>R</code> syntax is given below.</p>
<pre class="r"><code>&gt; #Type I SS (Balanced)
&gt; anova(lm(y ~ A * B, data))
&gt; 
&gt; #Type II SS (Unbalanced)
&gt; Anova(lm(y ~ A * B, data), type = &quot;II&quot;)
&gt; 
&gt; #Type III SS (Unbalanced)
&gt; Anova(lm(y ~ A * B, data), type = &quot;III&quot;)
&gt; 
&gt; #Variance components
&gt; summary(lmer(y ~ 1 + (1 | A) + (1 | B) + (1 | A:B), data))</code></pre>
<p>Note that for fixed factor models, when null hypotheses of interactions are rejected, the null hypothesis of the individual constituent factors are unlikely to represent the true nature of the effects and thus are of little value. The nature of such interactions are further explored by fitting simpler linear models (containing at least one less factor) separately for each of the levels of the other removed factor(s). Such <em>Main effects</em> tests are based on a subset of the data, and therefore estimates of the overall residual (unexplained) variability are unlikely to be as precise as the estimates based on the global model. Consequently, F-ratios involving <code>MSResid</code> should use the estimate of <code>MSResid</code> from the global model rather than that based on the smaller, theoretically less precise subset of data. For random and mixed models, since the objective is to generalise the effect of one factor over and above any interactions with other factors, the main factor effects can be interpreted even in the presence of significant interactions. Nevertheless, it should be noted that when a significant interaction is present in a mixed model, the power of the main fixed effects will be reduced (since the amount of variability explained by the interaction term will be relatively high, and this term is used as the denominator for the F-ratio calculation).</p>
</div>
<div id="assumptions" class="section level2">
<h2>Assumptions</h2>
<p>Hypothesis tests assume that the residuals are:</p>
<ul>
<li><p>normally distributed. Boxplots using the appropriate scale of replication (reflecting the appropriate residuals/F-ratio denominator (see table above) should be used to explore normality. Scale transformations are often useful.</p></li>
<li><p>equally varied. Boxplots and plots of means against variance (using the appropriate scale of replication) should be used to explore the spread of values. Residual plots should reveal no patterns. Scale transformations are often useful.</p></li>
<li><p>independent of one another.</p></li>
</ul>
<p><strong>Planned and unplanned comparisons</strong></p>
<p>As with single factor analysis of variance, planned and unplanned multiple comparisons (such as <em>Tukey</em>’s test) can be incorporated into or follow the linear model respectively so as to further investigate any patterns or trends within the main factors and/or the interactions. As with single factor analysis of variance, the contrasts must be defined prior to fitting the linear model, and no more than <span class="math inline">\(p−1\)</span> (where <span class="math inline">\(p\)</span> is the number of levels of the factor) contrasts can be defined for a factor.</p>
<p><strong>Unbalanced designs</strong></p>
<p>A factorial design can be thought of as a table made up of rows (representing the levels of one factor), columns (levels of another factor), and cells (the individual combinations of the set of factors). Whilst the middle left table does not have equal sample sizes in each cell, the sample sizes are in proportion and as such, does not present the issues discussed below for unbalanced designs.</p>
<p>In addition to impacting on normality and homogeneity of variance, unequal sample sizes in factorial designs have major implications for the partitioning of the total sums of squares into each of the model components. For balanced designs, the total sums of squares (<code>SSTotal</code>) is equal to the additive sums of squares of each of the components (including the residual). For example, in a two factor balanced design, <code>SSTotal=SSA+SSB+SSAB+SSResid</code>. This can be represented diagrammatically by a <em>Venn Diagram</em> in which each of the <code>SS</code> for the term components butt against one another and are surrounded by the <code>SSResid</code>. However, in unbalanced designs, the sums of squares will be non-orthogonal and the sum of the individual components does not add up to the total sums of squares. Diagrammatically, the <code>SS</code> of the terms intersect or are separated.</p>
<p>In regular <em>sequential sums of squares</em> (<strong>Type I SS</strong>), the sum of the individual sums of squares must be equal to the total sums of squares, the sums of squares of the last factor to be estimated will be calculated as the difference between the total sums of squares and what has already been accounted for by other components. Consequently, the order in which factors are specified in the model (and thus estimated) will alter their sums of squares and therefore their F-ratios. To overcome this problem, traditionally there are two other alternative methods of calculating sums of squares.</p>
<ul>
<li><p><strong>Type II (hierarchical) SS</strong> estimate the sums of squares of each term as the improvement it contributes upon addition of that term to a model of greater complexity and lower in the hierarchy (recall that the hierarchical structure descends from the simplest model down to the fully populated model). The SS for the interaction as well as the first factor to be estimated are the same as for Type I SS. Type II SS estimate the contribution of a factor over and above the contributions of other factors of equal or lower complexity but not above the contributions of the interaction terms or terms nested within the factor. However, these sums of squares are weighted by the sample sizes of each level and therefore are biased towards the trends produced by the groups (levels) that have higher sample sizes. As a result of the weightings, Type II SS actually test hypotheses about really quite complex combinations of factor levels. Rather than test a hypothesis that <span class="math inline">\(\mu_{High}=\mu_{Medium}=\mu_{Low}\)</span>, Type II SS might be testing that <span class="math inline">\(4\times\mu_{High}=1\times\mu_{Medium}=0.25\times\mu_{Low}\)</span>.</p></li>
<li><p><strong>Type III (marginal or orthogonal) SS</strong> estimate the sums of squares of each term as the improvement based on a comparison of models with and without the term and are unweighted by sample sizes. Type III SS essentially measure just the unique contribution of each factor over and above the contributions of the other factors and interactions. For unbalanced designs,Type III SS essentially test equivalent hypotheses to balanced Type I SS and are therefore arguably more appropriate for unbalanced factorial designs than Type II SS. Importantly, Type III SS are only interpretable if they are based on orthogonal contrasts (such as sum or helmert contrasts and not treatment contrasts).</p></li>
</ul>
<p>The choice between Type II and III SS clearly depends on the nature of the question. For example, if we had measured the growth rate of seedlings subjected to two factors (temperature and fertiliser), Type II SS could address whether there was an effect of temperature across the level of fertiliser treatment, whereas Type III SS could assess whether there was an effect of temperature within each level of the fertiliser treatment.</p>
<p>When an entire combination, or cell, is missing (perhaps due to unforeseen circumstances) it is not possible to test all the main effects and/or interactions. The bottom right table above depicts such as situation. One solution is to fit a large single factor ANOVA with as many levels as there are cells (this is known as a cell means model) and investigate various factor and interaction effects via specific contrasts (see the following tables). Difficulties in establishing appropriate error terms, makes missing cells in random and mixed factor designs substantially more complex.</p>
</div>
</div>
<div id="data-generation" class="section level1">
<h1>Data generation</h1>
<p>Imagine we has designed an experiment in which we had measured the response (<span class="math inline">\(y\)</span>) under a combination of two different potential influences (Factor A: levels a1 and a2; and Factor B: levels b1, b2 and b3), each combination replicated <span class="math inline">\(10\)</span> times (<span class="math inline">\(n=10\)</span>). As this section is mainly about the generation of artificial data (and not specifically about what to do with the data), understanding the actual details are optional and can be safely skipped.</p>
<pre class="r"><code>&gt; set.seed(123)
&gt; nA &lt;- 2  #number of levels of A
&gt; nB &lt;- 3  #number of levels of B
&gt; nsample &lt;- 10  #number of reps in each
&gt; A &lt;- gl(nA, 1, nA, lab = paste(&quot;a&quot;, 1:nA, sep = &quot;&quot;))
&gt; B &lt;- gl(nB, 1, nB, lab = paste(&quot;b&quot;, 1:nB, sep = &quot;&quot;))
&gt; data &lt;- expand.grid(A = A, B = B, n = 1:nsample)
&gt; X &lt;- model.matrix(~A * B, data = data)
&gt; eff &lt;- c(40, 15, 5, 0, -15, 10)
&gt; sigma &lt;- 3  #residual standard deviation
&gt; n &lt;- nrow(data)
&gt; eps &lt;- rnorm(n, 0, sigma)  #residuals
&gt; data$y &lt;- as.numeric(X %*% eff + eps)
&gt; head(data)  #print out the first six rows of the data set
   A  B n        y
1 a1 b1 1 38.31857
2 a2 b1 1 54.30947
3 a1 b2 1 49.67612
4 a2 b2 1 45.21153
5 a1 b3 1 40.38786
6 a2 b3 1 70.14519
&gt; 
&gt; with(data, interaction.plot(A, B, y))</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/generate_data-1.png" width="672" /></p>
<pre class="r"><code>&gt; 
&gt; ## ALTERNATIVELY, we could supply the population means and get the effect parameters from these.  To
&gt; ## correspond to the model matrix, enter the population means in the order of: a1b1, a2b1, a1b1,
&gt; ## a2b2,a1b3,a2b3
&gt; pop.means &lt;- as.matrix(c(40, 55, 45, 45, 40, 65), byrow = F)
&gt; ## Generate a minimum model matrix for the effects
&gt; XX &lt;- model.matrix(~A * B, expand.grid(A = factor(1:2), B = factor(1:3)))
&gt; ## Use the solve() function to solve what are effectively simultaneous equations
&gt; (eff &lt;- as.vector(solve(XX, pop.means)))
[1]  40  15   5   0 -15  10
&gt; 
&gt; data$y &lt;- as.numeric(X %*% eff + eps)</code></pre>
<p>With these sort of data, we are primarily interested in investigating whether there is a relationship between the continuous response variable and the treatment type. Does treatment type effect the response?.</p>
<div id="assumptions-1" class="section level2">
<h2>Assumptions</h2>
<p>The assumptions are:</p>
<ul>
<li><p>All of the observations are independent - this must be addressed at the design and collection stages. Importantly, to be considered independent replicates, the replicates must be made at the same scale at which the treatment is applied. For example, if the experiment involves subjecting organisms housed in tanks to different water temperatures, then the unit of replication is the individual tanks not the individual organisms in the tanks. The individuals in a tank are strictly not independent with respect to the treatment.</p></li>
<li><p>The response variable (and thus the residuals) should be normally distributed for each sampled populations (combination of factors). Boxplots of each treatment combination are useful for diagnosing major issues with normality.</p></li>
<li><p>The response variable should be equally varied (variance should not be related to mean as these are supposed to be estimated separately) for each combination of treatments. Again, boxplots are useful.</p></li>
</ul>
</div>
<div id="exploratory-data-analysis" class="section level2">
<h2>Exploratory data analysis</h2>
<p><strong>Normality and Homogeneity of variance</strong></p>
<pre class="r"><code>&gt; boxplot(y ~ A * B, data)
&gt; 
&gt; # OR via ggplot2
&gt; library(ggplot2)</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/exp1_data-1.png" width="672" /></p>
<pre class="r"><code>&gt; ggplot(data, aes(y = y, x = A, fill = B)) + geom_boxplot()</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/exp1_data-2.png" width="672" /></p>
<p><strong>Conclusions</strong></p>
<p>there is no evidence that the response variable is consistently non-normal across all populations - each boxplot is approximately symmetrical. There is no evidence that variance (as estimated by the height of the boxplots) differs between the five populations. More importantly, there is no evidence of a relationship between mean and variance - the height of boxplots does not increase with increasing position along the <span class="math inline">\(y\)</span>-axis. Hence it there is no evidence of non-homogeneity</p>
<p>Obvious violations could be addressed either by:</p>
<ul>
<li>transform the scale of the response variables (to address normality etc). Note transformations should be applied to the entire response variable (not just those populations that are skewed).</li>
</ul>
</div>
</div>
<div id="model-fitting" class="section level1">
<h1>Model fitting</h1>
<p>The observed response (<span class="math inline">\(y_i\)</span>) are assumed to be drawn from a normal distribution with a given mean (<span class="math inline">\(\mu\)</span>) and standard deviation (<span class="math inline">\(\sigma\)</span>). The expected values are themselves determined by the linear predictor (<span class="math inline">\(\boldsymbol X \boldsymbol \beta\)</span>). In this case, <span class="math inline">\(\boldsymbol \beta\)</span> represents the intercept associated with the first combination of groups, as well as the (effects) differences between this intercept and each other group. <span class="math inline">\(\boldsymbol X\)</span> is the model matrix. MCMC sampling requires priors on all parameters. We will employ weakly informative priors. Specifying ‘uninformative’ priors is always a bit of a balancing act. If the priors are too vague (wide) the MCMC sampler can wander off into nonscence areas of likelihood rather than concentrate around areas of highest likelihood (desired when wanting the outcomes to be largely driven by the data). On the other hand, if the priors are too strong, they may have an influence on the parameters. In such a simple model, this balance is very forgiving - it is for more complex models that prior choice becomes more important. For this simple model, we will go with zero-centered Gaussian (normal) priors with relatively large standard deviations (<span class="math inline">\(100\)</span>) for both the intercept and the treatment effect and a wide half-cauchy (<span class="math inline">\(\text{scale}=5\)</span>) for the standard deviation.</p>
<p><span class="math display">\[y_i \sim N(\mu_i,\sigma),  \]</span></p>
<p>where <span class="math inline">\(\mu_i=\beta_0 +\boldsymbol \beta \boldsymbol X\)</span>. The assumed priors are: <span class="math inline">\(\beta \sim N(0,100)\)</span> and <span class="math inline">\(\sigma \sim \text{Cauchy}(0,5)\)</span>. Exploratory data analysis suggests that the intercept and effects could be drawn from similar distributions (with mean in the <span class="math inline">\(10\)</span>’s and variances in the <span class="math inline">\(100\)</span>’s). Whilst we might therefore be tempted to provide different priors for the intercept, compared to the effects, for a simple model such as this, it is unlikely to be necessary. However, for more complex models, where prior specification becomes more critical, separate priors would probably be necessary. We proceed to code the model into <code>STAN</code>.</p>
<pre class="r"><code>&gt; modelString = &quot;
+   data {
+   int&lt;lower=1&gt; n;
+   int&lt;lower=1&gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&lt;lower=0&gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   // Likelihood
+   y~normal(mu,sigma);
+   
+   // Priors
+   beta ~ normal(0,100);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &quot;
&gt; ## write the model to a stan file 
&gt; writeLines(modelString, con = &quot;fact_anovaModel.stan&quot;)</code></pre>
<p>Arrange the data as a list (as required by <code>STAN</code>). As input, <code>STAN</code> will need to be supplied with: the response variable, the predictor variable, the total number of observed items. This all needs to be contained within a list object. We will create two data lists, one for each of the hypotheses.</p>
<pre class="r"><code>&gt; Xmat &lt;- model.matrix(~A * B, data)
&gt; data.list &lt;- with(data, list(y = y, X = Xmat, nX = ncol(Xmat), n = nrow(data)))</code></pre>
<p>Define the nodes (parameters and derivatives) to monitor and chain parameters.</p>
<pre class="r"><code>&gt; params &lt;- c(&quot;beta&quot;, &quot;sigma&quot;, &quot;log_lik&quot;)
&gt; nChains = 2
&gt; burnInSteps = 500
&gt; thinSteps = 1
&gt; numSavedSteps = 2000  #across all chains
&gt; nIter = ceiling(burnInSteps + (numSavedSteps * thinSteps)/nChains)
&gt; nIter
[1] 1500</code></pre>
<p>Now compile and run the Stan code via the <code>rstan</code> interface. Note that the first time <code>stan</code> is run after the <code>rstan</code> package is loaded, it is often necessary to run any kind of randomization function just to initiate the .Random.seed variable.</p>
<pre class="r"><code>&gt; library(rstan)</code></pre>
<p>During the warmup stage, the No-U-Turn sampler (NUTS) attempts to determine the optimum stepsize - the stepsize that achieves the target acceptance rate (<span class="math inline">\(0.8\)</span> or <span class="math inline">\(80\)</span>% by default) without divergence (occurs when the stepsize is too large relative to the curvature of the log posterior and results in approximations that are likely to diverge and be biased) - and without hitting the maximum treedepth (<span class="math inline">\(10\)</span>). At each iteration of the NUTS algorithm, the number of leapfrog steps doubles (as it increases the treedepth) and only terminates when either the NUTS criterion are satisfied or the tree depth reaches the maximum (<span class="math inline">\(10\)</span> by default).</p>
<pre class="r"><code>&gt; data.rstan &lt;- stan(data = data.list, file = &quot;fact_anovaModel.stan&quot;, chains = nChains, pars = params,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &#39;fact_anovaModel&#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.064 seconds (Warm-up)
Chain 1:                0.085 seconds (Sampling)
Chain 1:                0.149 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &#39;fact_anovaModel&#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.07 seconds (Warm-up)
Chain 2:                0.087 seconds (Sampling)
Chain 2:                0.157 seconds (Total)
Chain 2: 
&gt; 
&gt; print(data.rstan, par = c(&quot;beta&quot;, &quot;sigma&quot;))
Inference for Stan model: fact_anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]  40.19    0.03 0.90  38.43  39.57  40.17  40.81  41.99   710 1.00
beta[2]  14.71    0.05 1.33  12.05  13.83  14.71  15.56  17.39   655 1.01
beta[3]   4.99    0.04 1.29   2.42   4.11   5.03   5.88   7.35   845 1.00
beta[4]  -0.35    0.04 1.29  -2.80  -1.22  -0.37   0.53   2.15   907 1.00
beta[5] -14.51    0.07 1.86 -18.22 -15.78 -14.49 -13.21 -10.84   772 1.00
beta[6]  11.12    0.07 1.85   7.41   9.93  11.15  12.42  14.68   791 1.01
sigma     2.89    0.01 0.28   2.41   2.70   2.88   3.07   3.48  1521 1.00

Samples were drawn using NUTS(diag_e) at Tue Feb 18 14:32:34 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).</code></pre>
</div>
<div id="mcmc-diagnostics" class="section level1">
<h1>MCMC diagnostics</h1>
<p>In addition to the regular model diagnostic checks (such as residual plots), for Bayesian analyses, it is necessary to explore the characteristics of the MCMC chains and the sampler in general. Recall that the purpose of MCMC sampling is to replicate the posterior distribution of the model likelihood and priors by drawing a known number of samples from this posterior (thereby formulating a probability distribution). This is only reliable if the MCMC samples accurately reflect the posterior. Unfortunately, since we only know the posterior in the most trivial of circumstances, it is necessary to rely on indirect measures of how accurately the MCMC samples are likely to reflect the likelihood. I will briefly outline the most important diagnostics.</p>
<ul>
<li><p><em>Traceplots</em> for each parameter illustrate the MCMC sample values after each successive iteration along the chain. Bad chain mixing (characterised by any sort of pattern) suggests that the MCMC sampling chains may not have completely traversed all features of the posterior distribution and that more iterations are required to ensure the distribution has been accurately represented.</p></li>
<li><p><em>Autocorrelation</em> plot for each parameter illustrate the degree of correlation between MCMC samples separated by different lags. For example, a lag of <span class="math inline">\(0\)</span> represents the degree of correlation between each MCMC sample and itself (obviously this will be a correlation of <span class="math inline">\(1\)</span>). A lag of <span class="math inline">\(1\)</span> represents the degree of correlation between each MCMC sample and the next sample along the chain and so on. In order to be able to generate unbiased estimates of parameters, the MCMC samples should be independent (uncorrelated).</p></li>
<li><p><em>Potential scale reduction factor</em> (Rhat) statistic for each parameter provides a measure of sampling efficiency/effectiveness. Ideally, all values should be less than <span class="math inline">\(1.05\)</span>. If there are values of <span class="math inline">\(1.05\)</span> or greater it suggests that the sampler was not very efficient or effective. Not only does this mean that the sampler was potentially slower than it could have been but, more importantly, it could indicate that the sampler spent time sampling in a region of the likelihood that is less informative. Such a situation can arise from either a misspecified model or overly vague priors that permit sampling in otherwise nonscence parameter space.</p></li>
</ul>
<p>Prior to examining the summaries, we should have explored the convergence diagnostics. We use the package <code>mcmcplots</code> to obtain density and trace plots.</p>
<pre class="r"><code>&gt; library(mcmcplots)
&gt; s = as.array(data.rstan)
&gt; wch = grep(&quot;beta&quot;, dimnames(s)$parameters)
&gt; s = s[, , wch]
&gt; mcmc &lt;- do.call(mcmc.list, plyr:::alply(s[, , -(length(s[1, 1, ]))], 2, as.mcmc))
&gt; denplot(mcmc, parms = c(&quot;beta&quot;))</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag-1.png" width="672" /></p>
<pre class="r"><code>&gt; traplot(mcmc, parms = c(&quot;beta&quot;))</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag-2.png" width="672" /></p>
<p>These plots show no evidence that the chains have not reasonably traversed the entire multidimensional parameter space.</p>
<pre class="r"><code>&gt; #Raftery diagnostic
&gt; raftery.diag(mcmc)
$`1`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s

$`2`

Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95 

You need a sample size of at least 3746 with these values of q, r and s</code></pre>
<p>The Raftery diagnostics for each chain estimate that we would require no more than <span class="math inline">\(5000\)</span> samples to reach the specified level of confidence in convergence. As we have <span class="math inline">\(10500\)</span> samples, we can be confidence that convergence has occurred.</p>
<pre class="r"><code>&gt; #Autocorrelation diagnostic
&gt; stan_ac(data.rstan, pars = c(&quot;beta&quot;))</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag3-1.png" width="672" /></p>
<p>A lag of 10 appears to be sufficient to avoid autocorrelation (poor mixing).</p>
<pre class="r"><code>&gt; stan_rhat(data.rstan, pars = c(&quot;beta&quot;))</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag4-1.png" width="672" /></p>
<pre class="r"><code>&gt; stan_ess(data.rstan, pars = c(&quot;beta&quot;))</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_diag4-2.png" width="672" /></p>
<p>Rhat and effective sample size. In this instance, most of the parameters have reasonably high effective samples and thus there is likely to be a good range of values from which to estimate paramter properties.</p>
</div>
<div id="model-validation" class="section level1">
<h1>Model validation</h1>
<p>Model validation involves exploring the model diagnostics and fit to ensure that the model is broadly appropriate for the data. As such, exploration of the residuals should be routine. Ideally, a good model should also be able to predict the data used to fit the model. Residuals are not computed directly within <code>rstan</code> However, we can calculate them manually form the posteriors.</p>
<pre class="r"><code>&gt; mcmc = as.matrix(data.rstan)
&gt; # generate a model matrix
&gt; newdata = data
&gt; Xmat = model.matrix(~A * B, newdata)
&gt; ## get median parameter estimates
&gt; wch = grep(&quot;beta\\[&quot;, colnames(mcmc))
&gt; coefs = apply(mcmc[, wch], 2, median)
&gt; fit = as.vector(coefs %*% t(Xmat))
&gt; resid = data$y - fit
&gt; ggplot() + geom_point(data = NULL, aes(y = resid, x = fit)) + theme_classic()</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals-1.png" width="672" /></p>
<p>Residuals against predictors</p>
<pre class="r"><code>&gt; library(dplyr)
&gt; library(tidyr)
&gt; mcmc = as.matrix(data.rstan)
&gt; wch = grep(&quot;beta\\[&quot;, colnames(mcmc))
&gt; # generate a model matrix
&gt; newdata = newdata
&gt; Xmat = model.matrix(~A * B, newdata)
&gt; ## get median parameter estimates
&gt; coefs = apply(mcmc[, wch], 2, median)
&gt; print(coefs)
    beta[1]     beta[2]     beta[3]     beta[4]     beta[5]     beta[6] 
 40.1693379  14.7128347   5.0341367  -0.3693605 -14.4877785  11.1514524 
&gt; 
&gt; fit = as.vector(coefs %*% t(Xmat))
&gt; resid = data$y - fit
&gt; newdata = newdata %&gt;% cbind(fit, resid)
&gt; ggplot(newdata) + geom_point(aes(y = resid, x = A)) + theme_classic()</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals2-1.png" width="672" /></p>
<pre class="r"><code>&gt; 
&gt; ggplot(newdata) + geom_point(aes(y = resid, x = B)) + theme_classic()</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals2-2.png" width="672" /></p>
<p>And now for studentised residuals</p>
<pre class="r"><code>&gt; mcmc = as.matrix(data.rstan)
&gt; wch = grep(&quot;beta\\[&quot;, colnames(mcmc))
&gt; # generate a model matrix
&gt; newdata = data
&gt; Xmat = model.matrix(~A * B, newdata)
&gt; ## get median parameter estimates
&gt; coefs = apply(mcmc[, wch], 2, median)
&gt; fit = as.vector(coefs %*% t(Xmat))
&gt; resid = data$y - fit
&gt; sresid = resid/sd(resid)
&gt; ggplot() + geom_point(data = NULL, aes(y = sresid, x = fit)) + theme_classic()</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_residuals3-1.png" width="672" /></p>
<p>For this simple model, the studentized residuals yield the same pattern as the raw residuals (or the Pearson residuals for that matter). Lets see how well data simulated from the model reflects the raw data.</p>
<pre class="r"><code>&gt; mcmc = as.matrix(data.rstan)
&gt; wch = grep(&quot;beta\\[&quot;, colnames(mcmc))
&gt; #generate a model matrix
&gt; Xmat = model.matrix(~A*B, data)
&gt; ##get median parameter estimates
&gt; coefs = mcmc[,wch]
&gt; fit = coefs %*% t(Xmat)
&gt; ## draw samples from this model
&gt; yRep = sapply(1:nrow(mcmc), function(i) rnorm(nrow(data), fit[i,], mcmc[i, &#39;sigma&#39;]))
&gt; newdata = data.frame(A=data$A, B=data$B, yRep) %&gt;% gather(key=Sample, value=Value,-A,-B)
&gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=A, fill=&#39;Model&#39;), alpha=0.5)+
+  geom_violin(data=data, aes(y=y,x=A,fill=&#39;Obs&#39;), alpha=0.5) +
+  geom_point(data=data, aes(y=y, x=A), position=position_jitter(width=0.1,height=0),
+             color=&#39;black&#39;) + theme_classic()</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep-1.png" width="672" /></p>
<pre class="r"><code>&gt; 
&gt; ggplot(newdata) +
+  geom_violin(aes(y=Value, x=B, fill=&#39;Model&#39;, group=B, color=A), alpha=0.5)+
+  geom_point(data=data, aes(y=y, x=B, group=B,color=A)) + theme_classic()</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep-2.png" width="672" /></p>
<p>The predicted trends do encapsulate the actual data, suggesting that the model is a reasonable representation of the underlying processes. Note, these are prediction intervals rather than confidence intervals as we are seeking intervals within which we can predict individual observations rather than means. We can also explore the posteriors of each parameter.</p>
<pre class="r"><code>&gt; library(bayesplot)
&gt; mcmc_intervals(as.matrix(data.rstan), regex_pars = &quot;beta|sigma&quot;)</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep2-1.png" width="672" /></p>
<pre class="r"><code>&gt; mcmc_areas(as.matrix(data.rstan), regex_pars = &quot;beta|sigma&quot;)</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_rep2-2.png" width="672" /></p>
</div>
<div id="parameter-estimates" class="section level1">
<h1>Parameter estimates</h1>
<p>Although all parameters in a Bayesian analysis are considered random and are considered a distribution, rarely would it be useful to present tables of all the samples from each distribution. On the other hand, plots of the posterior distributions have some use. Nevertheless, most workers prefer to present simple statistical summaries of the posteriors. Popular choices include the median (or mean) and <span class="math inline">\(95\)</span>% credibility intervals.</p>
<pre class="r"><code>&gt; mcmcpvalue &lt;- function(samp) {
+     ## elementary version that creates an empirical p-value for the
+     ## hypothesis that the columns of samp have mean zero versus a general
+     ## multivariate distribution with elliptical contours.
+ 
+     ## differences from the mean standardized by the observed
+     ## variance-covariance factor
+ 
+     ## Note, I put in the bit for single terms
+     if (length(dim(samp)) == 0) {
+         std &lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - mean(samp),
+             transpose = TRUE)
+         sqdist &lt;- colSums(std * std)
+         sum(sqdist[-1] &gt; sqdist[1])/length(samp)
+     } else {
+         std &lt;- backsolve(chol(var(samp)), cbind(0, t(samp)) - colMeans(samp),
+             transpose = TRUE)
+         sqdist &lt;- colSums(std * std)
+         sum(sqdist[-1] &gt; sqdist[1])/nrow(samp)
+     }
+ 
+ }</code></pre>
<p>First, we look at the results from the additive model.</p>
<pre class="r"><code>&gt; print(data.rstan, pars = c(&quot;beta&quot;, &quot;sigma&quot;))
Inference for Stan model: fact_anovaModel.
2 chains, each with iter=1500; warmup=500; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=2000.

          mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
beta[1]  40.19    0.03 0.90  38.43  39.57  40.17  40.81  41.99   710 1.00
beta[2]  14.71    0.05 1.33  12.05  13.83  14.71  15.56  17.39   655 1.01
beta[3]   4.99    0.04 1.29   2.42   4.11   5.03   5.88   7.35   845 1.00
beta[4]  -0.35    0.04 1.29  -2.80  -1.22  -0.37   0.53   2.15   907 1.00
beta[5] -14.51    0.07 1.86 -18.22 -15.78 -14.49 -13.21 -10.84   772 1.00
beta[6]  11.12    0.07 1.85   7.41   9.93  11.15  12.42  14.68   791 1.01
sigma     2.89    0.01 0.28   2.41   2.70   2.88   3.07   3.48  1521 1.00

Samples were drawn using NUTS(diag_e) at Tue Feb 18 14:32:34 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&gt; 
&gt; # OR
&gt; library(broom)
&gt; tidyMCMC(data.rstan, conf.int = TRUE, conf.method = &quot;HPDinterval&quot;, pars = c(&quot;beta&quot;, &quot;sigma&quot;))
# A tibble: 7 x 5
  term    estimate std.error conf.low conf.high
  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 beta[1]   40.2       0.905    38.5      42.0 
2 beta[2]   14.7       1.33     12.2      17.5 
3 beta[3]    4.99      1.29      2.35      7.29
4 beta[4]   -0.349     1.29     -2.78      2.16
5 beta[5]  -14.5       1.86    -18.4     -11.1 
6 beta[6]   11.1       1.85      7.40     14.7 
7 sigma      2.89      0.279     2.38      3.43</code></pre>
<p><strong>Conclusions</strong></p>
<ul>
<li><p>The intercept represents the mean of the first combination Aa1:Bb1 is <span class="math inline">\(40.2\)</span></p></li>
<li><p>Aa2:Bb1 is <span class="math inline">\(14.7\)</span> units greater than Aa1:Bb1</p></li>
<li><p>Aa1:Bb2 is <span class="math inline">\(5\)</span> units greater Aa1:Bb1</p></li>
<li><p>Aa1:Bb3 is <span class="math inline">\(-0.335\)</span> units greater Aa1:Bb1</p></li>
<li><p>Aa2:Bb2 is <span class="math inline">\(-14.6\)</span> units greater than the difference between (Aa1:Bb2 + Aa2:Bb1) and (2*Aa1:Bb1)</p></li>
<li><p>Aa2:Bb3 is <span class="math inline">\(11.1\)</span> units greater than the difference between (Aa1:Bb3 + Aa2:Bb1) and (2*Aa1:Bb1)</p></li>
</ul>
<p>The <span class="math inline">\(95\)</span>% credibility interval for both interactive effects (Aa2:Bb2 and Aa2:Bb3) do not contain <span class="math inline">\(0\)</span>, implying significant interactions between A and B. While workers attempt to become comfortable with a new statistical framework, it is only natural that they like to evaluate and comprehend new structures and output alongside more familiar concepts. One way to facilitate this is via Bayesian p-values that are somewhat analogous to the frequentist p-values for investigating the hypothesis that a parameter is equal to zero.</p>
<pre class="r"><code>&gt; ## since values are less than zero
&gt; mcmcpvalue(as.matrix(data.rstan)[, &quot;beta[2]&quot;])
[1] 0
&gt; mcmcpvalue(as.matrix(data.rstan)[, &quot;beta[3]&quot;])
[1] 0
&gt; mcmcpvalue(as.matrix(data.rstan)[, &quot;beta[4]&quot;])
[1] 0.777
&gt; mcmcpvalue(as.matrix(data.rstan)[, &quot;beta[5]&quot;])
[1] 0
&gt; mcmcpvalue(as.matrix(data.rstan)[, &quot;beta[6]&quot;])
[1] 0
&gt; mcmcpvalue(as.matrix(data.rstan)[, c(&quot;beta[5]&quot;, &quot;beta[6]&quot;)])
[1] 0</code></pre>
<p>There is evidence of an interaction between A and B. In a Bayesian context, we can compare models using the <strong>leave-one-out cross-validation</strong> statistics. Leave-one-out (LOO) cross-validation explores how well a series of models can predict withheld values <span class="citation">Vehtari, Gelman, and Gabry (2017)</span>. The LOO Information Criterion (LOOIC) is analogous to the AIC except that the LOOIC takes priors into consideration, does not assume that the posterior distribution is drawn from a multivariate normal and integrates over parameter uncertainty so as to yield a distribution of looic rather than just a point estimate. The LOOIC does however assume that all observations are equally influential (it does not matter which observations are left out). This assumption can be examined via the Pareto <span class="math inline">\(k\)</span> estimate (values greater than <span class="math inline">\(0.5\)</span> or more conservatively <span class="math inline">\(0.75\)</span> are considered overly influential). We can compute LOOIC if we store the loglikelihood from our <code>STAN</code> model, which can then be extracted to compute the information criterion using the package <code>loo</code>.</p>
<pre class="r"><code>&gt; library(loo)
&gt; (full = loo(extract_log_lik(data.rstan)))

Computed from 2000 by 60 log-likelihood matrix

         Estimate   SE
elpd_loo   -151.8  5.2
p_loo         6.3  1.1
looic       303.5 10.5
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k &lt; 0.5).
See help(&#39;pareto-k-diagnostic&#39;) for details.
&gt; 
&gt; # now fit a model without main factor
&gt; modelString2 = &quot;
+   data {
+   int&lt;lower=1&gt; n;
+   int&lt;lower=1&gt; nX;
+   vector [n] y;
+   matrix [n,nX] X;
+   }
+   parameters {
+   vector[nX] beta;
+   real&lt;lower=0&gt; sigma;
+   }
+   transformed parameters {
+   vector[n] mu;
+ 
+   mu = X*beta;
+   }
+   model {
+   // Likelihood
+   y~normal(mu,sigma);
+   
+   // Priors
+   beta ~ normal(0,1000);
+   sigma~cauchy(0,5);
+   }
+   generated quantities {
+   vector[n] log_lik;
+   
+   for (i in 1:n) {
+   log_lik[i] = normal_lpdf(y[i] | mu[i], sigma); 
+   }
+   }
+   
+   &quot;
&gt; 
&gt; ## write the model to a stan file 
&gt; writeLines(modelString2, con = &quot;fact_anovaModel2.stan&quot;)
&gt; 
&gt; Xmat &lt;- model.matrix(~A + B, data)
&gt; data.list &lt;- with(data, list(y = y, X = Xmat, n = nrow(data), nX = ncol(Xmat)))
&gt; data.rstan.red &lt;- stan(data = data.list, file = &quot;fact_anovaModel2.stan&quot;, chains = nChains,
+     iter = nIter, warmup = burnInSteps, thin = thinSteps)

SAMPLING FOR MODEL &#39;fact_anovaModel2&#39; NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 1: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 1: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 1: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 1: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 1: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 1: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 1: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 1: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 1: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 1: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.061 seconds (Warm-up)
Chain 1:                0.068 seconds (Sampling)
Chain 1:                0.129 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL &#39;fact_anovaModel2&#39; NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 1500 [  0%]  (Warmup)
Chain 2: Iteration:  150 / 1500 [ 10%]  (Warmup)
Chain 2: Iteration:  300 / 1500 [ 20%]  (Warmup)
Chain 2: Iteration:  450 / 1500 [ 30%]  (Warmup)
Chain 2: Iteration:  501 / 1500 [ 33%]  (Sampling)
Chain 2: Iteration:  650 / 1500 [ 43%]  (Sampling)
Chain 2: Iteration:  800 / 1500 [ 53%]  (Sampling)
Chain 2: Iteration:  950 / 1500 [ 63%]  (Sampling)
Chain 2: Iteration: 1100 / 1500 [ 73%]  (Sampling)
Chain 2: Iteration: 1250 / 1500 [ 83%]  (Sampling)
Chain 2: Iteration: 1400 / 1500 [ 93%]  (Sampling)
Chain 2: Iteration: 1500 / 1500 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.064 seconds (Warm-up)
Chain 2:                0.062 seconds (Sampling)
Chain 2:                0.126 seconds (Total)
Chain 2: 
&gt; 
&gt; (reduced = loo(extract_log_lik(data.rstan.red)))

Computed from 2000 by 60 log-likelihood matrix

         Estimate  SE
elpd_loo   -196.6 3.9
p_loo         4.4 0.5
looic       393.2 7.7
------
Monte Carlo SE of elpd_loo is 0.1.

All Pareto k estimates are good (k &lt; 0.5).
See help(&#39;pareto-k-diagnostic&#39;) for details.
&gt; 
&gt; par(mfrow = 1:2, mar = c(5, 3.8, 1, 0) + 0.1, las = 3)
&gt; plot(full, label_points = TRUE)
&gt; plot(reduced, label_points = TRUE)</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_looic-1.png" width="672" /></p>
<p>the expected out-of-sample predictive accuracy is substantially lower for the model that includes the interaction (full model).</p>
</div>
<div id="graphical-summaries" class="section level1">
<h1>Graphical summaries</h1>
<p>A nice graphic is often a great accompaniment to a statistical analysis. Although there are no fixed assumptions associated with graphing (in contrast to statistical analyses), we often want the graphical summaries to reflect the associated statistical analyses. After all, the sample is just one perspective on the population(s). What we are more interested in is being able to estimate and depict likely population parameters/trends. Thus, whilst we could easily provide a plot displaying the raw data along with simple measures of location and spread, arguably, we should use estimates that reflect the fitted model. In this case, it would be appropriate to plot the credibility interval associated with each group.</p>
<pre class="r"><code>&gt; mcmc = as.matrix(data.rstan)
&gt; wch = grep(&quot;^beta&quot;, colnames(mcmc))
&gt; ## Calculate the fitted values
&gt; newdata = expand.grid(A=levels(data$A), B=levels(data$B))
&gt; Xmat = model.matrix(~A*B,newdata)
&gt; coefs = mcmc[,wch]
&gt; fit=coefs %*% t(Xmat)
&gt; newdata = newdata %&gt;% cbind(tidyMCMC(fit, conf.int=TRUE, conf.method=&#39;HPDinterval&#39;))
&gt; newdata
   A  B estimate std.error conf.low conf.high
1 a1 b1 40.18899 0.9047706 38.49347  42.01653
2 a2 b1 54.89674 0.9051450 53.09543  56.61192
3 a1 b2 45.17758 0.9211897 43.52976  47.13596
4 a2 b2 45.37979 0.8898798 43.70321  47.20260
5 a1 b3 39.84017 0.9091679 38.15775  41.68992
6 a2 b3 65.67259 0.9105872 63.89731  67.49493
&gt; 
&gt; ggplot(newdata, aes(y=estimate, x=B, fill=A)) +
+  geom_blank() +
+  geom_line(aes(x=as.numeric(B), linetype=A)) +
+  geom_linerange(aes(ymin=conf.low, ymax=conf.high))+
+  geom_point(aes(shape=A), size=3)+
+  scale_y_continuous(&#39;Y&#39;)+
+  scale_x_discrete(&#39;B&#39;)+
+  scale_shape_manual(&#39;A&#39;,values=c(21,16))+
+  scale_fill_manual(&#39;A&#39;,values=c(&#39;white&#39;,&#39;black&#39;))+
+  scale_linetype_manual(&#39;A&#39;,values=c(&#39;solid&#39;,&#39;dashed&#39;))+
+  theme_classic() +
+  theme(legend.justification=c(0,1), legend.position=c(0.05,1),
+   axis.title.y=element_text(vjust=2, size=rel(1.25)),
+   axis.title.x=element_text(vjust=-2, size=rel(1.25)),
+   plot.margin=unit(c(0.5,0.5,2,2), &#39;lines&#39;),
+   legend.key.size=unit(1,&#39;cm&#39;)) + theme_classic()</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/mcmc_post1-1.png" width="672" /></p>
</div>
<div id="finite-population-standard-deviations" class="section level1">
<h1>Finite population standard deviations</h1>
<p>Variance components, the amount of added variance attributed to each influence, are traditionally estimated for so called random effects. These are the effects for which the levels employed in the design are randomly selected to represent a broader range of possible levels. For such effects, effect sizes (differences between each level and a reference level) are of little value. Instead, the “importance” of the variables are measured in units of variance components. On the other hand, regular variance components for fixed factors (those whose measured levels represent the only levels of interest) are not logical - since variance components estimate variance as if the levels are randomly selected from a larger population. Nevertheless, in order to compare and contrast the scale of variability of both fixed and random factors, it is necessary to measure both on the same scale (sample or population based variance).</p>
<p>Finite-population variance components assume that the levels of all factors (fixed and random) in the design are all the possible levels available (<span class="citation">Gelman and others (2005)</span>). In other words, they are assumed to represent finite populations of levels. Sample (rather than population) statistics are then used to calculate these finite-population variances (or standard deviations). Since standard deviation (and variance) are bound at zero, standard deviation posteriors are typically non-normal. Consequently, medians and HPD intervals are more robust estimates.</p>
<pre><code># A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 sd.A        10.4     0.942      8.64     12.4 
2 sd.B         3.06    0.634      1.81      4.25
3 sd.AB       10.4     0.734      9.02     11.9 
4 sd.resid     2.84    0.0811     2.72      3.00
# A tibble: 4 x 5
  term     estimate std.error conf.low conf.high
  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 sd.A         39.1     1.94     35.0       42.6
2 sd.B         11.5     1.90      7.70      15.1
3 sd.AB        39.0     0.946    37.2       41.0
4 sd.resid     10.6     0.862     9.37      12.5</code></pre>
<p><img src="/STAN/factorial-anova-stan/2020-02-01-factorial-anova-stan_files/figure-html/effects_modelv4-1.png" width="672" /></p>
<p>Approximately <span class="math inline">\(39\)</span>% of the total finite population standard deviation is due to the interaction between factor A and factor B.</p>
</div>
<div id="r-squared" class="section level1">
<h1>R squared</h1>
<p>In a frequentist context, the <span class="math inline">\(R^2\)</span> value is seen as a useful indicator of goodness of fit. Whilst it has long been acknowledged that this measure is not appropriate for comparing models (for such purposes information criterion such as AIC are more appropriate), it is nevertheless useful for estimating the amount (percent) of variance explained by the model. In a frequentist context, <span class="math inline">\(R^2\)</span> is calculated as the variance in predicted values divided by the variance in the observed (response) values. Unfortunately, this classical formulation does not translate simply into a Bayesian context since the equivalently calculated numerator can be larger than the an equivalently calculated denominator - thereby resulting in an <span class="math inline">\(R^2\)</span> greater than <span class="math inline">\(100\)</span>%. <span class="citation">Gelman et al. (2019)</span> proposed an alternative formulation in which the denominator comprises the sum of the explained variance and the variance of the residuals.</p>
<p>So in the standard regression model notation of:</p>
<p><span class="math display">\[ y_i \sim \text{Normal}(\boldsymbol X \boldsymbol \beta, \sigma),\]</span></p>
<p>the <span class="math inline">\(R^2\)</span> could be formulated as</p>
<p><span class="math display">\[ R^2 = \frac{\sigma^2_f}{\sigma^2_f + \sigma^2_e},\]</span></p>
<p>where <span class="math inline">\(\sigma^2_f=\text{var}(\boldsymbol X \boldsymbol \beta)\)</span>, and for normal models <span class="math inline">\(\sigma^2_e=\text{var}(y-\boldsymbol X \boldsymbol \beta)\)</span></p>
<pre class="r"><code>&gt; mcmc &lt;- as.matrix(data.rstan)
&gt; Xmat = model.matrix(~A * B, data)
&gt; wch = grep(&quot;^beta&quot;, colnames(mcmc))
&gt; coefs = mcmc[, wch]
&gt; fit = coefs %*% t(Xmat)
&gt; resid = sweep(fit, 2, data$y, &quot;-&quot;)
&gt; var_f = apply(fit, 1, var)
&gt; var_e = apply(resid, 1, var)
&gt; R2 = var_f/(var_f + var_e)
&gt; tidyMCMC(as.mcmc(R2), conf.int = TRUE, conf.method = &quot;HPDinterval&quot;)
# A tibble: 1 x 5
  term  estimate std.error conf.low conf.high
  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 var1     0.913   0.00814    0.898     0.925
&gt; 
&gt; # for comparison with frequentist
&gt; summary(lm(y ~ A * B, data))

Call:
lm(formula = y ~ A * B, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.5694 -1.8517 -0.0589  1.7120  6.5966 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  40.1940     0.8980  44.760  &lt; 2e-16 ***
Aa2          14.7163     1.2700  11.588 2.88e-16 ***
Bb2           4.9823     1.2700   3.923 0.000249 ***
Bb3          -0.3464     1.2700  -0.273 0.786077    
Aa2:Bb2     -14.5093     1.7960  -8.079 7.37e-11 ***
Aa2:Bb3      11.1056     1.7960   6.184 8.65e-08 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.84 on 54 degrees of freedom
Multiple R-squared:   0.92, Adjusted R-squared:  0.9125 
F-statistic: 124.1 on 5 and 54 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="dealing-with-interactions" class="section level1">
<h1>Dealing with interactions</h1>
<p>In the presence of interations, conclusions about the main effects are overly simplistic at best and completely inaccurate at worst. Therefore, in the presense of interactions we should attempt to tease the analysis appart a little. In the current working example, we have identified that there is a significant interaction between Factor A and Factor B. Our exploration of the regression coefficients, indicated that the pattern between b1, b2 and b3 might differ between a1 and a2. Similarly, if we consider the coefficients from the perspective of Factor A, we can see that the patterns between a1 and a2 are similar for b1 and b3, yet very different for b2.</p>
<p>At this point, we can then split the two-factor model up into a series of single-factor models, either:</p>
<ul>
<li><p>examining the effects of Factor B separately for each level of Factor A (two single-factor models) or</p></li>
<li><p>examining the effects of Factor A separately for each level of Factor B (three single-factor models)</p></li>
</ul>
<p>However, rather than subset the data and fit isolated smaller models, it is arguably better to treat these explorations as contrasts. As such we could either:</p>
<ul>
<li><p>apply specific contrasts to the already fit model</p></li>
<li><p>define the specific contrasts and use them to refit the model</p></li>
</ul>
<p>We will do the former of these options since we have already fit the global model. For this demonstration, we will explore the effect of factor A at each level of factor B. I will illustrate two ways to perform these contrasts on an already fit model:</p>
<ol style="list-style-type: decimal">
<li>By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.</li>
</ol>
<pre class="r"><code>&gt; mcmc &lt;- as.matrix(data.rstan)
&gt; wch = grep(&quot;^beta&quot;, colnames(mcmc))
&gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&gt; Xmat = model.matrix(~A * B, data = newdata)
&gt; coefs = mcmc[, wch]
&gt; fit = coefs %*% t(Xmat)
&gt; head(fit)
          
iterations        1        2        3        4        5        6
      [1,] 39.69752 55.00221 44.75174 45.00506 40.68290 66.39012
      [2,] 38.09011 54.98489 46.07381 45.40083 40.12613 65.72993
      [3,] 38.43453 55.88735 45.44974 44.95014 39.88235 65.69477
      [4,] 40.62015 55.15234 45.25819 45.63459 39.89825 65.41017
      [5,] 41.36307 54.24942 45.07712 46.12218 39.55757 64.96870
      [6,] 41.36075 54.50463 45.34008 44.16493 38.64767 66.31968
&gt; 
&gt; ## we want to compare columns 2-1, 4-3 and 6-5
&gt; comps = fit[, c(2, 4, 6)] - fit[, c(1, 3, 5)]
&gt; tidyMCMC(comps, conf.int = TRUE, conf.method = &quot;HPDinterval&quot;)
# A tibble: 3 x 5
  term  estimate std.error conf.low conf.high
  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 2       14.7        1.33    12.2      17.5 
2 4        0.202      1.29    -2.37      2.74
3 6       25.8        1.26    23.4      28.3 </code></pre>
<ol start="2" style="list-style-type: decimal">
<li>By generating the posteriors of the cell means (means of each factor combination) and then manually compare the appropriate columns for specific levels of factor B.</li>
</ol>
<pre class="r"><code>&gt; mcmc &lt;- as.matrix(data.rstan)
&gt; wch = grep(&quot;^beta&quot;, colnames(mcmc))
&gt; newdata = expand.grid(A = levels(data$A), B = levels(data$B))
&gt; Xmat = model.matrix(~A * B, data = newdata)
&gt; contr = attr(Xmat, &quot;contrasts&quot;)
&gt; newdata.a1 = model.frame(~A * B, expand.grid(A = levels(data$A)[1], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&gt; Xmat.a1 = model.matrix(~A * B, data = newdata.a1, contrasts = contr)
&gt; newdata.a2 = model.frame(~A * B, expand.grid(A = levels(data$A)[2], B = levels(data$B)),
+     xlev = list(A = levels(data$A), B = levels(data$B)))
&gt; Xmat.a2 = model.matrix(~A * B, data = newdata.a2, contrasts = contr)
&gt; Xmat = Xmat.a2 - Xmat.a1
&gt; coefs = mcmc[, wch]
&gt; fit = coefs %*% t(Xmat)
&gt; tidyMCMC(fit, conf.int = TRUE, conf.method = &quot;HPDinterval&quot;)
# A tibble: 3 x 4
  estimate std.error conf.low conf.high
     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1   14.7        1.33    12.2      17.5 
2    0.202      1.29    -2.37      2.74
3   25.8        1.26    23.4      28.3 </code></pre>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references hanging-indent">
<div id="ref-gelman2019r">
<p>Gelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” <em>The American Statistician</em> 73 (3): 307–9.</p>
</div>
<div id="ref-gelman2015stan">
<p>Gelman, Andrew, Daniel Lee, and Jiqiang Guo. 2015. “Stan: A Probabilistic Programming Language for Bayesian Inference and Optimization.” <em>Journal of Educational and Behavioral Statistics</em> 40 (5): 530–43.</p>
</div>
<div id="ref-gelman2005analysis">
<p>Gelman, Andrew, and others. 2005. “Analysis of Variance—Why It Is More Important Than Ever.” <em>The Annals of Statistics</em> 33 (1): 1–53.</p>
</div>
<div id="ref-rstanpackage">
<p>Stan Development Team. 2018. “RStan: The R Interface to Stan.” <a href="http://mc-stan.org/">http://mc-stan.org/</a>.</p>
</div>
<div id="ref-vehtari2017practical">
<p>Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. “Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and Waic.” <em>Statistics and Computing</em> 27 (5): 1413–32.</p>
</div>
</div>
</div>

    </div>

    

<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/tutorials/">tutorials</a>
  
  <a class="badge badge-light" href="/tags/stan/">STAN</a>
  
  <a class="badge badge-light" href="/tags/anova/">anova</a>
  
  <a class="badge badge-light" href="/tags/factor-analysis/">factor analysis</a>
  
  <a class="badge badge-light" href="/tags/factorial-designs/">factorial designs</a>
  
</div>



    
      








  
  
    
  
  





  
  
  
  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="/authors/andrea-gabrio/"></a></h5>
      
      
      <ul class="network-icon" aria-hidden="true">
        
      </ul>
    </div>
  </div>



      
      
      <div class="article-widget">
        <div class="hr-light"></div>
        <h3>Related</h3>
        <ul>
          
          <li><a href="/jags/factorial-anova-jags/factorial-anova-jags/">Factorial Analysis of Variance - JAGS</a></li>
          
          <li><a href="/stan/single-factor-anova-stan/single-factor-anova-stan/">Single Factor Anova - STAN</a></li>
          
          <li><a href="/stan/ancova-stan/ancova-stan/">Analysis of Covariance - STAN</a></li>
          
          <li><a href="/jags/single-factor-anova-jags/single-factor-anova-jags/">Single Factor Anova - JAGS</a></li>
          
          <li><a href="/jags/ancova-jags/ancova-jags/">Analysis of Covariance - JAGS</a></li>
          
        </ul>
      </div>
      
    

    

    


  </div>
</article>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.9ef1b53ee2bde6c7f33b150c6ba4d452.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">

  <p class="powered-by">
    &#169; Andrea Gabrio &middot;
    <code>2020</code> 
    &middot; Based on the 
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
