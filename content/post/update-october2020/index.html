---
title: "Why health economists do not care about statistical significance ?"
author: Andrea Gabrio
date: '2020-10-23'
slug: update-october2020
categories: ["health economics", "statistics"]
tags: ["decision-making", "cost-effectiveness analysis", "health economics"]
subtitle: ''
summary: ''
authors: ["Andrea Gabrio"]
lastmod: '2020-10-23T11:54:30+01:00'
featured: yes
draft: no
image:
  caption: 'The irrelevance of inference'
  focal_point: 'Center'
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  preview_only: no
projects: []
bibliography: [bib_oct2020.bib]
---

<link href="index_files/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="index_files/anchor-sections/anchor-sections.js"></script>


<p>Hello dear readers!</p>
<p>I have finally come back from my lethargy with a new exciting posts about why the job of health economists, although inevitably involving some statistics, can be very different from what standard statisticians typically do. To make this point, I will abuse and give my own opinion of the notorious (and now quite old) paper published by Dr. Claxton (<span class="citation">Claxton (1999)</span>).</p>
<p>Before starting my discussion I would like to point out a very nice <a href="https://aheblog.com/2017/03/22/the-irrelevance-of-inference-almost-20-years-on/#:~:text=The%20Irrelevance%20of%20Inference%20was,the%20evaluation%20of%20health%20technologies.&amp;text=From%20a%20Bayesian%20perspective%20estimation%20and%20inference%20is%20a%20decision%20problem.">post</a> made by <a href="https://aheblog.com/author/samuelwatson/">Sam Watson</a> on the <a href="https://aheblog.com/">Academic Health Economists’ Blog</a>, who nicely provided his own opinion on the matter and discussed the pros and cons of the paper. I really recommend people interested in knowing more about health economics to check out this blog which is one of the most popular in the field and which has contributions from many many health economists on different topics.</p>
<p>In this post, in contrast to what Sam did in his own, I will not focus on the technical details about the health economics decision-making problem of minimising the expected loss / maximising the utility function in terms of societal preferences (i.e. social welfare in terms of effectiveness and costs). Instead, here I would like to address the much simpler and basic question <strong>why health economists do not use statistical significance in their analyses?</strong>. In my own experience, especially in trial-based analyses, I had to work closely with both health economists and statisticians who often are unaware of what the other “people” are doing. Since cost-effectiveness analyses have become more and more important over the last decade, I believe it is imperative that even statisticians should learn at least the basics of what their colleagues are doing and most importantly why. Of course, the same applies for health economists who should know a bit of statistics in order to do their job. However, in general, I have the feeling statisticians are reluctant to care about health economics, perhaps due to different statistical methodology required for these analyses compared with standard methods used for the analysis of clinical outcomes.</p>
<p>Apologies for the very long premise. So, let’s start with the most basic question of all. what is the objective of health economics ? To inform decision-makers about the cost-effectiveness of a given treatment with respect to alternatives. Unlike the standard clinical analysis which focuses merely on detecting whether there is a “clinically relevant” difference between treatments in terms of some pre-defined outcome measure, the health economic analysis does not qualify as a mere yes/no problem due to the existence of <strong>opportunity costs</strong>. These are the losses, either in terms of forgone benefits or extra costs, that the society/health care provider would incur by funding a treatment which is not cost-effective compared to others. Precisely, the decision-making nature of the problem comes from the fact that only a limited amount of resources are available to decision-makers, who need to define some sort of rule to prioritise the distribution of the funds across a pool of possible treatments. Thus, if the objective is to maximise the health benefits for a given budget, then treatments should be selected based on a target quantity, which summarises effectiveness, costs and the preferences of decision-makers, while also taking into account the uncertainty about our conclusions. This quantity takes the name of incremental net benefit and is given by</p>
<p><span class="math display">\[ INB = K\Delta_e - \Delta_c,\]</span></p>
<p>where <span class="math inline">\(\Delta_e\)</span> and <span class="math inline">\(\Delta_c\)</span> are the mean differences between two competing interventions in terms of some effectiveness and cost measures, while <span class="math inline">\(K\)</span> is the acceptance threshold representing the budget the decision-maker is willing to spend to obtain an increment of one unit of effectiveness (cost per unit of effectiveness gained). If we were to evaluate an hypothesis test about cost-effectiveness of treatment 2 vs treatment 1, we would then test: <span class="math inline">\(INB\leq 0\)</span> (<span class="math inline">\(H_0\)</span>) vs <span class="math inline">\(INB &gt; 0\)</span> (<span class="math inline">\(H_1\)</span>).</p>
<p>A natural test statistic for this hypothesis is:</p>
<p><span class="math display">\[ t = \frac{\sqrt{n}Kd_e-d_c}{\sqrt{K^2 s^2_e -2Ks_{ce}+s^2_c}}, \]</span></p>
<p>where <span class="math inline">\(d_e\)</span> and <span class="math inline">\(d_c\)</span> are the in-sample estimates of the corresponding population values, while <span class="math inline">\(s\)</span> are the sample standard deviations. Under the null, this test statistic has a t-student distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. However, we can see how not rejecting the null hypothesis when a new treatment has a positive but statistically insignificant mean incremental net benefit imposes unnecessary costs which can be valued in either monetary or effectiveness terms. Decisions should be based only on the mean irrespective of whether any differences in this quantity are regarded as statistically significant. This is because one of the mutually exclusive alternatives must be chosen and this decision cannot be deferred. The opportunity costs of failing to make the correct decision based on a single test statistic are symmetrical while the definition of which of the alternatives is regarded as current practice is completely irrelevant.</p>
<div id="so-how-do-you-make-the-decision-if-there-no-hypothesis-test" class="section level2">
<h2>So how do you make the decision if there no hypothesis test ?</h2>
<p>Although the ordinary rules of statistical analyses do not apply, we still need to summarise the uncertainty associated with our results based on the mean INB given that decision-making problems must take into account and quantify the impact that sampling uncertainty has on our conclusions. This is typically achieved through the use of re-sampling methods, such as bootstrapping, (frequentist approach) or Bayesian methods. The two approaches are very different from a theoretical perspective but I will not address this point to save me of few weeks of time. Here, I am most interested in what type of results we will obtain once applied these methods. Well, typically we will look at something like this:</p>
<p><img src="index_files/figure-html/cepboot-1.png" width="768" /></p>
<p>This is known as <strong>Cost-effectiveness Plane</strong> and is a graphical representation of the re-sampled (frequentist) or posterior (Bayesian) distribution of the mean effectiveness and cost differentials. The red dot at the centre of the distribution is associated with the population estimates of <span class="math inline">\(\Delta_e\)</span> and <span class="math inline">\(\Delta_c\)</span> while all the other black dots are used to quantify the uncertainty around our average estimate. I will no go into details of how these can be derived, but I will limit myself to provide the interpretation to this plot. Given the value of the acceptance threshold <span class="math inline">\(K\)</span> (assumed to depend on the preferences of the decision-makers), we can compare its value with those associated to each of the dots in the plot. Next, we follow the intuitive rule which defines the probability that treatment 2 is cost-effective compared to treatment 1 as:</p>
<p><span class="math display">\[\frac{\sum_{j=1}^JI[\hat{INB}_j&gt;0]}{J},\]</span></p>
<p>where <span class="math inline">\(\hat{INB}_j\)</span> is the estimate of the INB based on the <span class="math inline">\(j-\)</span>th re-sampled (frequentist) or posterior (Bayesian) sample, and <span class="math inline">\(I[\hat{INB}_j]\)</span> is an indicator function which takes value 1 if the <span class="math inline">\(j-\)</span>th estimate is positive and 0 otherwise. Essentially, we compute the probability of cost-effectiveness as the proportion of estimates of INB which are &gt; 0 with respect to the total number of estimates avaiable (<span class="math inline">\(J\)</span>). This can be also expressed as</p>
<p><span class="math display">\[ P(T_{n-1} &lt; \frac{\sqrt{n}Kd_e-d_c}{\sqrt{K^2 s^2_e -2Ks_{ce}+s^2_c}}),\]</span></p>
<p>where <span class="math inline">\(T_{n-1}\)</span> is the standard t-student distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. Finally, given that uncertainty with respect to the value of <span class="math inline">\(K\)</span> should also be taken into account, we will need to compute this probability for a range of values of <span class="math inline">\(K\)</span>, often based on some guidelines of the decision-makers. A very nice summary of these results is given by the following plot, known as the <strong>Cost-Effectiveness Acceptability Curve</strong>.</p>
<p><img src="index_files/figure-html/ceacplot-1.png" width="768" /></p>
<p>The graph shows the estimated probability of cost-effectiveness for a range of values of the acceptance threshold. Indeed, by varying <span class="math inline">\(K\)</span> the proportion of estimated <span class="math inline">\(INB\)</span> which are positive will change and will provide a summary of how our cost-effectiveness probability changes as we increase/decrease the “willingness to pay” of the decision-makers.</p>
<p>If we wanted to test the null hypothesis based on the INB test-statistic (which, as I tried to show before, we should not!), we would find that the equation for the probability shown before corresponds to <span class="math inline">\(1\)</span> - the classical frequentist pvalue for this test. However, this interpretation is only possible when:</p>
<ol style="list-style-type: decimal">
<li><p>We have equal sample sizes for the 2 treatments.</p></li>
<li><p>We have the willingness to compute variance estimates by matched pairs.</p></li>
</ol>
<p>In all other cases, frequentist hypothesis testing will not have a Bayesian justification, and in any event the multiple testing implied by drawing a plot of (1 – p) is hard to justify within the frequentist statistical framework.</p>
</div>
<div id="conclusions" class="section level2">
<h2>Conclusions</h2>
<p>Outputs such as the CE plane and the CEAC are what really matter to health economists, whose job is merely to provide decision-makers with this evidence for each treatment comparison under consideration for a given funding decision. Based on the estimated probability of cost-effectiveness and their preferences in terms of budget allocation, decision-makers will prioritise the allocation of resources towards certain treatments, therefore negleting those funds to other treatments. An alternative and always available option could be to retain the funds and do not allocate resources to any treatment under consideration. In this scenario, the implicit element is that decision-makers are willing to postpone the decision to the future, waiting for more evidence to be collected to reduce the risk of making an inefficient/incorrect decision based on the current evidence.</p>
<div id="refs" class="references">
<div id="ref-claxton1999irrelevance">
<p>Claxton, Karl. 1999. “The Irrelevance of Inference: A Decision-Making Approach to the Stochastic Evaluation of Health Care Technologies.” <em>Journal of Health Economics</em> 18 (3): 341–64.</p>
</div>
</div>
</div>
