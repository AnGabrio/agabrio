---
title: Inverse Probability Weighting
summary: The inverse probability weighting (IPW) approach preserves the semiparametric structure of the underlying model of substantive interest and clearly separates the model of substantive interest from the model used to account for the missing data
tags:
- Weighting Methods
- Semiparametric Methods
- Weighting Adjustments
- Inverse Probability Weighting
- Augmented Inverse Probability Weighting
date: "2016-04-27T00:00:00Z"
weight: 1

# Optional external URL for project (replaces project detail page).
external_link: ""

categories: ["rubric"]
bibliography: [ipw.bib]

reading_time: false  # Show estimated reading time?
share: false  # Show social sharing links?
profile: false  # Show author profile?
commentable: false  # Allow visitors to comment? Supported by the Page, Post, and Docs content types.
editable: true  # Allow visitors to edit the page? Supported by the Page, Post, and Docs content types.

image:
  caption: Photo by rawpixel on Unsplash
  focal_point: Smart
  preview_only: true

links:
#- icon: 
#  icon_pack: 
#  name: 
#  url: 
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""
url_poster: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: example
---

<script src="index_files/header-attrs/header-attrs.js"></script>
<link href="index_files/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="index_files/anchor-sections/anchor-sections.js"></script>


<p>In certain cases, it is possible to reduce biases from case deletion by the application of weights. After incomplete cases are removed, the remaining complete cases can be weighted so that their distribution more closely resembles that of the full sample with respect to auxiliary variables. <em>Weighting methods</em> can eliminate bias due to differential response related to the variables used to model the response probabilities, but it cannot correct for biases related to variables that are unused or unmeasured (<span class="citation">Little and Rubin (2019)</span>). <span class="citation">Robins, Rotnitzky, and Zhao (1994)</span> introduced <em>Inverse Probability Weighting</em> (IPW) as a weighted regression approach that require an explicit model for the missingness but relaxes some of the parametric assumptions in the data model. Their method is an extension of <em>Generalized Estimating Equations</em> (GEE), a popular technique for modeling marginal or populationaveraged relationships between a response variable and predictors (<span class="citation">Zeger, Liang, and Albert (1988)</span>).</p>
<p>Let <span class="math inline">\(y_i=(y_{i1},\ldots,y_{iK})\)</span> denote a vector of variables for unit <span class="math inline">\(i\)</span> subject to missing values with <span class="math inline">\(y_i\)</span> being fully observed for <span class="math inline">\(i=1\ldots,n_r\)</span> units and partially-observed for <span class="math inline">\(i=n_r+1,\ldots,n\)</span> units. Define <span class="math inline">\(m_i=1\)</span> if <span class="math inline">\(y_i\)</span> is incomplete and <span class="math inline">\(m_i=0\)</span> if complete. Let <span class="math inline">\(x_i=(x_{i1},\ldots,x_{ip})\)</span> denote a vector of fully observed covariates and suppose the interest is in estimating the mean of the distribution of <span class="math inline">\(y_i\)</span> given <span class="math inline">\(x_i\)</span>, having the form <span class="math inline">\(g(x_i,\beta)\)</span>, where <span class="math inline">\(g()\)</span> is a possibly non-linear regression function indexed by a parameter <span class="math inline">\(\beta\)</span> of dimension <span class="math inline">\(d\)</span>. Let also <span class="math inline">\(z_i=(z_{i1},\ldots,z_{iq})\)</span> be a vector of fully observed auxiliary variables that potentially predictive of missingness but are not included in the model for <span class="math inline">\(y_i \mid x_i\)</span>. When there are no missing data, a consistent estimate of <span class="math inline">\(\beta\)</span> is given by the solution to the following GEE, under mild regularity conditions (<span class="citation">Liang and Zeger (1986)</span>),</p>
<p>\[
\sum_{i=1}^n = D_i(x_i,\beta)(y_i-g(x_i,\beta))=0,
\]</p>
<p>where <span class="math inline">\(D_i(x_i,\beta)\)</span> is a suitably chosen <span class="math inline">\((d\times k)\)</span> matrix of known functions of <span class="math inline">\(x_i\)</span>. With missing data, the equation is applied only to the complete cases (<span class="math inline">\(n_{r}\)</span>), which yields consistent estimates provided that</p>
<p>\[
p(m_i=1 \mid x_i,y_i,z_i,\phi)=p(m_i=1\mid x_i,\phi),
\]</p>
<p>that is, missingness does not depend on <span class="math inline">\(y_i\)</span> or <span class="math inline">\(z_i\)</span> after conditioning on <span class="math inline">\(x_i\)</span>. IPW GEE methods (<span class="citation">Robins and Rotnitzky (1995)</span>) replace the equation with</p>
<p>\[
\sum_{i=1}^{n_r} = w_i(\hat{\alpha})D_i(x_i,\beta)(y_i-g(x_i,\beta))=0,
\]</p>
<p>where <span class="math inline">\(w_i(\hat{\alpha})=\frac{1}{p(x_i,z_i \mid \hat{\alpha})}\)</span>, with <span class="math inline">\(p(x_i,z_i \mid \hat{\alpha})\)</span> being an estimate of the probability of being a complete unit, obtained for example via logistic regressions on <span class="math inline">\(m_i\)</span> on <span class="math inline">\(x_i\)</span> and <span class="math inline">\(z_i\)</span>. If the logistic regression is correctly specified, IPW GEE yields a consistent estimator of <span class="math inline">\(\beta\)</span> provided that</p>
<p>\[
p(m_i=1 \mid x_i,y_i,z_i,\phi)=p(m_i=1\mid x_i,z_i\phi).
\]</p>
<div id="example" class="section level2">
<h2>Example</h2>
<p>Suppose the full data consists of a single outcome variable <span class="math inline">\(y\)</span> and an additional variable <span class="math inline">\(z\)</span> and that the objective is to estimate the population outcome mean <span class="math inline">\(\mu=\text{E}[y]\)</span>. If data were fully observed for <span class="math inline">\(i=1,\ldots,n\)</span> individuals, an obvious estimator of <span class="math inline">\(\mu\)</span> would be the sample outcome mean</p>
<p>\[
\bar{y}=\frac{1}{n}\sum_{i=1}^ny_i,
\]</p>
<p>which is equivalent to the solution to the estimating equation <span class="math inline">\(\sum_{i=1}^n(y_i-\mu)=0\)</span>. When <span class="math inline">\(y\)</span> is partially observed (while <span class="math inline">\(Z\)</span> is always fully observed), individuals may fall into one of two missingness patterns <span class="math inline">\(r=(r_{y},r_{z})\)</span>, namely <span class="math inline">\(r=(1,1)\)</span> if both variables are observed or <span class="math inline">\(r=(1,0)\)</span> if <span class="math inline">\(y\)</span> is missing. Let <span class="math inline">\(c=1\)</span> if <span class="math inline">\(r=(1,1)\)</span> and <span class="math inline">\(c=0\)</span> otherwise, so that the observed data can be summarised as <span class="math inline">\((c,cy,z)\)</span>. Assuming that missingness only depends on <span class="math inline">\(z\)</span>, that is</p>
<p>\[
p(c=1 \mid y,z)=p(c=1 \mid z)=\pi(z),
\]</p>
<p>then the missing data mechanism is <em>Missing At Random</em> (MAR). Under these conditions, the sample mean of the complete cases <span class="math inline">\(\bar{y}_{cc}=\frac{\sum_{i=1}^nc_iy_i}{c_i}\)</span>, i.e. the solution to the equation <span class="math inline">\(\sum_{i=1}^nc_i(y_i-\mu)=0\)</span>, is not a consistent estimator of <span class="math inline">\(\mu\)</span>. To correct for this, the IPW complete case estimating equation</p>
<p>\[
\sum_{i=1}^n\frac{c_i}{\pi(z_i)}(y_i-\mu)=0,
\]</p>
<p>can be used to weight the contribution of each complete case by the inverse of <span class="math inline">\(\pi(z_i)\)</span>. The solution of the equation corresponds to the IPW estimator</p>
<p>\[
\mu_{ipw}=\left(\sum_{i=1}^n \frac{c_i}{\pi(z_i)} \right)^{-1} \sum_{i=1}^n \frac{c_iy_i}{\pi(z_i)},
\]</p>
<p>which is unbiased under MAR and for <span class="math inline">\(\pi(z)&gt;0\)</span>. In case you want to have a look at the <a href="https://www4.stat.ncsu.edu/~davidian/st790/notes/chap5.pdf">proof</a> of this I put here the link. In most situations <span class="math inline">\(\pi(z_i)\)</span> is not known and must be estimated from the data, typically posing some model for <span class="math inline">\(p(c=1 \mid z, \hat{\alpha})\)</span>, indexed by some parameter <span class="math inline">\(\hat{\alpha}\)</span>, for example a logistic regression</p>
<p>\[
\text{logit}(\pi)=\alpha_0 + \alpha_1z.
\]</p>
<p>Of course, if the model for <span class="math inline">\(\pi(z)\)</span> is misspecified, <span class="math inline">\(\mu_{ipw}\)</span> can be an inconsistent estimator. In addition, IPW methods typically used data only from the completers discarding all the partially observed values, which is clearly inefficient.</p>
</div>
<div id="conclusions" class="section level2">
<h2>Conclusions</h2>
<p>Thus, IPW estimators can correct for the bias of unweighted estimators due to the dependence of the missingness mechanism on <span class="math inline">\(z_i\)</span> (<span class="citation">Schafer and Graham (2002)</span>). The basic intuition of IPW methods is that each subject’s contribution to the weighted <em>Complete Case Analysis</em> (CCA) is replicated <span class="math inline">\(w_i\)</span> times in order to account once for herself and <span class="math inline">\((1-w_i)\)</span> times for those subjects with the same responses and covariates who are missing. These models are called <em>semiparametric</em> because they apart from requiring the regression equation to have a specific form, they do not specify any probability distribution for the response variable (<span class="citation">Molenberghs et al. (2014)</span>). Older GEE methods can accommodate missing values only if they are <em>Missing Completely At Random</em> (MCAR), while more recent methods allow them to be MAR or even <em>Missing Not At Random</em> (MNAR), provided that a model for the missingness is correctly specified (<span class="citation">Robins, Rotnitzky, and Zhao (1995)</span>,<span class="citation">Rotnitzky, Robins, and Scharfstein (1998)</span>).</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-liang1986longitudinal" class="csl-entry">
Liang, Kung-Yee, and Scott L Zeger. 1986. <span>“Longitudinal Data Analysis Using Generalized Linear Models.”</span> <em>Biometrika</em> 73 (1): 13–22.
</div>
<div id="ref-little2019statistical" class="csl-entry">
Little, Roderick JA, and Donald B Rubin. 2019. <em>Statistical Analysis with Missing Data</em>. Vol. 793. John Wiley &amp; Sons.
</div>
<div id="ref-molenberghs2014handbook" class="csl-entry">
Molenberghs, Geert, Garrett Fitzmaurice, Michael G Kenward, Anastasios Tsiatis, and Geert Verbeke. 2014. <em>Handbook of Missing Data Methodology</em>. Chapman; Hall/CRC.
</div>
<div id="ref-robins1995semiparametric" class="csl-entry">
Robins, James M, and Andrea Rotnitzky. 1995. <span>“Semiparametric Efficiency in Multivariate Regression Models with Missing Data.”</span> <em>Journal of the American Statistical Association</em> 90 (429): 122–29.
</div>
<div id="ref-robins1994estimation" class="csl-entry">
Robins, James M, Andrea Rotnitzky, and Lue Ping Zhao. 1994. <span>“Estimation of Regression Coefficients When Some Regressors Are Not Always Observed.”</span> <em>Journal of the American Statistical Association</em> 89 (427): 846–66.
</div>
<div id="ref-robins1995analysis" class="csl-entry">
———. 1995. <span>“Analysis of Semiparametric Regression Models for Repeated Outcomes in the Presence of Missing Data.”</span> <em>Journal of the American Statistical Association</em> 90 (429): 106–21.
</div>
<div id="ref-rotnitzky1998semiparametric" class="csl-entry">
Rotnitzky, Andrea, James M Robins, and Daniel O Scharfstein. 1998. <span>“Semiparametric Regression for Repeated Outcomes with Nonignorable Nonresponse.”</span> <em>Journal of the American Statistical Association</em> 93 (444): 1321–39.
</div>
<div id="ref-schafer2002missing" class="csl-entry">
Schafer, Joseph L, and John W Graham. 2002. <span>“Missing Data: Our View of the State of the Art.”</span> <em>Psychological Methods</em> 7 (2): 147.
</div>
<div id="ref-zeger1988models" class="csl-entry">
Zeger, Scott L, Kung-Yee Liang, and Paul S Albert. 1988. <span>“Models for Longitudinal Data: A Generalized Estimating Equation Approach.”</span> <em>Biometrics</em>, 1049–60.
</div>
</div>
</div>
